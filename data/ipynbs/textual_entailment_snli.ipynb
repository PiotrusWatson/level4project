{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4NbGwIC9-z",
        "colab_type": "text"
      },
      "source": [
        "##HAHA ITS TIME TO SPEND 5 HOURS DOWNLOADING THINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "918a8dc8-8a6d-4a0e-a0e2-f0c511571d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-10 14:23:11--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  25.3MB/s    in 3.6s    \n",
            "\n",
            "2020-03-10 14:23:19 (25.3 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "a7b5f2af-a08d-4f33-8c46-2d6499136df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-10 14:23:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-10 14:23:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-10 14:23:27--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.06MB/s    in 6m 28s  \n",
            "\n",
            "2020-03-10 14:29:55 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "8dc631dd-4837-44c6-8cf1-ce79ddaceddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-10 14:30:20--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  5.46MB/s    in 0.9s    \n",
            "\n",
            "2020-03-10 14:30:22 (5.46 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "2713bae4-d8dc-4edb-aa7d-abe36aebe568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "outputId": "eb9e44ad-966b-4ddb-dfec-e28af650719f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1-baseline.git\n",
        "import sys\n",
        "sys.path.insert(1, 'fnc-1-baseline/utils')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1-baseline'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "Receiving objects:   0% (1/121)   \rReceiving objects:   1% (2/121)   \rReceiving objects:   2% (3/121)   \rReceiving objects:   3% (4/121)   \rReceiving objects:   4% (5/121)   \rReceiving objects:   5% (7/121)   \rReceiving objects:   6% (8/121)   \rReceiving objects:   7% (9/121)   \rReceiving objects:   8% (10/121)   \rReceiving objects:   9% (11/121)   \rReceiving objects:  10% (13/121)   \rReceiving objects:  11% (14/121)   \rReceiving objects:  12% (15/121)   \rReceiving objects:  13% (16/121)   \rReceiving objects:  14% (17/121)   \rReceiving objects:  15% (19/121)   \rReceiving objects:  16% (20/121)   \rReceiving objects:  17% (21/121)   \rReceiving objects:  18% (22/121)   \rReceiving objects:  19% (23/121)   \rReceiving objects:  20% (25/121)   \rReceiving objects:  21% (26/121)   \rReceiving objects:  22% (27/121)   \rReceiving objects:  23% (28/121)   \rReceiving objects:  24% (30/121)   \rReceiving objects:  25% (31/121)   \rReceiving objects:  26% (32/121)   \rReceiving objects:  27% (33/121)   \rReceiving objects:  28% (34/121)   \rReceiving objects:  29% (36/121)   \rReceiving objects:  30% (37/121)   \rReceiving objects:  31% (38/121)   \rReceiving objects:  32% (39/121)   \rReceiving objects:  33% (40/121)   \rReceiving objects:  34% (42/121)   \rReceiving objects:  35% (43/121)   \rReceiving objects:  36% (44/121)   \rReceiving objects:  37% (45/121)   \rReceiving objects:  38% (46/121)   \rReceiving objects:  39% (48/121)   \rReceiving objects:  40% (49/121)   \rReceiving objects:  41% (50/121)   \rReceiving objects:  42% (51/121)   \rremote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121\u001b[K\n",
            "Receiving objects:  43% (53/121)   \rReceiving objects:  44% (54/121)   \rReceiving objects:  45% (55/121)   \rReceiving objects:  46% (56/121)   \rReceiving objects:  47% (57/121)   \rReceiving objects:  48% (59/121)   \rReceiving objects:  49% (60/121)   \rReceiving objects:  50% (61/121)   \rReceiving objects:  51% (62/121)   \rReceiving objects:  52% (63/121)   \rReceiving objects:  53% (65/121)   \rReceiving objects:  54% (66/121)   \rReceiving objects:  55% (67/121)   \rReceiving objects:  56% (68/121)   \rReceiving objects:  57% (69/121)   \rReceiving objects:  58% (71/121)   \rReceiving objects:  59% (72/121)   \rReceiving objects:  60% (73/121)   \rReceiving objects:  61% (74/121)   \rReceiving objects:  62% (76/121)   \rReceiving objects:  63% (77/121)   \rReceiving objects:  64% (78/121)   \rReceiving objects:  65% (79/121)   \rReceiving objects:  66% (80/121)   \rReceiving objects:  67% (82/121)   \rReceiving objects:  68% (83/121)   \rReceiving objects:  69% (84/121)   \rReceiving objects:  70% (85/121)   \rReceiving objects:  71% (86/121)   \rReceiving objects:  72% (88/121)   \rReceiving objects:  73% (89/121)   \rReceiving objects:  74% (90/121)   \rReceiving objects:  75% (91/121)   \rReceiving objects:  76% (92/121)   \rReceiving objects:  77% (94/121)   \rReceiving objects:  78% (95/121)   \rReceiving objects:  79% (96/121)   \rReceiving objects:  80% (97/121)   \rReceiving objects:  81% (99/121)   \rReceiving objects:  82% (100/121)   \rReceiving objects:  83% (101/121)   \rReceiving objects:  84% (102/121)   \rReceiving objects:  85% (103/121)   \rReceiving objects:  86% (105/121)   \rReceiving objects:  87% (106/121)   \rReceiving objects:  88% (107/121)   \rReceiving objects:  89% (108/121)   \rReceiving objects:  90% (109/121)   \rReceiving objects:  91% (111/121)   \rReceiving objects:  92% (112/121)   \rReceiving objects:  93% (113/121)   \rReceiving objects:  94% (114/121)   \rReceiving objects:  95% (115/121)   \rReceiving objects:  96% (117/121)   \rReceiving objects:  97% (118/121)   \rReceiving objects:  98% (119/121)   \rReceiving objects:  99% (120/121)   \rReceiving objects: 100% (121/121)   \rReceiving objects: 100% (121/121), 23.99 KiB | 8.00 MiB/s, done.\n",
            "Resolving deltas:   0% (0/63)   \rResolving deltas:   3% (2/63)   \rResolving deltas:   4% (3/63)   \rResolving deltas:  11% (7/63)   \rResolving deltas:  12% (8/63)   \rResolving deltas:  25% (16/63)   \rResolving deltas:  30% (19/63)   \rResolving deltas:  41% (26/63)   \rResolving deltas:  46% (29/63)   \rResolving deltas:  50% (32/63)   \rResolving deltas:  55% (35/63)   \rResolving deltas:  63% (40/63)   \rResolving deltas:  68% (43/63)   \rResolving deltas: 100% (63/63)   \rResolving deltas: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "e240b4ef-1f74-4c9d-a326-b526d949ae55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-10 14:30:34--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  6.07MB/s    in 0.9s    \n",
            "\n",
            "2020-03-10 14:30:35 (6.07 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "outputId": "e5206366-6098-40cf-a6e2-59a48db1c254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pwd\n",
        "from score import report_score"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJXKPPODFqp",
        "colab_type": "text"
      },
      "source": [
        "##LOOK AT ALL THIS CODE TO IMPORT DATA GOD THERE MUST BE SOMETHING WRONG WITH ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "outputId": "7d8faaee-b1c9-4b14-a8c9-33195799944b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "6c13e8a5-ac8e-4173-d405-a42b1ad1073c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "bc79f8d1-1e80-4359-c7d4-dec17d0baeae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "\n",
        "def split_test(facts):\n",
        "   unique = facts.drop_duplicates(\"claim_text\")\n",
        "   train_unique, val_unique = train_test_split(unique, test_size=0.1, random_state=8)\n",
        "   val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "   train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "   return train_facts, val_facts\n",
        "\n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/competition_test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/competition_test_stances.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "train_challenge, val_challenge = train_test_split(train_challenge, test_size=0.2, random_state=8)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "\n",
        "train_challenge = train_challenge.rename(columns={\"articleBody\": \"article\", \"Headline\": \"claim_text\", \"Stance\": \"cred_label\"})\n",
        "test_challenge = test_challenge.rename(columns={\"articleBody\": \"article\", \"Headline\": \"claim_text\", \"Stance\": \"cred_label\"})\n",
        "print(train_challenge.head())\n",
        "train_challenge, val_challenge = split_test(train_challenge)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Body ID  ... cred_label\n",
            "11142      686  ...          2\n",
            "4398       251  ...          2\n",
            "30345     1689  ...          2\n",
            "41235     2154  ...          1\n",
            "33237     1829  ...          2\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "challenge_mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None, is_folding=False):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_text\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  \n",
        "  if is_folding:\n",
        "    results = []\n",
        "    folded = KFold(n_splits=10, shuffle=True)\n",
        "    splitted_object = folded.split(unique)\n",
        "    for train_result, test_result in splitted_object:\n",
        "      train_ilocs = unique.iloc[train_result][\"claim_text\"]\n",
        "      test_ilocs = unique.iloc[test_result][\"claim_text\"]\n",
        "      results.append((facts[facts[\"claim_text\"].isin(train_ilocs)], facts[facts[\"claim_text\"].isin(test_ilocs)]))\n",
        "\n",
        "    return results\n",
        "\n",
        "  train_unique, big_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "  val_unique, test_unique = train_test_split(big_unique, test_size=0.5, random_state=8)\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_text\"].isin(test_unique[\"claim_text\"])]\n",
        "  val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "  train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "  return train_facts, test_facts, val_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts, val_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes, val_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "b43f3b8e-2dd3-4013-d1d3-6535c774de47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>vice news we dont have a timeline on the decis...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>a schedule i narcotic along with heroin and ec...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>now do you think you were maybe talking just a...</td>\n",
              "      <td>cnn.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>made to the new yorker that marijuana is no mo...</td>\n",
              "      <td>time.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jun_27_donald-trump_white-house-criticism...</td>\n",
              "      <td>obamacare signed law cbo estimated 23 million ...</td>\n",
              "      <td>donald trump</td>\n",
              "      <td>about the affordable health care act in its da...</td>\n",
              "      <td>eugeneweekly.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4849</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama to ban guns from 42 million social secur...</td>\n",
              "      <td>bearingarms.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4850</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama is looking to ban social security recipi...</td>\n",
              "      <td>rightwingnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>main navigation recent posts obama to ban 42 m...</td>\n",
              "      <td>downtrend.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>get news like this in your facebook news feed ...</td>\n",
              "      <td>thegatewaypundit.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>to prove everyone wrong yet again this time it...</td>\n",
              "      <td>zerohedge.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...        article_source\n",
              "187            1  ...            reason.com\n",
              "188            1  ...            reason.com\n",
              "189            1  ...               cnn.com\n",
              "190            1  ...              time.com\n",
              "526            1  ...      eugeneweekly.com\n",
              "...          ...  ...                   ...\n",
              "4849           0  ...       bearingarms.com\n",
              "4850           0  ...     rightwingnews.com\n",
              "4851           0  ...         downtrend.com\n",
              "4852           0  ...  thegatewaypundit.com\n",
              "4853           0  ...         zerohedge.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Beq65oTgcBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, train_loader, test_loader, val_loader, test_data, val_data, tokeniser, batch_size):\n",
        "    self.train_loader = train_loader\n",
        "    self.test_loader = test_loader\n",
        "    self.val_loader = val_loader\n",
        "    self.test_data = test_data\n",
        "    self.val_data = val_data\n",
        "    self.batch_size = batch_size\n",
        "    self.word_embeddings_small = load_glove_embeddings(\"glove.6B.50d.txt\", tokeniser.word_to_id, 50) \n",
        "    self.word_embeddings_large = load_glove_embeddings(\"glove.6B.300d.txt\", tokeniser.word_to_id, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts4lYd83j-c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"claim_text\", \"article\"]\n",
        "big_labels = [\"claim_text\", \"article\", \"article_source\"]\n",
        "\n",
        "def get_list(panda, labels):\n",
        "  label_to_data = {}\n",
        "  for label in labels:\n",
        "    label_to_data[label] = panda[label]\n",
        "\n",
        "  x_list = convert_to_lists(label_to_data)\n",
        "  if labels[0] == \"claim_text\":\n",
        "    y_list = panda[\"cred_label\"].tolist()\n",
        "  else:\n",
        "    y_list = panda[\"Stance\"].tolist()\n",
        "  return x_list, y_list\n",
        "\n",
        "def get_loader(x, y, vocab_size, max_length, batch_size, name, training=True, drop_last=True):\n",
        "  stuff = []\n",
        "  for key in x:\n",
        "    stuff.append(torch.from_numpy(x[key]).type(torch.LongTensor))\n",
        "  stuff.append(torch.from_numpy(y).type(torch.DoubleTensor))\n",
        "  tensorset = data_utils.TensorDataset(*stuff)\n",
        "  loader = data_utils.DataLoader(tensorset, batch_size=batch_size, drop_last=drop_last, shuffle=training)\n",
        "  loader.name = name\n",
        "\n",
        "  return loader\n",
        "\n",
        "  \n",
        "def get_dataset(train, test, val, vocab_size, max_length, batch_size, labels, name):\n",
        "  is_challenge = labels[0] == \"articleBody\"\n",
        "  train_list_x, train_list_y = get_list(train, labels)\n",
        "\n",
        "  test_list_x, test_list_y = get_list(test, labels)\n",
        "  val_list_x, val_list_y = get_list(val, labels)\n",
        "\n",
        "\n",
        "\n",
        "  #tokenising various stuff, setting up numpy dictionaries :)\n",
        "  tokeniser = Tokeniser(train_list_x, vocab_size, max_length)\n",
        "  x_train = tokeniser.do_everything(train_list_x)\n",
        "  x_test = tokeniser.do_everything(test_list_x)\n",
        "  x_val = tokeniser.do_everything(val_list_x)\n",
        "  y_train = np.array(train_list_y, dtype=np.float32)\n",
        "  y_test = np.array(test_list_y, dtype=np.float32)\n",
        "  y_val = np.array(val_list_y, dtype=np.float32)\n",
        "  \n",
        "  #datasets/loaders\n",
        "  train_loader = get_loader(x_train, y_train, vocab_size, max_length, batch_size, name, True)\n",
        "  test_loader = get_loader(x_test, y_test, vocab_size, max_length, batch_size, name, False, drop_last=False)\n",
        "  val_loader = get_loader(x_val, y_val, vocab_size, max_length, batch_size, name, False)\n",
        "  return Dataset(train_loader, test_loader, val_loader, y_test, y_val, tokeniser, batch_size)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MMrKlu6_jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "outputId": "ffe3640c-0918-4ab4-ab44-9bf706d8cb84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 100\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "\n",
        "snopes_dataset = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "fact_dataset = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "challenge_dataset = get_dataset(train_challenge, test_challenge, val_challenge, VOCAB_SIZE, MAX_LENGTH, 500, labels, \"challenge_data\")\n",
        "big_snopes = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "big_fact = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39258\n",
            "39258\n",
            "33766\n",
            "33766\n",
            "27708\n",
            "27708\n",
            "44868\n",
            "44868\n",
            "37174\n",
            "37174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "outputId": "32e38d2f-c361-44d2-a577-826882160b19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx_train = x_tokeniser.do_everything(x_train_lists)\\nx_test = x_tokeniser.do_everything(x_test_lists)\\ny_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\\ny_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "outputId": "2547080c-b35f-48a3-a0ba-753f4746db75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "\"\"\""
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we_shufflin = True\\nshufflin_test = False\\n#alright lets tensordataset textual entailment stuff\\ntrain_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\\ntrain_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\\ntrain_loader.name = \"entailment_data\"\\n\\ntest_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\\ntest_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\\ntest_loader.name = \"entailment_data\"\\n\\n\\n#POLITIFACT/SNOPES W/ SOURCES\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smeSRlk30Ccq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTdDpyN44DQa",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL ENTAILMENT MODEL CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    \n",
        "    self.embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.normaliser = torch.nn.BatchNorm1d(self.embedding_size)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x[:, 0:self.hp.max_length])\n",
        "    #embedding = self.normaliser(embedding.transpose(1,2))\n",
        "    embedding = self.dropout(embedding)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    tanh_W_H = self.dropout(tanh_W_H)\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.premise_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "    self.hp = hp\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    premise_factor = self.premise_dropout(premise_factor)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    hypothesis_factor = self.hypothesis_dropout(hypothesis_factor)\n",
        "    if self.hp.use_better:\n",
        "      return better_mush(premise_factor,hypothesis_factor)\n",
        "    else:\n",
        "      return premise_factor * hypothesis_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=hp.mlp_one)\n",
        "    self.linear2 = torch.nn.Linear(hp.mlp_one, hp.mlp_two)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(hp.mlp_two, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "      x = self.dropout1(x)\n",
        "    else:\n",
        "      x = torch.relu(self.linear1(x.reshape(self.hp.batch_size, -1)))\n",
        "      x = self.dropout1(x)\n",
        "      x = torch.relu(self.linear2(x))\n",
        "      x = self.dropout2(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    print(word_embeddings.shape)\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout)]\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    self.dropouts[1](premise_embedding)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    self.dropouts[3](hypothesis_embedding)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    self.dropouts[4](factorised_mush)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention*premise_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpWRHhOxCjFl",
        "colab_type": "text"
      },
      "source": [
        "##EVAL SUMMARY :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUhazL34GWZ",
        "colab_type": "text"
      },
      "source": [
        "##SHEENABASELINE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_UvQQWx4IcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout)]*5\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    processed_premise = self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    premise_embedding = self.dropouts[1](premise_embedding)\n",
        "    \n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    processed_hypothesis = self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    hypothesis_embedding = self.dropouts[3](hypothesis_embedding)\n",
        "    if self.hp.use_better:\n",
        "      combined = better_mush(premise_embedding, hypothesis_embedding)\n",
        "    else:\n",
        "      combined = premise_embedding * hypothesis_embedding\n",
        "    \n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    avg = self.dropouts[4](avg)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      output = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      output = torch.sigmoid(self.final_linear(x))\n",
        "    return output, hypothesis_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWRCDtWR4Lcq",
        "colab_type": "text"
      },
      "source": [
        "##BAD DECLARE CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMmJP6kC4Th3",
        "colab_type": "text"
      },
      "source": [
        "## GOOD DECLARE CODE???\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRhCjK84VeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(RealDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(10000, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(100, 8)\n",
        "    self.linear_almost_there = torch.nn.Linear(8, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.dropout0 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    lengths = self.hp.max_length - (premise == 0).sum(dim=1)\n",
        "    lengths = lengths.repeat(50, 1).transpose(0,1)\n",
        "    summed_embeddings = torch.sum(embeddings, 1)\n",
        "    mean_embeddings = torch.unsqueeze(summed_embeddings / lengths, 1) #change to accurate size of lenfgth\n",
        "    flattened_embeddings = mean_embeddings.reshape(self.hp.batch_size, -1)\n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100]).reshape(self.hp.batch_size, -1)\n",
        "    #TODO: use repeat function to get 100*100 #DONE!\n",
        "    main_embeddings = torch.cat((flattened_embeddings.repeat(1, 100), added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    attention_weights = softmax(torch.tanh(self.premise_linear(main_embeddings)))#TODO: turn into row vector\n",
        "\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis, attention_weights.unsqueeze(2))\n",
        "    \n",
        "\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    new_lengths = lengths.repeat(1, 2)\n",
        "\n",
        "    avg = torch.sum(combined, 1)/new_lengths #todo: fix padding\n",
        "    avg = self.dropout0(avg)\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    smaller = self.dropout1(smaller)\n",
        "    even_smaller = F.relu(self.linear_almost_there(smaller))\n",
        "    even_smaller = self.dropout2(even_smaller)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      output = softmax(self.linear_final(even_smaller))\n",
        "    else:\n",
        "      output = torch.sigmoid(self.linear_final(even_smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "##TRAIN/TEST/HELPERS\n",
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# given the losses, checks if it should stop (or not :))\n",
        "# this performs early stopping -\n",
        "def should_stop(losses, train_losses, limit, threshold=-0.01):\n",
        "  shouldnt_stop = False \n",
        "  is_learning = False\n",
        "  #print(\"losses:\",losses)\n",
        "  #print(\"train_losses:\", train_losses)\n",
        "  \n",
        "  if len(losses) < limit:\n",
        "    return False \n",
        "  \n",
        "  last = losses[-1]\n",
        "  last_train = train_losses[-1]\n",
        "\n",
        "  if limit == 2:\n",
        "    #print(\"Threshold: {}, result {}\".format(threshold, last-losses[-2]))\n",
        "    return last - losses[-2] >= threshold\n",
        "  \n",
        "  for i in range(-2,- limit-1,-1):\n",
        "    shouldnt_stop = (shouldnt_stop or last - losses[i] < threshold)\n",
        "    last = losses[i]\n",
        "  return not shouldnt_stop\n",
        "def get_l2(model, filters):\n",
        "  reg_loss = None\n",
        "  for param in model.parameters():\n",
        "    if param.shape[0] in filters:\n",
        "      if reg_loss is None:\n",
        "        reg_loss = torch.sum(param**2)\n",
        "      else:\n",
        "        reg_loss = reg_loss + param.norm(2)**2\n",
        "  return reg_loss\n",
        "\n",
        "def train(model=None, \n",
        "          dataset = None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(dataset.train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "  old_models = []\n",
        "  \n",
        "  \n",
        "  is_binary = hp.num_classes == 1\n",
        "  is_validating = False\n",
        "  has_stopped = False\n",
        "  has_reset = False\n",
        "  has_decreased = False\n",
        "\n",
        "  if is_binary:\n",
        "    loss_function=torch.nn.BCELoss()\n",
        "  else:\n",
        "    loss_function=torch.nn.CrossEntropyLoss(hp.weights)\n",
        "  \n",
        "  if dataset.train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif dataset.train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  elif dataset.train_loader.name == \"challenge_data\" and hp.num_classes != 4:\n",
        "      raise ValueError(\"Four classes are needed for challenge fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  \n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    val_results = []\n",
        "    old_models.append(model.state_dict())\n",
        "    for i in range(2):\n",
        "      \n",
        "      total_loss = 0\n",
        "      batch_count = 0\n",
        "      correct = 0\n",
        "      penal = 0\n",
        "      l2 = 0\n",
        "\n",
        "      if is_validating:\n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.val_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 1\n",
        "      elif has_stopped:\n",
        "        \n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.train_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 10\n",
        "      else:\n",
        "        model.train(True)\n",
        "        #print(\"im trainin friends!!\")\n",
        "        loader = dataset.train_loader\n",
        "        torch.enable_grad()\n",
        "        debug_amount = 10\n",
        "      \n",
        "      for batch_index, train_data in enumerate(loader):\n",
        "      #setting everything up\n",
        "        model.hidden_state = model.reset_for_testing(train_data[0].shape[0])\n",
        "        train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "        predicted_y, attention = model(*train_data[:-1])\n",
        "        actual_y = train_data[-1]\n",
        "        squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "        if hp.C > 0:\n",
        "          attentionT = attention.transpose(1,2)\n",
        "          identity = torch.eye(attention.size(1))\n",
        "          identity = Variable(identity.unsqueeze(0).expand(loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "          penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "        if hp.decay > 0:\n",
        "          l2 = get_l2(model, hp.filters)\n",
        "\n",
        "      #get loss, accuracy\n",
        "        if is_binary:\n",
        "          loss = loss_function(squeezed_y, actual_y.double())\n",
        "          loss += hp.C * penal/loader.batch_size + hp.decay * l2\n",
        "          correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "          if is_validating:\n",
        "            val_results.append(torch.round(squeezed_y))\n",
        "          \n",
        "        else:\n",
        "          loss = loss_function(squeezed_y,actual_y.long())\n",
        "          loss += hp.C * (penal/loader.batch_size) + hp.decay * l2\n",
        "          correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "          if is_validating:\n",
        "            val_results.append(torch.argmax(squeezed_y, 1))\n",
        "        total_loss += loss.data\n",
        "\n",
        "        if using_gradient_clipping:\n",
        "          torch.nn.utils.clip_grad_norm(model.parameters(), hp.grad_clip_amount)\n",
        "      \n",
        "      #cleaning up regularisation\n",
        "        if hp.C > 0:\n",
        "          del(penal)\n",
        "          del(identity)\n",
        "          del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "        optimiser.zero_grad()\n",
        "        if not is_validating and not has_stopped:\n",
        "          loss.backward()\n",
        "          optimiser.step()\n",
        "        if hp.is_debug and batch_index % debug_amount == 0:\n",
        "          print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, ISvAL: {}, HasStopped: {}\".format(\n",
        "              epoch, batch_index * len(train_data[0]), len(loader.dataset),\n",
        "              100. * batch_index / len(loader), loss.item(), is_validating, has_stopped\n",
        "          ))\n",
        "\n",
        "        \n",
        "        batch_count += 1\n",
        "      \n",
        "        free_data(train_data)\n",
        "      \n",
        "      correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "      accuracy = correct_but_numpy / float(batch_count * loader.batch_size)\n",
        "\n",
        "      if (not is_validating):\n",
        "        losses.append(total_loss/batch_count)\n",
        "        accuracies.append(accuracy)\n",
        "      else:\n",
        "        val_losses.append(total_loss/batch_count)\n",
        "        val_accuracies.append(accuracy)\n",
        "      \n",
        "      if not has_decreased:\n",
        "        has_decreased = not (should_stop(val_losses, losses, 2, hp.early_threshold)) and len(val_losses) > 1\n",
        "      if hp.use_early_stopping and is_validating:\n",
        "        has_stopped = should_stop(val_losses,losses, hp.early_stopping, hp.early_threshold) and has_decreased\n",
        "        if has_stopped and not has_reset:\n",
        "          print(\"resetting model HERE\")\n",
        "          model.load_state_dict(old_models[-1])\n",
        "          model.eval()\n",
        "          losses[-1] = losses[-2]\n",
        "          val_losses[-1] = val_losses[-2]\n",
        "          has_reset = True\n",
        "          \n",
        "      print(\"Average loss is:\",total_loss/batch_count, \"while validation_status:\", is_validating, \"and stopping_status\", has_stopped)\n",
        "      print(\"Accuracy of the model\", accuracy)\n",
        "      print(\"batch count???\", batch_count)\n",
        "\n",
        "\n",
        "\n",
        "      is_validating = not is_validating\n",
        "  return losses, val_losses, accuracies, val_accuracies, torch.cat(val_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, val_losses, accuracies, val_accuracies, title=\"sup nerds\"):\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "  \n",
        "  ax1.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Train Accuracy\")\n",
        "  ax1.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax1.plot(range(1, epochs+1), val_accuracies, scalex=True, scaley=True, label=\"Val Accuracy\")\n",
        "  ax1.annotate(str(val_accuracies[-1]), xy=(epochs,val_accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  ax2.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Train Loss\")\n",
        "  ax2.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax2.plot(range(1, epochs+1), val_losses,scalex=True, scaley=True, label=\"Val Loss\")\n",
        "  ax2.annotate(str(val_losses[-1]), xy=(epochs,val_losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax1.legend()\n",
        "  ax2.legend()\n",
        "\n",
        "  ax1.set_xlabel(\"Epochs\", fontsize=16)\n",
        "  ax1.set_ylabel(\"Accuracy\", fontsize=16)\n",
        "  ax2.set_xlabel(\"Epochs\", fontsize=16)\n",
        "  ax2.set_ylabel(\"Loss\", fontsize=16)\n",
        "  plt.title(title)\n",
        "  fig.tight_layout()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwADakVSwJat",
        "colab_type": "text"
      },
      "source": [
        "NEW FUNCTIONS TO AUTOMATE THE RUNNING OF LOTS OF DATASETS/MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2DLo4OoUO4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels, is_binary):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (is_binary):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc_full))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmSdvMewHrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model, dataset, hp, is_plot=True):\n",
        "  runnable_model = model(hp, dataset.word_embeddings_small).cuda()\n",
        "  if hp.num_classes == 1:\n",
        "    optimiser = torch.optim.Adam(runnable_model.parameters(), lr=hp.lr)\n",
        "  else:\n",
        "    optimiser = torch.optim.Adagrad(runnable_model.parameters(), lr=hp.lr)\n",
        "  losses, val_losses, accuracies, val_accuracies, val_results = train(model=runnable_model,\n",
        "                       dataset = dataset,\n",
        "                       optimiser = optimiser,\n",
        "                       hp = hp,\n",
        "                       using_gradient_clipping=hp.grad_clip)\n",
        "  if is_plot:\n",
        "    plot_stuff(hp.epochs, losses,val_losses, accuracies, val_accuracies)\n",
        "  torch.cuda.empty_cache()\n",
        "  evaluation_summary(\"VALIDATION\", val_results.cpu().detach() ,dataset.val_data[:len(val_results)], hp.num_classes==1)\n",
        "  check_loader = dataset.test_loader\n",
        "\n",
        "  predicted_ys = batch_wise_evaluate(runnable_model, \n",
        "         check_loader,\n",
        "         hp)\n",
        "\n",
        "  return predicted_ys, runnable_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_results(model_name, dataset_name, predictions, true_labels):\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(predictions.shape) == 1):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  return {\"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc_full}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oMDNooNrMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_to_dict(results):\n",
        "  big_results = {\"model_name\": [],\n",
        "                 \"dataset_name\": [],\n",
        "                \"precision\": [],\n",
        "                 \"recall\": [],\n",
        "                 \"accuracy\": [],\n",
        "                 \"f1\": [],\n",
        "                 \"auc\": []}\n",
        "  for result in results:\n",
        "    for key in result:\n",
        "      big_results[key].append(result[key])\n",
        "\n",
        "  return pd.DataFrame.from_dict(big_results)\n",
        "\n",
        "def process_results(big_results):\n",
        "  return (big_results[\"model_name\"][0], big_results[\"dataset_name\"][0], big_results.mean(), big_results.std())\n",
        "  \n",
        "  \n",
        "def get_avgs(some_results):\n",
        "  avg_results = {\"model_name\": some_results[0][\"model_name\"],\n",
        "                 \"dataset_name\": some_results[0][\"dataset_name\"],\n",
        "                \"precision\": 0.0,\n",
        "                 \"recall\": 0.0,\n",
        "                 \"accuracy\": 0.0,\n",
        "                 \"f1\": 0.0,\n",
        "                 \"auc\": 0.0}\n",
        "  for result in some_results:\n",
        "    for key in result:\n",
        "      if type(result[key]) is float:\n",
        "        avg_results[key] += result[key]\n",
        "  \n",
        "  for key in avg_results:\n",
        "    if(type(avg_results[key] is float)):\n",
        "      avg_results[key] /= len(some_results)\n",
        "  \n",
        "  return avg_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "##RUNNING THE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datasets = {\n",
        "    \"politifact\": fact_dataset,\n",
        "    \"snopes\": snopes_dataset,\n",
        "    \"challenge\": challenge_dataset\n",
        "}\n",
        "models = {\n",
        "    \"my_model\": TextualEntailmentModel,\n",
        "    \"my_model_better\": TextualEntailmentModel,\n",
        "    \"sheena_model\": BaselineSentenceEntailment,\n",
        "    \"sheena_model_better\": BaselineSentenceEntailment,\n",
        "    \"real_declare\": RealDeclare\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N1ykUhFf7BCH",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"snopes\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 60\n",
        "  mlp_two = 10\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 13\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.6\n",
        "  C = 1\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00004\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 0.5\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.00005\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3DuwQLD_iln",
        "colab_type": "code",
        "outputId": "c35a82c9-52e8-4842-c988-90577fa80fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters_snopes)"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([39258, 50])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:135: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss is: tensor(3.8571, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.4904918032786885\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8515, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5576923076923077\n",
            "batch count??? 13\n",
            "Running EPOCH: 2\n",
            "Average loss is: tensor(3.8570, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.4904918032786885\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8518, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5576923076923077\n",
            "batch count??? 13\n",
            "Running EPOCH: 3\n",
            "Average loss is: tensor(3.8567, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.4902459016393443\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8522, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5576923076923077\n",
            "batch count??? 13\n",
            "Running EPOCH: 4\n",
            "Average loss is: tensor(3.8562, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.4926229508196721\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8542, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5553846153846154\n",
            "batch count??? 13\n",
            "Running EPOCH: 5\n",
            "Average loss is: tensor(3.8545, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5113934426229508\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8579, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.4423076923076923\n",
            "batch count??? 13\n",
            "Running EPOCH: 6\n",
            "Average loss is: tensor(3.8531, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5259016393442623\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8578, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.4423076923076923\n",
            "batch count??? 13\n",
            "Running EPOCH: 7\n",
            "Average loss is: tensor(3.8495, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.5294262295081967\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8567, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.44384615384615383\n",
            "batch count??? 13\n",
            "Running EPOCH: 8\n",
            "Average loss is: tensor(3.8355, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.5507377049180328\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8442, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.5046153846153846\n",
            "batch count??? 13\n",
            "Running EPOCH: 9\n",
            "Average loss is: tensor(3.8093, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6348360655737705\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8406, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.5692307692307692\n",
            "batch count??? 13\n",
            "Running EPOCH: 10\n",
            "Average loss is: tensor(3.7872, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6818852459016393\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8386, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6184615384615385\n",
            "batch count??? 13\n",
            "Running EPOCH: 11\n",
            "Average loss is: tensor(3.7678, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.710327868852459\n",
            "batch count??? 122\n",
            "resetting model HERE\n",
            "Average loss is: tensor(3.8423, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6046153846153847\n",
            "batch count??? 13\n",
            "Running EPOCH: 12\n",
            "Average loss is: tensor(3.7431, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.7263114754098361\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8423, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6046153846153847\n",
            "batch count??? 13\n",
            "Running EPOCH: 13\n",
            "Average loss is: tensor(3.7430, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.7264754098360656\n",
            "batch count??? 122\n",
            "Average loss is: tensor(3.8423, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6046153846153847\n",
            "batch count??? 13\n",
            "Evaluation for: VALIDATION\n",
            "Classifier 'VALIDATION' has Acc=0.605 P=0.604 R=0.602 F1=0.602 AUC=0.604\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.595     0.549     0.571       623\n",
            "         1.0      0.612     0.656     0.633       677\n",
            "\n",
            "    accuracy                          0.605      1300\n",
            "   macro avg      0.604     0.602     0.602      1300\n",
            "weighted avg      0.604     0.605     0.603      1300\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[342 233]\n",
            " [281 444]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApYAAAEbCAYAAABgNMSRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSyyNMcYYY0xA/H8UU5EGxPOwGgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Njt1FiPx6FfO",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_challenge:\n",
        "  lstm_hidden_size = 100\n",
        "  dense_dimension = 200\n",
        "  attention_hops = 30\n",
        "  batch_size = datasets[\"challenge\"].batch_size\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 70\n",
        "  mlp_one = 100\n",
        "  mlp_two = 30\n",
        "  num_classes = 4\n",
        "  avg=False\n",
        "  weights = torch.tensor([2, 1, 0.2, 1], dtype=torch.double).cuda()\n",
        "  epochs = 12\n",
        "  inner_dropout = 0\n",
        "  outer_dropout = 0\n",
        "  C = 0\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.01\n",
        "  grad_clip = False\n",
        "  grad_clip_amount = 1\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.0005\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJ_FyWx36Sr",
        "colab_type": "code",
        "outputId": "cb61463d-9654-401b-c57e-b0758c0de241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"challenge\"], Hyperparameters_challenge)"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([27708, 50])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-263-e012c4c42f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"challenge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHyperparameters_challenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-257-2b8d6b9c1840>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, dataset, hp, is_plot)\u001b[0m\n\u001b[1;32m      9\u001b[0m                        \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                        using_gradient_clipping=hp.grad_clip)\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplot_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-253-741510a756ba>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, optimiser, hp, using_gradient_clipping)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_validating\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m           \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_debug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdebug_amount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_politi:\n",
        "  lstm_hidden_size = 30\n",
        "  dense_dimension = 10\n",
        "  attention_hops = 5\n",
        "  batch_size = datasets[\"politifact\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 50\n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.5\n",
        "  C = 0.5\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00008\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 1\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.004\n",
        "  use_better=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXeIuPBZF8Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"politifact\"], Hyperparameters_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4wRSAvtABCT",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL_ENTAILMENT W/ BETTERMUSH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Kd6J8o4j6k",
        "colab_type": "text"
      },
      "source": [
        "runnin my textual entailent model :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2oQo2CM3XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_b_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 50\n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 11\n",
        "  inner_dropout = 0.3\n",
        "  outer_dropout = 0.6\n",
        "  C = 0.6\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00004\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.01\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0ID4OwKBnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters_b_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uR6B4eAE7Ydh",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_b_politi:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 8\n",
        "  mlp_one = 50  \n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.7\n",
        "  weights = [1, 1, 0.25, 1]\n",
        "  C = 0.6\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00007\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.009\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0_fGUTfKLKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"politifact\"], Hyperparameters_b_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4JkXr8fcoee",
        "colab_type": "text"
      },
      "source": [
        "WOAH WERE DOIN SOME VALIDATION\n",
        "PLEASE VALIDATE ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgdGdgfwsOxa",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu() ,datasets[\"politifact\"].test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Zfw_4Acupe",
        "colab_type": "text"
      },
      "source": [
        "JUST TESTIN HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViWwxJG5Oys",
        "colab_type": "text"
      },
      "source": [
        "##running sheena's model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ngDR0NMc26u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = dataset[\"snopes\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 9\n",
        "  inner_dropout=0.5\n",
        "  outer_dropout=0.5\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.00007\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.009\n",
        "  use_better = False\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Sy7yz2yfOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"snopes\"], SheenaParameters_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqq85WyvO4vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_politi:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = dataset[\"challenge\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 11\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.00005\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  use_better = False\n",
        "  early_threshold = -0.06"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOunnQsb5B7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sheena_predicted_ys, model = run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters_politi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LavaeLb_wcPS",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_b_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  mlp_one = 25  \n",
        "  mlp_two = 10\n",
        "  avg=False\n",
        "  epochs = 14\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.00005\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.013\n",
        "  use_better = True\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1qVR4CrMGJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"snopes\"], SheenaParameters_b_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Czr397iowaXX",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_b_politi:\n",
        "  lstm_hidden_size = 40\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  mlp_one = 25  \n",
        "  mlp_two = 10\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.0001\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  use_better = True\n",
        "  early_threshold = -0.013"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--XfnpT3wZ9c",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters_b_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"sheena model\",predicted_ys.cpu(), datasets[\"politifact\"].test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1DvOud6d0r",
        "colab_type": "text"
      },
      "source": [
        "##OK TESTING ON BROKE DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfFA1PNpzA8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeclareParameters_snopes:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 100\n",
        "  num_classes = 1\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0.7\n",
        "  epochs = 20\n",
        "  C = 0\n",
        "  is_debug = False\n",
        "  lr=0.00008\n",
        "  decay = 0.8\n",
        "  filters = [100, 8]\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"real_declare\"], datasets[\"snopes\"], DeclareParameters_snopes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1c6Az3UST7bY",
        "colab": {}
      },
      "source": [
        "class DeclareParameters_politi:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"politifact\"].batch_size\n",
        "  max_length = 100\n",
        "  num_classes = 1\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0\n",
        "  epochs = 30\n",
        "  C = 0\n",
        "  is_debug = False\n",
        "  lr=0.0001\n",
        "  decay = 0.01\n",
        "  filters = [100, 8]\n",
        "  grad_clip = False\n",
        "  grad_clip_amount = 3\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.04"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-BrIP06dkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8801833b-6c3a-42f6-e584-c4437ee15cb6"
      },
      "source": [
        "run_model(models[\"real_declare\"], datasets[\"politifact\"], DeclareParameters_politi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss is: tensor(0.7360, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5022268907563026\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.7253, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5189285714285714\n",
            "batch count??? 28\n",
            "Running EPOCH: 2\n",
            "Average loss is: tensor(0.7170, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5090756302521008\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.7108, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5996428571428571\n",
            "batch count??? 28\n",
            "Running EPOCH: 3\n",
            "Average loss is: tensor(0.6992, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.6681512605042017\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.6985, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6360714285714286\n",
            "batch count??? 28\n",
            "Running EPOCH: 4\n",
            "Average loss is: tensor(0.6749, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.7239075630252101\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.6881, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6360714285714286\n",
            "batch count??? 28\n",
            "Running EPOCH: 5\n",
            "Average loss is: tensor(0.6407, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.7560924369747899\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.6848, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6314285714285715\n",
            "batch count??? 28\n",
            "Running EPOCH: 6\n",
            "Average loss is: tensor(0.6016, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.7836134453781513\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.6887, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6346428571428572\n",
            "batch count??? 28\n",
            "Running EPOCH: 7\n",
            "Average loss is: tensor(0.5605, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.8083193277310924\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.7024, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6382142857142857\n",
            "batch count??? 28\n",
            "Running EPOCH: 8\n",
            "Average loss is: tensor(0.5198, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.8287394957983193\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.7205, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6371428571428571\n",
            "batch count??? 28\n",
            "Running EPOCH: 9\n",
            "Average loss is: tensor(0.4828, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.8499579831932773\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.7418, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6321428571428571\n",
            "batch count??? 28\n",
            "Running EPOCH: 10\n",
            "Average loss is: tensor(0.4480, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.8703361344537816\n",
            "batch count??? 238\n",
            "Average loss is: tensor(0.7692, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6307142857142857\n",
            "batch count??? 28\n",
            "Running EPOCH: 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZsRrUK77HAU",
        "colab_type": "text"
      },
      "source": [
        "TESTING ON REAL DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JetqyT7Imn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "declare_predicted_ys, _ =  run_model(models[\"real_declare\"], datasets[\"politifact\"], DeclareParameters_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCjS7Dfz7I8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"real declare model\", declare_predicted_ys.cpu(), datasets[\"politifact\"].test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hECl8V-P8noH",
        "colab_type": "text"
      },
      "source": [
        "                  \"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDZugTi6AEHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_params = {\n",
        "    \"my_model\": {\"politifact\": Hyperparameters_politi, \"snopes\":Hyperparameters_snopes},\n",
        "    #\"my_model_better\":{\"politifact\": Hyperparameters_b_politi, \"snopes\":Hyperparameters_b_snopes},\n",
        "    \"sheena_model\": {\"politifact\": SheenaParameters_politi, \"snopes\": SheenaParameters_snopes},\n",
        "    #\"sheena_model_better\": {\"politifact\": SheenaParameters_b_politi, \"snopes\" : SheenaParameters_b_snopes},\n",
        "    \"real_declare\": {\"politifact\":DeclareParameters_politi, \"snopes\": DeclareParameters_snopes}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWBCcIDk674v",
        "colab_type": "text"
      },
      "source": [
        "##VALIDATION LAND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGG5mT_uBEGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_amount = 5\n",
        "per_avg_amount = 10\n",
        "import csv\n",
        "\n",
        "full_results = []\n",
        "avg_results = []\n",
        "processed_results = []\n",
        "\n",
        "\n",
        "\n",
        "for data_name in datasets:\n",
        "  for model_name in models:\n",
        "    some_results = []\n",
        "  \n",
        "    for per_avg_i in range(per_avg_amount):\n",
        "      predicted_ys, model = run_model(models[model_name], datasets[data_name], all_params[model_name][data_name])\n",
        "      full_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      some_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      \n",
        "    processed_results.append(process_results(list_to_dict(some_results)))\n",
        "    print(processed_results)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUR-r4M717ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for result in full_results:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iImnSu2nFmgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}