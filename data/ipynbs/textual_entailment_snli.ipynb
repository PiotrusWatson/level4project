{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4NbGwIC9-z",
        "colab_type": "text"
      },
      "source": [
        "##HAHA ITS TIME TO SPEND 5 HOURS DOWNLOADING THINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "ac2d1b51-9704-4d60-d091-27050fd33b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-09 18:59:13--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  15.0MB/s    in 8.8s    \n",
            "\n",
            "2020-03-09 18:59:27 (10.3 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "7c32d6f3-9ff7-4c88-d774-5afc5f9f1304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-09 18:59:35--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-09 18:59:36--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-09 18:59:36--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.19MB/s    in 6m 29s  \n",
            "\n",
            "2020-03-09 19:06:05 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "2fc78944-5cb0-4f21-fca7-8b8517d71238",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-09 19:06:40--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "\rPolitiFact.zip        0%[                    ]       0  --.-KB/s               \rPolitiFact.zip      100%[===================>]   4.75M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-09 19:06:40 (33.1 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "3660e6d5-a4c5-4e25-fe35-4225b42a9c3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "outputId": "f61cefbc-3711-4eef-afb6-c915e5775fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1-baseline.git\n",
        "import sys\n",
        "sys.path.insert(1, 'fnc-1-baseline/utils')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1-baseline'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "Receiving objects:   0% (1/121)   \rReceiving objects:   1% (2/121)   \rReceiving objects:   2% (3/121)   \rReceiving objects:   3% (4/121)   \rReceiving objects:   4% (5/121)   \rReceiving objects:   5% (7/121)   \rReceiving objects:   6% (8/121)   \rReceiving objects:   7% (9/121)   \rReceiving objects:   8% (10/121)   \rReceiving objects:   9% (11/121)   \rReceiving objects:  10% (13/121)   \rReceiving objects:  11% (14/121)   \rReceiving objects:  12% (15/121)   \rReceiving objects:  13% (16/121)   \rReceiving objects:  14% (17/121)   \rReceiving objects:  15% (19/121)   \rReceiving objects:  16% (20/121)   \rReceiving objects:  17% (21/121)   \rReceiving objects:  18% (22/121)   \rReceiving objects:  19% (23/121)   \rReceiving objects:  20% (25/121)   \rReceiving objects:  21% (26/121)   \rReceiving objects:  22% (27/121)   \rReceiving objects:  23% (28/121)   \rReceiving objects:  24% (30/121)   \rReceiving objects:  25% (31/121)   \rReceiving objects:  26% (32/121)   \rReceiving objects:  27% (33/121)   \rReceiving objects:  28% (34/121)   \rReceiving objects:  29% (36/121)   \rReceiving objects:  30% (37/121)   \rReceiving objects:  31% (38/121)   \rReceiving objects:  32% (39/121)   \rReceiving objects:  33% (40/121)   \rReceiving objects:  34% (42/121)   \rReceiving objects:  35% (43/121)   \rReceiving objects:  36% (44/121)   \rReceiving objects:  37% (45/121)   \rReceiving objects:  38% (46/121)   \rReceiving objects:  39% (48/121)   \rReceiving objects:  40% (49/121)   \rReceiving objects:  41% (50/121)   \rReceiving objects:  42% (51/121)   \rremote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121\u001b[K\n",
            "Receiving objects:  43% (53/121)   \rReceiving objects:  44% (54/121)   \rReceiving objects:  45% (55/121)   \rReceiving objects:  46% (56/121)   \rReceiving objects:  47% (57/121)   \rReceiving objects:  48% (59/121)   \rReceiving objects:  49% (60/121)   \rReceiving objects:  50% (61/121)   \rReceiving objects:  51% (62/121)   \rReceiving objects:  52% (63/121)   \rReceiving objects:  53% (65/121)   \rReceiving objects:  54% (66/121)   \rReceiving objects:  55% (67/121)   \rReceiving objects:  56% (68/121)   \rReceiving objects:  57% (69/121)   \rReceiving objects:  58% (71/121)   \rReceiving objects:  59% (72/121)   \rReceiving objects:  60% (73/121)   \rReceiving objects:  61% (74/121)   \rReceiving objects:  62% (76/121)   \rReceiving objects:  63% (77/121)   \rReceiving objects:  64% (78/121)   \rReceiving objects:  65% (79/121)   \rReceiving objects:  66% (80/121)   \rReceiving objects:  67% (82/121)   \rReceiving objects:  68% (83/121)   \rReceiving objects:  69% (84/121)   \rReceiving objects:  70% (85/121)   \rReceiving objects:  71% (86/121)   \rReceiving objects:  72% (88/121)   \rReceiving objects:  73% (89/121)   \rReceiving objects:  74% (90/121)   \rReceiving objects:  75% (91/121)   \rReceiving objects:  76% (92/121)   \rReceiving objects:  77% (94/121)   \rReceiving objects:  78% (95/121)   \rReceiving objects:  79% (96/121)   \rReceiving objects:  80% (97/121)   \rReceiving objects:  81% (99/121)   \rReceiving objects:  82% (100/121)   \rReceiving objects:  83% (101/121)   \rReceiving objects:  84% (102/121)   \rReceiving objects:  85% (103/121)   \rReceiving objects:  86% (105/121)   \rReceiving objects:  87% (106/121)   \rReceiving objects:  88% (107/121)   \rReceiving objects:  89% (108/121)   \rReceiving objects:  90% (109/121)   \rReceiving objects:  91% (111/121)   \rReceiving objects:  92% (112/121)   \rReceiving objects:  93% (113/121)   \rReceiving objects:  94% (114/121)   \rReceiving objects:  95% (115/121)   \rReceiving objects:  96% (117/121)   \rReceiving objects:  97% (118/121)   \rReceiving objects:  98% (119/121)   \rReceiving objects:  99% (120/121)   \rReceiving objects: 100% (121/121)   \rReceiving objects: 100% (121/121), 23.99 KiB | 614.00 KiB/s, done.\n",
            "Resolving deltas:   0% (0/63)   \rResolving deltas:   1% (1/63)   \rResolving deltas:   4% (3/63)   \rResolving deltas:   9% (6/63)   \rResolving deltas:  31% (20/63)   \rResolving deltas:  38% (24/63)   \rResolving deltas:  44% (28/63)   \rResolving deltas:  47% (30/63)   \rResolving deltas:  50% (32/63)   \rResolving deltas:  55% (35/63)   \rResolving deltas:  57% (36/63)   \rResolving deltas:  63% (40/63)   \rResolving deltas:  65% (41/63)   \rResolving deltas: 100% (63/63)   \rResolving deltas: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "c6cac834-b910-4a3a-f8e2-29d0a22e421c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-09 19:06:50--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "\rSnopes.zip            0%[                    ]       0  --.-KB/s               \rSnopes.zip          100%[===================>]   5.30M  35.1MB/s    in 0.2s    \n",
            "\n",
            "2020-03-09 19:06:50 (35.1 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "outputId": "c626968a-af1c-4bfd-8973-d589fa370ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd\n",
        "from score import report_score"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJXKPPODFqp",
        "colab_type": "text"
      },
      "source": [
        "##LOOK AT ALL THIS CODE TO IMPORT DATA GOD THERE MUST BE SOMETHING WRONG WITH ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "0a5f7f94-83e4-48c3-8817-8578491fee80"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "f1b79dd2-ba8f-4ec5-cd5e-859d3daf60fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "2cd2410e-f067-46ff-a3fe-60d544b04657",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "\n",
        "def split_test(facts):\n",
        "   unique = facts.drop_duplicates(\"claim_text\")\n",
        "   train_unique, val_unique = train_test_split(unique, test_size=0.1, random_state=8)\n",
        "   val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "   train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "   return train_facts, val_facts\n",
        "\n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/competition_test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/competition_test_stances.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "train_challenge, val_challenge = train_test_split(train_challenge, test_size=0.2, random_state=8)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "\n",
        "train_challenge = train_challenge.rename(columns={\"articleBody\": \"article\", \"Headline\": \"claim_text\", \"Stance\": \"cred_label\"})\n",
        "test_challenge = test_challenge.rename(columns={\"articleBody\": \"article\", \"Headline\": \"claim_text\", \"Stance\": \"cred_label\"})\n",
        "print(train_challenge.head())\n",
        "train_challenge, val_challenge = split_test(train_challenge)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Body ID  ... cred_label\n",
            "11142      686  ...          2\n",
            "4398       251  ...          2\n",
            "30345     1689  ...          2\n",
            "41235     2154  ...          1\n",
            "33237     1829  ...          2\n",
            "\n",
            "[5 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "challenge_mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None, is_folding=False):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_text\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  \n",
        "  if is_folding:\n",
        "    results = []\n",
        "    folded = KFold(n_splits=10, shuffle=True)\n",
        "    splitted_object = folded.split(unique)\n",
        "    for train_result, test_result in splitted_object:\n",
        "      train_ilocs = unique.iloc[train_result][\"claim_text\"]\n",
        "      test_ilocs = unique.iloc[test_result][\"claim_text\"]\n",
        "      results.append((facts[facts[\"claim_text\"].isin(train_ilocs)], facts[facts[\"claim_text\"].isin(test_ilocs)]))\n",
        "\n",
        "    return results\n",
        "\n",
        "  train_unique, big_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "  val_unique, test_unique = train_test_split(big_unique, test_size=0.5, random_state=8)\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_text\"].isin(test_unique[\"claim_text\"])]\n",
        "  val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "  train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "  return train_facts, test_facts, val_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts, val_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes, val_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "7aa44766-416a-4e7d-f884-34e91ba6895f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>vice news we dont have a timeline on the decis...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>a schedule i narcotic along with heroin and ec...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>now do you think you were maybe talking just a...</td>\n",
              "      <td>cnn.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>made to the new yorker that marijuana is no mo...</td>\n",
              "      <td>time.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jun_27_donald-trump_white-house-criticism...</td>\n",
              "      <td>obamacare signed law cbo estimated 23 million ...</td>\n",
              "      <td>donald trump</td>\n",
              "      <td>about the affordable health care act in its da...</td>\n",
              "      <td>eugeneweekly.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4849</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama to ban guns from 42 million social secur...</td>\n",
              "      <td>bearingarms.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4850</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama is looking to ban social security recipi...</td>\n",
              "      <td>rightwingnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>main navigation recent posts obama to ban 42 m...</td>\n",
              "      <td>downtrend.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>get news like this in your facebook news feed ...</td>\n",
              "      <td>thegatewaypundit.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>to prove everyone wrong yet again this time it...</td>\n",
              "      <td>zerohedge.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...        article_source\n",
              "187            1  ...            reason.com\n",
              "188            1  ...            reason.com\n",
              "189            1  ...               cnn.com\n",
              "190            1  ...              time.com\n",
              "526            1  ...      eugeneweekly.com\n",
              "...          ...  ...                   ...\n",
              "4849           0  ...       bearingarms.com\n",
              "4850           0  ...     rightwingnews.com\n",
              "4851           0  ...         downtrend.com\n",
              "4852           0  ...  thegatewaypundit.com\n",
              "4853           0  ...         zerohedge.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Beq65oTgcBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, train_loader, test_loader, val_loader, test_data, val_data, tokeniser):\n",
        "    self.train_loader = train_loader\n",
        "    self.test_loader = test_loader\n",
        "    self.val_loader = val_loader\n",
        "    self.test_data = test_data\n",
        "    self.val_data = val_data\n",
        "    self.word_embeddings_small = load_glove_embeddings(\"glove.6B.50d.txt\", tokeniser.word_to_id, 50) \n",
        "    self.word_embeddings_large = load_glove_embeddings(\"glove.6B.300d.txt\", tokeniser.word_to_id, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts4lYd83j-c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"claim_text\", \"article\"]\n",
        "big_labels = [\"claim_text\", \"article\", \"article_source\"]\n",
        "\n",
        "def get_list(panda, labels):\n",
        "  label_to_data = {}\n",
        "  for label in labels:\n",
        "    label_to_data[label] = panda[label]\n",
        "\n",
        "  x_list = convert_to_lists(label_to_data)\n",
        "  if labels[0] == \"claim_text\":\n",
        "    y_list = panda[\"cred_label\"].tolist()\n",
        "  else:\n",
        "    y_list = panda[\"Stance\"].tolist()\n",
        "  return x_list, y_list\n",
        "\n",
        "def get_loader(x, y, vocab_size, max_length, batch_size, name, training=True, drop_last=True):\n",
        "  stuff = []\n",
        "  for key in x:\n",
        "    stuff.append(torch.from_numpy(x[key]).type(torch.LongTensor))\n",
        "  stuff.append(torch.from_numpy(y).type(torch.DoubleTensor))\n",
        "  tensorset = data_utils.TensorDataset(*stuff)\n",
        "  loader = data_utils.DataLoader(tensorset, batch_size=batch_size, drop_last=drop_last, shuffle=training)\n",
        "  loader.name = name\n",
        "\n",
        "  return loader\n",
        "\n",
        "  \n",
        "def get_dataset(train, test, val, vocab_size, max_length, batch_size, labels, name):\n",
        "  is_challenge = labels[0] == \"articleBody\"\n",
        "  train_list_x, train_list_y = get_list(train, labels)\n",
        "\n",
        "  test_list_x, test_list_y = get_list(test, labels)\n",
        "  val_list_x, val_list_y = get_list(val, labels)\n",
        "\n",
        "\n",
        "\n",
        "  #tokenising various stuff, setting up numpy dictionaries :)\n",
        "  tokeniser = Tokeniser(train_list_x, vocab_size, max_length)\n",
        "  x_train = tokeniser.do_everything(train_list_x)\n",
        "  x_test = tokeniser.do_everything(test_list_x)\n",
        "  x_val = tokeniser.do_everything(val_list_x)\n",
        "  y_train = np.array(train_list_y, dtype=np.float32)\n",
        "  y_test = np.array(test_list_y, dtype=np.float32)\n",
        "  y_val = np.array(val_list_y, dtype=np.float32)\n",
        "  \n",
        "  #datasets/loaders\n",
        "  train_loader = get_loader(x_train, y_train, vocab_size, max_length, batch_size, name, True)\n",
        "  test_loader = get_loader(x_test, y_test, vocab_size, max_length, batch_size, name, False, drop_last=False)\n",
        "  val_loader = get_loader(x_val, y_val, vocab_size, max_length, batch_size, name, False)\n",
        "  return Dataset(train_loader, test_loader, val_loader, y_test, y_val, tokeniser)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MMrKlu6_jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "outputId": "7ec6be3f-b8f8-44b8-ffd6-1ca5afbd0ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 100\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "\n",
        "snopes_dataset = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "fact_dataset = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "challenge_dataset = get_dataset(train_challenge, test_challenge, val_challenge, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"challenge_data\")\n",
        "big_snopes = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "big_fact = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39093\n",
            "39093\n",
            "33766\n",
            "33766\n",
            "27708\n",
            "27708\n",
            "44623\n",
            "44623\n",
            "37174\n",
            "37174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b00c3dc0-c2d1-427f-ba01-e17d87f376ba"
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx_train = x_tokeniser.do_everything(x_train_lists)\\nx_test = x_tokeniser.do_everything(x_test_lists)\\ny_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\\ny_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3021f51a-7e49-46b6-8608-23309792f569"
      },
      "source": [
        "\"\"\"we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we_shufflin = True\\nshufflin_test = False\\n#alright lets tensordataset textual entailment stuff\\ntrain_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\\ntrain_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\\ntrain_loader.name = \"entailment_data\"\\n\\ntest_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\\ntest_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\\ntest_loader.name = \"entailment_data\"\\n\\n\\n#POLITIFACT/SNOPES W/ SOURCES\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smeSRlk30Ccq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTdDpyN44DQa",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL ENTAILMENT MODEL CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    \n",
        "    self.embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.normaliser = torch.nn.BatchNorm1d(self.embedding_size)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x[:, 0:self.hp.max_length])\n",
        "    #embedding = self.normaliser(embedding.transpose(1,2))\n",
        "    embedding = self.dropout(embedding)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    tanh_W_H = self.dropout(tanh_W_H)\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.premise_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "    self.hp = hp\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    premise_factor = self.premise_dropout(premise_factor)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    hypothesis_factor = self.hypothesis_dropout(hypothesis_factor)\n",
        "    if self.hp.use_better:\n",
        "      return better_mush(premise_factor,hypothesis_factor)\n",
        "    else:\n",
        "      return premise_factor * hypothesis_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=hp.mlp_one)\n",
        "    self.linear2 = torch.nn.Linear(hp.mlp_one, hp.mlp_two)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(hp.mlp_two, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "      x = self.dropout1(x)\n",
        "    else:\n",
        "      x = torch.relu(self.linear1(x.reshape(self.hp.batch_size, -1)))\n",
        "      x = self.dropout1(x)\n",
        "      x = torch.relu(self.linear2(x))\n",
        "      x = self.dropout2(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    print(word_embeddings.shape)\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout)]\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    self.dropouts[1](premise_embedding)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    self.dropouts[3](hypothesis_embedding)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    self.dropouts[4](factorised_mush)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention*premise_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpWRHhOxCjFl",
        "colab_type": "text"
      },
      "source": [
        "##EVAL SUMMARY :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUhazL34GWZ",
        "colab_type": "text"
      },
      "source": [
        "##SHEENABASELINE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_UvQQWx4IcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout)]*5\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    processed_premise = self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    premise_embedding = self.dropouts[1](premise_embedding)\n",
        "    \n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    processed_hypothesis = self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    hypothesis_embedding = self.dropouts[3](hypothesis_embedding)\n",
        "    if self.hp.use_better:\n",
        "      combined = better_mush(premise_embedding, hypothesis_embedding)\n",
        "    else:\n",
        "      combined = premise_embedding * hypothesis_embedding\n",
        "    \n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    avg = self.dropouts[4](avg)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      output = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      output = torch.sigmoid(self.final_linear(x))\n",
        "    return output, hypothesis_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWRCDtWR4Lcq",
        "colab_type": "text"
      },
      "source": [
        "##BAD DECLARE CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMmJP6kC4Th3",
        "colab_type": "text"
      },
      "source": [
        "## GOOD DECLARE CODE???\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRhCjK84VeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(RealDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(10000, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(100, 8)\n",
        "    self.linear_almost_there = torch.nn.Linear(8, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.dropout0 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    lengths = self.hp.max_length - (premise == 0).sum(dim=1)\n",
        "    lengths = lengths.repeat(50, 1).transpose(0,1)\n",
        "    summed_embeddings = torch.sum(embeddings, 1)\n",
        "    mean_embeddings = torch.unsqueeze(summed_embeddings / lengths, 1) #change to accurate size of lenfgth\n",
        "    flattened_embeddings = mean_embeddings.reshape(self.hp.batch_size, -1)\n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100]).reshape(self.hp.batch_size, -1)\n",
        "    #TODO: use repeat function to get 100*100 #DONE!\n",
        "    main_embeddings = torch.cat((flattened_embeddings.repeat(1, 100), added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    attention_weights = softmax(torch.tanh(self.premise_linear(main_embeddings)))#TODO: turn into row vector\n",
        "\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis, attention_weights.unsqueeze(2))\n",
        "    \n",
        "\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    new_lengths = lengths.repeat(1, 2)\n",
        "\n",
        "    avg = torch.sum(combined, 1)/new_lengths #todo: fix padding\n",
        "    avg = self.dropout0(avg)\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    smaller = self.dropout1(smaller)\n",
        "    even_smaller = F.relu(self.linear_almost_there(smaller))\n",
        "    even_smaller = self.dropout2(even_smaller)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      output = softmax(self.final_linear(even_smaller))\n",
        "    else:\n",
        "      output = torch.sigmoid(self.final_linear(even_smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "##TRAIN/TEST/HELPERS\n",
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# given the losses, checks if it should stop (or not :))\n",
        "# this performs early stopping -\n",
        "def should_stop(losses, train_losses, limit, threshold=-0.01):\n",
        "  shouldnt_stop = False \n",
        "  is_learning = False\n",
        "  #print(\"losses:\",losses)\n",
        "  #print(\"train_losses:\", train_losses)\n",
        "  \n",
        "  if len(losses) < limit:\n",
        "    return False \n",
        "  \n",
        "  last = losses[-1]\n",
        "  last_train = train_losses[-1]\n",
        "\n",
        "  if limit == 2:\n",
        "    #print(\"Threshold: {}, result {}\".format(threshold, last-losses[-2]))\n",
        "    return last - losses[-2] >= threshold\n",
        "  \n",
        "  for i in range(-2,- limit-1,-1):\n",
        "    shouldnt_stop = (shouldnt_stop or last - losses[i] < threshold)\n",
        "    last = losses[i]\n",
        "  return not shouldnt_stop\n",
        "def get_l2(model, filters):\n",
        "  reg_loss = None\n",
        "  for param in model.parameters():\n",
        "    if param.shape[0] in filters:\n",
        "      if reg_loss is None:\n",
        "        reg_loss = torch.sum(param**2)\n",
        "      else:\n",
        "        reg_loss = reg_loss + param.norm(2)**2\n",
        "  return reg_loss\n",
        "\n",
        "def train(model=None, \n",
        "          dataset = None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(dataset.train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "  \n",
        "\n",
        "  is_binary = hp.num_classes == 1\n",
        "  is_validating = False\n",
        "  has_stopped = False\n",
        "  has_decreased = False\n",
        "\n",
        "  if is_binary:\n",
        "    loss_function=torch.nn.BCELoss()\n",
        "  else:\n",
        "    loss_function=torch.nn.CrossEntropyLoss(hp.weights)\n",
        "  \n",
        "  if dataset.train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif dataset.train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  elif dataset.train_loader.name == \"challenge_data\" and hp.num_classes != 4:\n",
        "      raise ValueError(\"Four classes are needed for challenge fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  \n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    val_results = []\n",
        "    for i in range(2):\n",
        "      \n",
        "      total_loss = 0\n",
        "      batch_count = 0\n",
        "      correct = 0\n",
        "      penal = 0\n",
        "      l2 = 0\n",
        "\n",
        "      if is_validating:\n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.val_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 1\n",
        "      elif has_stopped:\n",
        "        \n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.train_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 10\n",
        "      else:\n",
        "        model.train(True)\n",
        "        #print(\"im trainin friends!!\")\n",
        "        loader = dataset.train_loader\n",
        "        torch.enable_grad()\n",
        "        debug_amount = 10\n",
        "      \n",
        "      for batch_index, train_data in enumerate(loader):\n",
        "      #setting everything up\n",
        "        model.hidden_state = model.reset_for_testing(train_data[0].shape[0])\n",
        "        train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "        predicted_y, attention = model(*train_data[:-1])\n",
        "        actual_y = train_data[-1]\n",
        "        squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "        if hp.C > 0:\n",
        "          attentionT = attention.transpose(1,2)\n",
        "          identity = torch.eye(attention.size(1))\n",
        "          identity = Variable(identity.unsqueeze(0).expand(loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "          penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "        if hp.decay > 0:\n",
        "          l2 = get_l2(model, hp.filters)\n",
        "\n",
        "      #get loss, accuracy\n",
        "        if is_binary:\n",
        "          loss = loss_function(squeezed_y, actual_y.double())\n",
        "          loss += hp.C * penal/loader.batch_size + hp.decay * l2\n",
        "          correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "          if is_validating:\n",
        "            val_results.append(torch.round(squeezed_y))\n",
        "          \n",
        "        else:\n",
        "          loss = loss_function(squeezed_y,actual_y.long())\n",
        "          loss += hp.C * (penal/loader.batch_size) + hp.decay * l2\n",
        "          correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "          if is_validating:\n",
        "            val_results.append(torch.argmax(squeezed_y, 1))\n",
        "        total_loss += loss.data\n",
        "\n",
        "        if using_gradient_clipping:\n",
        "          torch.nn.utils.clip_grad_norm(model.parameters(), hp.grad_clip_amount)\n",
        "      \n",
        "      #cleaning up regularisation\n",
        "        if hp.C > 0:\n",
        "          del(penal)\n",
        "          del(identity)\n",
        "          del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "        optimiser.zero_grad()\n",
        "        if not is_validating and not has_stopped:\n",
        "          loss.backward()\n",
        "          optimiser.step()\n",
        "        if hp.is_debug and batch_index % debug_amount == 0:\n",
        "          print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, ISvAL: {}, HasStopped: {}\".format(\n",
        "              epoch, batch_index * len(train_data[0]), len(loader.dataset),\n",
        "              100. * batch_index / len(loader), loss.item(), is_validating, has_stopped\n",
        "          ))\n",
        "\n",
        "      \n",
        "        batch_count += 1\n",
        "      \n",
        "        free_data(train_data)\n",
        "      correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "      accuracy = correct_but_numpy / float(batch_count * loader.batch_size)\n",
        "\n",
        "      if (not is_validating):\n",
        "        losses.append(total_loss/batch_count)\n",
        "        accuracies.append(accuracy)\n",
        "      else:\n",
        "        val_losses.append(total_loss/batch_count)\n",
        "        val_accuracies.append(accuracy)\n",
        "      \n",
        "      if not has_decreased:\n",
        "        has_decreased = not (should_stop(val_losses, losses, 2, hp.early_threshold)) and len(val_losses) > 1\n",
        "      if hp.use_early_stopping and is_validating:\n",
        "        has_stopped = should_stop(val_losses,losses, hp.early_stopping, hp.early_threshold) and has_decreased\n",
        "\n",
        "      print(\"Average loss is:\",total_loss/batch_count, \"while validation_status:\", is_validating, \"and stopping_status\", has_stopped)\n",
        "      print(\"Accuracy of the model\", accuracy)\n",
        "      print(\"batch count???\", batch_count)\n",
        "\n",
        "\n",
        "\n",
        "      is_validating = not is_validating\n",
        "  return losses, val_losses, accuracies, val_accuracies, torch.cat(val_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, val_losses, accuracies, val_accuracies, title=\"sup nerds\"):\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "  \n",
        "  ax1.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Train Accuracy\")\n",
        "  ax1.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax1.plot(range(1, epochs+1), val_accuracies, scalex=True, scaley=True, label=\"Val Accuracy\")\n",
        "  ax1.annotate(str(val_accuracies[-1]), xy=(epochs,val_accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  ax2.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Train Loss\")\n",
        "  ax2.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax2.plot(range(1, epochs+1), val_losses,scalex=True, scaley=True, label=\"Val Loss\")\n",
        "  ax2.annotate(str(val_losses[-1]), xy=(epochs,val_losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax1.legend()\n",
        "  ax2.legend()\n",
        "\n",
        "  ax1.set_xlabel(\"Epochs\", fontsize=16)\n",
        "  ax1.set_ylabel(\"Accuracy\", fontsize=16)\n",
        "  ax2.set_xlabel(\"Epochs\", fontsize=16)\n",
        "  ax2.set_ylabel(\"Loss\", fontsize=16)\n",
        "  plt.title(title)\n",
        "  fig.tight_layout()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwADakVSwJat",
        "colab_type": "text"
      },
      "source": [
        "NEW FUNCTIONS TO AUTOMATE THE RUNNING OF LOTS OF DATASETS/MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2DLo4OoUO4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels, is_binary):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (is_binary):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc_full))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmSdvMewHrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model, dataset, hp, is_plot=True):\n",
        "  runnable_model = model(hp, dataset.word_embeddings_small).cuda()\n",
        "\n",
        "  optimiser = torch.optim.Adam(runnable_model.parameters(), lr=hp.lr)\n",
        "  losses, val_losses, accuracies, val_accuracies, val_results = train(model=runnable_model,\n",
        "                       dataset = dataset,\n",
        "                       optimiser = optimiser,\n",
        "                       hp = hp,\n",
        "                       using_gradient_clipping=hp.grad_clip)\n",
        "  if is_plot:\n",
        "    plot_stuff(hp.epochs, losses,val_losses, accuracies, val_accuracies)\n",
        "  torch.cuda.empty_cache()\n",
        "  evaluation_summary(\"VALIDATION\", val_results.cpu().detach() ,dataset.val_data[:len(val_results)], hp.num_classes==1)\n",
        "  check_loader = dataset.test_loader\n",
        "\n",
        "  predicted_ys = batch_wise_evaluate(runnable_model, \n",
        "         check_loader,\n",
        "         hp)\n",
        "\n",
        "  return predicted_ys, runnable_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_results(model_name, dataset_name, predictions, true_labels):\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(predictions.shape) == 1):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  return {\"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc_full}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oMDNooNrMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_to_dict(results):\n",
        "  big_results = {\"model_name\": [],\n",
        "                 \"dataset_name\": [],\n",
        "                \"precision\": [],\n",
        "                 \"recall\": [],\n",
        "                 \"accuracy\": [],\n",
        "                 \"f1\": [],\n",
        "                 \"auc\": []}\n",
        "  for result in results:\n",
        "    for key in result:\n",
        "      big_results[key].append(result[key])\n",
        "\n",
        "  return pd.DataFrame.from_dict(big_results)\n",
        "\n",
        "def process_results(big_results):\n",
        "  return (big_results[\"model_name\"][0], big_results[\"dataset_name\"][0], big_results.mean(), big_results.std())\n",
        "  \n",
        "  \n",
        "def get_avgs(some_results):\n",
        "  avg_results = {\"model_name\": some_results[0][\"model_name\"],\n",
        "                 \"dataset_name\": some_results[0][\"dataset_name\"],\n",
        "                \"precision\": 0.0,\n",
        "                 \"recall\": 0.0,\n",
        "                 \"accuracy\": 0.0,\n",
        "                 \"f1\": 0.0,\n",
        "                 \"auc\": 0.0}\n",
        "  for result in some_results:\n",
        "    for key in result:\n",
        "      if type(result[key]) is float:\n",
        "        avg_results[key] += result[key]\n",
        "  \n",
        "  for key in avg_results:\n",
        "    if(type(avg_results[key] is float)):\n",
        "      avg_results[key] /= len(some_results)\n",
        "  \n",
        "  return avg_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "##RUNNING THE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datasets = {\n",
        "    \"politifact\": fact_dataset,\n",
        "    \"snopes\": snopes_dataset,\n",
        "    \"challenge\": challenge_dataset\n",
        "}\n",
        "models = {\n",
        "    \"my_model\": TextualEntailmentModel,\n",
        "    \"my_model_better\": TextualEntailmentModel,\n",
        "    \"sheena_model\": BaselineSentenceEntailment,\n",
        "    \"sheena_model_better\": BaselineSentenceEntailment,\n",
        "    \"real_declare\": RealDeclare\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N1ykUhFf7BCH",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 60\n",
        "  mlp_two = 10\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 10\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.6\n",
        "  C = 1\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00004\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 0.5\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.006\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3DuwQLD_iln",
        "colab_type": "code",
        "outputId": "73a93738-52f1-4f50-9afe-34893bfe63f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters_snopes)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([39093, 50])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:132: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss is: tensor(3.8560, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5009917355371901\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.8604, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "batch count??? 15\n",
            "Running EPOCH: 2\n",
            "Average loss is: tensor(3.8562, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5006611570247934\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.8601, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "batch count??? 15\n",
            "Running EPOCH: 3\n",
            "Average loss is: tensor(3.8560, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5012396694214876\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.8598, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "batch count??? 15\n",
            "Running EPOCH: 4\n",
            "Average loss is: tensor(3.8559, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5008264462809917\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.8591, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "batch count??? 15\n",
            "Running EPOCH: 5\n",
            "Average loss is: tensor(3.8556, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5009090909090909\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.8573, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "batch count??? 15\n",
            "Running EPOCH: 6\n",
            "Average loss is: tensor(3.8542, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5291735537190083\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.8457, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.5786666666666667\n",
            "batch count??? 15\n",
            "Running EPOCH: 7\n",
            "Average loss is: tensor(3.8419, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.5623140495867769\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.8096, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.62\n",
            "batch count??? 15\n",
            "Running EPOCH: 8\n",
            "Average loss is: tensor(3.8197, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6320661157024794\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.7902, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6313333333333333\n",
            "batch count??? 15\n",
            "Running EPOCH: 9\n",
            "Average loss is: tensor(3.7968, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6648760330578513\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.7860, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6453333333333333\n",
            "batch count??? 15\n",
            "Running EPOCH: 10\n",
            "Average loss is: tensor(3.7770, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.6887603305785124\n",
            "batch count??? 121\n",
            "Average loss is: tensor(3.7860, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6453333333333333\n",
            "batch count??? 15\n",
            "Evaluation for: VALIDATION\n",
            "Classifier 'VALIDATION' has Acc=0.645 P=0.643 R=0.642 F1=0.642 AUC=0.643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.663     0.689     0.676       805\n",
            "         1.0      0.623     0.594     0.608       695\n",
            "\n",
            "    accuracy                          0.645      1500\n",
            "   macro avg      0.643     0.642     0.642      1500\n",
            "weighted avg      0.644     0.645     0.645      1500\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[555 282]\n",
            " [250 413]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApYAAAEbCAYAAABgNMSRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Njt1FiPx6FfO",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_challenge:\n",
        "  lstm_hidden_size = 100\n",
        "  dense_dimension = 200\n",
        "  attention_hops = 30\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 70\n",
        "  mlp_one = 100\n",
        "  mlp_two = 30\n",
        "  num_classes = 4\n",
        "  avg=False\n",
        "  weights = torch.tensor([1, 1, 0.25, 1], dtype=torch.double).cuda()\n",
        "  epochs = 30\n",
        "  inner_dropout = 0\n",
        "  outer_dropout = 0\n",
        "  C = 0\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.7\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 0.5\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = False\n",
        "  early_threshold = -0.0005\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJ_FyWx36Sr",
        "colab_type": "code",
        "outputId": "2475c8fa-fd7f-4be5-b945-e25787c4908f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"challenge\"], Hyperparameters_challenge)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([27708, 50])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:132: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss is: tensor(1.3367, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.7298055555555556\n",
            "batch count??? 360\n",
            "Average loss is: tensor(1.3321, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.7323076923076923\n",
            "batch count??? 39\n",
            "Running EPOCH: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_politi:\n",
        "  lstm_hidden_size = 30\n",
        "  dense_dimension = 10\n",
        "  attention_hops = 5\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 50\n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 6\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.5\n",
        "  C = 0.5\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00008\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.01\n",
        "  use_better=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXeIuPBZF8Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"politifact\"], Hyperparameters_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4wRSAvtABCT",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL_ENTAILMENT W/ BETTERMUSH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Kd6J8o4j6k",
        "colab_type": "text"
      },
      "source": [
        "runnin my textual entailent model :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2oQo2CM3XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_b_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 50\n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 11\n",
        "  inner_dropout = 0.3\n",
        "  outer_dropout = 0.6\n",
        "  C = 0.6\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00004\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.01\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0ID4OwKBnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters_b_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uR6B4eAE7Ydh",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_b_politi:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 8\n",
        "  mlp_one = 50  \n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.7\n",
        "  weights = [1, 1, 0.25, 1]\n",
        "  C = 0.6\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00007\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.009\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0_fGUTfKLKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"politifact\"], Hyperparameters_b_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4JkXr8fcoee",
        "colab_type": "text"
      },
      "source": [
        "WOAH WERE DOIN SOME VALIDATION\n",
        "PLEASE VALIDATE ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgdGdgfwsOxa",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu() ,datasets[\"politifact\"].test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Zfw_4Acupe",
        "colab_type": "text"
      },
      "source": [
        "JUST TESTIN HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViWwxJG5Oys",
        "colab_type": "text"
      },
      "source": [
        "##running sheena's model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ngDR0NMc26u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 9\n",
        "  inner_dropout=0.5\n",
        "  outer_dropout=0.5\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.00007\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.009\n",
        "  use_better = False\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Sy7yz2yfOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"snopes\"], SheenaParameters_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqq85WyvO4vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_politi:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 11\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.00005\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  use_better = False\n",
        "  early_threshold = -0.06"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOunnQsb5B7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sheena_predicted_ys, model = run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters_politi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LavaeLb_wcPS",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_b_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  mlp_one = 25  \n",
        "  mlp_two = 10\n",
        "  avg=False\n",
        "  epochs = 14\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.00005\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.013\n",
        "  use_better = True\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1qVR4CrMGJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"snopes\"], SheenaParameters_b_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Czr397iowaXX",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_b_politi:\n",
        "  lstm_hidden_size = 40\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  mlp_one = 25  \n",
        "  mlp_two = 10\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  lr=0.0001\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  use_better = True\n",
        "  early_threshold = -0.013"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--XfnpT3wZ9c",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters_b_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"sheena model\",predicted_ys.cpu(), datasets[\"politifact\"].test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1DvOud6d0r",
        "colab_type": "text"
      },
      "source": [
        "##OK TESTING ON BROKE DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfFA1PNpzA8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeclareParameters_snopes:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 100\n",
        "  num_classes = 1\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0.7\n",
        "  epochs = 20\n",
        "  C = 0\n",
        "  is_debug = False\n",
        "  lr=0.00008\n",
        "  decay = 0.8\n",
        "  filters = [100, 8]\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"real_declare\"], datasets[\"snopes\"], DeclareParameters_snopes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1c6Az3UST7bY",
        "colab": {}
      },
      "source": [
        "class DeclareParameters_politi:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 100\n",
        "  num_classes = 1\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0.65\n",
        "  epochs = 13\n",
        "  C = 0\n",
        "  is_debug = False\n",
        "  lr=0.00008\n",
        "  decay = 0.8\n",
        "  filters = [100, 8]\n",
        "  grad_clip = True\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.04"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-BrIP06dkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_model(models[\"real_declare\"], datasets[\"politifact\"], DeclareParameters_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZsRrUK77HAU",
        "colab_type": "text"
      },
      "source": [
        "TESTING ON REAL DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JetqyT7Imn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "declare_predicted_ys, _ =  run_model(models[\"real_declare\"], datasets[\"politifact\"], DeclareParameters_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCjS7Dfz7I8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"real declare model\", declare_predicted_ys.cpu(), datasets[\"politifact\"].test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hECl8V-P8noH",
        "colab_type": "text"
      },
      "source": [
        "                  \"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDZugTi6AEHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_params = {\n",
        "    \"my_model\": {\"politifact\": Hyperparameters_politi, \"snopes\":Hyperparameters_snopes},\n",
        "    #\"my_model_better\":{\"politifact\": Hyperparameters_b_politi, \"snopes\":Hyperparameters_b_snopes},\n",
        "    \"sheena_model\": {\"politifact\": SheenaParameters_politi, \"snopes\": SheenaParameters_snopes},\n",
        "    #\"sheena_model_better\": {\"politifact\": SheenaParameters_b_politi, \"snopes\" : SheenaParameters_b_snopes},\n",
        "    \"real_declare\": {\"politifact\":DeclareParameters_politi, \"snopes\": DeclareParameters_snopes}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWBCcIDk674v",
        "colab_type": "text"
      },
      "source": [
        "##VALIDATION LAND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGG5mT_uBEGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_amount = 5\n",
        "per_avg_amount = 10\n",
        "import csv\n",
        "\n",
        "full_results = []\n",
        "avg_results = []\n",
        "processed_results = []\n",
        "\n",
        "\n",
        "\n",
        "for data_name in datasets:\n",
        "  for model_name in models:\n",
        "    some_results = []\n",
        "  \n",
        "    for per_avg_i in range(per_avg_amount):\n",
        "      predicted_ys, model = run_model(models[model_name], datasets[data_name], all_params[model_name][data_name])\n",
        "      full_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      some_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      \n",
        "    processed_results.append(process_results(list_to_dict(some_results)))\n",
        "    print(processed_results)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUR-r4M717ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for result in full_results:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iImnSu2nFmgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}