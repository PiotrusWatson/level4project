{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4NbGwIC9-z",
        "colab_type": "text"
      },
      "source": [
        "##HAHA ITS TIME TO SPEND 5 HOURS DOWNLOADING THINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "b56f43fe-0653-49fa-f1d6-cd85741abb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-11 17:11:03--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  68.6MB/s    in 1.3s    \n",
            "\n",
            "2020-02-11 17:11:04 (68.6 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "19c92107-4b6e-4bd2-bd97-02132d460ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-11 17:11:13--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-02-11 17:11:13--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-02-11 17:11:13--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.16MB/s    in 6m 26s  \n",
            "\n",
            "2020-02-11 17:17:39 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "e521a15e-d472-4dd7-9c6e-070b75cc9c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-11 17:18:05--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  3.93MB/s    in 1.2s    \n",
            "\n",
            "2020-02-11 17:18:07 (3.93 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "23539df4-7e19-4217-c05b-9cc0a54573ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "4a6dfe89-00cb-4d53-9cb3-8dcc3842e407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-11 17:18:16--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  4.33MB/s    in 1.2s    \n",
            "\n",
            "2020-02-11 17:18:17 (4.33 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "outputId": "6e2afa91-d35c-4f54-abc9-316aac7cd511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJXKPPODFqp",
        "colab_type": "text"
      },
      "source": [
        "##LOOK AT ALL THIS CODE TO IMPORT DATA GOD THERE MUST BE SOMETHING WRONG WITH ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "59940e67-7442-4bc6-adb4-212974579d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "68930a91-3ed4-4a81-a018-cf4a0f894962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None, is_folding=False):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_text\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  \n",
        "  if is_folding:\n",
        "    results = []\n",
        "    folded = KFold(n_splits=10, shuffle=True)\n",
        "    splitted_object = folded.split(unique)\n",
        "    for train_result, test_result in splitted_object:\n",
        "      train_ilocs = unique.iloc[train_result][\"claim_text\"]\n",
        "      test_ilocs = unique.iloc[test_result][\"claim_text\"]\n",
        "      results.append((facts[facts[\"claim_text\"].isin(train_ilocs)], facts[facts[\"claim_text\"].isin(test_ilocs)]))\n",
        "\n",
        "    return results\n",
        "\n",
        "  train_unique, big_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "  val_unique, test_unique = train_test_split(big_unique, test_size=0.5, random_state=8)\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_text\"].isin(test_unique[\"claim_text\"])]\n",
        "  val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "  train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "  return train_facts, test_facts, val_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts, val_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes, val_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "2d880b5d-323e-4141-9360-23aef070a4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>vice news we dont have a timeline on the decis...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>a schedule i narcotic along with heroin and ec...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>now do you think you were maybe talking just a...</td>\n",
              "      <td>cnn.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>made to the new yorker that marijuana is no mo...</td>\n",
              "      <td>time.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jun_27_donald-trump_white-house-criticism...</td>\n",
              "      <td>obamacare signed law cbo estimated 23 million ...</td>\n",
              "      <td>donald trump</td>\n",
              "      <td>about the affordable health care act in its da...</td>\n",
              "      <td>eugeneweekly.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4849</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama to ban guns from 42 million social secur...</td>\n",
              "      <td>bearingarms.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4850</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama is looking to ban social security recipi...</td>\n",
              "      <td>rightwingnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>main navigation recent posts obama to ban 42 m...</td>\n",
              "      <td>downtrend.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>get news like this in your facebook news feed ...</td>\n",
              "      <td>thegatewaypundit.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>to prove everyone wrong yet again this time it...</td>\n",
              "      <td>zerohedge.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...        article_source\n",
              "187            1  ...            reason.com\n",
              "188            1  ...            reason.com\n",
              "189            1  ...               cnn.com\n",
              "190            1  ...              time.com\n",
              "526            1  ...      eugeneweekly.com\n",
              "...          ...  ...                   ...\n",
              "4849           0  ...       bearingarms.com\n",
              "4850           0  ...     rightwingnews.com\n",
              "4851           0  ...         downtrend.com\n",
              "4852           0  ...  thegatewaypundit.com\n",
              "4853           0  ...         zerohedge.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Beq65oTgcBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, train_loader, test_loader, val_loader, test_data, val_data, tokeniser):\n",
        "    self.train_loader = train_loader\n",
        "    self.test_loader = test_loader\n",
        "    self.val_loader = val_loader\n",
        "    self.test_data = test_data\n",
        "    self.val_data = val_data\n",
        "    self.word_embeddings_small = load_glove_embeddings(\"glove.6B.50d.txt\", tokeniser.word_to_id, 50) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts4lYd83j-c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"claim_text\", \"article\"]\n",
        "big_labels = [\"claim_text\", \"article\", \"article_source\"]\n",
        "\n",
        "def get_list(panda, labels):\n",
        "  label_to_data = {}\n",
        "  for label in labels:\n",
        "    label_to_data[label] = panda[label]\n",
        "  \n",
        "  x_list = convert_to_lists(label_to_data)\n",
        "  y_list = panda[\"cred_label\"].tolist()\n",
        "  return x_list, y_list\n",
        "\n",
        "def get_loader(x, y, vocab_size, max_length, batch_size, name, training=True, drop_last=True):\n",
        "  stuff = []\n",
        "  for key in x:\n",
        "    stuff.append(torch.from_numpy(x[key]).type(torch.LongTensor))\n",
        "  stuff.append(torch.from_numpy(y).type(torch.DoubleTensor))\n",
        "\n",
        "  tensorset = data_utils.TensorDataset(*stuff)\n",
        "  loader = data_utils.DataLoader(tensorset, batch_size=batch_size, drop_last=drop_last, shuffle=training)\n",
        "  loader.name = name\n",
        "  return loader\n",
        "\n",
        "  \n",
        "def get_dataset(train, test, val, vocab_size, max_length, batch_size, labels, name):\n",
        "  train_list_x, train_list_y = get_list(train, labels)\n",
        "  test_list_x, test_list_y = get_list(test, labels)\n",
        "  val_list_x, val_list_y = get_list(val, labels)\n",
        "\n",
        "\n",
        "\n",
        "  #tokenising various stuff, setting up numpy dictionaries :)\n",
        "  tokeniser = Tokeniser(train_list_x, vocab_size, max_length)\n",
        "  x_train = tokeniser.do_everything(train_list_x)\n",
        "  x_test = tokeniser.do_everything(test_list_x)\n",
        "  x_val = tokeniser.do_everything(val_list_x)\n",
        "  y_train = np.array(train_list_y, dtype=np.float32)\n",
        "  y_test = np.array(test_list_y, dtype=np.float32)\n",
        "  y_val = np.array(val_list_y, dtype=np.float32)\n",
        "  \n",
        "  #datasets/loaders\n",
        "  train_loader = get_loader(x_train, y_train, vocab_size, max_length, batch_size, name, True)\n",
        "  test_loader = get_loader(x_test, y_test, vocab_size, max_length, batch_size, name, False, drop_last=False)\n",
        "  val_loader = get_loader(x_val, y_val, vocab_size, max_length, batch_size, name, False)\n",
        "  return Dataset(train_loader, test_loader, val_loader,  y_test, y_val, tokeniser)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MMrKlu6_jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "outputId": "da19367d-3eea-479b-c92d-3e242fee49e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "\n",
        "snopes_dataset = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "fact_dataset = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "big_snopes = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "big_fact = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39093\n",
            "33766\n",
            "44623\n",
            "37174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smeSRlk30Ccq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTdDpyN44DQa",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL ENTAILMENT MODEL CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    \n",
        "    self.embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.normaliser = torch.nn.BatchNorm1d(self.embedding_size)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.medium_dropout)\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    embedding = self.normaliser(embedding.transpose(1,2))\n",
        "    embedding = self.dropout(embedding.transpose(1,2))\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.large_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    tanh_W_H = self.dropout(tanh_W_H)\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.premise_dropout = torch.nn.Dropout(p=hp.large_dropout)\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_dropout = torch.nn.Dropout(p=hp.medium_dropout)\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    premise_factor = self.premise_dropout(premise_factor)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    hypothesis_factor = self.hypothesis_dropout(hypothesis_factor)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=50)\n",
        "    self.linear2 = torch.nn.Linear(50, 20)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.large_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.medium_dropout)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "      x = self.dropout1(x)\n",
        "    else:\n",
        "      x = torch.relu(self.linear1(x.reshape(self.hp.batch_size, -1)))\n",
        "      x = self.dropout1(x)\n",
        "      x = torch.relu(self.linear2(x))\n",
        "      x = self.dropout2(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    print(word_embeddings.shape)\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.large_dropout),\n",
        "                     torch.nn.Dropout(p=hp.medium_dropout),\n",
        "                     torch.nn.Dropout(p=hp.large_dropout),\n",
        "                     torch.nn.Dropout(p=hp.medium_dropout),\n",
        "                     torch.nn.Dropout(p=hp.large_dropout)]\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    self.dropouts[1](premise_embedding)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    self.dropouts[3](hypothesis_embedding)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    self.dropouts[4](factorised_mush)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention*premise_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpWRHhOxCjFl",
        "colab_type": "text"
      },
      "source": [
        "##EVAL SUMMARY :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUhazL34GWZ",
        "colab_type": "text"
      },
      "source": [
        "##SHEENABASELINE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_UvQQWx4IcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    combined = premise_embedding * hypothesis_embedding\n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWRCDtWR4Lcq",
        "colab_type": "text"
      },
      "source": [
        "##BAD DECLARE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db8ikkk64Kx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def load_embeddings(self, word_embeddings):\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, self.hp)\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(101, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    mean_embeddings = torch.unsqueeze(torch.sum(embeddings, 1) / self.hp.max_length, 1) #change to accurate size of lenfgth\n",
        "  \n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    #TODO: use repeat function to get 100*100\n",
        "    main_embeddings = torch.cat((mean_embeddings, added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    attention_weights = softmax(self.premise_linear(processed_premise))#TODO: turn into row vector\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis,attention_weights.transpose(1,2))\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    avg = torch.sum(combined, 1)/self.hp.max_length #todo: fix padding\n",
        "\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    output = torch.sigmoid(self.linear_final(smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMmJP6kC4Th3",
        "colab_type": "text"
      },
      "source": [
        "## GOOD DECLARE CODE???\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRhCjK84VeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(RealDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 1)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(100, 50)\n",
        "    self.linear_almost_there = torch.nn.Linear(50, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    lengths = self.hp.max_length - (premise == 0).sum(dim=1)\n",
        "    lengths = lengths.repeat(50, 1).transpose(0,1)\n",
        "    summed_embeddings = torch.sum(embeddings, 1)\n",
        "    mean_embeddings = torch.unsqueeze(summed_embeddings / lengths, 1) #change to accurate size of lenfgth\n",
        "\n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    #TODO: use repeat function to get 100*100 #DONE!\n",
        "    main_embeddings = torch.cat((mean_embeddings.repeat(1, 100, 1), added_embeddings), 2)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    attention_weights = softmax(self.premise_linear(main_embeddings.transpose(1,2)))#TODO: turn into row vector\n",
        "    repeated_weights = attention_weights.repeat(1, 1, 100)\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis, repeated_weights)\n",
        "\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    new_lengths = lengths.repeat(1, 2)\n",
        "    avg = torch.sum(combined, 1)/new_lengths #todo: fix padding\n",
        "\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    even_smaller = F.relu(self.linear_almost_there(smaller))\n",
        "    output = torch.sigmoid(self.linear_final(even_smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "##TRAIN/TEST/HELPERS\n",
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model=None, \n",
        "          dataset = None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "\n",
        "  is_binary = hp.num_classes == 1\n",
        "  is_validating = False\n",
        "  \n",
        "  if dataset.train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif dataset.train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  \n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "\n",
        "    for i in range(2):\n",
        "      \n",
        "      total_loss = 0\n",
        "      batch_count = 0\n",
        "      correct = 0\n",
        "      penal = 0\n",
        "\n",
        "      if is_validating:\n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.val_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 1\n",
        "      else:\n",
        "        model.train(True)\n",
        "        loader = dataset.train_loader\n",
        "        torch.enable_grad()\n",
        "        debug_amount = 10\n",
        "      \n",
        "      for batch_index, train_data in enumerate(loader):\n",
        "      #setting everything up\n",
        "        model.hidden_state = model.reset_for_testing(train_data[0].shape[0])\n",
        "        train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "        predicted_y, attention = model(*train_data[:-1])\n",
        "        actual_y = train_data[-1]\n",
        "        squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "        if hp.C > 0:\n",
        "          attentionT = attention.transpose(1,2)\n",
        "          identity = torch.eye(attention.size(1))\n",
        "          identity = Variable(identity.unsqueeze(0).expand(loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "          penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "        if is_binary:\n",
        "          loss = loss_function(squeezed_y, actual_y.double())\n",
        "          loss += hp.C * penal/loader.batch_size\n",
        "          correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "        else:\n",
        "          loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/loader.batch_size)\n",
        "          correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "        total_loss += loss.data\n",
        "\n",
        "        if using_gradient_clipping:\n",
        "          torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      \n",
        "      #cleaning up regularisation\n",
        "        if hp.C > 0:\n",
        "          del(penal)\n",
        "          del(identity)\n",
        "          del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "        optimiser.zero_grad()\n",
        "        if not is_validating:\n",
        "          loss.backward()\n",
        "          optimiser.step()\n",
        "        if hp.is_debug and batch_index % debug_amount == 0:\n",
        "          print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, ISvAL: {}\".format(\n",
        "              epoch, batch_index * len(train_data[0]), len(loader.dataset),\n",
        "              100. * batch_index / len(loader), loss.item(), is_validating\n",
        "          ))\n",
        "\n",
        "      \n",
        "        batch_count += 1\n",
        "      \n",
        "        free_data(train_data)\n",
        "\n",
        "      print(\"Average loss is:\",total_loss/batch_count, \"while validation_status:\", is_validating)\n",
        "      correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "      accuracy = correct_but_numpy / float(batch_count * loader.batch_size)\n",
        "      print(\"Accuracy of the model\", accuracy)\n",
        "      if (not is_validating):\n",
        "        losses.append(total_loss/batch_count)\n",
        "        accuracies.append(accuracy)\n",
        "      else:\n",
        "        val_losses.append(total_loss/batch_count)\n",
        "        val_accuracies.append(accuracy)\n",
        "\n",
        "      is_validating = not is_validating\n",
        "  return losses, val_losses, accuracies, val_accuracies "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, val_losses, accuracies, val_accuracies, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  \n",
        "  plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "  plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.plot(range(1, epochs+1), val_accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "  plt.annotate(str(val_accuracies[-1]), xy=(epochs,val_accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.plot(range(1, epochs+1), val_losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(val_losses[-1]), xy=(epochs,val_losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwADakVSwJat",
        "colab_type": "text"
      },
      "source": [
        "NEW FUNCTIONS TO AUTOMATE THE RUNNING OF LOTS OF DATASETS/MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmSdvMewHrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model, dataset, hp):\n",
        "  runnable_model = model(hp, dataset.word_embeddings_small).cuda()\n",
        "  bce_loss = torch.nn.BCELoss()\n",
        "  cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "  optimiser = torch.optim.Adam(runnable_model.parameters(), lr=hp.lr)\n",
        "  losses, val_losses, accuracies, val_accuracies = train(model=runnable_model,\n",
        "                       dataset = dataset,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = optimiser,\n",
        "                       hp = hp,\n",
        "                       using_gradient_clipping=True)\n",
        "  plot_stuff(hp.epochs, losses,val_losses, accuracies, val_accuracies)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  check_loader = dataset.test_loader\n",
        "  predicted_ys = batch_wise_evaluate(runnable_model, \n",
        "         check_loader,\n",
        "         hp)\n",
        "  return predicted_ys, runnable_model\n",
        "\n",
        "\n",
        "\n",
        "def get_results(model_name, dataset_name, predictions, true_labels):\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(predictions.shape) == 1):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  return {\"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc_full}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2DLo4OoUO4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(predictions.shape) == 1):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc_full))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oMDNooNrMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_to_dict(results):\n",
        "  big_results = {\"model_name\": [],\n",
        "                 \"dataset_name\": [],\n",
        "                \"precision\": [],\n",
        "                 \"recall\": [],\n",
        "                 \"accuracy\": [],\n",
        "                 \"f1\": [],\n",
        "                 \"auc\": []}\n",
        "  for result in results:\n",
        "    for key in result:\n",
        "      big_results[key].append(result[key])\n",
        "\n",
        "  return pd.DataFrame.from_dict(big_results)\n",
        "\n",
        "def process_results(big_results):\n",
        "  return (big_results[\"model_name\"][0], big_results[\"dataset_name\"][0], big_results.mean(), big_results.std())\n",
        "  \n",
        "  \n",
        "def get_avgs(some_results):\n",
        "  avg_results = {\"model_name\": some_results[0][\"model_name\"],\n",
        "                 \"dataset_name\": some_results[0][\"dataset_name\"],\n",
        "                \"precision\": 0.0,\n",
        "                 \"recall\": 0.0,\n",
        "                 \"accuracy\": 0.0,\n",
        "                 \"f1\": 0.0,\n",
        "                 \"auc\": 0.0}\n",
        "  for result in some_results:\n",
        "    for key in result:\n",
        "      if type(result[key]) is float:\n",
        "        avg_results[key] += result[key]\n",
        "  \n",
        "  for key in avg_results:\n",
        "    if(type(avg_results[key] is float)):\n",
        "      avg_results[key] /= len(some_results)\n",
        "  \n",
        "  return avg_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "##RUNNING THE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datasets = {\n",
        "    \"politifact\": fact_dataset,\n",
        "    \"snopes\": snopes_dataset\n",
        "}\n",
        "models = {\n",
        "    \"my_model\": TextualEntailmentModel,\n",
        "    \"sheena_model\": BaselineSentenceEntailment,\n",
        "    \"broke_declare\": BaselineDeclare,\n",
        "    \"real_declare\": RealDeclare\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 15\n",
        "  dense_dimension = 10\n",
        "  attention_hops = 7\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 50\n",
        "  gravity = 20\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  small_dropout = 0.3\n",
        "  medium_dropout = 0.6\n",
        "  large_dropout = 0.75\n",
        "  C = 0.3\n",
        "  is_debug = True\n",
        "  lr=0.007\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4wRSAvtABCT",
        "colab_type": "text"
      },
      "source": [
        "##CROSS VALIDATION ZONE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Kd6J8o4j6k",
        "colab_type": "text"
      },
      "source": [
        "runnin my textual entailent model :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "e51d40cf-2770-44c0-d8c5-b54f0ad6ed4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "NUM_OF_AVGS = 5\n",
        "avgs = []\n",
        "\"\"\"\n",
        "for i in range(NUM_OF_AVGS):\n",
        "  \n",
        "  \n",
        "  \n",
        "  avgs.append(results)\n",
        "\n",
        "print(process_results(list_to_dict(avgs)))\n",
        "\"\"\"\n",
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters)\n",
        "results = get_results(\"my_model\", \"politifact\", predicted_ys.cpu(), datasets[\"snopes\"].test_data)\n",
        "print(results)\n",
        "#textual_entailment_model.to(device)\n",
        "\n"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([39093, 50])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/12119 (0%)]\tLoss: 1.489453, ISvAL: False\n",
            "Train Epoch: 0 [2560/12119 (21%)]\tLoss: 1.487290, ISvAL: False\n",
            "Train Epoch: 0 [5120/12119 (43%)]\tLoss: 1.489471, ISvAL: False\n",
            "Train Epoch: 0 [7680/12119 (64%)]\tLoss: 1.486864, ISvAL: False\n",
            "Train Epoch: 0 [10240/12119 (85%)]\tLoss: 1.486735, ISvAL: False\n",
            "Average loss is: tensor(1.4871, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.500748005319149\n",
            "Train Epoch: 0 [0/1507 (0%)]\tLoss: 1.483958, ISvAL: True\n",
            "Train Epoch: 0 [256/1507 (20%)]\tLoss: 1.484970, ISvAL: True\n",
            "Train Epoch: 0 [512/1507 (40%)]\tLoss: 1.485129, ISvAL: True\n",
            "Train Epoch: 0 [768/1507 (60%)]\tLoss: 1.485257, ISvAL: True\n",
            "Train Epoch: 0 [1024/1507 (80%)]\tLoss: 1.489750, ISvAL: True\n",
            "Average loss is: tensor(1.4858, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.60703125\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/12119 (0%)]\tLoss: 1.486906, ISvAL: False\n",
            "Train Epoch: 1 [2560/12119 (21%)]\tLoss: 1.486524, ISvAL: False\n",
            "Train Epoch: 1 [5120/12119 (43%)]\tLoss: 1.486676, ISvAL: False\n",
            "Train Epoch: 1 [7680/12119 (64%)]\tLoss: 1.489207, ISvAL: False\n",
            "Train Epoch: 1 [10240/12119 (85%)]\tLoss: 1.484866, ISvAL: False\n",
            "Average loss is: tensor(1.4859, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.5073969414893617\n",
            "Train Epoch: 1 [0/1507 (0%)]\tLoss: 1.484129, ISvAL: True\n",
            "Train Epoch: 1 [256/1507 (20%)]\tLoss: 1.503973, ISvAL: True\n",
            "Train Epoch: 1 [512/1507 (40%)]\tLoss: 1.468501, ISvAL: True\n",
            "Train Epoch: 1 [768/1507 (60%)]\tLoss: 1.472543, ISvAL: True\n",
            "Train Epoch: 1 [1024/1507 (80%)]\tLoss: 1.435518, ISvAL: True\n",
            "Average loss is: tensor(1.4729, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.5890625\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/12119 (0%)]\tLoss: 1.471976, ISvAL: False\n",
            "Train Epoch: 2 [2560/12119 (21%)]\tLoss: 1.451772, ISvAL: False\n",
            "Train Epoch: 2 [5120/12119 (43%)]\tLoss: 1.453701, ISvAL: False\n",
            "Train Epoch: 2 [7680/12119 (64%)]\tLoss: 1.411260, ISvAL: False\n",
            "Train Epoch: 2 [10240/12119 (85%)]\tLoss: 1.376505, ISvAL: False\n",
            "Average loss is: tensor(1.4315, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.6490192819148937\n",
            "Train Epoch: 2 [0/1507 (0%)]\tLoss: 1.473517, ISvAL: True\n",
            "Train Epoch: 2 [256/1507 (20%)]\tLoss: 1.609652, ISvAL: True\n",
            "Train Epoch: 2 [512/1507 (40%)]\tLoss: 1.403590, ISvAL: True\n",
            "Train Epoch: 2 [768/1507 (60%)]\tLoss: 1.409162, ISvAL: True\n",
            "Train Epoch: 2 [1024/1507 (80%)]\tLoss: 1.472229, ISvAL: True\n",
            "Average loss is: tensor(1.4736, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.63046875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'model_name': 'my_model', 'dataset_name': 'politifact', 'precision': 0.6034165529120612, 'recall': 0.6040017733167184, 'accuracy': 0.6033920417482062, 'f1': 0.6028429718259447, 'auc': 0.6034165529120612}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4JkXr8fcoee",
        "colab_type": "text"
      },
      "source": [
        "WOAH WERE DOIN SOME VALIDATION\n",
        "PLEASE VALIDATE ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "240958e4-a242-42d7-9682-6dec8870d37b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu() ,datasets[\"politifact\"].test_data)"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.544 P=0.500 R=0.272 F1=0.352 AUC=0.500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.000     0.000     0.000         0\n",
            "         1.0      1.000     0.544     0.705      2855\n",
            "\n",
            "    accuracy                          0.544      2855\n",
            "   macro avg      0.500     0.272     0.352      2855\n",
            "weighted avg      1.000     0.544     0.705      2855\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0 1301]\n",
            " [   0 1554]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.27215411558669, 0.54430823117338, 0.3524608754819687)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Zfw_4Acupe",
        "colab_type": "text"
      },
      "source": [
        "JUST TESTIN HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsngYK8wcvc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "74ea10c0-b5f9-4dfa-a8c7-0c9839eafee5"
      },
      "source": [
        "test_results= batch_wise_evaluate(text_model, datasets[\"politifact\"].test_loader, Hyperparameters)\n",
        "evaluation_summary(\"textual entailment test model\", test_results.cpu(), datasets[\"politifact\"].test_data)"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: textual entailment test model\n",
            "Classifier 'textual entailment test model' has Acc=0.544 P=0.500 R=0.272 F1=0.352 AUC=0.500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.000     0.000     0.000         0\n",
            "         1.0      1.000     0.544     0.705      2855\n",
            "\n",
            "    accuracy                          0.544      2855\n",
            "   macro avg      0.500     0.272     0.352      2855\n",
            "weighted avg      1.000     0.544     0.705      2855\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0 1301]\n",
            " [   0 1554]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.27215411558669, 0.54430823117338, 0.3524608754819687)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViWwxJG5Oys",
        "colab_type": "text"
      },
      "source": [
        "running sheena's model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ngDR0NMc26u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  dropout=0\n",
        "  C = 0.3\n",
        "  is_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOunnQsb5B7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sheena_predicted_ys, model = run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"sheena model\", sheena_predicted_ys.cpu(), datasets[\"politifact\"].val_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1DvOud6d0r",
        "colab_type": "text"
      },
      "source": [
        "OK TESTING ON BROKE DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "broke_real_results, broke_predicted_ys = run_model(models[\"broke_declare\"], datasets[\"politifact\"], Hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-BrIP06dkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"broke declare model\", broke_predicted_ys.cpu(), broke_real_results.cpu(), datasets[\"politifact\"].test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZsRrUK77HAU",
        "colab_type": "text"
      },
      "source": [
        "TESTING ON REAL DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JetqyT7Imn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "declare_real_results, declare_predicted_ys =  run_model(models[\"real_declare\"], datasets[\"politifact\"], Hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCjS7Dfz7I8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"real declare model\", declare_predicted_ys.cpu(), declare_real_results.cpu(), datasets[\"politifact\"].test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hECl8V-P8noH",
        "colab_type": "text"
      },
      "source": [
        "                  \"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWBCcIDk674v",
        "colab_type": "text"
      },
      "source": [
        "##VALIDATION LAND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGG5mT_uBEGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_amount = 5\n",
        "per_avg_amount = 10\n",
        "import csv\n",
        "\n",
        "full_results = []\n",
        "avg_results = []\n",
        "processed_results = []\n",
        "\n",
        "\n",
        "\n",
        "for data_name in datasets:\n",
        "  for model_name in models:\n",
        "    some_results = []\n",
        "  \n",
        "    for per_avg_i in range(per_avg_amount):\n",
        "      results, predicted_ys = run_model(models[model_name], datasets[data_name], Hyperparameters)\n",
        "      full_results.append(get_results(model_name, data_name, predicted_ys.cpu(), results.cpu(), datasets[data_name].test_data))\n",
        "      some_results.append(get_results(model_name, data_name, predicted_ys.cpu(), results.cpu(), datasets[data_name].test_data))\n",
        "      \n",
        "    processed_results.append(process_results(list_to_dict(some_results)))\n",
        "    print(processed_results)\n",
        "      #avg_results.append(get_avgs(some_results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUR-r4M717ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for result in full_results:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWgiTDHE2tP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}