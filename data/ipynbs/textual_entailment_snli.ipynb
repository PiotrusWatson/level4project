{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "917a59d2-bd07-485f-ba15-b23d979b3694",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 13:23:03--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  17.6MB/s    in 8.4s    \n",
            "\n",
            "2019-12-19 13:23:12 (10.8 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "9daf5a05-4285-47b0-9640-a26585fc58e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 13:23:40--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-12-19 13:23:40--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-12-19 13:23:41--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.16MB/s    in 6m 30s  \n",
            "\n",
            "2019-12-19 13:30:11 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "dae568c9-174e-4fc4-e098-ee3bc538d5a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 13:30:35--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  2.20MB/s    in 2.2s    \n",
            "\n",
            "2019-12-19 13:30:39 (2.20 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "aae84c29-99f3-4c4d-ef11-d1cd6597aa60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "40bfa863-197b-4c25-d5bc-df1cae38d764"
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 14:37:45--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  2.45MB/s    in 2.2s    \n",
            "\n",
            "2019-12-19 14:37:48 (2.45 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "3baaecf5-8e3b-4f88-9d09-2e8d4c6b7399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "5eba375c-fe94-4d6f-8729-eaed00fb8afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "\n",
        "def preprocess_fact_data(facts):\n",
        "  mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique_claims = facts[\"claim_id\"].unique()\n",
        "\n",
        "#splitting the claims\n",
        "  train_claims, test_claims = train_test_split(unique_claims, test_size=0.2, random_state=8)\n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_claims)]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_claims)]\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 150\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with_sources = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "if (with_sources):\n",
        "#AND THE SAME FOR FACT CHECKING (CURRENTLY SET UP KINDA RIGIDLY FOR FIRST TEST :())\n",
        "  train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "  train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "\n",
        "else:\n",
        "  train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    #callback()\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    \n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, new_hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, _ = self.hypothesis_processor(hypothesis, new_hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding).reshape(self.hp.batch_size, -1)\n",
        "    return self.MLP(factorised_mush), better_mush(premise_attention, hypothesis_attention)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params \n",
        "\n",
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies\n",
        "\n",
        "def evaluate(model, test_premise, test_hypothesis, test_y):\n",
        "\n",
        "  model.hp.batch_size = test_hypothesis.shape[0] #why\n",
        "  model.initial_hidden_state = model.init_hidden()\n",
        "\n",
        "  premise_variable = Variable(torch.from_numpy(test_premise).type(torch.LongTensor)).cuda()\n",
        "  hypothesis_variable = Variable(torch.from_numpy(test_hypothesis).type(torch.LongTensor)).cuda()\n",
        "  y_actual_variable = Variable(torch.from_numpy(test_y).type(torch.DoubleTensor)).cuda()\n",
        "  y_predicted = model(premise_variable, hypothesis_variable)\n",
        "  y_predicted_rounded = torch.round(y_predicted.type(torch.DoubleTensor).squeeze(1))\n",
        "\n",
        "  test_data_count = premise_variable.size(0)\n",
        "\n",
        "\n",
        "\n",
        "  total_accuracy = torch.eq(torch.argmax(y_predicted,1), y_actual_variable).data.sum()\n",
        "  average_accuracy = total_accuracy.data.cpu().numpy().astype(int)/float(test_data_count)\n",
        "  return average_accuracy, torch.argmax(y_predicted,1)\n",
        "\n",
        "\n",
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "    \n",
        "  average_accuracy = total_accuracy.data.cpu().numpy()/float(batch_count * test_loader.batch_size)\n",
        "  return average_accuracy, torch.cat(all_results, 0)\n",
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)\n",
        "  \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 150\n",
        "  dense_dimension = 300\n",
        "  attention_hops = 30\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 450\n",
        "  num_classes = 1\n",
        "  epochs = 8\n",
        "  C = 0.1\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "02c71247-d56a-400f-e846-c85355d79699",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",x_tokeniser.word_to_id,300)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34370\n",
            "torch.Size([34370, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "462f792e-bcfd-47da-f61c-8a8be89f47f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, glove_embeddings).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adagrad(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n",
        "\n",
        "print(torch.cuda.memory_allocated)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.236691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.236415\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.239891\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.241125\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.236493\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.233588\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.241109\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.248661\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.242655\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.234992\n",
            "Average loss is: tensor(1.2573, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5112894917582418\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.239099\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 1.233493\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 1.482090\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 1.239736\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 1.244819\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 1.214971\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 1.168440\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 1.184986\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 1.099661\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 1.289108\n",
            "Average loss is: tensor(1.2288, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5764938186813187\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 1.344956\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 1.053732\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 1.022948\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 1.157705\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 1.014936\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 1.062422\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 1.051178\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 1.236914\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 0.801475\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 0.886970\n",
            "Average loss is: tensor(0.9940, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.7942994505494505\n",
            "Running EPOCH: 4\n",
            "Train Epoch: 3 [0/23454 (0%)]\tLoss: 0.985822\n",
            "Train Epoch: 3 [2560/23454 (11%)]\tLoss: 0.902748\n",
            "Train Epoch: 3 [5120/23454 (22%)]\tLoss: 0.770036\n",
            "Train Epoch: 3 [7680/23454 (33%)]\tLoss: 1.027191\n",
            "Train Epoch: 3 [10240/23454 (44%)]\tLoss: 0.832792\n",
            "Train Epoch: 3 [12800/23454 (55%)]\tLoss: 0.854884\n",
            "Train Epoch: 3 [15360/23454 (66%)]\tLoss: 0.765783\n",
            "Train Epoch: 3 [17920/23454 (77%)]\tLoss: 1.043764\n",
            "Train Epoch: 3 [20480/23454 (88%)]\tLoss: 0.664230\n",
            "Train Epoch: 3 [23040/23454 (99%)]\tLoss: 0.648152\n",
            "Average loss is: tensor(0.7704, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9107142857142857\n",
            "Running EPOCH: 5\n",
            "Train Epoch: 4 [0/23454 (0%)]\tLoss: 0.643952\n",
            "Train Epoch: 4 [2560/23454 (11%)]\tLoss: 0.625999\n",
            "Train Epoch: 4 [5120/23454 (22%)]\tLoss: 0.637354\n",
            "Train Epoch: 4 [7680/23454 (33%)]\tLoss: 0.937118\n",
            "Train Epoch: 4 [10240/23454 (44%)]\tLoss: 0.699313\n",
            "Train Epoch: 4 [12800/23454 (55%)]\tLoss: 0.620993\n",
            "Train Epoch: 4 [15360/23454 (66%)]\tLoss: 0.562584\n",
            "Train Epoch: 4 [17920/23454 (77%)]\tLoss: 0.649454\n",
            "Train Epoch: 4 [20480/23454 (88%)]\tLoss: 0.577836\n",
            "Train Epoch: 4 [23040/23454 (99%)]\tLoss: 0.578108\n",
            "Average loss is: tensor(0.6430, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9666037087912088\n",
            "Running EPOCH: 6\n",
            "Train Epoch: 5 [0/23454 (0%)]\tLoss: 0.569981\n",
            "Train Epoch: 5 [2560/23454 (11%)]\tLoss: 0.567859\n",
            "Train Epoch: 5 [5120/23454 (22%)]\tLoss: 0.607368\n",
            "Train Epoch: 5 [7680/23454 (33%)]\tLoss: 0.898217\n",
            "Train Epoch: 5 [10240/23454 (44%)]\tLoss: 0.606875\n",
            "Train Epoch: 5 [12800/23454 (55%)]\tLoss: 0.571039\n",
            "Train Epoch: 5 [15360/23454 (66%)]\tLoss: 0.551055\n",
            "Train Epoch: 5 [17920/23454 (77%)]\tLoss: 0.565300\n",
            "Train Epoch: 5 [20480/23454 (88%)]\tLoss: 0.551334\n",
            "Train Epoch: 5 [23040/23454 (99%)]\tLoss: 0.555882\n",
            "Average loss is: tensor(0.5907, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9865212912087912\n",
            "Running EPOCH: 7\n",
            "Train Epoch: 6 [0/23454 (0%)]\tLoss: 0.550378\n",
            "Train Epoch: 6 [2560/23454 (11%)]\tLoss: 0.550437\n",
            "Train Epoch: 6 [5120/23454 (22%)]\tLoss: 0.553040\n",
            "Train Epoch: 6 [7680/23454 (33%)]\tLoss: 0.856935\n",
            "Train Epoch: 6 [10240/23454 (44%)]\tLoss: 0.556280\n",
            "Train Epoch: 6 [12800/23454 (55%)]\tLoss: 0.553795\n",
            "Train Epoch: 6 [15360/23454 (66%)]\tLoss: 0.548734\n",
            "Train Epoch: 6 [17920/23454 (77%)]\tLoss: 0.548710\n",
            "Train Epoch: 6 [20480/23454 (88%)]\tLoss: 0.549361\n",
            "Train Epoch: 6 [23040/23454 (99%)]\tLoss: 0.548533\n",
            "Average loss is: tensor(0.5650, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9945054945054945\n",
            "Running EPOCH: 8\n",
            "Train Epoch: 7 [0/23454 (0%)]\tLoss: 0.548076\n",
            "Train Epoch: 7 [2560/23454 (11%)]\tLoss: 0.548019\n",
            "Train Epoch: 7 [5120/23454 (22%)]\tLoss: 0.548594\n",
            "Train Epoch: 7 [7680/23454 (33%)]\tLoss: 0.637137\n",
            "Train Epoch: 7 [10240/23454 (44%)]\tLoss: 0.549141\n",
            "Train Epoch: 7 [12800/23454 (55%)]\tLoss: 0.551025\n",
            "Train Epoch: 7 [15360/23454 (66%)]\tLoss: 0.548442\n",
            "Train Epoch: 7 [17920/23454 (77%)]\tLoss: 0.548149\n",
            "Train Epoch: 7 [20480/23454 (88%)]\tLoss: 0.548529\n",
            "Train Epoch: 7 [23040/23454 (99%)]\tLoss: 0.547775\n",
            "Average loss is: tensor(0.5520, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9988839285714286\n",
            "<function memory_allocated at 0x7f11378dc048>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "42920a50-d2da-44a8-bb3c-38b3b0380450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3gVZdrH8e+dRu8dQu9FikaxoCCI\nCiqIve5iQ3QtrLuu9bW7q6urq2LDAmsDEREVCxbEBhZQehGkhi5FQWqS+/1jJiHEAAdIMim/z3XN\ndaY8M3OfkwO588xTzN0REREREQGIizoAERERESk8lByKiIiISBYlhyIiIiKSRcmhiIiIiGRRcigi\nIiIiWZQcioiIiEgWJYciRYyZNTIzN7OEqGMREZHiR8mhiIiIiGRRcihSiKl2UERECpqSQylRzOwm\nM1tuZpvMbJ6Z9Qj3DzOz+7KV62Zmqdm2F5vZLWY228w2mNlQMyu9h3v0N7OvzOzhsOwiM+uV7Xgl\nM3vBzFaGsdxnZvHZzv3azB41s3XAXWYWH17rFzNbCJySy/0Whu9pkZldmLefmoiIlCRKDqXEMLOW\nwDXA4e5eATgJWLwfl7gwPKcp0AK4fS9lOwPzgOrAv4EXzMzCY8OANKAZ0Ak4Ebg8x7kLgVrA/cAV\nwKlh2RTgrGzvqRzwONArfE9HA1P34z2JiIjsRsmhlCTpQCmgjZkluvtid/95P84f7O7L3H09QdJ2\n/l7KLnH359w9HfgfUAeoZWa1gN7AIHf/3d3XAI8C52U7d4W7P+Huae6+FTgH+G+2e/8rx70ygHZm\nVsbdV7r7rP14TyIiIrtRciglhrsvAAYBdwFrzGyEmdXdj0ssy7a+BNjbuauy3XdLuFoeaAgkAivN\nbKOZbQSeBWru4T6E98l578xr/w6cCwwMr/membWK7e2IiIj8kZJDKVHc/TV370KQpDnwYHjod6Bs\ntqK1czm9frb1BsCKAwhhGbAdqO7ulcOloru3zR5mjnNW5nLvXYXdx7l7T4LaybnAcwcQl4iICKDk\nUEoQM2tpZt3NrBSwDdhK8EgWgnZ6vc2sqpnVJqhhzOkvZpZsZlWB24DX9zcGd18JfAT8x8wqmlmc\nmTU1s657OW0kcF147yrAzdneUy0z6xu2PdwObM72nkRERPabkkMpSUoBDwC/EDz2rQncEh57GZhG\n0EHlI3JP/F4Ljy0Efgbuy6VMLP4EJAGzgQ3AKIJavz15DhgXxvcDMDrbsTjgBoJazPVAV+CqA4xL\nREQEc8/5BEtEcjKzxcDl7v5J1LGIiIjkJ9UcioiIiEgWJYciIiIikkWPlUVEREQki2oORURERCRL\nQtQB5IXq1at7o0aNog5DRKRImTJlyi/uXiPqOESkcCkWyWGjRo2YPHly1GGIiBQpZrZk36VEpKTR\nY2URERERyaLkUERERESyKDkUERERkSzFos2hiBRfO3fuJDU1lW3btkUdSpFVunRpkpOTSUxMjDoU\nESkClByKSKGWmppKhQoVaNSoEWYWdThFjruzbt06UlNTady4cdThiEgRoMfKIlKobdu2jWrVqikx\nPEBmRrVq1VTzKiIxU3IoIoWeEsODo89PRPZHyX6s/Mt8mD4SarWBmm2galOIL9kfiYiIiJRsJTsT\nWjUdvnwYPCPYjk+C6i3DZLF1kDDWbAOVkkF/eYuUaGPGjKFfv37MmTOHVq1aRR2OiEi+KdnJYbsz\noWVvWDsP1syBNbODZfFXMP31XeVKVQyTxdZQs23wWqstlK0aXewiUqCGDx9Oly5dGD58OHfffXe+\n3CM9PZ34+Ph8ubaISKxKdnIIkFgG6nYMluy2boA1c2HNrCBxXD0bZr0FU4btKlO+1q7axczaxhqt\nIKlcgb4FEclfmzdv5quvvuKzzz7jtNNOy0oOH3zwQV555RXi4uLo1asXDzzwAAsWLGDgwIGsXbuW\n+Ph43njjDZYtW8bDDz/M2LFjAbjmmmtISUmhf//+NGrUiHPPPZePP/6Yf/zjH2zatIkhQ4awY8cO\nmjVrxssvv0zZsmVZvXo1AwcOZOHChQA8/fTTfPjhh1StWpVBgwYBcNttt1GzZk2uv/76aD4oESkW\nlBzuSZkq0PCoYMnkDptWBrWLq2eHtY2zYPILkJbZE9CgSqOgZjH7o+lqTSFeY4yJHIy7353F7BW/\n5ek129StyJ2ntd1rmbfffpuTTz6ZFi1aUK1aNaZMmcKaNWt4++23+fbbbylbtizr168H4MILL+Tm\nm2+mX79+bNu2jYyMDJYtW7bX61erVo0ffvgBgHXr1nHFFVcAcPvtt/PCCy9w7bXXct1119G1a1fe\neust0tPT2bx5M3Xr1uWMM85g0KBBZGRkMGLECL777rs8+FREpCRTcrg/zKBi3WBpdsKu/RnpsH7R\nrsfSmcnjvPdztGdsESaLrXclj5Xqqz2jSCE3fPjwrNq48847j+HDh+PuXHLJJZQtWxaAqlWrsmnT\nJpYvX06/fv2AYPDpWJx77rlZ6zNnzuT2229n48aNbN68mZNOOgmA8ePH89JLLwEQHx9PpUqVqFSp\nEtWqVePHH39k9erVdOrUiWrVquXZ+xaRkknJYV6Ii4fqzYKlTZ9d+3dug1+ytWdcPRuWTIQZI3eV\nSaqwqz1jVm1jWyin/+BFctpXDV9+WL9+PePHj2fGjBmYGenp6ZgZZ599dszXSEhIICMjI2s755iD\n5crtaorSv39/xowZQ4cOHRg2bBgTJkzY67Uvv/xyhg0bxqpVq7j00ktjjklEZE+UHOanxNJQp0Ow\nZLd1I6ydC6tn7UocZ78NP/xvV5lyNXcNsZO1qD2jSEEbNWoUF198Mc8++2zWvq5du1KpUiWGDh3K\nhRdemPVYuWrVqiQnJzNmzBhOP/10tm/fTnp6Og0bNmT27Nls376drVu38umnn9KlS5dc77dp0ybq\n1KnDzp07efXVV6lXrx4APXr04Omnn2bQoEFZj5UrVapEv379uOOOO9i5cyevvfZagXwmIlK8KTmM\nQpnK0ODIYMnkDptWZXs0PSdIHicPhbStYSGDo/4CJ90fSdgiJdHw4cO56aabdtt35plnMmfOHPr0\n6UNKSgpJSUn07t2bf/7zn7z88stceeWV3HHHHSQmJvLGG2/QpEkTzjnnHNq1a0fjxo3p1KnTHu93\n77330rlzZ2rUqEHnzp3ZtGkTAI899hgDBgzghRdeID4+nqeffpqjjjqKpKQkjj/+eCpXrqyeziKS\nJ8zdo47hoKWkpPjkyZOjDiN/ZKTDhsVBwjjrLZj5Jpw3HFr1jjoykQIxZ84cWrduHXUYhVZGRgaH\nHnoob7zxBs2bN99judw+RzOb4u4p+R2jiBQtmj6vsIuLD3o6tz4NTn8Gah8C71wLm9dEHZmIRGz2\n7Nk0a9aMHj167DUxFBHZH3qsXJQkJMEZz8GzXeHta+CC19XTWaQEa9OmTda4hyIieUU1h0VNzdbQ\n826YP273AblFRERE8kCBJodm9qKZrTGzmXs4fqGZTTezGWY20cw65FauxDviSmjSDcbdCut+jjoa\nERERKUYKuuZwGHDyXo4vArq6+yHAvcCQggiqyImLg9OfDgbWHj0A0tOijkhERESKiQJNDt39C2D9\nXo5PdPcN4eY3QHKBBFYUVawLpz4CyyfDlw9HHY2IiIgUE4W5zeFlwAd7OmhmA8xssplNXrt2bQGG\nVYi0OxMOOQc+/zekFtOhfEQKgfLly0cdgohIgSmUyaGZHU+QHN60pzLuPsTdU9w9pUaNGgUXXGHT\n+yGoUCd4vLzj96ijERERkSKu0CWHZtYeeB7o6+7roo6n0CtTGfo9A+sXwrjboo5GpMRYvHgx3bt3\np3379vTo0YOlS5cC8MYbb9CuXTs6dOjAcccdB8CsWbM44ogj6NixI+3bt2f+/PlRhi4isleFapxD\nM2sAjAYudvefoo6nyGh8LBx9DUx8AlqcDC331udHpAj74GZYNSNvr1n7EOj1wH6fdu211/LnP/+Z\nP//5z7z44otcd911jBkzhnvuuYdx48ZRr149Nm7cCMAzzzzD9ddfz4UXXsiOHTtIT0/P2/cgIpKH\nCnoom+HAJKClmaWa2WVmNtDMBoZF7gCqAU+Z2VQzU0O6WHX/P6jVDt65BjaX0DaYIgVo0qRJXHDB\nBQBcfPHFfPXVVwAcc8wx9O/fn+eeey4rCTzqqKP45z//yYMPPsiSJUsoU6ZMZHGLiOxLgdYcuvv5\n+zh+OXB5AYVTvCSUgjOGwJBu8O51cN5rmj1Fip8DqOEraM888wzffvst7733HocddhhTpkzhggsu\noHPnzrz33nv07t2bZ599lu7du0cdqohIrgpdm0M5CLXaQo87Yd778MNLUUcjUqwdffTRjBgxAoBX\nX32VY489FoCff/6Zzp07c88991CjRg2WLVvGwoULadKkCddddx19+/Zl+vTpUYYuIrJXharNoeSB\nI68Optb78BZo1AWqNY06IpEib8uWLSQn7xp29YYbbuCJJ57gkksu4aGHHqJGjRoMHToUgBtvvJH5\n8+fj7vTo0YMOHTrw4IMP8vLLL5OYmEjt2rW59dZbo3orIiL7ZO4edQwHLSUlxSdPVvPELL+mwtNH\nQ/UWcMmHEK+/AaTomjNnDq1bt446jCIvt8/RzKa4e0pEIYlIIaXHysVRpWQ45RFI/R6+eiTqaERE\nRKQIUXJYXB1yFrQ7CyY8AMunRB2NiIiIFBFKDouzUx6GCrVh9JWwY0vU0YgcsOLQ/CVK+vxEZH8o\nOSzOylSB05+GdfPh4/+LOhqRA1K6dGnWrVunBOcAuTvr1q2jdOnSUYciIkWEeioUd026wlHXwKTB\nwewpzXtGHZHIfklOTiY1NZW1azW4+4EqXbr0br2tRUT2RslhSdD9/+Dn8fD2X+CqSVCuWtQRicQs\nMTGRxo0bRx2GiEiJocfKJUFi6WD2lK0bgtlT9HhORERE9kDJYUlR+xDofjvMHQtTX406GhERESmk\nlByWJEddAw27wAc3wfpFUUcjIiIihZCSw5IkLh76PQ0WB28NhIz0qCMSERGRQkbJYUlTuQH0fhiW\nfQNfPRp1NCIiIlLIKDksidqfA237wYR/wYofo45GREREChElhyWRWTD3crmaMHqAZk8RERGRLEoO\nS6qyVeH0p+CXn+CTO6OORkRERAoJJYclWdPjofNV8N0QWPBJ1NGIiIhIIVCgyaGZvWhma8xs5h6O\ntzKzSWa23cz+XpCxlVgn3Ak1WsGYv8CW9VFHIyIiIhEr6JrDYcDJezm+HrgOeLhAohFILANnPAdb\n1sHYQZo9RUREpIQr0OTQ3b8gSAD3dHyNu38P7Cy4qIQ67aH7bTD7bZg2IupoREREJEJFts2hmQ0w\ns8lmNnnt2rVRh1P0HX0dNDga3r8RNiyJOhoRERGJSJFNDt19iLunuHtKjRo1og6n6IuLh37PBOua\nPUVERKTEKrLJoeSDKg2h979h6USY+HjU0YiIiEgElBzK7jqcD637wPj7YeW0qKMRERGRAlbQQ9kM\nByYBLc0s1cwuM7OBZjYwPF7bzFKBG4DbwzIVCzLGEs8MTnsMylYLZk/ZuTXqiERERKQAJRTkzdz9\n/H0cXwUkF1A4sidlq8LpT8IrZ8Ind0OvB6KOSERERAqIHitL7pqdAEcMgG+fhp/HRx2NiIiIFBAl\nh7JnJ9wN1VvAmKs1e4qIiEgJoeRQ9iypbDB7yu9r4b0bNHuKiIhICaDkUPaubkfodgvMegumj4w6\nGhEREclnSg5l37r8FeofCe//HTYujToaERERyUdKDmXf4uLhjGfBM+CtqzR7ioiISDGm5FBiU6UR\n9HoQlnwFk56MOhoRERHJJ0oOJXYdL4RWp8L4e2HVzKijERERkXyg5FBiZwanPQ5lqsDoK2Dntqgj\nEhERkTym5FD2T7lq0PdJWDM7qEEUERGRYkXJoey/5j3h8Mth0mBY+HnU0YiIiEgeUnIoB6bnvVCt\nGYy5CrZuiDoaEQl9+OGHtGzZkmbNmvHAA3+cF33JkiX06NGD9u3bA7Q0s6z57M3sQTObGS7nZtvf\nw8x+MLOpZvaVmTUL9zcws8/M7Eczm25mvcP9iWb2PzObYWZzzOyWcH9pM/vOzKaZ2SwzuzvbPbqH\n95gZnpsQ7r8wvPYMM5toZh2ynfPX8DozzWy4mZUO9w8zs0VhvFPNrGO4/8Zs+2aaWbqZVQ2PvWhm\na8ws1wbVZvY3M3Mzq34QcZmZ3W9mP4Wfy3X7+eMVKRjuXuSXww47zCUCqZPd767q/salUUciIu6e\nlpbmTZo08Z9//tm3b9/u7du391mzZu1W5qyzzvJhw4a5uzswD3g5WOUU4GMgASgHfA9UDI/9BLQO\n168GhoXrQ4CrwvU2wOJw/QJgRLheFlgMNAIMKB/uTwS+BY4kqKhYBrQIj90DXBauHw1UCdd7Ad+G\n6/WARUCZcHsk0D9cHwac5Xv5vQGcBozPtn0ccCgwM5ey9YFxwBKg+kHEdQnwEhAXbtfcW4xatES1\nqOZQDly9w6DrTTBzFMwYFXU0IiXed999R7NmzWjSpAlJSUmcd955vP3227uVmT17Nt27d8/c3AT0\nDdfbAF+4e5q7/w5MB04OjzlQMVyvBKyIYX+5sPavDLAD+M0Dm8MyieHiQDVgh7v/FB77GDgTwN0n\nunvm44lvgKyaToJEtkx4n7LZ7h+L84HhmRvu/gWwp0nkHwX+EcaaWf5A4roKuMfdM8JrrNmPeEUK\njJJDOThdboDkw2HsDfBratTRiJRoy5cvp379+lnbycnJLF++fLcyHTp0YPTo0ZmblYEKZlYNmAac\nbGZlw0enxxPUmAFcDrxvZqnAxUDm8+q7gIvC/e8D14b7RwG/AyuBpcDD7r4ewMzizWwqsAb42N2/\nBX4BEswsJTz/rGz3zu4y4AMAd18OPBxefyXwq7t/lK3s/eFj30fNrFT2i5hZWYLE981c7kGOsn2B\n5e4+bS/FYo2rKXCumU02sw/MrPm+7i8SBSWHcnDiE+CMIZCRBm8NhIyMqCMSkb14+OGH+fzzz+nU\nqRNABWA5kB4mMO8DEwlq1CYBmdMh/RXo7e7JwFDgkXD/+QSPmJOB3sDLZhYHHBGeWxdoDPzNzJoA\nuHu6u3ckqGk7wszaubsD5wGPmtl3BDWau03FZGbHEyRhN4XbVQhqPRuH9ylnZheFxW8BWgGHA1Uz\nz8nmNODrzIR1T8Ik8lbgjr2U2Z+4SgHb3D0FeA54cW/3F4mKkkM5eFWbwMn/gsVfwjdPRR2NSIlV\nr149li1blrWdmppKvXr1ditTt25dRo8ezY8//ghBYoi7bwxf73f3ju7ek6B94E9mVgPoENbwAbxO\n0N4OgqRoZHjuJKA0UJ2gzeGH7r4zfHT6NZBZK0i2e35G+Oja3Se5+7HufgTwBUE7RwDMrD3wPNDX\n3deFu08AFrn7WnffCYzOjMvdV4aPsLcTJLNH5PioziPbI+W9aEqQ5E0zs8UECe0PZlb7QOICUsNt\ngLeA9jHEIFLgCjQ5jKE3mJnZ42a2IHwccGhBxicH4dA/Qcve8OndsHpW1NGIlEiHH3448+fPZ9Gi\nRezYsYMRI0bQp0+f3cr88ssvZOyq4a9DWHsVPu6tFq63J0hcPgI2AJXMrEV4Tk9gTri+FOgRntOa\nIDlcG+7vHu4vR9DpZK6Z1TCzyuH+MuG15obbNcPXUgS1cM+E2w0IEqqLs7VJzLz3keFjcAvjmBOe\nUyd8NeB0IOt3jplVAroCuzfGzIW7z3D3mu7eyN0bESR3h7r7qgOJCxhD8LieMIbs54kUGgVdcziM\nXQ2cc9MLaB4uA4CnCyAmyQuZs6eUrgRvXgFp26OOSKTESUhIYPDgwZx00km0bt2ac845h7Zt23LH\nHXfwzjvvADBhwgRatmxJixYtIOg4cX94eiLwpZnNJuiFfFHYOSUNuAJ408ymEbQ5vDE852/AFeH+\n4QS9ch14EihvZrMIej0PdffpBMnoZ2Y2Pdz/sbuPDa91o5nNIegI8667jw/330HQYeWpcAiayQBh\nTeYo4AdgBsHvsyHhOa+a2Yxwf3XgvmwfUz/go7DTTRYzy3yU3tLMUs3ssn183AcS1wPAmWFs/yJo\nyylS6Fjw77gAb2jWCBjr7u1yOfYsMMHdh4fb84Bu7r5yb9dMSUnxyZMn50O0st9+GgevnQNHXwsn\n3rfv8iJyQDIynB3pGZhBqYT4A7qGmU0J27+JiGRJiDqAHOoRjHWVKTXc94fk0MwGENQu0qBBgwIJ\nTmLQ4iQ47BKYOBianwSNj406IpGD4u6kZTg70zPYkRYs29My2BFu77Y/23rW/vRd52QvuyO39Rj3\n7UzPYGd68If9Vd2actPJrSL+lESkOClsyWHM3H0IYVV9SkpKwVZ/yt6ddD8s+iKYPWXgV1CmctQR\nSQmQlp7B7zvS2bIjjd+3p/H79vTgdUfmaxpbtqezeXsaW3aksXl7jrLh+tYd6exIDxPAMCHLywcs\nCXFGUkJcsMTHkRgfR6nM7XBfUkIc5UolZO0rFb/reGL87uUOa1gl74ITESHG5NDMxgNXu/vcXI61\nAJ5x9+5/PHO/LWf3sa2Sw31SlCSVgzOegxdPhHeuhXNeCtokioTcnW07M7Ilamls2REmbtkStV37\ndiVzmWVzJnzb02IfRqlMYjzlSiVQrlQ85ZKC16rlkqhfpSxlkuKzkq9Se0jIkhKCY4nxu+/brUxu\n++PjiIvTvwURKdxirTnsxq5R8HOqQNDrKi+8A1xjZiOAzgSDh+61vaEUUsmHQY874OM7YMpQSLk0\n6ogkn6WlZ7Dy120s37iV5Ru2Zr2u+HUrG7fs3JXwhclfRoy1cQlxRrlSCZQvlUDZpF1JXdVyZbP2\nBa9hslcqIVgyyyYlULZUfFbZskkJxCtBExHZo/15rLyn/8qbApv3cGw3YW+wbkD1cET9Owl6yOHu\nzxAMwNobWABsIZiHUoqqo66FhZ/Dh7dA/c5Qq23UEclB2LYz/Q+JX+Zr6oYtrPpt2x8SvurlS1Gv\nShmql0+iQamylN8tUUugfKn4MKkLErtgX7aEr1T8AXe2EBGRA7PH3spmdgm7krNjCIYX2JSjWBmg\nHfCpu5+aX0Hui3orF2Kb18DTx0CZKjDgs+CRsxRKv23bGSZ6W1m+YUuQ+GVLAn/ZvGO38vFxRu2K\npalXpQzJlctQr0oZ6mV7rVu5DKUTldgVZuqtLCK52VvNYQa7pi+yHNuZ1hGMRfhg3ocmxUL5msH0\nei/3gw9vhj5PRB1RieTu/LJ5R7Zkb0tW0pcavm7alrbbOaUS4rKSvdZ1Ku6W+NWrUobaFUuTEK9J\nlkREips9Jofu/j/gfwBm9hlwVW4dUkT2qenx0OWv8NUj0KQbtDsz6oiKnbT0DFZv2r5b4pea4/Fv\nzg4bFUolZCV7RzSuSnKVMtSrXDZrX/XySZg6EomIlDgxtTl09+P3XUpkL46/FRZ/Be8OgrqHQtXG\nUUdUJGVkON8vXs/XC34hdcNWUsPkb9Vv20jP0eCvevkk6lUuQ6s6FejRumZY41c2q+avUpnEiN6F\niIgUZjF3SDGzigSdRRoQzJ+Znbv7vXkZmBQz8Ylw5vPw7LHw5mVwyYeQkBR1VEWCu/Pjso28O20F\n789YyerfthNnZLX3O7xRlbC2b1etX73KZSiTpPZ+IiKy/2Id5/AY4F1gT6MZO6DkUPauSsOgzeHI\nP8H4e+FEfWX2xN2Zufw3xk5fwdjpK1m+cStJ8XF0bVmDU9vX4YTWtShXqsiOYS8iIoVYrL9d/gss\nJph8fYa779h7cZE9aNM3GPNw4uPQuCs0PyHqiAoNd2fe6k2MnbaSsdNXsHjdFhLijGObV+eGni3o\n2bYWFUvrUbCIiOSvWJPD1sA57j4lP4OREuKkf8LSb+CtK+Gqr6FC7agjitSCNZuzaggXrNlMnMHR\nTaszsGtTTmpbmyrl9PhdREQKTqzJ4VKgVH4GIiVIYhk4aygM6QajB8DFYyCuZA2JsnTdFt6dvoJ3\np61g7qpNmMHhjapy7+nt6NWuNtXL65+biIhEI9bk8G7gZjP71N1/y8+ApISo2Qp6/zuYe/nrR+HY\nv0UdUb5bvnEr74U1hNNTfwXg0AaVuePUNpzSvg61Kubs5yUiIlLwYk0OTwVqAYvMbBKwPsdxd/c/\n52lkUvx1uhgWToDx90PDLtCgc9QR5bk1v23jvRkrGTt9JVOWbADgkHqVuLV3K3ofUofkKmUjjlBE\nRGR3sSaHXQh6JP8G5DZB7p7mXRbZMzM49VFInRwMbzPwy2CavSLul83b+WDmKsZOW8F3i9fjDq1q\nV+DGk1pyyiF1aFRdUwiKiEjhFesg2BqxWPJH6UpB+8MXTwweMZ/zcpA0FjEbt+xg3KxVjJ2+kok/\nryM9w2laoxzXdW/OaR3q0KxmhahDFBERiYkGSpPoJR8GPe6Ej/8PJr8Ah18edUQx+W3bTj6etZqx\n01fw1YJf2JnuNKhaloFdm3Bq+7q0ql1B08+JiEiRE+sg2A32Vcbdlx58OFJiHXUNLPocPrwV6h8J\ntdtFHVGutuxI45M5axg7bQUTflrLjrQM6lUuwyXHNObU9nU4pF4lJYQiIlKkxVpzuJh9tyvUXF1y\n4OLi4PRn4JljYNSlMOAzSCocbfO27Uxnwrw1vDttJZ/OXc22nRnUrFCKC45owGkd6tKpfmXi4pQQ\niohI8RBrcngpf0wOqxH0Ym6Mps6TvFC+BpwxBF46HT64CfoOjiyU7WnpfPnTL4ydvoKPZ6/m9x3p\nVCuXxFmHJXNq+7oc3qgq8UoIRUSkGIq1Q8qwPRx6xMxeBprkWURSsjXpBsfeAF/+J1g/5KwCu/XO\n9Awm/ryOd6etYNysVWzalkalMomc2r4up3Woy5FNqpIQX7IG6xYRkZInLzqkvAIMBW7Pg2uJQLdb\nYPFX8O4gqHcoVM3fvz227Ejj0Y9/YtSUVDZs2UmFUgn0bFuL09rX5Zhm1UlKUEIoIiIlR14khzWB\nmKd2MLOTgccI2ig+7+4P5DjeEHgRqEEw2PZF7p6aB3FKURGfCGc+D890CdofXvoRJOTP/MIzl//K\ndSN+ZOHa3zmlfR36dKhL11rpPJoAACAASURBVBY1KJ2oJrQiIlIyxdpb+bhcdicB7YBbgC9jvE48\n8CTQE0gFvjezd9x9drZiDwMvufv/zKw78C/g4liuL8VI5QbQZzCMvBjG3wMn3penl0/PcJ77ciH/\n+Wge1cqV4tXLO3NMs+p5eg8REZGiKNaawwn8sUNKZmv8z4GrYrzOEcACd18IYGYjgL5A9uSwDXBD\nuP4ZMCbGa0tx06ZPMObhxCegcVdo3jNPLrti41ZuGDmVbxaup1e72vzrjEOoXDZ/aiZFRESKmliT\nw+Nz2bcNWOLuq/bjfvWAZdm2U4GcE+pOA84gePTcD6hgZtXcfV32QmY2ABgA0KDBPodhlKLqxPtg\nySR460oY+DVUrHNQlxs7fQW3jp5BWobz77Pac/ZhyRqXUEREJJtYeyt/nt+BZPN3YLCZ9Qe+AJYD\n6bnENAQYApCSkqK5nYurxDJw9lAY0g3eGgAXj4G4/W8PuGnbTu56ZzZv/pBKx/qV+e+5HTXHsYiI\nSC72q0OKmbUDugJVCTqLTHD3WftxieVA/WzbyeG+LO6+gqDmEDMrD5zp7hv3J04pZmq0hF7/hneu\nga8egeNu3K/TpyzZwKDXf2T5hq1c170Z1/ZoTqKGpBEREclVrB1SEoBhwPnsamsI4Gb2GtDf3f9Q\nu5eL74HmZtaYICk8D7ggx72qA+vdPYOgs8uLscQoxVyni2DhBPjsX9CwCzQ8ap+npKVnMPizBTwx\nfgF1KpVm5JVHkdKoav7HKiIiUoTFWn1yJ3AOcAfBjChlwtc7gHPD131y9zTgGmAcMAcY6e6zzOwe\nM+sTFusGzDOzn4BawP0xxijFmRmc+ihUrg9vXg5b1u+1+NJ1Wzjn2Un895P59O1Ql/evP1aJoYiI\nSAzMfd/N9cxsETDU3e/J5dgdwCXu3jgf4otJSkqKT548OarbS0Fa/gO8cCK0OAnOfSVIGrNxd0b/\nsJw735mFGdx3ejv6dqwXUbAihZuZTXH3lKjjEJHCJdaaw7rAxD0cmxgeF8l/9Q6FE+6EuWPh++d3\nO/Trlp1cM/xH/vbGNNrUrcgH1x+rxFBERGQ/xdohZQVwDPBJLseODo+LFIwj/wILP4dxt0GDI6H2\nIUz6eR03jJzK2k3bufGklgzs2pT4OA1RIyIisr9iTQ5fBW4zs4xwfSVQm6BDyW3Ag/kTnkgu4uLg\n9KfhmS74G5fwSOPnGPz1ChpVK8foq4+mfXLlqCMUEREpsmJ9rHwXMAq4G5gPbAYWEHQWGQX8oS2i\nSL4qX4MVPR7D1y2g/jd3ct7h9Xnvui5KDEVERA5SrINgpwEXmNn9wHHsGufwi/0c51DkoLk7r323\nlHvHOn+LP4MrEt7knGbzIKl91KGJiIgUefs1CHaYCCoZlMis27ydm96cwSdzVnNs8+r0OfNxeHM5\njP1r0FmlWtOoQxQRESnS9neGlPoEM5yUznnM3cfnVVAiuZkwbw03jprOr1t28n+ntuGSoxsRF2dw\n5vPwTBcYdSlc9jEkJEUdqoiISJEV6wwpTQg6ohyRuSt89XDdgf2f8FYkBtt2pvPAB3MZNnExLWqV\n56VLj6B1nYq7ClSuD30Hw+sXwad3w0kaN11ERORAxVpz+DzQABgEzAV25FtEItnMXfUb1w+fyrzV\nm+h/dCNu7tWK0om5/B3S+jQ4/AqYNBgaHxcMki0iIiL7Ldbk8HCC+ZPfzM9gRDJlZDhDJy7mwQ/m\nUrFMIsMuOZxuLWvu/aQT74Olk2DMVTDwK6iosdlFRET2V6xD2aSi2kIpIGt+28afh37HvWNnc1yL\n6owbdOy+E0OAxNJw1lDYuRVGD4CM9PwPVkREpJiJNTn8J3CTmZXLz2BEPpq1ipP++wXfL17P/f3a\n8dyfUqhWvlTsF6jRAno/DIu/hC8fyb9ARUREiqlYxzl82cxaAYvN7Btgwx+L+J/zPDopMbbsSOPe\nsXMY/t1S2tWryH/P7USzmuUP7GIdL4CFn8GEf0KjY6Dh0XkbrIiISDEWa2/l/sAtQDpwKH98xOx5\nG5aUJNNTNzJoxFQWrfudgV2bckPPFiQlxFqpnQszOOURSJ0Mb14etD8sWzXvAhYRESnGYv0NfDfw\nFlDD3eu5e+McS5N8jFGKqfQM58nPFnDGUxPZujOdVy/vzM29Wh1cYpipdEU460XYvAbevgZcf7+I\niIjEItbfwtWAp9x9Y34GIyXH8o1bOf+5b3ho3DxOalubD68/jqObVs/bm9Q7FHreDfPeg++ey9tr\ni4iIFFOxDmXzFdAa+DQfY5ES4t1pK7j1rRlkZDgPn92BMw+th5nt+8QDceTVsPBz+Og2aHAk1NH8\nyyIiInsTa83h9cAVZnahmVUzs7icS6w3NLOTzWyemS0ws5tzOd7AzD4zsx/NbLqZ9Y712lK4bdq2\nkxten8q1w3+kWc3yvH/9sZx1WHL+JYYQtD88/SkoWy2YXm/75vy7l4iISDEQa1I3BzgEeAlYA+zM\nZdknM4sHngR6AW2A882sTY5itwMj3b0TcB7wVIwxSiE2Zcl6ej/+JWOmLmfQCc1548qjaFitgEZG\nKlcdzhgC6xbAB/8omHuKiIgUUbE+Vr6HvOmRfASwwN0XApjZCKAvMDtbGQcyJ86tBKzIg/tKRNLS\nM3h8/AIGj59PvSpleGPg0RzWsErBB9L4ODjuRvji39C4K3Q4t+BjEBERKQJiHefwrj0dM7NuwJ9i\nvF89YFm27VSgc44ydwEfmdm1QDnghD3cdwAwAKBBgwYx3l4K0pJ1v3P9iKlMXbaRMw9N5q4+bahQ\nOjG6gLreFAyO/d4NkJwC1ZpGF4uIiEghdUBjhphZMzO7x8wWEXRSOScPYzofGObuyUBv4OXc2jS6\n+xB3T3H3lBo1auTh7SUvfLNwHb0f+5KFazfzxPmd+M85HaJNDAHiE+DM5yEuAUZdAmnbo41HRESk\nENqfjiSVzGyAmX0NzANuI5gp5WqgboyXWQ7Uz7adHO7L7jJgJIC7TwJKA3k8xonkpzWbtnHNaz9S\nq1JpPhx0HKd1iPXrUQAqJQcdVFZOg0/uijoaERGRQmevyWHYE7m3mb0OrASeARoSdCoBGOTuz7r7\nbzHe73uguZk1NrMkgg4n7+QosxToEd6/NUFyuDbG60vE0jOc64dPZfP2nTx94WHUrVwm6pD+qNUp\ncMSV8M1TMO/DqKMREREpVPaYHJrZfwhq9d4FTiWYIeVkoAFwB7Df44+4expwDTCOoAf0SHefFT6i\n7hMW+xvBsDnTgOFAf3dNb1FUPPbpfCYtXMe9fdvRsnaFqMPZs573QK1DYMxV8Jv6PImIiGSyPeVd\nZpZB0HP4fYIEbV22Y5UIHil3c/cvCiLQvUlJSfHJkydHHUaJ9+X8tfzpxe8489BkHj67Q9Th7Nsv\n8+HZrlC3E/z5HYiLjzoikQJlZlPcPSXqOESkcNnbY+UXgE3AKcA8MxtsZkcUTFhS1Kz+bRuDRkyl\nec3y3Nu3XdThxKZ6czjlYVjyFXzxcNTRiIiIFAp7TA7d/QqgNnAhMBm4EphkZnOAm8ibcQ+lGEhL\nz+C64T+yZUc6T15wKGWSilANXIfzof258PkDsHBC1NGIiIhEbq8dUtx9m7sPd/fMtoa3AOnAzQRt\nDh8ws4vMrHT+hyqF1X8/mc+3i9Zzf792NK9ViNsZ5sYMTvkPVGsGr5wF3z0HauIqIiIlWMxD2bj7\nSnf/t7u3I5jp5EmgOcGUeivzKT4p5D7/aS1PTljAuSn1OePQ5KjDOTClKsCl46Dp8fD+3+GtK2HH\nlqijEhERicQBDYLt7pPd/VqC8Q3PBCbkZVBSNKz8dSt/fX0qLWtV4O6+baMO5+CUrQrnvw7H3wbT\nR8LzJ8C6n6OOSkREpMAdUHKYyd13uvtb7t4vrwKSoiGzneH2nek8eeGhlE4sQu0M9yQuDrr+Ay4a\nBZtWwJBuMPe9qKMSEREpUAeVHErJ9fBHP/H94g3884xDaFqjfNTh5K1mJ8CVXwRzL4+4AD6+E9LT\noo5KRESkQCg5lP02fu5qnvn8Zy7o3IC+HetFHU7+qNwALvkQDusPX/8XXj4dNq+JOioREZF8p+RQ\n9svyjVu5YeQ0WtepyB2ntok6nPyVWBpOewz6PgWp38Ozx8HSb6OOSkREJF8pOZSY7UzP4NrXfiAt\n3XmquLQzjEWnC+GyjyGhFAzrDd8+q+FuRESk2FJyKDF7aNw8fli6kQfOPITG1ctFHU7BqtMeBnwO\nzXrCB/+ANy+H7ZujjkpERCTPKTmUmHwyezVDvljIxUc25NT2daMOJxplKsN5r0H3/4NZo+H5HrD2\np6ijEhERyVNKDmWfUjds4W9vTKNdvYrcfmrrqMOJVlwcHPd3uGg0/L4WnjseZr8ddVQiIiJ5Rsmh\n7NWOtAz+8tqPZGQ4T15wKKUSSkg7w31penww3E2NVjDyTzDuNg13IyIixYKSQ9mrBz6Yy7RlG/n3\nWe1pWK2EtTPcl0rJcMn7cPjlMGkwvNQHNq2OOioREZGDouRQ9ujDmat48etF9D+6Eb0OqRN1OIVT\nQik45T/Qbwgs/wGePRaWTIw6KhERkQOm5FBytWz9Fm4cNY0OyZW4pXerqMMp/DqcC1d8CknlYNip\nMOlJDXcjIiJFkpJD+YPtaen85bUfMGCw2hnGrlZbGDABWvaCcbfCG/1h+6aIgxIREdk/BZ4cmtnJ\nZjbPzBaY2c25HH/UzKaGy09mtrGgYyzp/vX+XKan/spDZ3egftWyUYdTtJSuBOe+AifcDXPegee6\nw5q5UUclIiISswJNDs0sHngS6AW0Ac43s93mYHP3v7p7R3fvCDwBjC7IGEu692esZNjExVzWpTEn\nta0ddThFkxl0GQR/ege2bggSxJlvRh2ViIhITAq65vAIYIG7L3T3HcAIoO9eyp8PDC+QyIQl637n\nplHT6Vi/MjedrHaGB63xscFwN7XbwahL4YObIX1n1FGJiIjsVUEnh/WAZdm2U8N9f2BmDYHGwPg9\nHB9gZpPNbPLatWvzPNCSZtvOdK5+9Qfi4ozBF3QiKUHNUfNExbrQ/z3ofBV8+3TQWeW3lVFHJSIi\nskeFOQM4Dxjl7um5HXT3Ie6e4u4pNWrUKODQip/73pvNrBW/8Z+zO5BcRe0M81R8IvR6AM58AVbN\nCIa7WfRl1FGJiIjkqqCTw+VA/WzbyeG+3JyHHikXiHenreCVb5Yy4LgmnNCmVtThFF+HnAVXjIfS\nleGlvvD1YxruRkRECp2CTg6/B5qbWWMzSyJIAN/JWcjMWgFVgEkFHF+Js+iX37n5zekc1rAKN57U\nMupwir+arYIEsfWp8PEd8PpFsO3XqKMSERHJUqDJobunAdcA44A5wEh3n2Vm95hZn2xFzwNGuKta\nJT9ltjNMSojjifM7kRhfmFsZFCOlK8LZ/4MT74d5H8CQ42H17KijEhERAcCKQ/6VkpLikydPjjqM\nIueW0TMY/t1Shl5yOMe3rBl1OCXTkom7Bss+7TFof07UEUkJYmZT3D0l6jhEpHBRVVEJ9fbU5Qz/\nbilXdWuqxDBKDY8Ohrup0xFGXwHv/R3SdkQdlYiIlGBKDkugBWs2c8voGRzRqCp/69ki6nCkQm34\n8ztw1DXw/XMwtBf8uqd+WiIiIvlLyWEJs3VHOn959QdKJ8bz+PmdSFA7w8IhPhFOuj9oi7h2bjDc\nzcIJUUclIiIlkDKDEubOd2by05pNPHpuR2pXKh11OJJT29NhwAQoVwNe7gdf/gcyMqKOSkREShAl\nhyXIm1NSGTk5lb90a0bXFho4vNCq3hwu/xTa9oNP74HXL4StG6OOSkRESgglhyXE/NWbuH3MTDo3\nrsqgE5pHHY7sS6nywYwqJz8I8z+CId2C2VVERETymZLDEmDLjjSufvUHypWK5wm1Myw6zODIgcHc\nzGnb4PkTYOprUUclIiLFnLKEEuD/xsxiwdrNPHZeJ2pWVDvDIqfBkcFwN8mHw5ir4N1BkLY96qhE\nRKSYUnJYzI2cvIw3f0jluu7NOaZZ9ajDkQNVviZcPAaOGQRThsJzPeD752HTqqgjExGRYkbJYTE2\nb9Um7nh7Jkc3rcZ1PdTOsMiLT4Ced8O5r0LaVnjvb/CfVvB8T/j6cVi/MOoIRUSkGND0ecXU79vT\n6DP4K37dmsb713ehZgU9Ti5W3GHtPJjzLsx9F1ZOC/bXagetTwuWmm2Cdosie6Dp80QkN0oOiyF3\n56+vT+WdaSt45fLOHN1Uj5OLvQ1LYO5YmDMWlk4CHKo0DhPFPlDvMIjTgwLZnZJDEclNQtQBSN57\n/ftljJm6ght6tlBiWFJUaQhH/SVYNq+Bue8FtYrfPA0TH4fytaH1qUGy2PCYYEYWERGRXKjmsJiZ\ns/I3Tn/ya45oXJVhlxxBfJweK5ZoWzcG4yTOeRcWfAI7t0DpytCyd5AoNj0eEstEHaVERDWHIpIb\n1RwWI5u3p/GXV3+gctlEHj23oxJDgTKVof05wbJjC/w8Pnj8PO89mPYaJJaD5idAq9OgxYlQulLU\nEYuISMSUHBYT7s4to2eweN3vDL/iSKqXLxV1SFLYJJUNHy2fCuk7YfGXQRvFuWNh9tsQlwhNugXH\nW54C5TXFoohISaTHysXEK98s4fYxM7nxpJb85fhmUYcjRUlGBqR+H/R6nvMubFgMFgcNjoJWYTJZ\nuUHUUUo+0GNlEclNgSeHZnYy8BgQDzzv7g/kUuYc4C7AgWnufsHerlnSk8OZy3/ljKcnclSTagzt\nfzhxepwsB8odVs8MahTnvAtrZgX763QMax37QI2W0cYoeUbJoYjkpkCTQzOLB34CegKpwPfA+e4+\nO1uZ5sBIoLu7bzCzmu6+Zm/XLcnJ4W/bdnLaE1+xfWcG719/LFXLJUUdkhQn634Oh8h5N6hdBKje\nIqxRPA3qdtJYikWYkkMRyU1Btzk8Aljg7gsBzGwE0BeYna3MFcCT7r4BYF+JYUnm7tz85nRSN2zl\n9QFHKjGUvFetKRxzfbD8tmLXEDlfPwZfPQIVk3cNkdPgKIiLjzpiERE5SAWdHNYDlmXbTgU65yjT\nAsDMviZ49HyXu3+Y80JmNgAYANCgQclsD/XyN0t4f8Yqbu7VipRGVaMOR4q7inXhiCuCZct6+OnD\nIFGcPBS+fQbKVguHyOkDTbpCgjpFiYgURYWxt3IC0BzoBiQDX5jZIe6+MXshdx8CDIHgsXJBBxm1\nGam/ct/YOXRvVZMBxzaJOhwpacpWhY4XBMv2zcEYinPehVlj4MeXIalCMDRO69OgWU8oVT7qiEVE\nJEYFnRwuB+pn204O92WXCnzr7juBRWb2E0Gy+H3BhFj4/bp1J1e/NoXq5ZP4z9kd1AFFolWqPLQ9\nPVjStsOiL2DOO8Ej6JlvQnwpqNM+aKtYvXn42gKqNNJMLSIihVBBT7b6PdDczBqbWRJwHvBOjjJj\nCGoNMbPqBI+ZFxZkkIWZu/OPUdNYuXEbgy88lCpqZyiFSUIpaN4T+jwBf58P/d+Hwy+HhNJB7eIn\nd8GIC2BwCtxfGwYfDiMuhE/uhqnDIXUKbPs16ndRZG3cuJGnnnoq0hjMrJOZvRCum5k9bmYLzGy6\nmR26h3MmmNk8M5saLjXD/f3NbG22/ZeH+zua2SQzmxVe99xs12psZt+G93w9/F2zP/FPMLMD6qRj\nZu+bWeUDOTeGay/Oo+vs1/szs1Lh57gg/Fwbhfu7mdmw/bz3MDM7K1wfZGZl9+f8vBB+d3rn4fUW\nh7nKvso9FH5fHzKzu8zs7wd4v9PNrE2Ofdea2dzw+v/OcayBmW3OvJ+ZJZnZF2a218rBAq05dPc0\nM7sGGEfQnvBFd59lZvcAk939nfDYiWY2G0gHbnT3dQUZZ2E29OvFjJu1mttPac2hDapEHY7InsXF\nQ6NjgiXT1o2wbgH88lO4zA9ef/oQMtJ2lStfe/daxsz1ivUgrqD/pi06MpPDq6++usDvbWYJ7p4G\n3ArcF+7uRfDkpzlB+/Kn+WM780wXuntuw0687u7X5Ni3BfiTu883s7rAFDMbFzY/ehB41N1HmNkz\nwGXhffOdu+dZ0lGIXAZscPdmZnYewed77j7OicUg4BWCn2VB6gikAO/HekK27/bBGABUdfd0M7vr\nIK5zOjCWsCOvmR1P0LG3g7tvz/zDKptHgA8yN9x9h5l9SvAzfHVPNynwNofu/j45fijufke2dQdu\nCBfJZuqyjfzrgzmc0LoWl3VpHHU4IvuvTGVITgmW7NJ3BoNvZyaNa8PXGaNge7aaxMRyUL3ZH5PG\nqk0hsXSBvpXC6Oabb+bnn3+mY8eO9OzZk4ceeoiHHnqIkSNHsn37dvr168fdd9/N4sWL6dWrF0BD\nM5tF0Lynr7tvNbPrgIFAGjDb3c8zs6rAi0ATgl/mA9x9evhLrmm4f2nYUbC9u08LQ+oLvBT+v/6N\nmVU2szruvvJg3qe7/5RtfYWZrQFqmNmvQHcgc2zc/xGMmbvH5NDMygBDgQ7AXKBMtmMnAncDpYCf\ngUuALsBl7n52WKYb8Hd3PzWs3Utx91/M7E/A3wnG653u7hebWQ3gGSCzF+Ugd/86xre9NltcNwEX\nARnAB+5+s5lNCOOYHNZkTXb3Rvt4f08Dh4f7Rrn7nbncty/BZwgwChhsZgbsAPZazR+We4Jg+Lpl\n4TmE37G6wGdm9gvwMsH3ZlB4/AqgDcGYyB8CU4BDgVkEfxRsMbPDCBKf8sAvQP99fa/CWuR7gDJm\n1gX4F/AxsX23LyJIjE8m+Nyfc/cnwktfa2anAYnA2e4+N8d93wnjnGJm/8pxrCPBd6IswXfs0nAY\nvysIEsokYAFwMUFi2wfoama3A2cCVwEPuPt22H2EFzM7HVgE/J7joxgTvvc9Joe4e5FfDjvsMC+u\nMjIyfMqS9f73kVO91e0f+NH/+tQ3/r4j6rBECkZGhvtvq9wXfuH+3fPu79/k/lI/90faud9ZMdtS\nyf2/7d1fOcv9w1vdJw91XzzRffMvUb+DArVo0SJv27Zt1va4ceP8iiuu8IyMDE9PT/dTTjnFP//8\nc1+0aJHHx8c7MMuDsW5HAheF6yuAUuF65fD1CeDOcL07MDVcv4vgF3eZcPt44E0P/28mqOHokm37\nU4Lkabf/w4EJwAxgKvB/7BqDtz+wEphOkJjUz+XcI4A5BM2kqhMMl5Z5rD4wM+c5Oc6/geApFkB7\ngqQ4JbzWF0C58NhNwB0ElSpLs+1/Ottntzg8ry3BmL7Vw/1Vw9fXMj8PggRxTrbPbWouy8Rc4u0F\nTATK5rj2hMzPNoxh8d7eX45z48Pz24fb9wB9wvWZQHK2+/+c+b72tQBnECRf8QTJ4EbgrOyfVbhe\nPrxuYrg9ETgEaESQXB8T7n+RIOFODMvUCPefm+093riHz/LxbN+pwdlijPW7fRXBdzAhx2e3GLg2\nXL+aYHKP3D6LzdnW7yJI5CH4bnfN9rn/N1yvlq38fdnuMSzzMwy3pxL8AfMt8DlweLbPdFL4mnW/\nbD/vtXv72RXG3spC0OlkzI/LGf7dUuau2kTZpHhO71SXgV2bUqmsGvFLCWEGFWoFS+Njdz+24/dg\nkO6sR9ThY+pFX0Datl3lylT9Y2eY6s2hckOIL97/BX700Ud89NFHdOrUCYDNmzczf/58GjRoQOPG\njVmwYMHWsOgUgl/EEPyyetXMxhDUMEBQW3YmgLuPN7NqZlYxPPaOu2depw7Zarj2w4XuvtzMKgBv\nEtSSvAS8Cwz34HHZlQQ1gd0zTzKzOgS1Tn929ww7sAHZjwMeD9/bdDObHu4/kqD26uvwuknAJA+a\nR30InGZmo4BTgH/kuGZ34A13/yW87vpw/wlAm2xxVjSz8u7+GUGtUCxOAIa6+5Yc197f9wdwTljb\nm0Dws2tDUMt5xx8vc0COI/j5pQMrzGx8boXcfXN47FQzm8P/t3fnUXbW9R3H3x8m+0I2QohZIAhB\naaRBwkDEYilSVqNWRDBY0lMVWhG0Fo9g0aqUeozHpUeKBwOyBBJCDEqBItBElhbIgmFNCIgxkxDI\nxhIyJCGZb//4/WbmZnJnSTKZZ27m8zrnnjvPc5/7u9/75E7me7+/5UlJ4jN5fGNNNFZXpwOXkKqJ\n44AH8rmsIn2JICKmAlN3Ica2frY/Cvw8cvdyk/M+J98vIiXEbSJpAOkL2EN5103AHfnncZKuAgaS\nErzfNtNMN2Aw6fN6LDBL0qGkhPDH+dzu8IRIXdtbJfWPiI3NNWqdRESw6E+vc9v8Fdzz9Gq2bKvj\nqJEDuPqTH2DS+PfQr6f/ucwa9OibZkEPP2rH/XXb4c2axvGM9UnjsvvSMjv1qnqk7ugDDk+XBKxP\nGgcfCj333yeu/BIRXH755Vx44YU77F++fDk9e+6wDuV2GrsbzyT9Uf8Y8E1JH2jlZUq7rN4BSvv3\n27JCBRGxKt9vlHQbqRp4c+w43nwa0DDYPv8Bvwf4ZkQ8nnevBwaWjBEr+3ptJOCBiDivzGMzgYuB\nDaTu27J/YMvYDzg+IjaX7szjxn5c5vjaiPhQG9veRuMk01bHWEgaQ6rCHRupG/PGZp5X/2+4Mk9i\nGEA6z+1tGmm86lJSN3i9pkvVBenf5rmImNi0EUmXAZPLtP9wRFyyizE17Y5tzpZ8v532y6tuBD4R\nEU9JmkKeqFvGSmBOpJLgfEl1pMrxccDZeYLKQKBO0uaI+Fl+Xk9gc9kWcXLYKby+aStzcpXwpTVv\n069nN84+ZiTnVY9m3IgBRYdnVln2q0rL5Aw6JM2cLlW7oXFCzNoXUtL42nNp2Z3Y3nhcVY+0qHe5\nW98D0jqPDfvydidY9Lt///5s3NiYp5x66qlceeWVTJ48mX79+rFq1Sq6d2++50HSfqSu23mSHiWt\nKNEPeIT0B/d7eYzduoh4q0ylbgnwtZLtu4CLla6GdRzwZjQZF5YTjoGRxul1B84CHsyPlY5PnJTb\nrx87dicpgZxd31ZE1wPL0QAADt5JREFUhKR5wNmkBO4C4Df5OZ8EqiPi8iYxP0waozhX0jhS1yvA\n48A1kg6LiJck9QVGRBrv+BCpi/ML+XWamgvcKelHEbFe0uBcabof+DK5siVpfEQs3sXK4QPAtyTd\nGmnsXX3by4FjgPn5/bf2/vYnJT9vShpG6q7+XZnXu4t0Hh/L7c7NiUgDSdXAxRHxt02e+zBwoaSb\ngANJ3ee35cc2Av1J4wWJiCckjSKNLSz9xjda0sSIeCy/j0eBF0hjTCdGxGP5czM2Ip5rQ+Ww/nXr\ntfWz/UB+L/Ny9bj+vO+2iHhT0uuS/iIiHiFVzOuriP2B1fm9TabxS07T+H9NOq/zJI0lVbjXRURD\nV0seP/l2fWIoaUg+5t3mYnNyWJCI4Ik/bmDm/BXc++yrbN1Wx/hRA/nBp47izKOG09dVQrP212cw\n9KmGUdU77t+2BTb8MSWNry+H2nVQuz4lk7XrYfVT6X7zG2WbBdLC330G5+SxmcSyIbkcAr0GtvvM\n6yFDhnDCCScwbtw4Tj/9dKZOncqSJUuYODEVWPr168f06dOpqmr2ModVwPTc3SXSOK038h+XG3KX\nZC0pWdhJRCyVNKCku+pe4AzSgPpa0oQOACQtjojxpArGb/MfwSpSYviLfNglkiaRqmIbSOPFAM4h\nVTeH5KoKpAkJi0ljA2fmLrnfA9fnx98LvFUm7GuBX+buzCWkrkEiYm1ue4ak+sz/X4BluVvu7hzP\nTuci0ioc/wY8JGl7jmMKqUv0mnweu5GSp4vKncvmRMR9eRLDQklbSef4CuCHpC7FL5Iqqq29v6ck\n/Z5UqasBGibGaMcVRK4HbpH0Eunf4NwyYY0mVY2bupPUxf48aZzmYyWPXQfcJ+mViDgp75sFjI98\n+dzsBeBLkm7I7Vwbacbt2cB/5M9qN+AnpAkrrZkHfEPSYtKkjH+lDZ9tUmVzLPC0pHdJn9GfNXMs\nSssFXRQRn28lnguAnyst6/Myjb8jV5LGEa7N9/UJ4UzgF3lSz9mkLyk3SHqWNOHngqbJexknseNn\nZOf4W2+j85swYUIsXFhuBYTOZ8Omrfxq0UpmLFjBy2s30b9XN/7m6BGcWz2a9w/fv/UGzKw427fB\nO6+XJI/5tmn9jtu16xoTy3ebWalD+0HvQbnyOKSxGtlSctmjb7t2d0taFBG7taZfC21+FdgYEdPa\ns909JWk68NWI2J0xkdYCSVOBWyLi6VYPbrmdu0nj5P4nbx8C3B0R4/Y4SGsgaQ7wjSiZ9d+Uy1Md\noK4uePzl9dw2fwX3P/caW7fXcczBg/jhpw/jzA8Mp3ePZr/Fm1lnUtUN+g1Nt7baWtskcdxQPrlc\n/weomZ+2S7u4d3j9njt3a7/vLBjX5jHwHeFa4NNFB9FURJxfdAz7qoi4bE+er7Rw+HzgqfrE0PaO\nPCTj1y0lhuDkcK9au3ELsxet5PYFK1i+vpYBvbsz+fjRnFc9mrHD+rfegJlVvh590m3gqNaPBair\nS2s71lcea9fDpnXlk8s3VsBBrc0X6Vh5ssUtrR5olkVavHxsmf3LSbOSrZ1ExFbSSgAtcnLYzurq\ngv/9wzpm5CrhtrqgesxgvvLRsZw27iB6dXeV0MxasF/ubu49CIa8t+hozKwLcnLYTta8tZk7Fq1k\n5oIV1Gx4h0F9ujPlQ4dwbvVoDjuwX9HhmZmZmbWJk8M9sL0uePjFtcycv4IHl6xhe10w8dAhXHbq\n+zj1z4bRs5urhGZmZlZZnBzuhlff3MyshTXcvqCGVW+8w5C+Pfj8h8fwmWNHcehQVwnNzMyscjk5\nbKNt2+t4aNlaZsxfwdyla6gL+PBhB3DFGe/nlCOH0aNb+65XZmZmZlYEJ4etWPXGO9y+oIY7Ftaw\n+s3NHNCvJxd95L185thRHDykb9HhmZmZmbUrJ4dlbNtex9yla5gxfwW/W5bWSz3x8KF8+2NHcvL7\nh9G9ylVCMzMz2zc5OSxRs6GW2xfUMGthDWs2buHA/j25+KTDOGfCKEYN7lN0eGZmZmZ7XZdPDt/d\nXseDz7/GbfNX8OhL6xDwl0ccyHnVoznpiKF0c5XQzMzMupAunRzOXfoaX5/9DOve3sLwAb249OTD\nOWfCKN4zsHfRoZmZmZkVosOTQ0mnAT8FqoBpEfH9Jo9PAaYCq/Kun+2tC7iPHtyH8aMG8tnjRvGR\nsQdStV/7XdDezMzMrBJ1aHIoqQq4BjgFWAkskHRXRDzf5NDbI+LivR3PYQf2Z9oFE/b2y5iZmZlV\njI4eUFcNvBQRL+eLP88EPt7BMZiZmZlZMzo6ORwB1JRsr8z7mvqUpKclzZY0qlxDkr4oaaGkhWvX\nrt0bsZqZmZl1OZ1xKu5/AYdExFHAA8BN5Q6KiOsiYkJETBg6dGiHBmhmZma2r+ro5HAVUFoJHEnj\nxBMAImJ9RGzJm9OAYzooNjMzM7Mur6OTwwXA4ZLGSOoBnAvcVXqApOElm5OAJR0Yn5mZmVmX1qGz\nlSNim6SLgd+SlrK5ISKek/RdYGFE3AVcImkSsA3YAEzpyBjNzMzMujJFRNEx7LEJEybEwoULiw7D\nzKyiSFoUEV7Py8x20BknpJiZmZlZQfaJyqGktcCfdvPpBwDr2jGcva2S4q2kWKGy4q2kWKGy4q2k\nWGHP4j04Irzcg5ntYJ9IDveEpIWV1K1SSfFWUqxQWfFWUqxQWfFWUqxQefGaWefnbmUzMzMza+Dk\n0MzMzMwaODmE64oOYBdVUryVFCtUVryVFCtUVryVFCtUXrxm1sl1+TGHZmZmZtbIlUMzMzMza+Dk\n0MzMzMwadNnkUNINktZIerboWFojaZSkeZKel/ScpEuLjqklknpJmi/pqRzvd4qOqTWSqiT9XtLd\nRcfSGknLJT0jabGkTn1pIEkDJc2WtFTSEkkTi46pOZKOyOe0/vaWpK8UHVdzJH01/349K2mGpF5F\nx2Rm+4YuO+ZQ0onA28DNETGu6HhaImk4MDwinpTUH1gEfCIini84tLIkCegbEW9L6g48ClwaEY8X\nHFqzJP0TMAHYPyLOKjqelkhaDkyIiE6/ULOkm4BHImKapB5An4h4o+i4WiOpClgFHBcRu7vA/l4j\naQTp9+rIiHhH0izg3oi4sdjIzGxf0GUrhxHxMLCh6DjaIiJWR8ST+eeNwBJgRLFRNS+St/Nm93zr\ntN9CJI0EzgSmFR3LvkTSAOBE4HqAiNhaCYlhdjLwh86YGJboBvSW1A3oA7xScDxmto/osslhpZJ0\nCHA08ESxkbQsd9MuBtYAD0REZ473J8DXgbqiA2mjAO6XtEjSF4sOpgVjgLXAL3OX/TRJfYsOqo3O\nBWYUHURzImIV8ENgBbAaeDMi7i82KjPbVzg5rCCS+gG/Ar4SEW8VHU9LImJ7RIwHRgLVkjpl172k\ns4A1EbGo6Fh2wYcj4oPA6cCX8hCJzqgb8EHg2og4GtgEfKPYkFqXu78nAXcUHUtzJA0CPk5KwN8D\n9JV0frFRmdm+wslhhchj934F3BoRc4qOp61yN+I84LSiY2nGCcCkPI5vJvBXkqYXG1LLctWIiFgD\n3AlUFxtRs1YCK0uqxrNJyWJndzrwZES8VnQgLfgo8MeIWBsR7wJzgA8VHJOZ7SOcHFaAPMHjemBJ\nRPyo6HhaI2mopIH5597AKcDSYqMqLyIuj4iREXEIqStxbkR02gqMpL55UhK5i/avgU454z4iXgVq\nJB2Rd50MdMpJVE2cRyfuUs5WAMdL6pP/fziZNBbZzGyPddnkUNIM4DHgCEkrJf190TG14ATgc6Sq\nVv0yG2cUHVQLhgPzJD0NLCCNOez0S8RUiGHAo5KeAuYD90TEfQXH1JIvA7fmz8J44OqC42lRTrhP\nIVXiOq1cjZ0NPAk8Q/q/3JfRM7N20WWXsjEzMzOznXXZyqGZmZmZ7czJoZmZmZk1cHJoZmZmZg2c\nHJqZmZlZAyeHZmZmZtbAyaF1SZKmSIpmboVd/1fSjZJWFvX6ZmZm3YoOwKxgnyZdyaPUtiICMTMz\n6wycHFpXtzgiXio6CDMzs87C3cpmzSjpej5R0q8lvS1pvaRr8mUBS48dLulmSeskbZH0tKSdLsMn\naYykWyS9mo97WdJPyxx3tKRHJNVKelHSRU0eP0jSTZJeye2slnS3pAPb/0yYmVlX4sqhdXVVkpr+\nHtRFRF3J9nRgFvCfQDXwLaAvMAUaLrn2EDAIuAKoAc4HbpHUJyKuy8eNIV3yrja38SIwmnR95FL7\nA7cBPwG+C/wdcK2kFyJiXj7mFuBg4LL8esNI19fts7snwszMDJwcmi0ts+8e4KyS7Xsj4p/zz/dL\nCuC7kq6OiGWk5O1w4KSI+F0+7r8lDQOuknR9RGwHvgP0Bv48Il4paf+mJq/fH/jH+kRQ0sPAqcB5\nQH1yOBG4IiJuLXneHW1+12ZmZs1wcmhd3SfZeUJK09nKs5pszwSuIlURlwEnAqtKEsN604FfAkcC\nz5AqhHc3SQzLqS2pEBIRWyQtI1UZ6y0ALpMkYC7wbPhC6WZm1g6cHFpX92wbJqS81sz2iHw/GFhd\n5nmvljwOMISdE9FyXi+zbwvQq2T7M8C3ga+Tup9XS/o5cFWTLnEzM7Nd4gkpZq0b1sz2qny/ATio\nzPMOKnkcYB2NCeUeiYg1EfGliBgBvA+4kdRtfWF7tG9mZl2Xk0Oz1p3TZPtcoA54Im8/BIyUdEKT\n4z4LrAGez9v3A2dJGt6ewUXECxFxBaniOK492zYzs67H3crW1Y2XdECZ/QtLfj5D0lRScldN6s69\nOSJezI/fCFwKzJH0TVLX8WTgFODCPBmF/LwzgP+TdDXwEqmSeFpE7LTsTXMkDQAeBG4lTah5F/g4\nabb0/W1tx8zMrBwnh9bVNTfDd2jJz+cDXwP+AdgK/AKon71MRGyS9BHgB8D3SbONXwA+FxHTS45b\nLul40mSWfwf6kbqmf7OLMW8GngS+QFrOpi6/3uSI2NW2zMzMdiBPcDQrT9IU0mzjw30VFTMz6yo8\n5tDMzMzMGjg5NDMzM7MG7lY2MzMzswauHJqZmZlZAyeHZmZmZtbAyaGZmZmZNXByaGZmZmYNnBya\nmZmZWYP/B3r3MaJaIcPkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "d7f9657e-ed4d-4c6b-cdfd-e2369427d92e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "accuracy, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)\n",
        "print(predicted_ys.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "bf97bbb1-44f8-42e9-dd2c-9a2a51fa8204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(accuracy)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), y_fact_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6183268229166666\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.623 P=0.624 R=0.625 F1=0.623\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.665     0.595     0.628      3266\n",
            "         1.0      0.584     0.655     0.617      2836\n",
            "\n",
            "    accuracy                          0.623      6102\n",
            "   macro avg      0.624     0.625     0.623      6102\n",
            "weighted avg      0.627     0.623     0.623      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1942  979]\n",
            " [1324 1857]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6243097469451503,\n",
              " 0.6247033158662529,\n",
              " 0.6225827597509014,\n",
              " 0.6225095111289524)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}