{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "c8dea63f-a425-4b56-f796-afc9f489e0dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-24 23:38:16--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  25.1MB/s    in 4.0s    \n",
            "\n",
            "2019-12-24 23:38:20 (22.5 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "2e0fbf3e-a04b-47c3-9f33-3212e37ac55b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-24 23:38:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-12-24 23:38:28--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-12-24 23:38:28--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.97MB/s    in 6m 28s  \n",
            "\n",
            "2019-12-24 23:44:56 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "f3cca549-b281-4406-fa56-3c119a4d66f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-24 23:45:20--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  5.47MB/s    in 0.9s    \n",
            "\n",
            "2019-12-24 23:45:22 (5.47 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "1269199a-238e-4705-a35c-e0c1527c35c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "baf768b4-5dfb-4302-fa87-9ec157d2a40a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-24 23:45:30--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  6.06MB/s    in 0.9s    \n",
            "\n",
            "2019-12-24 23:45:31 (6.06 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "331c28ca-3208-4eaa-93dd-fb69724a9a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "4f013ead-5fbd-4828-c4e2-184d025d78a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "outputId": "c7e43b2c-8e57-4280-e529-1c615732efaa"
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "\n",
        "def slice_snopes(claims, claim_id):\n",
        "  print(claims.shape)\n",
        "  true_claims = claims[claim_id == 1]\n",
        "  false_claims = claims[claim_id == 0]\n",
        "  print(len(true_claims))\n",
        "  print(len(false_claims))\n",
        "  return np.random.shuffle(np.hstack([true_claims, false_claims]))\n",
        "\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique_claims = facts[\"claim_id\"].unique()\n",
        "  unique_creds = facts[facts[\"claim_id\"].index.unique()][\"cred_label\"]\n",
        "  if (slice_function):\n",
        "    unique_claims = slice_function(unique_claims, unique_creds)\n",
        "  \n",
        "#splitting the claims\n",
        "  train_claims, test_claims = train_test_split(unique_claims, test_size=0.2, random_state=8)\n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_claims)]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_claims)]\n",
        "\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-5bea821f34ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_facts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_facts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m#get unique claims to divide dataset cleanly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrain_facts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_facts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_fact_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfacts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoliti_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mtrain_snopes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_snopes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_fact_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnopes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnopes_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_snopes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-5bea821f34ea>\u001b[0m in \u001b[0;36mpreprocess_fact_data\u001b[0;34m(facts, mapping, slice_function)\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mfacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfacts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cred_label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0munique_claims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfacts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"claim_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0munique_creds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfacts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfacts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"claim_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cred_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0munique_claims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_claims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_creds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2999\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\\n                9,\\n            ...\\n            29546, 29547, 29548, 29549, 29550, 29551, 29552, 29553, 29554,\\n            29555],\\n           dtype='int64', length=29556)] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with_sources = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "if (with_sources):\n",
        "#AND THE SAME FOR FACT CHECKING (CURRENTLY SET UP KINDA RIGIDLY FOR FIRST TEST :())\n",
        "  train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "\n",
        "else:\n",
        "  train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    #callback()\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    \n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, new_hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, _ = self.hypothesis_processor(hypothesis, new_hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding).reshape(self.hp.batch_size, -1)\n",
        "    return self.MLP(factorised_mush), better_mush(premise_attention, hypothesis_attention)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, unnormalised_predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  auc = roc_auc_score(true_labels, unnormalised_predictions)\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(real_results, 0), torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-MUj2zowGzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "b4b6163a-18d8-4219-b1c0-8c064b615e5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",x_tokeniser.word_to_id,300)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34370\n",
            "torch.Size([34370, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvFn7PUSd742",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(128)\n",
        "textual_entailment_model = None\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 150\n",
        "  dense_dimension = 300\n",
        "  attention_hops = 30\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 200\n",
        "  num_classes = 1\n",
        "  epochs = 8\n",
        "  C = 0.1\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "f9257fb8-0d59-4e5b-fa3a-cdc6ea0ba516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "pass\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, glove_embeddings).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n",
        "\n",
        "print(torch.cuda.memory_allocated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.247895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.236786\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.246000\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.243089\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.247443\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.257319\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.248260\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.360858\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.262335\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.308934\n",
            "Average loss is: tensor(1.2825, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.49480597527472525\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.259077\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 1.662565\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 1.300940\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 1.392794\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 1.547617\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 1.275012\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 1.317885\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 1.287874\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 1.205593\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 1.314262\n",
            "Average loss is: tensor(1.3944, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5030906593406593\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 1.190273\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 1.334768\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 1.346060\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 1.282258\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 1.216858\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 1.314112\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 1.203044\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 1.656331\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 1.153128\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 1.360225\n",
            "Average loss is: tensor(1.4395, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5948231456043956\n",
            "Running EPOCH: 4\n",
            "Train Epoch: 3 [0/23454 (0%)]\tLoss: 1.210795\n",
            "Train Epoch: 3 [2560/23454 (11%)]\tLoss: 1.935429\n",
            "Train Epoch: 3 [5120/23454 (22%)]\tLoss: 0.903169\n",
            "Train Epoch: 3 [7680/23454 (33%)]\tLoss: 1.277741\n",
            "Train Epoch: 3 [10240/23454 (44%)]\tLoss: 0.971966\n",
            "Train Epoch: 3 [12800/23454 (55%)]\tLoss: 1.382446\n",
            "Train Epoch: 3 [15360/23454 (66%)]\tLoss: 0.936140\n",
            "Train Epoch: 3 [17920/23454 (77%)]\tLoss: 2.380041\n",
            "Train Epoch: 3 [20480/23454 (88%)]\tLoss: 1.404039\n",
            "Train Epoch: 3 [23040/23454 (99%)]\tLoss: 1.738765\n",
            "Average loss is: tensor(1.7412, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.6344436813186813\n",
            "Running EPOCH: 5\n",
            "Train Epoch: 4 [0/23454 (0%)]\tLoss: 1.772189\n",
            "Train Epoch: 4 [2560/23454 (11%)]\tLoss: 1.318829\n",
            "Train Epoch: 4 [5120/23454 (22%)]\tLoss: 0.926483\n",
            "Train Epoch: 4 [7680/23454 (33%)]\tLoss: 1.238311\n",
            "Train Epoch: 4 [10240/23454 (44%)]\tLoss: 1.241838\n",
            "Train Epoch: 4 [12800/23454 (55%)]\tLoss: 1.540522\n",
            "Train Epoch: 4 [15360/23454 (66%)]\tLoss: 0.772550\n",
            "Train Epoch: 4 [17920/23454 (77%)]\tLoss: 2.852283\n",
            "Train Epoch: 4 [20480/23454 (88%)]\tLoss: 1.523466\n",
            "Train Epoch: 4 [23040/23454 (99%)]\tLoss: 0.992044\n",
            "Average loss is: tensor(1.7113, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5966689560439561\n",
            "Running EPOCH: 6\n",
            "Train Epoch: 5 [0/23454 (0%)]\tLoss: 1.001499\n",
            "Train Epoch: 5 [2560/23454 (11%)]\tLoss: 2.403592\n",
            "Train Epoch: 5 [5120/23454 (22%)]\tLoss: 0.742063\n",
            "Train Epoch: 5 [7680/23454 (33%)]\tLoss: 1.152182\n",
            "Train Epoch: 5 [10240/23454 (44%)]\tLoss: 1.010040\n",
            "Train Epoch: 5 [12800/23454 (55%)]\tLoss: 1.471390\n",
            "Train Epoch: 5 [15360/23454 (66%)]\tLoss: 0.830621\n",
            "Train Epoch: 5 [17920/23454 (77%)]\tLoss: 1.447608\n",
            "Train Epoch: 5 [20480/23454 (88%)]\tLoss: 1.327150\n",
            "Train Epoch: 5 [23040/23454 (99%)]\tLoss: 1.833016\n",
            "Average loss is: tensor(1.4725, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.6096754807692307\n",
            "Running EPOCH: 7\n",
            "Train Epoch: 6 [0/23454 (0%)]\tLoss: 1.690155\n",
            "Train Epoch: 6 [2560/23454 (11%)]\tLoss: 1.886871\n",
            "Train Epoch: 6 [5120/23454 (22%)]\tLoss: 2.105915\n",
            "Train Epoch: 6 [7680/23454 (33%)]\tLoss: 1.796717\n",
            "Train Epoch: 6 [10240/23454 (44%)]\tLoss: 0.928526\n",
            "Train Epoch: 6 [12800/23454 (55%)]\tLoss: 0.976942\n",
            "Train Epoch: 6 [15360/23454 (66%)]\tLoss: 0.941488\n",
            "Train Epoch: 6 [17920/23454 (77%)]\tLoss: 2.497625\n",
            "Train Epoch: 6 [20480/23454 (88%)]\tLoss: 1.580171\n",
            "Train Epoch: 6 [23040/23454 (99%)]\tLoss: 2.080615\n",
            "Average loss is: tensor(1.7201, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.6292067307692307\n",
            "Running EPOCH: 8\n",
            "Train Epoch: 7 [0/23454 (0%)]\tLoss: 1.887709\n",
            "Train Epoch: 7 [2560/23454 (11%)]\tLoss: 1.394395\n",
            "Train Epoch: 7 [5120/23454 (22%)]\tLoss: 1.579416\n",
            "Train Epoch: 7 [7680/23454 (33%)]\tLoss: 1.123383\n",
            "Train Epoch: 7 [10240/23454 (44%)]\tLoss: 0.722604\n",
            "Train Epoch: 7 [12800/23454 (55%)]\tLoss: 0.917469\n",
            "Train Epoch: 7 [15360/23454 (66%)]\tLoss: 0.836878\n",
            "Train Epoch: 7 [17920/23454 (77%)]\tLoss: 1.101580\n",
            "Train Epoch: 7 [20480/23454 (88%)]\tLoss: 1.204601\n",
            "Train Epoch: 7 [23040/23454 (99%)]\tLoss: 2.307651\n",
            "Average loss is: tensor(1.2811, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.7286658653846154\n",
            "<function memory_allocated at 0x7f1186114b70>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "bf4a5cc5-7ad9-4a64-b1d7-7de25c51461b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "f6a439cb-80bc-4d8d-97c9-29e55791a61d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "real_results, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "320b5100-9e05-4c31-8e33-0c6ddf6a6a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.537 P=0.534 R=0.535 F1=0.532 AUC=0.538\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.447     0.519     0.481      2517\n",
            "         1.0      0.620     0.550     0.583      3585\n",
            "\n",
            "    accuracy                          0.537      6102\n",
            "   macro avg      0.534     0.535     0.532      6102\n",
            "weighted avg      0.549     0.537     0.541      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1307 1614]\n",
            " [1210 1971]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5335329882009763,\n",
              " 0.5345298829881492,\n",
              " 0.5372009177318912,\n",
              " 0.5316552039560892)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}