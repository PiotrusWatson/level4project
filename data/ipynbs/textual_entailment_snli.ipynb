{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "67f687c0-4265-4663-ab53-dc91dfb2bcfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-26 17:12:06--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  19.4MB/s    in 7.8s    \n",
            "\n",
            "2020-01-26 17:12:15 (11.6 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "034f594b-fd4d-4ecd-96fb-f4276f9b6545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-26 17:12:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-01-26 17:12:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-01-26 17:12:26--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.01MB/s    in 6m 30s  \n",
            "\n",
            "2020-01-26 17:18:56 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b81e83f7-60e5-45d1-d3a0-88f03ae3d4ce"
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-26 17:19:20--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  2.21MB/s    in 2.1s    \n",
            "\n",
            "2020-01-26 17:19:23 (2.21 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "61c71dd6-6d68-4ec8-a491-ff9c79b69595"
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "60ceb6dc-370b-47af-9f00-6a5727f5081b"
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-26 17:19:36--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  2.43MB/s    in 2.2s    \n",
            "\n",
            "2020-01-26 17:19:39 (2.43 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ff90b0d-57f5-4b0b-c154-2de8b236b12f"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "25c45d31-dfb3-4ce4-d54f-b0fcdd52da42"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "1d4dbab0-b0ff-4315-dc72-5b7467b5ade0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "722f0b92-db70-45eb-d410-edbf0f2e28c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "outputId": "3a00142f-69b5-4b27-df5c-bc85df0bb8c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_id\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  train_unique, test_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_unique[\"claim_id\"])]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_unique[\"claim_id\"])]\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n",
        "train_facts.head(500)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>for firms moving overseas in order to create a...</td>\n",
              "      <td>foxnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>get a tax break specifically by outsourcing jo...</td>\n",
              "      <td>newslines.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>confusing clashes over taxes in wednesday s pr...</td>\n",
              "      <td>wsj.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>support on this bill in a time of tight budget...</td>\n",
              "      <td>senate.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>tax a lower rate for american manufacturing an...</td>\n",
              "      <td>archives.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>to have a different standard the senate will h...</td>\n",
              "      <td>thedailybeast.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>double standard for mcconnell to be less conce...</td>\n",
              "      <td>weaselzippers.us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>cory booker on government reform even billiona...</td>\n",
              "      <td>ontheissues.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>think are deeply committed to do and we are ob...</td>\n",
              "      <td>whitehouse.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>are deeply committed to do and we are obviousl...</td>\n",
              "      <td>haaretz.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cred_label  ...     article_source\n",
              "0             1  ...        foxnews.com\n",
              "1             1  ...      newslines.org\n",
              "2             1  ...            wsj.com\n",
              "3             1  ...         senate.gov\n",
              "4             1  ...       archives.gov\n",
              "..          ...  ...                ...\n",
              "554           1  ...  thedailybeast.com\n",
              "555           1  ...   weaselzippers.us\n",
              "556           1  ...    ontheissues.org\n",
              "557           1  ...     whitehouse.gov\n",
              "558           1  ...        haaretz.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "4ebff911-3511-4b14-f5e0-abf6ad8e4a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>morning new tv advertisement argues that posit...</td>\n",
              "      <td>desmoinesregister.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>iowans could not support household on current ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>not budged in five years leaving many falling ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>are working to support themselves or their fam...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>prove that i had those good hardworking skills...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>cap is melting palin im not one to attribute e...</td>\n",
              "      <td>mysinchew.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2767</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>control the weapons the theocracy does secreta...</td>\n",
              "      <td>blastmagazine.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>be left with only one conclusion mccain was co...</td>\n",
              "      <td>chrisweigant.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2850</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>speech politifact called claim false that demo...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2851</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>covering conduct going back as far as 1994 was...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...              article_source\n",
              "85             1  ...       desmoinesregister.com\n",
              "86             1  ...  americanprogressaction.org\n",
              "87             1  ...  americanprogressaction.org\n",
              "88             1  ...           iowademocrats.org\n",
              "89             1  ...           iowademocrats.org\n",
              "...          ...  ...                         ...\n",
              "2766           0  ...               mysinchew.com\n",
              "2767           0  ...           blastmagazine.com\n",
              "2768           0  ...            chrisweigant.com\n",
              "2850           0  ...               democrats.org\n",
              "2851           0  ...               democrats.org\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "snopes_tokeniser = Tokeniser(x_train_snopes_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n",
        "x_snopes_train = snopes_tokeniser.do_everything(x_train_snopes_list)\n",
        "x_snopes_test = snopes_tokeniser.do_everything(x_test_snopes_list)\n",
        "y_snopes_train = np.array(y_train_snopes_list, dtype=np.float32)\n",
        "y_snopes_test = np.array(y_test_snopes_list, dtype=np.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "train_fact_source_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_source_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_train).type(torch.LongTensor))\n",
        "test_snopes_data= data_utils.TensorDataset(torch.from_numpy(x_snopes_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_test).type(torch.LongTensor))\n",
        "train_snopes_loader = data_utils.DataLoader(train_snopes_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "test_snopes_loader = data_utils.DataLoader(test_snopes_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(x)\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "    else:\n",
        "      x = self.linear1(x.reshape(self.hp.batch_size, -1))\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, unnormalised_predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(unnormalised_predictions.shape) == 1):\n",
        "    auc = roc_auc_score(true_labels, unnormalised_predictions)\n",
        "  else:\n",
        "    auc = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(real_results, 0), torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "5adde4b5-b88c-476b-a47a-8c601266506a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",fact_tokeniser.word_to_id,300)\n",
        "small_gloves = load_glove_embeddings(\"glove.6B.50d.txt\", fact_tokeniser.word_to_id, 50)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36905\n",
            "36905\n",
            "torch.Size([36905, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 20\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  dropout=0.3\n",
        "  C = 0.3\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "b3bbdbb9-7251-46ab-de24-fe3ef417a10a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "pass\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, small_gloves).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.640659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.636334\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.618505\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.607989\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.556639\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.478453\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.220538\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.166956\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.171478\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.063984\n",
            "Average loss is: tensor(1.4087, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.7015367445054945\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 0.981407\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 0.924903\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 0.962546\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 0.951582\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 0.969870\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 0.900140\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 0.948486\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 0.861364\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 0.806378\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 0.812447\n",
            "Average loss is: tensor(0.9099, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9772063873626373\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 0.793016\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 0.777467\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 0.774048\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 0.777616\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 0.780651\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 0.777109\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 0.764779\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 0.757709\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 0.759112\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 0.714369\n",
            "Average loss is: tensor(0.7755, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9963083791208791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "c20f1eb4-2fb2-4eb0-cea8-a434934462ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3xUVf7/8dcnIRBCJ4D0DjakBhuo\nCCpYEVFEESmWdde+3/Wnrq66ll3brl1ZXYogwooi2EFERBQLWFBAOkgRaaLUQJLP7497Q4aYQIBk\nZpK8n4/Hfcydc9tnZlI+c84955i7IyIiIiICkBDrAEREREQkfig5FBEREZE9lByKiIiIyB5KDkVE\nRERkDyWHIiIiIrKHkkMRERER2UPJoUgxY2aNzczNrEysYxERkZJHyaGIiIiI7KHkUCSOqXZQRESi\nTcmhlCpmdquZrTazLWa2wMy6heUjzOz+iP26mNmqiOfLzex2M5tnZr+Y2XAzS87nGgPNbIaZPRru\nu8zMzozYXsXMhprZT2Es95tZYsSxn5jZY2a2EbjHzBLDc20ws6XA2Xlcb2n4mpaZWb/CfddERKQ0\nUXIopYaZHQ5cB3R090pAd2D5AZyiX3hMM6AlcOc+9j0OWADUAB4GhpqZhdtGABlAc6AdcAZwZa5j\nlwKHAQ8AVwHnhPumARdGvKYKwJPAmeFrOhH45gBek4iIyF6UHEppkgmUA44ysyR3X+7uSw7g+Kfd\nfaW7byJI2i7Zx74r3P0Fd88EXgTqAIeZ2WHAWcBN7r7N3dcBjwF9I45d4+5PuXuGu+8A+gCPR1z7\nn7mulQW0MrPy7v6Tu889gNckIiKyFyWHUmq4+2LgJuAeYJ2ZjTWzugdwipUR6yuAfR27NuK628PV\nikAjIAn4ycw2m9lm4D9ArXyuQ3id3NfOPvc24GLgmvCcb5vZEQV7OSIiIr+n5FBKFXd/2d07EyRp\nDjwUbtoGpETsWjuPwxtErDcE1hxECCuBdKCGu1cNl8rufnRkmLmO+SmPa+fs7D7J3U8nqJ38AXjh\nIOISEREBlBxKKWJmh5tZVzMrB+wEdhA0yUJwn95ZZlbdzGoT1DDmdq2Z1Tez6sAdwP8ONAZ3/wmY\nDPzLzCqbWYKZNTOzU/Zx2CvADeG1qwG3Rbymw8ysZ3jvYTqwNeI1iYiIHDAlh1KalAMeBDYQNPvW\nAm4Pt40CviXooDKZvBO/l8NtS4ElwP157FMQlwNlgXnAL8CrBLV++XkBmBTG9xUwPmJbAvBnglrM\nTcApwB8PMi4RERHMPXcLlojkZmbLgSvdfUqsYxERESlKqjkUERERkT2UHIqIiIjIHmpWFhEREZE9\nVHMoIiIiInuUiXUAhaFGjRreuHHjWIchIlKszJ49e4O714x1HCISX0pEcti4cWNmzZoV6zBERIoV\nM1ux/71EpLRRs7KIiIiI7KHkUERERET2UHIoIiIiInuUiHsORaTk2r17N6tWrWLnzp2xDqXYSk5O\npn79+iQlJcU6FBEpBpQcikhcW7VqFZUqVaJx48aYWazDKXbcnY0bN7Jq1SqaNGkS63BEpBhQs7KI\nxLWdO3eSmpqqxPAgmRmpqamqeRWRAlNyKCJxT4nhodH7JyIHonQnh9s2wLu3we4dsY5EREREJC5E\nNTk0s2Fmts7Mvt/Pfh3NLMPMLizSgJZNh8+HwEu9YeevRXopESneJkyYgJnxww8/xDoUEZEiFe2a\nwxFAj33tYGaJwEPA5CKPptUF0Pu/sPILGHE2bF1X5JcUkeJpzJgxdO7cmTFjxhTZNTIzM4vs3CIi\nBRXV5NDdpwOb9rPb9cBrQHQytWMuhEv/BxuXwNAzYNOyqFxWRIqPrVu3MmPGDIYOHcrYsWP3lD/0\n0EMcc8wxtGnThttuuw2AxYsXc9ppp9GmTRvat2/PkiVLmDZtGuecc86e46677jpGjBgBBNN/3nrr\nrbRv355x48bxwgsv0LFjR9q0aUPv3r3Zvn07AD///DO9evWiTZs2tGnThk8//ZS77rqLxx9/fM95\n77jjDp544okovCMiUpLF1VA2ZlYP6AWcCnTcz75XA1cDNGzY8NAu3LwbDHgTRl8Iw7rDZeOhdqtD\nO6eIFLq/vzmXeWt+K9RzHlW3Mnefe/Q+95k4cSI9evSgZcuWpKamMnv2bNatW8fEiRP5/PPPSUlJ\nYdOm4Htvv379uO222+jVqxc7d+4kKyuLlStX7vP8qampfPXVVwBs3LiRq666CoA777yToUOHcv31\n13PDDTdwyimn8Prrr5OZmcnWrVupW7cuF1xwATfddBNZWVmMHTuWL774ohDeFREpzeIqOQQeB251\n96z99a5z9+eB5wHS0tL8kK9cPw0GT4JRvWD4WXDpWGh04iGfVkSKvzFjxnDjjTcC0LdvX8aMGYO7\nM2jQIFJSUgCoXr06W7ZsYfXq1fTq1QsIBp8uiIsvvnjP+vfff8+dd97J5s2b2bp1K927dwdg6tSp\njBw5EoDExESqVKlClSpVSE1N5euvv+bnn3+mXbt2pKamFtrrFpHSKd6SwzRgbJgY1gDOMrMMd58Q\nlavXPDwnQRzVCy4aAYefGZVLi8j+7a+Gryhs2rSJqVOn8t1332FmZGZmYmZcdNFFBT5HmTJlyMrK\n2vM895iDFSpU2LM+cOBAJkyYQJs2bRgxYgTTpk3b57mvvPJKRowYwdq1axk8eHCBYxIRyU9cDWXj\n7k3cvbG7NwZeBf4UtcQwW9UGQYJY6ygY2w++Hh3Vy4tIfHn11Vfp378/K1asYPny5axcuZImTZpQ\npUoVhg8fvueewE2bNlGpUiXq16/PhAnBn6309HS2b99Oo0aNmDdvHunp6WzevJkPPvgg3+tt2bKF\nOnXqsHv3bkaPzvn7061bN5577jkg6Ljy66/BCAu9evXivffe48svv9xTyygiciiiPZTNGGAmcLiZ\nrTKzK8zsGjO7Jppx7FeF1OAexCYnw8Q/wSdPxjoiEYmRMWPG7Gkmzta7d29++uknzjvvPNLS0mjb\nti2PPvooAKNGjeLJJ5+kdevWnHjiiaxdu5YGDRrQp08fWrVqRZ8+fWjXrl2+17vvvvs47rjj6NSp\nE0ccccSe8ieeeIIPP/yQY445hg4dOjBv3jwAypYty6mnnkqfPn1ITEwsgndAREobcz/02/ViLS0t\nzWfNmlX4J85Ih9f/AHNfhxNvgNPvBc00IBJV8+fP58gjj4x1GHErKytrT0/nFi1a5LtfXu+jmc12\n97SijlFEipe4alaOO2XKQe+h0PFK+PRJmHgdZGbEOioREQDmzZtH8+bN6dat2z4TQxGRAxFvHVLi\nT0IinPUoVKgJ0/4JOzbBhcMgqXysIxORUu6oo45i6dKlsQ5DREoY1RwWhBl0uS1IEhe8q+n2RERE\npMRScnggjr0KLhwaTLc3/GzY8nOsIxIREREpVEoOD1Sr3sF0e5uWwrAzgkcRERGREkLJ4cFo3g0G\nvAE7f4Oh3eGnObGOSERERKRQKDk8WPXTYPB7kJgEI86G5Z/EOiIRKSIVK1aMdQgiIlGj5PBQ1Dwc\nrpgMlWrDSxfAD+/EOiIRERGRQ6Lk8FBVqR9Mt3fY0fC/y+Drl2IdkYhEwfLly+natSutW7emW7du\n/PjjjwCMGzeOVq1a0aZNG04++WQA5s6dy7HHHkvbtm1p3bo1ixYtimXoIiL7pHEOC0NKdbj8DXil\nP0y8FrZvhE43xjoqkZLn3dtg7XeFe87ax8CZDx7wYddffz0DBgxgwIABDBs2jBtuuIEJEyZw7733\nMmnSJOrVq8fmzZsBGDJkCDfeeCP9+vVj165dZGZmFu5rEBEpRKo5LCzlKsIl/4OjL4D374LJd0IJ\nmJpQRPI2c+ZMLr30UgD69+/PjBkzAOjUqRMDBw7khRde2JMEnnDCCfzjH//goYceYsWKFZQvr0H0\nRSR+qeawMJUpG0y3l5IKnz4F2zbCeU9Bot5mkUJxEDV80TZkyBA+//xz3n77bTp06MDs2bO59NJL\nOe6443j77bc566yz+M9//kPXrl1jHaqISJ5Uc1jYEhLgrEegy1/h25eD+xB374h1VCJSyE488UTG\njh0LwOjRoznppJMAWLJkCccddxz33nsvNWvWZOXKlSxdupSmTZtyww030LNnT+bM0fBXIhK/VKVV\nFMygy61QIRXe/guMugAuGQPlq8Y6MhE5CNu3b6d+/fp7nv/5z3/mqaeeYtCgQTzyyCPUrFmT4cOH\nA3DLLbewaNEi3J1u3brRpk0bHnroIUaNGkVSUhK1a9fmr3/9a6xeiojIfpmXgPvi0tLSfNasWbEO\nI2/fj4fxVwfD3lz2WjDsjYgU2Pz58znyyCNjHUaxl9f7aGaz3T0tRiGJSJxSs3JRa3UB9HsFNi2D\nYd013Z6IiIjENSWH0dCsKwx8U9PtiYiISNxTchgt9ToEg2Unlg2n25sR64hEio2ScPtLLOn9E5ED\nEdXk0MyGmdk6M/s+n+09zWyOmX1jZrPMrHM04ytyNVuG0+3VCTqp/PB2rCMSiXvJycls3LhRCc5B\ncnc2btxIcnJyrEMRkWIiqh1SzOxkYCsw0t1b5bG9IrDN3d3MWgOvuPsR+ztvXHdIycv2TTD6Iljz\nFZz7JLTvH+uIROLW7t27WbVqFTt37ox1KMVWcnIy9evXJykpaa9ydUgRkbxEdSgbd59uZo33sX1r\nxNMKQMmsKkipDpdPhFcuhzeuy5luzyzWkYnEnaSkJJo0aRLrMERESo24u+fQzHqZ2Q/A28DgWMdT\nZMpVhEvGQqsLYcrdwXR7WVmxjkpERERKubhLDt399bAp+Xzgvvz2M7Orw/sSZ61fvz56ARamMmXh\nghfg2Kth5tMw8VrI3B3rqERERKQUi7vkMJu7TweamlmNfLY/7+5p7p5Ws2bNKEdXiBIS4MyH4dQ7\ncqbb27U91lGJiIhIKRVXyaGZNTcLbrwzs/ZAOWBjbKOKAjM45f/B2f+ChZPgpQtgx+ZYRyUiIiKl\nUFQ7pJjZGKALUMPMVgF3A0kA7j4E6A1cbma7gR3AxV6axq/oeCWkpMJrV8Hws6D/eE23JyIiIlGl\nuZXj0ZIPYWw/qJAK/SdAarNYRyQiJZCGshGRvMRVs7KEmp0aTLe3a1swH/NP38Y6IhERESkllBzG\nq+zp9sokw/CzYdnHsY5IRERESgElh/GsRosgQaxSD17qDfPfinVEIiIiUsIpOYx3VerBoHehTmt4\npT98NTLWEYmIiEgJpuSwOMiebq9ZV3jjevj431ACOhKJiIhI/FFyWFyUrQB9x8AxF8EHf9d0eyIi\nIlIkojrOoRyiMmWh1/PBWIgzn4ZtG6Dn05CYFOvIREREpIRQcljcJCRAjwchpQZ8eD/s+AUuGgFl\nU2IdmYiIiJQAalYujszglFvgnMdg0WQY1StIEkVEREQOkZLD4ixtcFBruOarYLq9336KdUQiIiJS\nzCk5LO6OPh/6jYPNP8KwM2DjklhHJCIiIsWYksOSoGkXGBBOtzf0DFjzTawjEhERkWJKyWFJUa89\nDJ4MSeVhxDmwbHqsIxIREZFiSMlhSVKjOVwxGarUD6bbm/dGrCMSERGRYkbJYUlTuS4MegfqtIVx\nA2D2iFhHJCIiIsWIksOSKKU6XD4BmnWDN2+Ej/+l6fZERESkQJQcllRlK8AlY+CYPvDBvTDpr5pu\nT0RERPZLM6SUZIlJ0Os/wXR7nz0L2zdCz2c03Z6IiIjkS8lhSZeQAD3+CRVqwNT7wun2XtR0eyIi\nIpKnqDYrm9kwM1tnZt/ns72fmc0xs+/M7FMzaxPN+EosMzj5L3DO47B4Cow6H7ZvinVUIiIiEoei\nfc/hCKDHPrYvA05x92OA+4DnoxFUqZE2KJxu72sYcTb8tibWEYmIiEiciWpy6O7TgXyrrNz9U3f/\nJXz6GVA/KoGVJkf1hH6vBtPtDe0OGxbHOiIRERGJI/HcW/kK4N1YB1EiNT0FBr4Fu7fDsO5BTaKI\niIgIcZocmtmpBMnhrfvY52ozm2Vms9avXx+94EqKuu1g8CRISoER58LSj2IdkYiIiMSBuEsOzaw1\n8F+gp7tvzG8/d3/e3dPcPa1mzZrRC7AkqdEcrpgUTLc3+kKYNzHWEYmIiEiMxVVyaGYNgfFAf3df\nGOt4SoXs6fbqtoNxA2HW8FhHJCIiIjEU1XEOzWwM0AWoYWargLuBJAB3HwLcBaQCz5oZQIa7p0Uz\nxlIppTr0nxDMxfzWTbB9A5z0l2AIHBERESlVopocuvsl+9l+JXBllMKRSGVToO/LMPFamHo/bNsI\n3f8RDKItIiIipYZmSJEciUlw/hBIqQGfPRNMt3f+s5puT0REpBRRcih7S0iA7g9AhVT44N5gur0+\nL0LZCrGOTERERKJAbYbye2Zw0v/BuU/Ckg9gpKbbExERKS2UHEr+OgyAi16En76B4Wdpuj0REZFS\nQMmh7NtR58Flr8Gvq2DoGZpuT0REpIRTcij71+TkcLq9HTDsDFj9VawjEhERkSJSoOTQzKaa2RH5\nbGtpZlMLNyyJO3XbwhWTg44pL54LS6fFOiIREREpAgWtOewCVM5nWyXglEKJRuJbajMYPBmqNoTR\nF8HcCbGOSERERArZgTQrez7lzYCthRCLFAeV64TT7bUPp9sbFuuIREREpBDlO86hmQ0CBoVPHXje\nzLbk2q080Ar4oGjCk7hUvhr0fz1IDt+6OZhN5WRNtyciIlIS7KvmMAvIDBfL9Tx72Qg8B1xRtGFK\n3CmbAn1HQ5tL4MP74b3bICsr1lGJiIjIIcq35tDdXwReBDCzD4E/uvsP0QpMioHEJOj5LKSkwsyn\ng+n2ej4LZcrGOjIRERE5SAWaPs/dTy3qQKSYSkiAM+6HCjVgyj3hdHsjNd2eiIhIMVXguZXNrDJw\nFtAQSM612d39vsIMTIoRM+h8c1CD+OaNMLInXPoKpFSPdWQiIiJygAqUHJpZJ+BNoGo+uzig5LC0\na385lK8Orw6G4WfCZeOhSr1YRyUiIiIHoKBD2TwOLAc6AsnunpBrSSyyCKV4OfKccLq91TCsO2xY\nFOuIRERE5AAUNDk8ErjT3We7+66iDEhKgCYnwaC3IWNnkCBquj0REZFio6DJ4Y9AuaIMREqYOm1g\n8CQoWzGYbm/Jh7GOSERERAqgoMnh34Hbwk4pIgWT2iyYj7lqo3C6vddjHZGIiIjsR0GTw3OAw4Bl\nZvaWmY3MtbxYkJOY2TAzW2dm3+ez/Qgzm2lm6Wb2lwLGJvGsUu1gur36aTBuEHw5NNYRiYiIyD4U\ndCibzgQ9kn8Djs5je37zLuc2AngaGJnP9k3ADcD5BTyfFAflqwY9l18dBG//ORgs++RbNN2eiIhI\nHCroINhNCuNi7j7dzBrvY/s6YJ2ZnV0Y15M4UjYFLn4J3rgePnwAtq2HHg8Fg2iLiIhI3CjwINgi\nh+x30+1tgvOf03R7IiIicaSgg2A33N8+7v7joYdTcGZ2NXA1QMOG+w1P4kVCAnR/ACrUhCl3B9Pt\nXTxK0+2JiIjEiYLWHC5n//cVRnUgbHd/HngeIC0traD3PEq86HxTON3eDfDiedBvnKbbExERiQMF\nTQ4H8/vkMJWgF3MTNHWeHIz2/YOEcNwgGNYD+o+HKvVjHZWIiEipZu6HVulmZqOAFe5+ZwH2HQN0\nAWoAPwN3A0kA7j7EzGoDs4DKQBawFTjK3X/b13nT0tJ81qxZh/IyJJaWz4Axl0C5ytD/dajZMtYR\niZQKZjbb3dNiHYeIxJfCSA67A8PdvW7hhHTglByWAD/NgZd6Q1YG9HsV6neIdUQiJZ6SQxHJS2GM\nI1ILSC6E80hpVqc1XDEJylUKp9ubGuuIRERESqWC9lY+OY/iskAr4Hbg48IMSkqp6k2D6fZe6g2j\n+8AFz0OrC2IdlYiISKlS0A4p0/h9h5Ts6S0+Av5YWAFJKVepNgx8O7gH8dXBsGMTdLwy1lGJiIiU\nGgVNDk/No2wnQUeUtYUYj0gw3V7/8UEv5rf/D7ZtgFNu1XR7IiIiUVDQ6fM+KupARPaSVD6Ybu/N\nG2DaP4ME8cyHNd2eiIhIETug6fPMrBVwClAd2ARMc/e5RRGYCIlloOczwViInz4F2zdCr/9ouj0R\nEZEiVNAOKWWAEcAl5NxrCOBm9jIw0N0zCz88KfXM4Iz7g+n23r8Ldm6GPqOgXMVYRyYiIlIiFbSN\n7m6gD3AXwYwo5cPHu4CLw0eRotPpxqAWcelHMPI82LYx1hGJiIiUSAVNDi8D7nf3B9x9hbunh48P\nAPcDlxddiCKhdpcF9yGu/R6G94BfV8U6IhERkRKnoMlhXeDTfLZ9Gm4XKXpHnBVMsbdlLQw9A9Yv\niHVEIiIiJUpBk8M1QKd8tp0YbheJjsadYNA7kLkbhvWAVbNjHZGIiEiJUdDkcDRwh5n9zcyamll5\nM2tiZrcDdwCjii5EkTzUPiaYbi+5sqbbExERKUQFTQ7vAV4F/g4sArYCi4EHwvJ7iyI4kX2q3hQG\nTw4eR/eB71+LdUQiIiLFXoGSQ3fPcPdLgWOA6wh6J18HHOPu/dw9owhjFMlfpcNg4FtQvyO8egV8\n8UKsIxKJqffee4/DDz+c5s2b8+CDD/5u+4oVK+jWrRutW7cGONzM6mdvM7OHzOz7cLk4otzM7AEz\nW2hm883shrC8p5nNMbNvzGyWmXWOOGaAmS0KlwER5ZeY2Xfhce+ZWY2w/L6Ic002s7ph+S1h2Tdh\nXJlmVj3cdmNYNtfMboq4xkVhWZaZpUWUn25ms8PrzzazrhHbOoTli83sSbNgSiYza2tmn0W8xmML\nOy6RuOPuxX7p0KGDSym3a7v7y33d767sPvUf7llZsY5IJOoyMjK8adOmvmTJEk9PT/fWrVv73Llz\n99rnwgsv9BEjRri7O7AAGBWscjbwPsH4txWAL4HK4bZBwEggIXxeK3ysCFi43hr4IVyvDiwNH6uF\n69XCc68DaoT7PQzcE65X9vBvOnADMMRz/a0HzgWmhuutgO+BlPC8U4Dm4bYjgcOBaUBaxPHtgLoR\nx6+O2PYFcDzBWL7vAmeG5ZMj1s8imPyhUOPSoiXelgOai8zMGpjZiWbWNfdyIOcRKXRJ5YPBsdte\nBh89CO/8BbI0LruULl988QXNmzenadOmlC1blr59+zJx4sS99pk3bx5du+75k70F6BmuHwVM96Cl\naBswB+gRbvsjcK+7ZwG4+7rwcau7e7hPBSB7vTvwvrtvcvdfCJLOHgSJlwEVwpq5yoQdGt39t4gw\nI88V6RJgTLh+JPC5u2/3oPXqI+CC8Fzz3f13Qxm4+9funt2Bci5Q3szKmVkdguT0s/D1jATOzz4s\njBOgCnl3wDykuETiTYGSw7ATykxgOfAxwTehKQS/8NmPIrGVWAZ6Ph0MmP3lf+G1KyAjPdZRiUTN\n6tWradCgwZ7n9evXZ/Xq1Xvt06ZNG8aPH5/9tCpQycxSgW+BHmaWEjb1ngpkn6wZcHHYrPqumbXI\nPoGZ9TKzH4C3gcFhcT1gZcRlVwH13H03QaL5HUGSdRQwNOJcD5jZSqAfuSZXMLMUggQz++bi74GT\nzCw13HZWRLwF0Rv4yt3Tw3gjB05dFZYB3AQ8Esb1KHB7EcclEnMFrTn8L9CQ4JekB8EfjVOBrhGP\nIrFnBqffC6ffB3Nfh5f7QPrWWEclEjceffRRPvroI9q1awdQCVgNZLr7ZOAdgrFrxwAzgezq93LA\nTndPA14AhmWfz91fd/cjCGra7tvXtc0siSA5bEcwPu4cIpItd7/D3RsQjJBxXa7DzwU+cfdN4b7z\ngYcImn3fA76JiHefzOzo8Ng/FGD3PwI3h3HdTEQyW9hxicSLgiaHHYEb3P0pd3/f3T/KvRRlkCIH\nrNMN0PNZWPZxMNSNptuTUqBevXqsXJlTYbdq1Srq1au31z5169Zl/PjxfP311xAkhrj75vDxAXdv\n6+6nEzT/Lsw+FZBd3fg6wf2Fe3H36UDTsNZxNXvXltUPy9qG+y4Jm29fIRgrN7fRBDV7kfqS03Sb\nfc2h7t7B3U8GfomIN19hB5zXgcvdfUlYvDqMMXe8AAPIee3jgGOLIi6ReFLQ5HAVsOtQL2Zmw8xs\nnZl9n892C3uJLQ57rbU/1GtKKdauXzDd3rp5MKw7bF65/2NEirGOHTuyaNEili1bxq5duxg7dizn\nnXfeXvts2LCBrKys7Kd1CGsBzSwxbF7GzFoTJICTw/0mELQSAZxCmOyYWfOIXr3tCWoYNwKTgDPM\nrJqZVQPOCMtWA0eZWc3wXKcD88Pj9zRVE9wH+UP2EzOrEl53rxsozaxW+NiQ4L6+l/f1/phZVYLm\n79vc/ZPscnf/CfjNzI4PX8/lEddaE14bglayRYUdl0jcKUivFaA/MAOocCi9X4CTgfbA9/lsP4ug\nl5gR9Br7vCDnVW9l2afln7j/o4H7v450X/dDrKMRKVJvv/22t2jRwps2ber333+/u7v/7W9/84kT\nJ7q7+7hx47x58+beokULB9YD5Tz4+5sMzAuXz4C2nvO3OTup+o6gublNWH4rQceOb8LyzhHHDCYY\nD3cxMCii/BqChHAO8CaQGpa/RnC/XnZ5vYhjBgJj/ff/Mz4O4/0W6BZR3ougUiMd+BmYFJbfCWwL\n481esntep4XXXwI8TU4v7M7A7PAanwMdCjsuLVribcn+4d8vM3sAuDr8o/FLrs3u7gN+f1Se52kM\nvOXurfLY9h+CYQLGhM8XAF08+FaXr7S0NJ81a1ZBLi+l1drv4KXekLkL+r0K9TXEmIiZzfbgPkIR\nkT3KFGQnMxtIcNNwJkHNX+4m5oJlmPuXZw834HfJoZldTZCs0rBhw0K6vJRYtY+BwZNgVK/gHsSL\nR0Hz02IdlUiBZGRmsTMji527M8MlWE/PyKRWpWQaVE+JdYgiUoIUKDkkmDbvdeAKD29cjjV3fx54\nHoKawxiHI8VB9SZBgvhSb3i5L/QaAsdcGOuopJhxd9IzskjfncXOjL2TtZ27M/dK4vLeJ6csPbss\nI9c5dmeRHlGWkZX/n7hrTmnGbWceEcV3QERKuoImh6nAs1FIDPPr4SZSOCodBoPehjGXwGtXwvZN\ncNzVsY5KDsG+atX2SshyJXm9uq0AACAASURBVGHpuRK5nH0itueR3KVnZO0/qHyUSTCSkxJJTkqg\nXJngMXgerFctn0RyUiLlssv32ienrFzEcY1UaygihaygyeEMglHfPyjCWADeAK4zs7HAccCv+7vf\nUOSAJVeBy8bDq4Ph3Vtg+wbocnswRqIcknirVdufcmV+n3glJyVQLimRKillOSz39qREkssE2/eU\nl0nMtU924vf748okHtCkVCIiMVHQ5PBG4BUz+4VgUM/cHVLwcFqlfTGzMUAXoIaZrQLuBpLC44cQ\nDMB6FkHvtu0E83mKFL6kZOgzEt66ET56CLZtgLMegYTEWEdWqIqyVi09I4+ELiOLAvZx+52iqFVL\nLrP3OSLPW65MAqYvBCIiv1PQ5HB++DhyH/vs97+qu1+yn+0OXFvAmEQOTWIZOO9pSKkBnzwO2zfC\nBc9DmXJFcrniVqv2uyQtV61asmrVRERKpIImh/dSeD2SReKHGZz+d6hQAybfCTs3BwNnl6t0SKfd\nuTuTMV/8yKiZK9i0fVexqFWL3Ee1aiIipVeBkkN3vye/bWbWhWA0eZHi68TrISUVJl4HL54H/cYF\nCeMBSs/I5H9fruSZDxfz82/pdGxcjc4taqhWTUREio2C1hzuxcyaEySE/YGGwA6C0fBFiq+2l0L5\najBuIAzrAf1fh6oN9nsYwK6MLF6ZFSSFP/26k46Nq/HYxW05sdmBJ5giIiKxVODkMJxD8mKCSciP\nD4u/BR4k16TjIsXW4WdC/wnw8sUw9IwgQayV/xhyuzOzeG32Kp6aupjVm3fQvmFVHrmwDZ2ap6pZ\nVkREiqV9Tp9nZglAD4KE8FyCuTfXAOMJOo6c6u7ToxDnPmn6PCl0a78PBsvO2BlMt9eg416bMzKz\nGP/1ap6auoiVm3bQpkFVbj6tBae0rKmkUIoNTZ8nInnJt+bQzP4FXArUAnYSzJDyIjAFqAxcF40A\nRWKidiu4YhKMPB9Gngd9RkGL08jIzGLiN2t4cuoiVmzczjH1qvD3gUdz6uG1lBSKiEiJsK9m5ZsJ\neii/Awx0943ZG8xMPZel5KvWGK6YDC9dgI+5mFnt/smtC1qydMM2jqpTmRcuT+O0I5UUiohIybKv\nLpBDgS3A2cACM3vazI6NTlgi8SErpSbvpg3lWzuCjrNv4cLMtxlyWQfeur4zpx91mBJDEREpcfKt\nOXT3q8zseqAXwT2HfwD+aGYLCZqYVXsoJVZWlvPe3LU8PmUhC3/eylE172FYxSH86afnYV1VOPqv\nsQ5RRESkSOyzt7K77yToiTzGzOoQDF1zOXBbuMuDZvYs8Gq4r0ix5u5Mmvszj09ZyA9rt9CsZgWe\nvKQdZx9Th0Q/Fd66CaY/DNvWw9n/KnHT7YmIiBR4KBt3/wl4GHjYzNIIahP7Ekyp9xRQrUgiFIkC\nd2fK/HU8PmUhc9f8RpMaFXj84rac26YuiQnZTcdl4LyngsGxZzwGOzbBBS8U2XR7IiIisXBQg2C7\n+yxglpn9GTgHzZAixZS7M23Beh6bspA5q36lUWoK/7qoDT3b1s17VhIzOO2eYD7myXfAjs3Qd/Qh\nT7cnIiISLw4qOczm7rsJ7j98vXDCEYkOd2f6og089v5Cvlm5mfrVyvPwha3p1a4eSQWZqu7E68Lp\n9q6FEefAZa8d1HR7IiIi8eaQkkOR4sbd+WTxRv79/gK++nEz9aqW558XHEPv9vUpW+YA5y9uewmk\nVIdXBsCw7uF0ew2LJnAREZEoUXIopcbMJRt57P2FfLF8E3WqJHP/+a3ok9bgwJPCSC27w+UT4OU+\nEdPtHVl4QYuIiESZkkMp8T5fupHHpizks6WbOKxyOf5+3tFc3LEByUmF1NO44fEw6F0YdQEM6wH9\nxkEDDQkqIiLFk5JDKbFmr9jEv99fyCeLN1KzUjnuOucoLj2uYeElhZEOOzqYbm9ULxjZE/qMhBan\nF/51REREipiSQylxvv7xFx6bsojpC9dTo2JZ7jz7SPod14jyZYt4TMJqjWFwMN0eY/rC+c9B6z5F\ne00REZFCpuRQSow5qzbz2PsL+XDBeqpXKMvtZx5B/xMakVI2ij/mFWvCwLdh7KUw/irYvgmOvyZ6\n1xcRETlEUU8OzawH8ASQCPzX3R/Mtb0RMAyoCWwCLnP3VdGOU4qP71f/yuNTFjJl/jqqpiTx/3oc\nzoATGlOhXIy++yRXhn6vwvgr4b1bYeYz0LgTNOoEjTsHNYyak1lEROKUuUdvimQzSwQWAqcDq4Av\ngUvcfV7EPuOAt9z9RTPrCgxy9/77Om9aWprPmjWrCCOXeDRvzW88PmUhk+f9TOXkMlx1UlMGdmpM\npeSkWIcWyMqEr0bCkqmw4hPYvjEor1wvTBQ7QaPOkNpMyaLEhJnNdve0WMchIvEl2lUrxwKL3X0p\ngJmNBXoC8yL2OQr4c7j+ITAhqhFK3FuwdgtPfLCQd75bS6VyZbjptBYM7tyEyvGSFGZLSIS0QcHi\nDut/gOUzgkRx6TT47pVgv4q1965ZrNFSyaKIiMRMtJPDesDKiOergONy7fMtcAFB03MvoJKZpbr7\nxsidzOxq4GqAhg018HBpsHjdFh6fsoi3v/uJCmXLcEPX5lzRuSlVUuIsKcyLWTD+Ya0j4dirgmRx\n4+IgWcxOGL9/Ldi3Qk1odGJQq9i4M9Q8AhIOYSxGERGRAxCPHVL+AjxtZgOB6cBqIDP3Tu7+PPA8\nBM3K0QxQomvJ+q08+cEi3vh2DeWTEvlTl2Zc2bkp1SqUjXVoB88MarQIluyaxU1LgyRx+SdBwjhv\nYrBv+epBsti4c1C7eFgrJYsiIlJkop0crgYaRDyvH5bt4e5rCGoOMbOKQG933xy1CCVuLN+wjSc/\nWMSEb1ZTrkwifzi5GVef3JTqxTkpzI9ZcO9hajNof3mQLG5eESSKK8Jk8Ye3gn2Tq4Y1i+F9i7Vb\nB03YIiIihSDayeGXQAsza0KQFPYFLo3cwcxqAJvcPQu4naDnspQiP27czlNTFzH+69UkJRpXdG7C\nH05pRo2K5WIdWvSYBb2aqzWGdv2Css0rcxLFFZ/AgneC8nKVoeEJOR1c6rSBxHhsFBARkeIgqv9B\n3D3DzK4DJhEMZTPM3eea2b3ALHd/A+gC/NPMnKBZ+dpoxiixs3LTdp75cDGvzl5FQoIx4ITGXNOl\nKbUqJcc6tPhQtQFU7Qtt+gbPf1sDKz7NuW9x0aSgvGxFaHBckCw2PgnqtoPEYnBfpoiIxIWoDmVT\nVDSUTfG2evMOnvlwMeNmrcQwLj2uIX/s0ozDKispPCBbfg5qFLPvW1w/PyhPSgnmem7UOUgY63WA\nMqWoFlbypaFsRCQvanuSmFn7606e+XAx//tyJY5zcccGXHtqc+pUKR/r0IqnSodBqwuCBWDbhpxE\nccUn8OH9QXmZZKjfMaeDS/2OkKREXEREAkoOJerW/baTZ6ct4eUvfiQry7korQHXntqM+tVSYh1a\nyVKhBhzVM1ggmMrvx5k5zdDTHgQcEstCvbSwGboz1D8WyuqzEBEprdSsLFGzfks6Qz5awkufrSAj\ny7mwfX2u69qcBtWViMTEjs3w42ewIkwWf/oWPAsSkqBe+5ze0A2Oh3IVYx2tFAE1K4tIXpQcSpHb\nuDWd/0xfysiZy9mVkcUF7etzfdfmNEqtEOvQJNLO32Dl5zm9oVd/BZ4Jlhh0asnuDd3w+GD+aCn2\nlByKSF6UHEqR+WXbLp7/eCkvfrqcnbsz6dm2Htd3bU7TmqqFKhbStwbJYvZ9i6tnQ9ZusIRgbMXG\n4QwuDU+A8lVjHa0cBCWHIpIXJYdS6DZv38V/P17G8E+WsX13Jue2rssN3VrQvJaSwmJt13ZY9WVO\nzeKqWZCZDhjUbpUz3V+jEyGleqyjlQJQcigieVGHFCk0v+7YzdAZyxg+Yxlb0jM4u3UdbuzWgpaH\nVYp1aFIYyqZA01OCBWD3Tlg9K+wNPQNmD4fPnwu21To6bIYOl4o1Yxe3iIgcENUcyiH7beduhs9Y\nzn9nLGXLzgzObFWbG09rwRG1dV9aqZKRHtynuGJGkDCu/Bx2bw+21Twip4NLo87BsDsSc6o5FJG8\nKDmUg7Y1PYMRnyzjhY+X8euO3Zx+1GHcdFoLjq5bJdahSTzI3A1rvoHlHwfN0D9+Bru2BttSm4dN\n0OHA3JXrxjbWUkrJoYjkRcmhHLBt6RmMnLmC56cv4Zftu+l2RC1uOq0lx9RXUij7kJkBa78NahWX\nzwjGXEz/LdhWrUlOrWLjTlC1YWxjLSWUHIpIXpQcSoHt2JXJqM+WM+SjpWzatosuh9fkptNa0raB\neqrKQcjKhLXf7T2Ly87NwbaqDXMSxUadoFpjMItpuCWRkkMRyYuSQ9mvnbszeemzFQz5aCkbtqZz\nUosa3HRaSzo0qhbr0KQkycqCdXNzOris+BS2bwy2Va6XM91f485QvamSxUKg5FBE8qLkUPK1c3cm\nY774keemLWHdlnRObJbKzae3pGNjDVMiUZCVBRsW5Ez3t+IT2LY+2Faxdk6tYuOToEYLJYsHQcmh\niORFQ9nI76RnZPLKlyt55sMlrP1tJ8c2qc6Tl7Tj+KapsQ5NSpOEBKh1ZLAcexW4w4ZFOdP9Lf8E\nvn8t2LdCrWB8xezaxZpHBMeLiMgBU3Ioe+zKyGLc7JU8M3Uxa37dSVqjavy7TxtOaJaKqVZGYs0M\narYMlrTBQbK4aWlOreLyGTBvQrBvSmqQLGbft1jraCWLIiIFpORQ2J2ZxWuzV/HU1MWs3ryDdg2r\n8tCFrencvIaSQolfZpDaLFg6DAiSxV+WR3RwmQHz3wz2Ta66d81i7WMgITGm4YuIxCslh6VYRmYW\nr3+9mienLmLlph20qV+FB3q14pSWNZUUSvFjBtWbBEu7y4KyzSvDZPHjIGFc8E5QXq4KNDw+qFVs\n3Blqt4FE/TkUEQElh6VSRmYWb3y7hic/WMTyjdtpVa8yfx94NKceXktJoZQsVRtA1b7Qpm/w/Lc1\nObWKy2fAoklBedlK0PC4nN7QddtBYlLs4hYRiSH1Vi5FMrOct+as4Ykpi1i6YRtH1qnMzae14PSj\nDlNSKKXTlrV7j7O4/oegPKkCNDg2Z2Dueu2hTLnYxloE1FtZRPIS9Tu0zayHmS0ws8Vmdlse2xua\n2Ydm9rWZzTGzs6IdY0mTleW8+e0auj8+nRvHfkNSYgJDLmvP29d35oyjaysxlNKrUm1o1RvO+Tdc\n+zn8ZTFc9CK06wdb18HU+2F4D3iwIYw4B6Y9FNQ47t4Z68jztHnzZp599tmYxmBm7cxsaLhuZvZk\n+Pd+jpm1z2P/Smb2TcSywcweD7c9FlG+0Mw2RxyXGbHtjYjyEWa2LGJb2wOMf4SZXXiQr/2/ZnbU\nwRxbgHMvL6TzHNDry+8zNLPGZjbtAK99j5n9JVwfaGZRnzczjPvSQjzfNDPb7xcsM7vBzOab2ejw\ntT99kNfrYmYn5irrY2bzzGyumb2ca1tlM1sVeT0zm2Jm+xyoOKrNymaWCDwDnA6sAr40szfcfV7E\nbncCr7j7c+Ev2TtA42jGWVJkZTmT5q7l8SmLWPDzFlrUqsgzl7bnzFa1SUhQQijyOxVrwtHnBwvA\n9k3BYNzLZwRN0dP+CTgkloP6aWEzdCeofyyUTYlp6JCTHP7pT3+K+rXNrIy7ZwB/Be4Pi88EWoTL\nccBz4eMe7r4FaBtxntnA+HDbzRHl1wPtIg7d4e75JX63uPurh/SCDoK7Xxnta0bBfj/DgzQQ+B5Y\nUwjnOhCNgUuBl/ez3x4RP9uH4k/Aae6+yswGHsJ5ugBbgU/D2FoAtwOd3P0XM6uVa//7gOm5ykaF\n8TyQ30WiXXN4LLDY3Ze6+y5gLNAz1z4OVA7XqxD9H5xizz1ICs968mP+OPordmdl8eQl7XjvppM5\nu3UdJYYiBZVSHY48B858EK6ZAbcug0vGBuMu7toGHz8KI3sGNYtDu8MH98LiDyB9a0zCve2221iy\nZAlt27bllltuAeCRRx6hY8eOtG7dmrvvvhuA5cuXc+SRRwI0CmsbJptZedhTwzEvrCUaG5ZVN7MJ\nYdlnZtY6LL/HzEaZ2SfAKDOrBLR292/DkHoCIz3wGVDVzOrkF7+ZtQRqAR/nsfkSYMwhv0m/v6aZ\n2dNhi9aU8PrZ2zqY2UdmNtvMJplZHTM7wsy+iNinsZl9F67vqUUKW8m+MrNvzeyDsKyCmQ0zsy8s\naB3L/f9vX9ZHXPPy8LP41sxGhWV71Qia2dYCvL67zOxLM/vezJ43y7MZKb/PMBPYtL+gzewOC2p9\nZwCHh2UXAmnA6LB292wzmxBxzOlm9nr267CgBnmumX1gZjXD8mZm9l742XxsZkcU8H18EDgpvO7N\nZpZsZsPN7LvwMzk1PP9AM3vDzKYC2Z/freF+35rZgxHnvCj8TBea2Ul5vAdDgKbAu2Z2c65tjc1s\navh5fmBmDcPyc83s8zCmKWZ2mJk1Bq4Bbg7jPwm4CnjG3X8BcPd1EefuABwGTM4V0hsEv0/5c/eo\nLcCFwH8jnvcHns61Tx3gO4KaxV+ADvmc62pgFjCrYcOGLu5ZWVn+/ty1ftYT073RrW95l0c+9PFf\nrfSMzKxYhyZSMu3Y7L5gkvvkv7k/39X9nmrud1d2/3t19xe6uU++y33hZPcdv0YlnGXLlvnRRx+9\n5/mkSZP8qquu8qysLM/MzPSzzz7bP/roI1+2bJknJiY6MNeDv6evAJeF62uAcuF61fDxKeDucL0r\n8E24fg8wGygfPj8VeM1z/k6/BXSOeP4BkOb5/4+4C3g0j/JGwE9AYkRZRvg/4DPg/IjyEcACYA7w\nWPZr2cc1LwDeBxKBusDm8H9VEkHtTM1wv4uBYeH6N0CTcP1W4M5wfRpB0lMTWBmxT/Xw8R8R73NV\nYCFQgSBp+iafpWqueI8Oj6uR69wjgAsj9tu6r9cXeWy4Pgo4N1y/BrjmYD7DXLF2IPh/nkJQ6bMY\n+EvkexWuG/BDxHv9ckQsDvSL+Pl4OiKOFuH6ccDUcL1fPu/jq+H2LsBbETH+X8TnegTwI5BMULO5\nKuL9PTP8eUjJ9b5PA/4Vrp8FTMnnvVge8ZkNjHgdbwIDwvXBwIRwvRo5/UKujLjGPdnvYfh8AvAw\n8AnB70KPsDwhjK1+5PUijlsEpOb32cVjb+VLgBHu/i8zO4Hg22grd8+K3Mndnweeh6BDSgzijBvu\nzrQF63lsykLmrPqVhtVTePSiNpzfti5lEjXwr0iRSa4CLc8IFoD0LbDy85wOLjOfgU8eB0uAOm1y\npvtreDyUr1rk4U2ePJnJkyfTrl3QGrt161YWLVpEw4YNadKkCYsXL94R7jqbnNt35hDU6Ewg+McD\n0BnoDeDuU80s1cyyW3jecPfs89QhoobrIPQlqDTIq/xVd8+MKGvk7qvNrCkw1cy+c/clBE1sa4Gy\nBP8jbgXu3cc1TwbGhOdeE9YUQZCwtQLeDyvUEgkSVAiS6YsJaqEuDpdIxwPT3X0ZgLtn17CdAZxn\n4X13BElIQ3efT0TT+n50Bca5+4Zc5z7Q1wdwqpn9P4LkrTowF3jT3YcUMJb9OQl43d23A1jEvaGR\n3N3DGtDLzGw4cAJwebg5C/hfuP4SMN7MKgInAuMiKjvLhecaDYw+gBg7E3z5wd1/MLMVQMtw2/sR\n7+9pwPDs15LrfR8fPkb+HhXUCQQJPAQJ+sPhen3gf2EtbVlgWT7HlyFo8u8SHjPdzI4BLgPe8aAZ\nO6/j1hF8WdiY30mjaTXQIOJ5/bAs0hVADwB3n2lmyUANghciEdyd6Ys28Nj7C/lm5WbqVyvPw71b\n06t9PZKUFIpEX7lK0Py0YAHYtR1WfREki8tnwBfPw8ynAQsG4s4elLvRiUETdiFzd26//Xb+8Ic/\n7FW+fPlyypXbq/d1JlA+XD+bIKE4F7gj/EezL9si1ncQJDzZCvI3HwAzawOUcffZeWzuC1wbWeDu\nq8PHpRZ0jGgHLHH37AQuPUw0/sLBMYKa1RPy2PY/gsRkfBCCLzqAc/Z29wV7FZodTk4ClFsXd9+c\nz7ZIGYS3iplZAkFCkX8gwf/WZwlq71aa2T3s/dllK/BneIiGE9Si7SRIfvO7x88JXudmz+OeUzPr\nB9ySx3GL3f1AOxpt2/8uAKSHj5kUXl71FPBvd3/DzLoQ1BjmZRXwubvvBpaZ2UKCZPEEgubzPwEV\ngbJmttXdszsCJxP8vuYp2hnEl0ALM2tiZmUJfuFzf5P4EegGYGZHEryAQ/kmWuK4O58s3sCFQ2Yy\nYNgXrN+Szj8vOIap/9eFPh0bKDEUiRdlU6BpF+h6Bwx+F277EQa8BV1uC2odZw2D//WDh5vCc53g\nnf8H8ybCtg0HdblKlSqxZcuWPc+7d+/OsGHD2Lo1uAdy9erVrFuX//fsMKlo4O4fEtS4VSH4x/Ix\nQXMd4T+qDe7+Wx6nmA80j3j+BnB5eN/b8cCvEclbbnneUxjeS1YNmBlRVs3MyoXrNYBOwLzweZ3w\n0YDzCTo9YGbHmtnIPK47HbjYzBLDY08NyxcANcMWLMwsycyOBghrKDOBv5F3UvcZcLKZNQmPzc78\nJwHXZ9/bZ2btwvMtcPe2+Sy5E8OpBPe4peY693KCZlyA8wiaxff1+rITwQ1hTVx+idN+P0Mzq2fh\nfZW5TAfON7PyFtyPem7Eti1Apewn7r6G4JaGOwkSxWwJEbFdCswIf/aWmdlF4fUt/HKBu4/O533M\nPsde12Xvn+2WQEOCzz6394FBZpYS7ltY3+Y+JciFCOPIvt+2CjlJ+ICI/XPHP4Gg1jD7d6ElsNTd\n+7l7Q3dvTPAFaWR2Yhj+/NUm+JnJU1RrDt09w8yuI/gFSSRo559rZvcCs9z9DYL2/xfCmzYdGOhh\nA7nAzCUbeWzKQr5YtonalZO57/xW9EmrT7kymgpMJO4llYcmJwULQEY6rJ6dMzD316Pgi/8E22oe\nkTMod+POUDF3J8TfS01NpVOnTrRq1YozzzyTRx55hPnz53PCCUHlV8WKFXnppZdITMz370Ui8JKZ\nVSGo5XrS3TeHtUrDzGwOsJ29/1ntETbLVTGzSh70Qn6H4D6sxeFxg7L3NbNvctX89An3za0vMDbX\n/4Ejgf+YWRZB8vCg54x6MdqCTgtGcK/ZNWF5Q/KuKXmdoKl2HkHlxMzwteyyoOPEk+H7UQZ4nKDp\nFYKk8BGgSR7vw3ozu5qgCTSBoOXrdIKeo48Dc8LyZcA5ecSUr/B/5gPAR2aWCXxNcE/ZC8BEM/sW\neI+cWq/8Xt9mM3uBIHleS1B5A4CZXRPuM4R9fIYR6hDUXOaO9Ssz+x/wbfgefBmxeQQwxMx2ACeE\ntyaMJrjvcH7EftuAY83szvAc2U34/YDnwvIkgg6u37J/c4DM8H0aQVB7+pwFnYoyCHKO9NxNse7+\nngXDIs0ys13h+/LX/C5iwTA9/3X3/Q3Hdz0w3MxuIagIy35/7yGonf6F4AtB9s/Zm8CrFnRmup4g\nnzrDzOYRfGG5xd3zbCqO0AH4bB+1sxoEu7j4YtkmHnt/ITOXbqRWpXJce2pzLu7YgOQkJYUiJUbG\nLvjpm5zp/lZ+DrvCns+pLXIG5W7cCSof+hBxVgSDYIdf7Le4+38L87yHysweAUa5+5xYx1LShJU+\nP4YVPIdynqeBr919aETZVneveKgxSg4ze4LgXuG8anuDfZQcxrfZKzbx2PuLmLF4AzUqluNPXZpx\n6XENlRSKlAaZGfDTtznT/f34GaSHrbnVmwY1i616Q7NT932efBRRcpgMXOTuowrzvFKyWTC+5Tbg\ndHdPjyhXcljIzOwqd39hn/soOYxPX//4C49NWcT0hetJrVCWa05pxmXHN6J8WSWFIqVWViasnZPT\nG3rFJ3D8tdDl1oM6XVEkhyJS/MXjUDal2pxVm3ns/YV8uGA91VKSuO3MI7j8hEaklNVHJVLqJSRC\n3XbBcuJ1QbKYkb7/40REDoAyjjjx/epfeXzKIqbM/5kq5ZO4pfvhDDixMRXL6SMSkXwkJMbFtH0i\nUrIo84ix+T/9xuNTFjJp7s9UTi7D/53ekoGdGlMpOWn/B4uIiIgUMiWHMbJg7Rae+GAh73y3lkrl\nynDTaS0Y1KkJVcorKRQREZHYUXIYZYvXbeGJDxbz1pw1VChbhuu7NufKzk2pkqKkUERERGJPyWGU\nLF2/lSc/WMTEb9dQPimRP57SjKtOakq1Cvuc4UhEREQkqpQcFrHlG7bx5NRFTPh6NeXKJHL1yU25\n+qSmpFYst/+DRURERKJMyWER+XHjdp6auojxX6+mTIJxRecm/OGUZtRQUigiIiJxTMlhIVv1y3ae\nnrqYV2evIiHBuPyERvzxlGbUqpy8/4NF5P+3d+cxdpVlHMe/Pyt7sS2WLnTBIR2C4FJIragEWQpU\nBBsiaBFQjBEFxGoUo5iAVKJGE7cExMpW1lKRpcGixbBKZakEpBRahrZaSrFSoFBKl2kf/zjvXI+X\ne5k75c4507m/T3Iz57znvec8feed3Kfve957zMysZE4Om+T5V97g4rs7mL1gBUKc8uGxnHnYOEYM\nclJoZmZm2w8nh2/TC2s3cMk9Hcx6eAVB8NkPjeGsw8ax1+Bdyg7NzMzMrMecHG6j1a9u4JJ7nuX6\nh//F1q3BSRNGc/bh4xg9xE8rMDMzs+2Xk8Me+s9rG/ntvc9yzYP/pHNr8OmDRnHOEe2M2cNJoZmZ\nmW3/nBw2aM26jcy4bykz/7acTZ1bOeHA0ZxzxDjeM3S3skMzMzMzaxonh914+fVNzLh/KTPnL2fD\n5i1MGT+Kc44Yxz57Diw7NDMzM7Omc3JYxyvrN3HZ/cu48oFlrN+8heM/sBdfP7KdccOcFJqZmVn/\n5eSwyto3NnPFX5dxxV+X8drGTj75/pFMm9TOvsN3Lzs0MzMzs15XeHIoaTLwK2AAcFlE/KTq+C+A\nw9PursCwiBjc23G9dpD6wwAACgRJREFUtmEzVz6wnMvuX8qrGzqZfMAIpk1q570j39XblzYzMzPr\nMwpNDiUNAC4GjgKeAx6RNCciFnXViYhv5uqfAxzYmzGt29jJzPnLmXHfUta+sZmj9h/ONya1c8Be\ng3rzsmZmZmZ9UtEjhxOBjohYCiBpFjAFWFSn/snABb0VzF1P/5tvzX6cl9dv5oj9hvHNSfvy/tFO\nCs3MzKx1FZ0cjgJW5PafAz5cq6KkvYE24K46x88AzgAYO3bsNgXTNnQg48cMZtqkfRk/ptdnrs3M\nzMz6vL68IGUqcFNEbKl1MCJmADMAJkyYENtygbahu3HlFydue4RmZmZm/cw7Cr7eSmBMbn90Kqtl\nKnBDr0dkZmZmZhVFJ4ePAO2S2iTtSJYAzqmuJGk/YAjwt4LjMzMzM2tphSaHEdEJfA34M/AUMDsi\nnpQ0XdKnclWnArMiYpumi83MzMxs2xR+z2FEzAXmVpWdX7X/gyJjMjMzM7NM0dPKZmZmZtaHOTk0\nMzMzswonh2ZmZmZW4eTQzMzMzCrUHxYES/oP8M9tfPtQ4MUmhtMsfTUu6LuxOa6ecVw90x/j2jsi\n9mxmMGa2/esXyeHbIWlBREwoO45qfTUu6LuxOa6ecVw947jMrFV4WtnMzMzMKpwcmpmZmVmFk0OY\nUXYAdfTVuKDvxua4esZx9YzjMrOW0PL3HJqZmZnZ/3jk0MzMzMwqnByamZmZWUW/TQ4lXSFptaSF\ndY5L0q8ldUj6h6SDcse+IOmZ9PpCwXGdkuJ5QtJ8SR/MHVueyh+TtKCZcTUY22GS1qbrPybp/Nyx\nyZIWp/b8boExnZuLZ6GkLZL2SMd6rb0kjZF0t6RFkp6UNK1GncL7WINxFd7HGoyrjP7VSFxl9bGd\nJT0s6fEU24U16uwk6cbULg9Jek/u2PdS+WJJxzQzNjPr5yKiX76AQ4GDgIV1jh8L3AEIOBh4KJXv\nASxNP4ek7SEFxvXRrusBn+iKK+0vB4aW2GaHAbfXKB8APAvsA+wIPA7sX0RMVXWPB+4qor2AkcBB\naXt3YEn1v7mMPtZgXIX3sQbjKqN/dRtXiX1MwMC0vQPwEHBwVZ2zgEvT9lTgxrS9f2qnnYC21H4D\neiNOv/zyq/+9+u3IYUTcB7z0FlWmAFdH5kFgsKSRwDHAnRHxUkS8DNwJTC4qroiYn64L8CAwulnX\n7k4DbVbPRKAjIpZGxCZgFln7Fh3TycANzbhudyJiVUQ8mrZfA54CRlVVK7yPNRJXGX2swfaqpzf7\nV0/jKrKPRUSsS7s7pFf1CsIpwMy0fRNwpCSl8lkRsTEilgEdZO1oZtatfpscNmAUsCK3/1wqq1de\nhi+RjTx1CWCepL9LOqOkmD6SprnukHRAKiu9zSTtSpZg/SFXXEh7pam8A8lGdvJK7WNvEVde4X2s\nm7hK61/dtVcZfUzSAEmPAavJ/kNRt49FRCewFng3feBv0sy2X+8sOwCrTdLhZB/ch+SKD4mIlZKG\nAXdKejqNrBXlUbJnsa6TdCxwK9Be4PXfyvHAAxGRH2Xs9faSNJAsWfhGRLzazHO/HY3EVUYf6yau\n0vpXg7/HwvtYRGwBxksaDNwi6X0RUfP+WzOzZmnlkcOVwJjc/uhUVq+8MJI+AFwGTImINV3lEbEy\n/VwN3ELB00QR8WrXNFdEzAV2kDSUPtBmZPdb/d90X2+3l6QdyBKK6yLi5hpVSuljDcRVSh/rLq6y\n+lcj7ZUU3sdy13kFuJs3335QaRtJ7wQGAWvoG3+TZradauXkcA7w+bSi9GBgbUSsAv4MHC1piKQh\nwNGprBCSxgI3A6dFxJJc+W6Sdu/aTnEVOoIgaUS6nwlJE8n6zxrgEaBdUpukHck+ROcUGNcg4OPA\nbbmyXm2v1A6XA09FxM/rVCu8jzUSVxl9rMG4Cu9fDf4ey+pje6YRQyTtAhwFPF1VbQ7Qtdr9RLLF\nMpHKp6bVzG1kI7APNys2M+vf+u20sqQbyFY/DpX0HHAB2Q3dRMSlwFyy1aQdwHrgi+nYS5J+SPaB\nBDC9ahqpt+M6n+yeoUvS52RnREwAhpNNK0H2e7s+Iv7UrLgajO1E4ExJncAbwNT0QdQp6WtkCc4A\n4IqIeLKgmABOAOZFxOu5t/Z2e30MOA14It0TBnAeMDYXWxl9rJG4yuhjjcRVeP9qMC4op4+NBGZK\nGkCWKM+OiNslTQcWRMQcssT2GkkdZAu3pqa4n5Q0G1gEdAJnpylqM7Nu+fF5ZmZmZlbRytPKZmZm\nZlbFyaGZmZmZVTg5NDMzM7MKJ4dmZmZmVuHk0MzMzMwqnBxaS5J0uqSo83qlxLiuSl/ZY2ZmVop+\n+z2HZg06iey5s3mdZQRiZmbWFzg5tFb3WER0lB2EmZlZX+FpZbM6clPPh0q6VdI6SWskXZweZ5av\nO1LS1ZJelLRR0j8knVrjnG2SrpH0Qqq3VNKvatQ7UNL9ktZLekbSV6uOj5A0U9Lz6TyrJN0uaVjz\nW8LMzFqJRw6t1Q2QVP13sDUitub2rwVmA5cAE8keP7cbcDpUnqt7LzCE7NFrK4BTyR5rtmtEzEj1\n2sieb7s+neMZsse0HV11/XcB1wO/BKaTPXbvN5IWR8Tdqc41wN7Auel6w4EjgV23tSHMzMzAyaHZ\n0zXK/ggcl9ufGxHfTtvzJAUwXdKPImIJWfLWDhweEfekendIGg5cJOny9FzbC4FdgA9GxPO588+s\nuv7uwFldiaCk+4BjgJOBruTwI8B5EXFd7n2/b/hfbWZmVoeTQ2t1J/DmBSnVq5VnV+3PAi4iG0Vc\nAhwKrMwlhl2uBa4E9geeIBshvL0qMaxlfW6EkIjYKGkJ2Shjl0eAcyUJuAtYGH5QupmZNYGTQ2t1\nCxtYkPLvOvuj0s89gFU13vdC7jjAu3lzIlrLyzXKNgI75/Y/C1wAfIds+nmVpEuBi6qmxM3MzHrE\nC1LMuje8zv7K9PMlYESN943IHQd4kf8llG9LRKyOiLMjYhSwH3AV2bT1V5pxfjMza11ODs2695mq\n/anAVuChtH8vMFrSx6rqfQ5YDSxK+/OA4ySNbGZwEbE4Is4jG3F8XzPPbWZmrcfTytbqxksaWqN8\nQW77WEk/I0vuJpJN514dEc+k41cB04CbJX2fbOr4FOAo4CtpMQrpfccC8yX9COggG0mcHBFv+tqb\neiQNAv4CXEe2oGYzMIVstfS8Rs9jZmZWi5NDa3X1Vvjumds+FfgWcCawCfgd0LV6mYh4XdLHgZ8C\nPyFbbbwYOC0irs3VWy7pYLLFLD8GBpJNTd/Ww5g3AI8CXyb7Oput6XqnRERPz2VmZvZ/5AWOZrVJ\nOp1stXG7n6JiZmatwvccmpmZmVmFk0MzMzMzq/C0spmZmZlVeOTQzMzMzCqcHJqZmZlZhZNDMzMz\nM6twcmhmZmZmFU4OzczMzKziv3ZlirHsEpu9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "337e58ae-8887-4a0d-d40d-50695e0c4a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "real_results, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "b6134aa0-f21f-4b69-9e35-83dee7e88a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "print(predicted_ys.cpu().shape)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6102])\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.579 P=0.579 R=0.579 F1=0.579 AUC=0.637\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.557     0.561     0.559      2899\n",
            "         1.0      0.600     0.596     0.598      3203\n",
            "\n",
            "    accuracy                          0.579      6102\n",
            "   macro avg      0.579     0.579     0.579      6102\n",
            "weighted avg      0.580     0.579     0.580      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1627 1294]\n",
            " [1272 1909]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.578563386833046, 0.5786158780730855, 0.5794821370042609, 0.5785820866599488)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUa9XwZ-4Xny",
        "colab_type": "text"
      },
      "source": [
        "##Baseline Sentence Entailment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    combined = premise_embedding * hypothesis_embedding\n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fbaSIM4jhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineHyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 30\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  num_classes = 1\n",
        "  epochs = 4\n",
        "  C = 0.3\n",
        "  is_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKfpJ-Hk4ePj",
        "colab_type": "code",
        "outputId": "1646f7a0-7059-4766-9104-8a4b03248744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "baseline_model = BaselineSentenceEntailment(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(baseline_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "base_loss, base_accuracy = train(model=baseline_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.639844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.609534\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.562448\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.513971\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.370854\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.247730\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.201731\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.095351\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 0.985577\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.018056\n",
            "Average loss is: tensor(1.3236, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.7763564560439561\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 0.917524\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 0.851188\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 0.833851\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 0.764165\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 0.675535\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 0.710958\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 0.637587\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 0.689426\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 0.620090\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 0.651273\n",
            "Average loss is: tensor(0.7311, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9776785714285714\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 0.569747\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 0.603883\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 0.557308\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 0.548623\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 0.560586\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 0.558798\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 0.522106\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 0.538202\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 0.525426\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 0.531242\n",
            "Average loss is: tensor(0.5607, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9923162774725275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXQ16nQW6Xb7",
        "colab_type": "code",
        "outputId": "66649b0a-eb8d-48de-e60d-6c466577b006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, base_loss, base_accuracy)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE6ryndKHqF4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY6ih2k9hGy",
        "colab_type": "code",
        "outputId": "556f8a82-1800-49d7-d098-1ee0103eb5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "base_real_results, baseline_predicted_ys = batch_wise_evaluate(baseline_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlPE-kpx9riu",
        "colab_type": "code",
        "outputId": "a95a545c-3437-46f8-abd1-b9202c378121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "evaluation_summary(\"baseline model\", baseline_predicted_ys.cpu(), base_real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: baseline model\n",
            "Classifier 'baseline model' has Acc=0.618 P=0.622 R=0.624 F1=0.617 AUC=0.653\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.699     0.585     0.637      3492\n",
            "         1.0      0.544     0.663     0.598      2610\n",
            "\n",
            "    accuracy                          0.618      6102\n",
            "   macro avg      0.622     0.624     0.617      6102\n",
            "weighted avg      0.633     0.618     0.620      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[2042  879]\n",
            " [1450 1731]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6216220797462166,\n",
              " 0.6239917841766403,\n",
              " 0.6183218616846935,\n",
              " 0.6173278230631674)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gmzMChW2xxT",
        "colab_type": "text"
      },
      "source": [
        "##DECLARE BASELINE :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qhGP9Y-Cj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(101, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    mean_embeddings = torch.unsqueeze(torch.sum(embeddings, 1) / self.hp.max_length, 1) #change to accurate size of lenfgth\n",
        "  \n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    #TODO: use repeat function to get 100*100\n",
        "    main_embeddings = torch.cat((mean_embeddings, added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    attention_weights = softmax(self.premise_linear(processed_premise))#TODO: turn into row vector\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis,attention_weights.transpose(1,2))\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    avg = torch.sum(combined, 1)/self.hp.max_length #todo: fix padding\n",
        "\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    output = torch.sigmoid(self.linear_final(smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2AvWEFOBYMQ",
        "colab_type": "code",
        "outputId": "f4fcdca3-646d-427f-ef6d-440e5376416f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "declare_model = BaselineDeclare(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(declare_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "declare_loss, declare_accuracy = train(model=declare_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.646877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.643674\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.641803\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.643408\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.642186\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.642182\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.642047\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.641801\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.642131\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.641846\n",
            "Average loss is: tensor(1.6424, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.49514938186813184\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.642090\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 1.642573\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 1.641918\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 1.642794\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 1.642354\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 1.641929\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 1.641343\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 1.641710\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 1.643291\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 1.642041\n",
            "Average loss is: tensor(1.6418, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5048935439560439\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 1.642108\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 1.641767\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 1.641672\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 1.642505\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 1.642909\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 1.641992\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 1.641834\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 1.641059\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 1.641747\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 1.643338\n",
            "Average loss is: tensor(1.6419, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5000429258241759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZweMG4WBnoY",
        "colab_type": "code",
        "outputId": "ec9336b7-385b-4df2-bd8c-b3cfd68d94b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, declare_loss, declare_accuracy)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmSMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6sN7kk2TqdE",
        "colab_type": "code",
        "outputId": "be349bd2-cc90-45c9-dd22-2037968dc0cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "declare_real_results, declare_predicted_ys = batch_wise_evaluate(declare_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJHn9s8T1bk",
        "colab_type": "code",
        "outputId": "f4ad3b30-545e-4c51-c469-2129a78f7418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "evaluation_summary(\"declare model\", declare_predicted_ys.cpu(), declare_real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: declare model\n",
            "Classifier 'declare model' has Acc=0.521 P=0.500 R=0.261 F1=0.343 AUC=0.500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.000     0.000     0.000         0\n",
            "         1.0      1.000     0.521     0.685      6102\n",
            "\n",
            "    accuracy                          0.521      6102\n",
            "   macro avg      0.500     0.261     0.343      6102\n",
            "weighted avg      1.000     0.521     0.685      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0 2921]\n",
            " [   0 3181]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.2606522451655195, 0.521304490331039, 0.3426693956695034)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0JKeQxFT5kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE_jCwcNtVnh",
        "colab_type": "text"
      },
      "source": [
        "##New DeCLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msT39pfytW8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(RealDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = 2*self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 1)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(100, 50)\n",
        "    self.linear_almost_there = torch.nn.Linear(50, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    mean_embeddings = torch.unsqueeze(torch.sum(embeddings, 1) / self.hp.max_length, 1) #change to accurate size of lenfgth\n",
        "  \n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    #TODO: use repeat function to get 100*100 #DONE!\n",
        "    main_embeddings = torch.cat((mean_embeddings.repeat(1, 100, 1), added_embeddings), 2)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    attention_weights = softmax(self.premise_linear(processed_premise.transpose(1,2)))#TODO: turn into row vector\n",
        "    repeated_weights = attention_weights.repeat(1, 1, 100)\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis, repeated_weights)\n",
        "\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    avg = torch.sum(combined, 1)/self.hp.max_length #todo: fix padding\n",
        "\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    even_smaller = F.relu(self.linear_almost_there(smaller))\n",
        "    output = torch.sigmoid(self.linear_final(even_smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKIZlt47tn1s",
        "colab_type": "code",
        "outputId": "1e732ed5-2760-4cfe-bf30-a473283129ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "declare_real_model = RealDeclare(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(declare_real_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "real_declare_loss, real_declare_accuracy = train(model=declare_real_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.641342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.625593\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.621315\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.545739\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.459789\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.533641\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.368400\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.326027\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.295847\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.341015\n",
            "Average loss is: tensor(1.4765, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.718492445054945\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.231501\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 1.202943\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 1.197221\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 1.208486\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 1.179433\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 1.151256\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 1.184249\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 1.161783\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 1.093229\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 1.157116\n",
            "Average loss is: tensor(1.1711, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9090401785714286\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 1.064299\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 0.982547\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 1.081209\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 1.020322\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 1.058961\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 1.054254\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 1.002365\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 1.026987\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 1.003136\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 1.080290\n",
            "Average loss is: tensor(1.0464, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9627833104395604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z27nLF9IuB6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "0aa8d1ac-2929-46a9-f4fa-18f168bf3268"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, real_declare_loss, real_declare_accuracy)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNDMzM7NO/w+wUtVgVUnEoAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8m4y58jizv8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e1e5514c-e475-483f-c6b6-7d2ff9057429"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "real_declare_real_results, real_declare_predicted_ys = batch_wise_evaluate(declare_real_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJH7fF2NBAwQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "90bcebe6-d8f0-45a3-f0af-eefa9bf032ba"
      },
      "source": [
        "evaluation_summary(\"real declare model\", real_declare_predicted_ys.cpu(), real_declare_real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: real declare model\n",
            "Classifier 'real declare model' has Acc=0.627 P=0.632 R=0.639 F1=0.623 AUC=0.688\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.751     0.586     0.658      3743\n",
            "         1.0      0.513     0.691     0.589      2359\n",
            "\n",
            "    accuracy                          0.627      6102\n",
            "   macro avg      0.632     0.639     0.623      6102\n",
            "weighted avg      0.659     0.627     0.631      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[2193  728]\n",
            " [1550 1631]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6317510647404603, 0.6386441634671565, 0.626679777122255, 0.6234859647830251)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGG5mT_uBEGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}