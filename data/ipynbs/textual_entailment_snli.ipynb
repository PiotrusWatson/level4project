{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "2329cfc7-3a78-4576-c043-0db102ce5905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-15 16:42:53--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  40.3MB/s    in 2.2s    \n",
            "\n",
            "2020-01-15 16:42:56 (40.3 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "11e2e5bf-974c-4e2b-fe35-db9e7592b355"
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-15 16:43:03--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-01-15 16:43:03--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-01-15 16:43:03--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.06MB/s    in 6m 27s  \n",
            "\n",
            "2020-01-15 16:49:30 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "aa394250-94fb-40d5-b6ab-432f8004b0af"
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-15 16:49:54--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  3.97MB/s    in 1.2s    \n",
            "\n",
            "2020-01-15 16:49:56 (3.97 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "969604c0-105f-48a2-fa1c-4478f4e654d0"
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1ebb8493-14ee-41fe-93db-cf67b2a74989"
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-15 16:50:06--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  4.48MB/s    in 1.2s    \n",
            "\n",
            "2020-01-15 16:50:07 (4.48 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "outputId": "66aaf47f-cb64-40c9-ba23-1c3953b6c61c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "32026039-d691-4145-b638-bd9f56f03637",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "03d450bf-dd0e-4c45-e3b2-8294cc7c903e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "outputId": "859e21a1-6005-46ed-bc7f-618e91d3d2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_id\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  train_unique, test_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_unique[\"claim_id\"])]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_unique[\"claim_id\"])]\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n",
        "train_facts.head(500)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>for firms moving overseas in order to create a...</td>\n",
              "      <td>foxnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>get a tax break specifically by outsourcing jo...</td>\n",
              "      <td>newslines.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>confusing clashes over taxes in wednesday s pr...</td>\n",
              "      <td>wsj.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>support on this bill in a time of tight budget...</td>\n",
              "      <td>senate.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>tax a lower rate for american manufacturing an...</td>\n",
              "      <td>archives.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>to have a different standard the senate will h...</td>\n",
              "      <td>thedailybeast.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>double standard for mcconnell to be less conce...</td>\n",
              "      <td>weaselzippers.us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>cory booker on government reform even billiona...</td>\n",
              "      <td>ontheissues.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>think are deeply committed to do and we are ob...</td>\n",
              "      <td>whitehouse.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>are deeply committed to do and we are obviousl...</td>\n",
              "      <td>haaretz.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cred_label  ...     article_source\n",
              "0             1  ...        foxnews.com\n",
              "1             1  ...      newslines.org\n",
              "2             1  ...            wsj.com\n",
              "3             1  ...         senate.gov\n",
              "4             1  ...       archives.gov\n",
              "..          ...  ...                ...\n",
              "554           1  ...  thedailybeast.com\n",
              "555           1  ...   weaselzippers.us\n",
              "556           1  ...    ontheissues.org\n",
              "557           1  ...     whitehouse.gov\n",
              "558           1  ...        haaretz.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "outputId": "eb050568-2b99-45f9-a6a1-fc8e17871c2d"
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>morning new tv advertisement argues that posit...</td>\n",
              "      <td>desmoinesregister.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>iowans could not support household on current ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>not budged in five years leaving many falling ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>are working to support themselves or their fam...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>prove that i had those good hardworking skills...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>cap is melting palin im not one to attribute e...</td>\n",
              "      <td>mysinchew.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2767</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>control the weapons the theocracy does secreta...</td>\n",
              "      <td>blastmagazine.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>be left with only one conclusion mccain was co...</td>\n",
              "      <td>chrisweigant.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2850</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>speech politifact called claim false that demo...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2851</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>covering conduct going back as far as 1994 was...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...              article_source\n",
              "85             1  ...       desmoinesregister.com\n",
              "86             1  ...  americanprogressaction.org\n",
              "87             1  ...  americanprogressaction.org\n",
              "88             1  ...           iowademocrats.org\n",
              "89             1  ...           iowademocrats.org\n",
              "...          ...  ...                         ...\n",
              "2766           0  ...               mysinchew.com\n",
              "2767           0  ...           blastmagazine.com\n",
              "2768           0  ...            chrisweigant.com\n",
              "2850           0  ...               democrats.org\n",
              "2851           0  ...               democrats.org\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "snopes_tokeniser = Tokeniser(x_train_snopes_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n",
        "x_snopes_train = snopes_tokeniser.do_everything(x_train_snopes_list)\n",
        "x_snopes_test = snopes_tokeniser.do_everything(x_test_snopes_list)\n",
        "y_snopes_train = np.array(y_train_snopes_list, dtype=np.float32)\n",
        "y_snopes_test = np.array(y_test_snopes_list, dtype=np.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "train_fact_source_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_source_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_train).type(torch.LongTensor))\n",
        "test_snopes_data= data_utils.TensorDataset(torch.from_numpy(x_snopes_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_test).type(torch.LongTensor))\n",
        "train_snopes_loader = data_utils.DataLoader(train_snopes_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "test_snopes_loader = data_utils.DataLoader(test_snopes_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(x)\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "    else:\n",
        "      x = self.linear1(x.reshape(self.hp.batch_size, -1))\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, unnormalised_predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(unnormalised_predictions.shape) == 1):\n",
        "    auc = roc_auc_score(true_labels, unnormalised_predictions)\n",
        "  else:\n",
        "    auc = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(real_results, 0), torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "30795daf-8a21-4a9a-975b-f4e97e2467af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",snopes_tokeniser.word_to_id,300)\n",
        "small_gloves = load_glove_embeddings(\"glove.6B.50d.txt\", snopes_tokeniser.word_to_id, 50)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44784\n",
            "44784\n",
            "torch.Size([44784, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 20\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  dropout=0.3\n",
        "  C = 0.3\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "a6c4ec7b-bf36-4c01-8024-f1ea5c5f2cd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "pass\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, small_gloves).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_snopes_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/11721 (0%)]\tLoss: 1.633106\n",
            "Train Epoch: 0 [2560/11721 (22%)]\tLoss: 1.650242\n",
            "Train Epoch: 0 [5120/11721 (44%)]\tLoss: 1.633231\n",
            "Train Epoch: 0 [7680/11721 (67%)]\tLoss: 1.560354\n",
            "Train Epoch: 0 [10240/11721 (89%)]\tLoss: 1.271606\n",
            "Average loss is: tensor(1.5425, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.6183159722222222\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/11721 (0%)]\tLoss: 1.089642\n",
            "Train Epoch: 1 [2560/11721 (22%)]\tLoss: 1.017903\n",
            "Train Epoch: 1 [5120/11721 (44%)]\tLoss: 0.976196\n",
            "Train Epoch: 1 [7680/11721 (67%)]\tLoss: 0.915907\n",
            "Train Epoch: 1 [10240/11721 (89%)]\tLoss: 0.907893\n",
            "Average loss is: tensor(0.9647, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9725694444444445\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/11721 (0%)]\tLoss: 0.869804\n",
            "Train Epoch: 2 [2560/11721 (22%)]\tLoss: 0.840272\n",
            "Train Epoch: 2 [5120/11721 (44%)]\tLoss: 0.842352\n",
            "Train Epoch: 2 [7680/11721 (67%)]\tLoss: 0.813835\n",
            "Train Epoch: 2 [10240/11721 (89%)]\tLoss: 0.803466\n",
            "Average loss is: tensor(0.8259, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9973958333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "fac6f2ce-2e8f-4e63-8e41-b3ec86604d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZmZmdX9Fw/CdSKFW4xPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "84b448e5-9cbc-4004-82cb-858bc0bc3013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "real_results, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_snopes_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "ae150efb-3e6a-4e85-a092-0bb0b1820450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(predicted_ys.cpu().shape)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), real_results.cpu(), y_snopes_test)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3050])\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.623 P=0.632 R=0.632 F1=0.623 AUC=0.713\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.560     0.707     0.625      1353\n",
            "         1.0      0.704     0.557     0.622      1697\n",
            "\n",
            "    accuracy                          0.623      3050\n",
            "   macro avg      0.632     0.632     0.623      3050\n",
            "weighted avg      0.640     0.623     0.623      3050\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[956 752]\n",
            " [397 945]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6319459229295294,\n",
              " 0.6317215154259005,\n",
              " 0.6232786885245901,\n",
              " 0.6232737883502704)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUa9XwZ-4Xny",
        "colab_type": "text"
      },
      "source": [
        "##Baseline Sentence Entailment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    combined = premise_embedding * hypothesis_embedding\n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fbaSIM4jhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineHyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 30\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  num_classes = 1\n",
        "  epochs = 4\n",
        "  C = 0.3\n",
        "  is_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKfpJ-Hk4ePj",
        "colab_type": "code",
        "outputId": "887d0b77-3e38-42a1-a7eb-16fee66305d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "baseline_model = BaselineSentenceEntailment(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(baseline_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "base_loss, base_accuracy = train(model=baseline_model,\n",
        "                       train_loader=train_snopes_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/11721 (0%)]\tLoss: 1.639945\n",
            "Train Epoch: 0 [2560/11721 (22%)]\tLoss: 1.639275\n",
            "Train Epoch: 0 [5120/11721 (44%)]\tLoss: 1.629412\n",
            "Train Epoch: 0 [7680/11721 (67%)]\tLoss: 1.538554\n",
            "Train Epoch: 0 [10240/11721 (89%)]\tLoss: 1.318675\n",
            "Average loss is: tensor(1.5484, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.628125\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/11721 (0%)]\tLoss: 2.364672\n",
            "Train Epoch: 1 [2560/11721 (22%)]\tLoss: 1.107841\n",
            "Train Epoch: 1 [5120/11721 (44%)]\tLoss: 0.963672\n",
            "Train Epoch: 1 [7680/11721 (67%)]\tLoss: 0.990440\n",
            "Train Epoch: 1 [10240/11721 (89%)]\tLoss: 0.951709\n",
            "Average loss is: tensor(1.0493, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9519965277777778\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/11721 (0%)]\tLoss: 0.923537\n",
            "Train Epoch: 2 [2560/11721 (22%)]\tLoss: 0.905518\n",
            "Train Epoch: 2 [5120/11721 (44%)]\tLoss: 0.899291\n",
            "Train Epoch: 2 [7680/11721 (67%)]\tLoss: 0.887970\n",
            "Train Epoch: 2 [10240/11721 (89%)]\tLoss: 0.877543\n",
            "Average loss is: tensor(0.8947, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9954861111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXQ16nQW6Xb7",
        "colab_type": "code",
        "outputId": "a74a44da-982b-4292-a8a6-765cb375768a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, base_loss, base_accuracy)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3xW9fn/8deVQcJWhgIJGBAUBRkS\noAjiQCsqVXGg1RZxgKOu9lerVuuqtrVaV6tMFSd8HQhuURGZIuAGVCBs0CiIzEDG9fvjnMBNTOAO\nJjkJeT8fj/PI2ec6d0K48pnm7oiIiIiIACREHYCIiIiIVB5KDkVERERkByWHIiIiIrKDkkMRERER\n2UHJoYiIiIjsoORQRERERHZQcihSxZhZhpm5mSVFHYuIiOx7lByKiIiIyA5KDkUqMZUOiohIRVNy\nKNWKmd1gZqvMbKOZfW1mfcL9o83srpjzjjWzlTHbS83sJjObb2Y/mtkTZpZawjMGmdk0M7svPHeJ\nmZ0cc7y+mT1mZmvCWO4ys8SYa6eb2QNmtha43cwSw3v9YGZZwKnFPC8rfKclZnZB2X5qIiJSnSg5\nlGrDzA4FrgK6untd4CRgaSlucUF4zcHAIcAtuzm3O/A10Aj4N/CYmVl4bDSQB7QGOgO/Bi4tcm0W\ncCBwNzAY6BeemwmcHfNOtYGHgZPDdzoK+LQU7yQiIrILJYdSneQDKcDhZpbs7kvdfXEprv+fu69w\n93UESdtvd3PuMncf6e75wJNAU+BAMzsQOAW4zt03u3s28ABwXsy1q939v+6e5+5bgQHAgzHP/meR\nZxUA7c2spruvcfd5pXgnERGRXSg5lGrD3RcB1wG3A9lmNtbMmpXiFiti1pcBu7v225jnbglX6wAH\nAcnAGjNbb2brgeHAASU8h/A5RZ9deO/NwLnA5eE9XzeztvG9joiIyM8pOZRqxd2fc/deBEmaA/eE\nhzYDtWJObVLM5c1j1lsAq/cihBXANqCRu+8XLvXcvV1smEWuWVPMs3ee7P62u59IUDr5FTByL+IS\nEREBlBxKNWJmh5rZ8WaWAuQAWwmqZCFop3eKmTUwsyYEJYxF/cHM0s2sAXAz8H+ljcHd1wATgf+Y\nWT0zSzCzg83smN1c9jxwTfjs/YEbY97pQDM7PWx7uA3YFPNOIiIipabkUKqTFOBfwA8E1b4HADeF\nx54GPiPooDKR4hO/58JjWcBi4K5izonHQKAGMB/4EXiRoNSvJCOBt8P4PgbGxRxLAP5EUIq5DjgG\nuGIv4xIREcHci9ZgiUhRZrYUuNTd3406FhERkfKkkkMRERER2UHJoYiIiIjsoGplEREREdlBJYci\nIiIiskNS1AGUhUaNGnlGRkbUYYiIVClz5879wd0bRx2HiFQu+0RymJGRwZw5c6IOQ0SkSjGzZXs+\nS0SqG1Uri4iIiMgOSg5FREREZAclhyIiIiKywz7R5lBE9l25ubmsXLmSnJycqEOpslJTU0lPTyc5\nOTnqUESkClByKCKV2sqVK6lbty4ZGRmYWdThVDnuztq1a1m5ciUtW7aMOhwRqQJUrSwilVpOTg4N\nGzZUYriXzIyGDRuq5FVE4qbkUEQqPSWGv4w+PxEpjeqdHG5eC2/dBNs2Rh2JiIiISKVQvZPDrPdh\n1jAY1guWz4o6GhGpxMaPH4+Z8dVXX0UdiohIuareyeERZ8OgN8AL4Im+8P4/ID836qhEpBIaM2YM\nvXr1YsyYMeX2jPz8/HK7t4hIvKp3cghwUA+4fDp0OBc+uAce7wtrF0cdlYhUIps2bWLatGk89thj\njB07dsf+e+65hyOOOIKOHTty4403ArBo0SJOOOEEOnbsyJFHHsnixYuZPHky/fr123HdVVddxejR\no4Fg+s8bbriBI488khdeeIGRI0fStWtXOnbsyFlnncWWLVsA+O677+jfvz8dO3akY8eOzJgxg1tv\nvZUHH3xwx31vvvlmHnrooQr4RERkX6ahbABS60H/YdDm1/DaH2HY0dD3n3DkQFBDbpFK445X5zF/\n9YYyvefhzepx22/a7facCRMm0LdvXw455BAaNmzI3Llzyc7OZsKECcyaNYtatWqxbt06AC644AJu\nvPFG+vfvT05ODgUFBaxYsWK392/YsCEff/wxAGvXrmXw4MEA3HLLLTz22GNcffXVXHPNNRxzzDG8\n/PLL5Ofns2nTJpo1a8aZZ57JddddR0FBAWPHjuWjjz4qg09FRKozJYex2p8JzbvD+Cvg1Wvgm7fh\ntIehdqOoIxORCI0ZM4Zrr70WgPPOO48xY8bg7lx00UXUqlULgAYNGrBx40ZWrVpF//79gWDw6Xic\ne+65O9a//PJLbrnlFtavX8+mTZs46aSTAJg0aRJPPfUUAImJidSvX5/69evTsGFDPvnkE7777js6\nd+5Mw4YNy+y9RaR6UnJYVP00+P14+PBReO8OGHoUnP4otDkh6shEqr09lfCVh3Xr1jFp0iS++OIL\nzIz8/HzMjHPOOSfueyQlJVFQULBju+iYg7Vr196xPmjQIMaPH0/Hjh0ZPXo0kydP3u29L730UkaP\nHs23337LxRdfHHdMIiIlUZvD4iQkwFFXweD3oVZDePYseON6yN0adWQiUsFefPFFfv/737Ns2TKW\nLl3KihUraNmyJfXr1+eJJ57Y0SZw3bp11K1bl/T0dMaPHw/Atm3b2LJlCwcddBDz589n27ZtrF+/\nnvfee6/E523cuJGmTZuSm5vLs88+u2N/nz59GDp0KBB0XPnpp58A6N+/P2+99RazZ8/eUcooIvJL\nKDncnSbtgwTxV1fCRyNg+DGw5rOooxKRCjRmzJgd1cSFzjrrLNasWcNpp51GZmYmnTp14r777gPg\n6aef5uGHH6ZDhw4cddRRfPvttzRv3pwBAwbQvn17BgwYQOfOnUt83t///ne6d+9Oz549adu27Y79\nDz30EO+//z5HHHEEXbp0Yf78+QDUqFGD4447jgEDBpCYmFgOn4CIVDfm7lHH8ItlZmb6nDlzyvch\niyfBy1fAlrVw/C1w1NWQoF/EIuVtwYIFHHbYYVGHUWkVFBTs6Oncpk2bEs8r7nM0s7nunlneMYpI\n1aKSw3gdfDxcORMO7Qvv3gZPnQ7rd98DUUSkPM2fP5/WrVvTp0+f3SaGIiKloQ4ppVGrAQx4Gj59\nDt78CwztCf3uDwbTFhGpYIcffjhZWVlRhyEi+xiVHJaWGXS+AC6fCo0PhZcugZcGw9b1UUcmIiIi\n8ospOdxbDVrBRW/CcTfDly8F8zMvnRZ1VCIiIiK/iJLDXyIxCY75C1wyERKTYXQ/ePd2yNsedWQi\nIiIie0XJYVlIz4TLpgbT7U17AEb1ge+/jjoqERERkVJTclhWUuoEU+2d+yz8tBKG94aPRsI+MFSQ\nSHVXp06dqEMQEakwSg7L2mH9giFvMnrBG3+G5wbApuyooxIRERGJi5LD8lC3CVzwIpx8LyyZAo/2\ngK/eiDoqESlDS5cu5fjjj6dDhw706dOH5cuXA/DCCy/Qvn17OnbsSO/evQGYN28e3bp1o1OnTnTo\n0IGFCxdGGbqIyG5pnMPyYgbdh0DL3jDuUhj7W+gyCE76B9SoHXV0IlXTmzfCt1+U7T2bHAEn/6vU\nl1199dVceOGFXHjhhTz++ONcc801jB8/njvvvJO3336btLQ01q8PhrgaNmwY1157LRdccAHbt28n\nPz+/bN9BRKQMqeSwvB3QFi59D3peC3OfhGFHw6q5UUclIr/QzJkzOf/88wH4/e9/z7RpwVBWPXv2\nZNCgQYwcOXJHEtijRw/+8Y9/cM8997Bs2TJq1qwZWdwiInuiksOKkJQCJ94JrU+Ely+HUSfCsTdB\nrz8Gw+GISHz2ooSvog0bNoxZs2bx+uuv06VLF+bOncv5559P9+7def311znllFMYPnw4xx9/fNSh\niogUSyWHFanl0XDFdGjXH96/C0afCj8ujToqEdkLRx11FGPHjgXg2Wef5eijjwZg8eLFdO/enTvv\nvJPGjRuzYsUKsrKyaNWqFddccw2nn346n3/+eZShi4jslpLDilZzPzj7MThzFGTPh6G9grmaNeSN\nSKW1ZcsW0tPTdyz3338///3vf3niiSfo0KEDTz/9NA899BAA119/PUcccQTt27fnqKOOomPHjjz/\n/PO0b9+eTp068eWXXzJw4MCI30hEpGTm+0BSkpmZ6XPmzIk6jNJbvzyoZl42HQ4/Hfo9CLUaRB2V\nSKWyYMECDjvssKjDqPKK+xzNbK67Z0YUkohUUio5jNJ+LeDCV+GE24OhboYeBYvfjzoqERERqcaU\nHEYtITHomHLpu5BSF54+A976K+TmRB2ZiIiIVENKDiuLZp1gyAfQdTB8+AiMPB6+mxd1VCKVwr7Q\n/CVK+vxEpDSUHFYmNWrBqffB+S/A5u9hxHEw81EoKIg6MpHIpKamsnbtWiU4e8ndWbt2LampqVGH\nIiJVhAbZq4wO+TVcMQNeuRrevgkWvg1nDIV6zaKOTKTCpaens3LlSr7//vuoQ6myUlNTSU9PjzoM\nEakiKrS3spk9DvQDst29/W7O6wrMBM5z9xf3dN8q21t5T9xh7mh4+6+QWAN+8xC0OyPqqERkH6He\nyiJSnIquVh4N9N3dCWaWCNwDTKyIgCo1M8i8CC6bCg1awQsXwvgrIWdD1JGJiIjIPqpCk0N3nwKs\n28NpVwMvAdnlH1EV0ag1XDIRev8FPhsDw3rB8llRRyUiIiL7oErVIcXM0oD+wNA4zh1iZnPMbE61\naIuUmAzH3wwXvRlsP9EXJt0N+bnRxiUiIiL7lEqVHAIPAje4+x6757r7CHfPdPfMxo0bV0BolUSL\nX8Hl06DDeTDl3/D4SbB2cdRRiYiIyD6isiWHmcBYM1sKnA08ambqgVFUaj3oPxTOGR0khsN6BR1X\nNNSHiIiI/EKVKjl095bunuHuGcCLwJXuPj7isCqvdv3hypmQ3hVevRbGng+bf4g6KhEREanCKjQ5\nNLMxBEPUHGpmK83sEjO73Mwur8g49in1msHvx8NJ/4BF78KjPWDhO1FHJSIiIlVUhY5zWF722XEO\nS+u7efDSpZA9P5iG78Q7g1lXRESKoXEORaQ4lapaWX6hA9vB4PfhV3+A2SNhxLGw5rOooxIREZEq\nRMnhviY5Ffr+I6hq3rYBRvaBaQ9AQX7UkYmIiEgVoORwX3XwccH8zIeeDO/eDk+eButXRB2ViIiI\nVHJKDvdltRrAgKfgjKGw5lMY2hM+fyHqqERERKQSU3K4rzODTucHA2cf0BbGXRp0Wtm6PurIRERE\npBJSclhdNGgJg96A426GL8cFpYhLp0UdlYiIiFQySg6rk8QkOOYvcMk7kFQDRveDd26DvO1RRyYi\nIiKVhJLD6ii9C1w2FY4cCNMfhFHHw/dfRx2ViIiIVAJKDqurlDpw2sNw3nOwYTUM7w0fjdT8zCIi\nItWcksPqru2pcMVMyDga3vgzPHs2bPwu6qhEREQkIkoOBeoeCBe8AKfcF3RSGdoDvno96qhEREQk\nAkoOJWAG3QbDZVOgXhqMPR9euQa2bYo6MhEREalASg5lV40PhUvfg57XwcdPwfCjYeXcqKMSERGR\nCqLkUH4uqQaceAcMei0Y5uaxE+GDf0N+XtSRiYiISDlTcigly+gFV0yH9mfC+3fDEyfDuiVRRyUi\nIiLlSMmh7F7N/eCsUXDmqGAsxGG94JNnNeSNiIjIPkrJocSnwzlwxTRo2gkmXAkvXAhb1kUdlYiI\niJQxJYcSv/1awIWvwAl3wFdvwNCjYPGkqKMSERGRMqTkUEonIRF6XQeXvgspdeHp/vDWTZCbE3Vk\nIiIiUgaUHMreadYJhnwA3YbAh4/CyOPg2y+jjkpERER+ISWHsvdq1IJT7oULXoTNPwQJ4oz/QUFB\n1JGJiIjIXlJyKL9cmxPhypnQ+kSYeDM8fQb8tCrqqERERGQvKDmUslG7EZz3LPzmIVg5O+isMu/l\nqKMSERGRUlJyKGXHDLoMgsunQYNW8MIgePkKyNkQdWQiIiISJyWHUvYaHgyXTITef4HPx8KwnrD8\nw6ijEhERkTgoOZTykZgMx98MF70FWDD13qS7ID836shERERkN5QcSvlq0T2oZu54Pky5Fx77Nfyw\nKOqoREREpARKDqX8pdaDMx6Bc56EdVkw/GiY84TmZxYREamElBxKxWl3RjDkTfNu8Np1MOa3sOn7\nqKMSERGRGEoOpWLVawa/exlO+mcwL/PQHvDNxKijEhERkZCSQ6l4CQnQ40oY8j7UPgCeOwde/3+w\nfUvUkYmIiFR7Sg4lOge2g8GToMdVMHsUjDgGVn8adVQiIiLVWlzJoZlNMrO2JRw7xMwmlW1YUm0k\np8JJd8PACbBtE4zqA1Pvh4L8qCMTERGpluItOTwWqFfCsbrAMWUSjVRfrY6FK6ZD21PhvTvgyd/A\n+uVRRyUiIlLtlKZauaRxRw4GNsVzAzN73MyyzezLEo5fYGafm9kXZjbDzDqWIj6p6mo1CIa7OWMY\nrPkchvaEz5+POioREZFqJamkA2Z2EXBRuOnACDPbWOS0mkB74L04nzca+B/wVAnHlwDHuPuPZnYy\nMALoHue9ZV9gBp1+Cwf1gHFDYNxg+OZtOPU/UHO/qKMTERHZ5+2u5LAAyA8XK7JduKwFhgKXxPMw\nd58CrNvN8Rnu/mO4+SGQHs99ZR+0fwYMegOOvwXmjw9KEZdMjToqERGRfZ55HLNUmNn7wBXu/tUv\nfqBZBvCau7ffw3l/Btq6+6UlHB8CDAFo0aJFl2XLlv3S0KSyWjUXXhoczK5y1NVBwpiUEnVUIlWe\nmc1198yo4xCRyiWuNofuflxZJIbxMrPjCEojb9hNTCPcPdPdMxs3blxRoUkU0rrA5VOhy4Uw4+Gg\nR3N2hf04ioiIVCsltjksyszqAacALYDUIofd3f9eFgGZWQdgFHCyu68ti3vKPqBGbfjNQ9DmJHjl\nqmBMxBPvhG5DgnaKIiIiUibiSg7NrCfwKlBSjwAHfnFyaGYtgHHA7939m196P9kHtT0F0mYGCeKb\nf4GFE+H0R6Buk6gjExER2SfEO5TNg8BSoCuQ6u4JRZbEeG5iZmOAmcChZrbSzC4xs8vN7PLwlFuB\nhsCjZvapmc0p3etItVD3QDj/eTjlPlg6DYYeBQteizoqERGRfUK8HVI2AQPc/Y3yD6n0MjMzfc4c\n5ZHV0vdfB8PdrPkMjhwIJ/0TUupEHZVIlaAOKSJSnHhLDpcD6h4qlU/jQ+GSd6HXH+Hjp2H40bBS\nfyiIiIjsrXiTwzuAG8NOKSKVS1INOOF2GPQ65OfCY7+GyfdAfl7UkYmIiFQ58fZW7gccCCwxs5n8\nfCBrd/cLyzQykdLK6AmXT4M3rofJ/4BF78KZw6FBq6gjExERqTLiTQ57EfRI3gC0K+b4nhsuilSE\nmvvBWSPhkJPgtT/BsKPh5Hug0wUa8kZERCQOcSWH7t6yvAMRKVNHnA3Nu8P4K2DCH+Cbt+A3D0Ot\nBlFHJiIiUqnF2+ZQpOrZrzkMnAAn3AFfvwWP9oBF70UdlYiISKUWV3JoZi32tJR3oCJ7JSERel0H\ng9+D1PrwzJnw5o2QmxN1ZCIiIpVSvG0Ol7LndoVxDYQtEommHeGyD+Cd22DWUMiaDGeNgibto45M\nRESkUok3ObyYnyeHDQl6MbekDKbOEyl3yTXhlH9DmxODdogjj4M+t8GvroQEtbAQERGB+DukjC7h\n0P1m9jSgsUKk6mhzIlwxA165BibeDAvfhjOGQf20qCMTERGJXFkUlzxDULIoUnXUbgTnPRv0YF45\nB4b2gC/HRR2ViIhI5MoiOTwASC2D+4hULDPocmEwcHbD1vDiRTDuMsjZEHVkIiIikYmrWtnMehez\nuwbQHrgJmFqWQYlUqIYHw8Vvw5R7g2X5DOg/Ag7qEXVkIiIiFS7eDimT+XmHlMLpJj4AriirgEQi\nkZgMx/0VWp8A4wbD6FOg1x/h2JuCYyIiItVEvMnhccXsywGWufu3ZRiPSLSadwuqmd+8Eab+BxZP\ngjNHQqM2UUcmIiJSIeLtrfxBeQciUmmk1IUzHoFDfg2vXgvDe8NJd0OXizQ/s4iI7PPiLTkEwMza\nA8cADYB1wGR3n1cegYlE7vDTIb0rjL8SXvsjfPM2nPY/qNM46shERETKTbwdUpKA0cBv2dnWEMDN\n7DlgkLvnl314IhGr1wx+Nw4+Gh7MrjK0B5z+CBxyUtSRiYiIlIt4h7K5DRgA3EowI0rN8OutwLnh\nV5F9U0IC/OoKGDIZ6hwIzw2A1/4E27dEHZmIiEiZizc5/B1wl7vf7e7L3H1b+PVu4C5gYPmFKFJJ\nHHg4DJ4EPa6COY8FbRFXfxJ1VCIiImUq3uSwGTCjhGMzwuMi+76klKBzysAJsH0zjDoh6NVcoFYV\nIiKyb4g3OVwN9Czh2FHhcZHqo9WxcMV0aNsP3rsTRveDH5dFHZWIiMgvFm9y+Cxws5n9zcxamVlN\nM2tpZjcBNwNPl1+IIpVUrQZwzmg4Yxh8+wUM6wWf/R940fHiRUREqg7zOP4jC3srPwWcx64zpRgw\nBrjQ3fPKJcI4ZGZm+pw5c6J6vAj8uDSYl3nFh9DuTOh3P9TcP+qoRHbLzOa6e2bUcYhI5RJXcrjj\nZLN2QG92jnM4pTKMc6jkUCqFgnyY9gBM/mfQq7n/MGhZ3LTkIpWDkkMRKU6pBsEOE8HIk0GRSikh\nEXr/GQ4+DsYNgSdPg6Ougq6DYb8Wml1FRESqhNLOkNIcaA6kFj3m7pPKKiiRKi2tC1w2BSbeAjP+\nGyy1D4D0zHDpCs06B9P0iYiIVDLxzpDSiqBTSrfCXeFXD9cdSCzz6ESqqhq1od8DQanh8hmwck6w\nfP1GcNwS4IDDdyaLaZnQ6JBgwG0REZEIxfs/0SigBXAd0Bc4LlyOj/kqIkUdeDh0vTRof3j1HPjL\nErjgJej9l6Bd4ryXYcIf4NHucE8GPHUGTLobvpkIW9ZFHb1UQW+99RaHHnoorVu35l//+tfPji9b\ntow+ffrQoUMHgEPNLL3wmJndY2Zfhsu5MftHm9kSM/s0XDrF3tPMuppZnpmdHbPv32Y2z8wWmNnD\nZkG7CjOrYWYjzOwbM/vKzM4K9/c2s4+L3ic89paZrTez14rsv8rMFpmZm1mjmP1tzWymmW0zsz8X\nueZxM8s2sy+L7D8njLfAzDJj9jc0s/fNbJOZ/a/INXeb2Qoz21Rkf6nfRaQyibdauSvB/MkvlWcw\nIvu8Wg2gzQnBAlBQAGsXwao5sHJ2sEy9D7wgON6gVVCymN41KGU8sD0kJkcXv1Rq+fn5/OEPf+Cd\nd94hPT2drl27ctppp3H44YfvOOfPf/4zAwcO5MILL8TMVgP/BH5vZqcCRwKdgBRgspm96e4bwkuv\nd/cXiz7TzBKBe4CJMfuOIhgbt0O4axpwDDCZYPizbHc/xMwSCDo4AiwHBgG7JHOhe4FawGVF9k8H\nXgvvG2sdcA1wRjH3Gg38j2AEjlhfAmcCw4vszwH+BrQPl1ivhvdaWGT/3ryLSKURb3K4EthenoGI\nVEsJCdD4kGDpdH6wb9smWPNpmCzOgazJ8Pn/BceSUoP2iumZQVV0eleonxZZ+FK5fPTRR7Ru3ZpW\nrVoBcN555zFhwoRdksP58+dz//33F25uBE4P1w8nGIEiD8gzs88Jaoqe38NjrwZeIihEKOQEbdNr\nEDQ9Sga+C49dDLQFcPcC4IdwfSmAmRUUfYC7v2dmxxaz/5PwmqL7s4HsMOEtemyKmWUUs39BCffa\nDEwzs9bFXPNhCdeU+l1EKpN4k8N/ADeY2aTwH4qIlJeUOpDRK1ggGFT7p5U7k8WVs2HWCMj/b3C8\nbrOdbRfTu0LTjlCjVnTxS2RWrVpF8+bNd2ynp6cza9asXc7p2LEj48aN49prrwXYD6hrZg2Bz4Db\nzOw/BCVbxwHzYy6928xuBd4DbnT3bWaWBvQPz92RHLr7TDN7H1hDkBz+z90XmNl+4Sl/DxOkxcBV\n7v4dIlJpxJUcuvvTZtYWWGpmHwI//vwUv7DMoxORYAic/ZoHS/szg3152+G7L3Ymiytnw4JXwvMT\noUn7mOrorkH1tIbSEeC+++7jqquuYvTo0QB1gVVAvrtPNLOuwAzge2AmUDhp+E3AtwQlgSOAG4A7\ngQeBG9y9ILb0LCxlOwwobM/4jpkdDSwI981w9z+Z2Z+A+4Dfl98bi0hpxdtbeRDBL4d8gjYpRauY\nNV+YSEVKqhEMmZPWBbqHTZc2fR/TdnFOMJXf7FHBsZr77+wVnZ4ZXFdzv5LvL1VSWloaK1as2LG9\ncuVK0tJ2bXbQrFkzxo0bB4CZrQIOcPf1AO5+N3B3eOw54Jtw/5rw8m1m9gQ729JlAmPDxLARcIqZ\n5QFtgA/dfVN4rzeBHgRtD7cA48LrXwAuKaPXF5EyEm+18h3Ay8Alhb9E9oaZPQ70I2iMXLRhL2Fv\ntoeAUwh+gQxy94/39nki1UqdxnDoycECwYwt33+9s2Rx5RxY+A47/pZrdOjOji7pmdD4MEgs1dCn\nUsl07dqVhQsXsmTJEtLS0hg7dizPPffcLuf88MMPNGjQgIRg2KSmwEjY0bFkP3dfa2YdCDqTTAyP\nNXX3NeHv6DMIOm/g7i0L72tmo4HX3H182NN5sJn9k6Ba+RjgQXd3M3sVOBaYBPRh16prEakM3H2P\nC7AJ6BPPuXu4T2+CkscvSzh+CvAmwS+TXwGz4rlvly5dXETisPUn98Xvu3/wb/dnB7jf09L9tnrB\ncldT9ydOdX/nNvcFr7lv+DbaWGWvvP76696mTRtv1aqV33XXXe7u/re//c0nTJjg7u4vvPCCt27d\n2tu0aeME1ccpHvz+TSVI1OYDHwKdfOfv5knAFwRJ4TNAHf/57+/RwNnheiJBr98F4f3ujznvIGAK\n8DlB+8UW4f6uBJ0fNwNrgXkx10wNY90annNSuP+acDsPWA2MCvc3CfdvANaH6/XCY2MI2kLmhvsv\nCff3D7e3EXSeeTvm+UsJekBvCs85PNz/73C7IPx6+96+ixYtlWmJa25lM3uL4C/C/+3x5D3fKyO8\nV3Elh8OBye4+Jtz+GjjWd+6x8+UAACAASURBVFZpFEtzK4vsJXf4ccnOQbpXzoZvP4eCvOD4fi12\n9opO7wpNO0BSSrQxS5nR3MoiUpx465CuBZ43sx+Bt/h5hxTc/Wdd9vdCGrAiZntluO9nyaGZDQGG\nALRo0aIMHi1SDZkFnVUatIIOA4J9uVthzecx1dGzYV7YRCyxBjTpsGt19H4HqbNLGSkocDZvz2ND\nTh4btuayYWsuG3Py2JBTdD2PjduCr6d2aMpvu+l3oIiUnXiTwwXh16KDhsaq0Onz3H0EQa85MjMz\n1SFGpKwk14QW3YOl0IY1u3Z2mTsaZg0NjtVuHJMsVu95o/PyC3YkcBsLE7wwmduQk7sj6YtN+Dbk\n5LGxMPnblseeKnNqJidSr2YS9VKTqZuaREEctT8iIqURb3J4JxXTI3kV0DxmOz3cJyJRqtcU6v0G\nDvtNsJ2fB9nzdq2OLjpvdFqXndXRVWTe6Jzc/CKJXWHiVlzp3a4leRtyctmyPX+Pz6ibujOxq1cz\nmbT9alIvtS71aiZTL9xXeE5x68mJlf9zFJGqLd5xDm8v6Vg4kOnAMornFeAqMxsLdAd+2lN7QxGJ\nQGJSMNh2047QNRyJZMs6WPXxzqro+ePh4yeDYyn1YpLFcHaX2g3LNCR3Z8v2/F2StY27rBdfkrcx\nTAI35OSyPW/3rWOSEmxHUhckbEm0qlMnpiQvecf6roldEnVTk6mTkkRigqrgRaRy26txK8IBTgcS\nDFzagqDX1cVxXDeGYAiDRma2EriNYFol3H0Y8AZBj+VFBEPZXLQ38YlIBIqbN3rd4l3bLu5m3uj8\nxu3YlGth0lZSaV1Yklc06Qu/5hfsvoIjJSlhRwld3dRk6tdMpvn+NX9WQlcvJqmLTfpqJif+bKo0\nEZF9TVy9lQHMrD5wLnAhwTAzEEy3NBwY4zsnZ69w6q0sEr3teQU/K6ErWlqXs3kD9X+aT5MNX9Bi\nyzzabF9AAw/6t+V4Ml94Sz4paMMnBa35pKA137Jr6WKdlKQdiV1su7vYkry6qUXXd1bVpiRVaNPo\nSk+9lUWkOLstOTSzBIKJ1y8EfkMwDtZq4BHgD8B17j6lvIMUkfLl7uTkFsR0ktjZeSLednc5ubuv\nkk0wwqSuOfVSW1Gv4dnUTUmkRdKPtM37ipbbFtBi8zyO3PgOiQWvA5Bbuwm5Tbpg6ZkkZ3QjKe1I\nzRstIlLOSkwOw8nXzwcOAHIIZkh5EngXqAdcVREBisieFRQ4m7bH9ITdGtsztphesrtU0QbH8vZQ\nJVsjMeFnpXXN6tcstoRuZ/XsznNr19hdleyvd67GzBudvHI2yStnw+LX4QM0b7SISAUosVrZzAoI\neii/QTCN3dqYY/UJxjo8tjKUHKpaWaq63HAIlN2V0G0o0jM2tsp2UxxDoNSqkVikGjZpNx0odu1M\nUS81mdTkCKtkN/+ws1f0ytlBx5ftG4NjNfePGahb80aXhqqVRaQ4u6tWfgw4BzgV+DrsQfyUu39U\nIZGJVHGbt+Xx9rxvyd64bZd2dxt3qbINkrw9DYFiVtjebmeHibT9anJY07rBvj20u6vyQ6DUbgSH\n9g0W+Pm80avmwuR32XXe6MydYy9q3mgRkbjttkOKmaUSzDd5IcEE6QnANwRVzDcAx6nkUGRX2Rtz\nGD19Kc98uIwNOcE0dEkJVnxpXbEleUWqaGsmU6dGEgkaAmX3cjbA6o93DtS9cjZsCSs8kmtD2pE7\nk8W0TKh7YLTxVgIqORSR4pSmt3JTgqFrBgKHh7s/BB4FXnT3nHKJMA5KDqUyWJS9iZFTsnj5k1Xk\nFhTQt10TLj26JYc3rU9qcoKGQKlo7vDj0l2ro2Pnja7fYmeyWE3njVZyKCLFiTs53OUis0yC0sTz\ngIYEg1XvX8axxU3JoUTF3Zm99EdGTFnMuwuySUlK4JzMdC7t1YqMRrWjDk+KKpw3OnYqwJ/C6dx3\nzBsd036xis0bvX79ep577jmuvPLKuM4vj+TQzDoDV7n7JRb8RfQQwfi1Wwjar39czDW/Bf5K0C5g\nNfA7d//BzDoCw4A6wFLggthh08ysBTAfuN3d7zOzQ4H/i7l1K+BWd3+wFPEvBTLd/YdSvHbhtTPc\n/ajSXhfHfTOA0e5+bBncaymleD8za0DwmWYQfA8GuPuPZjYIyNjdJBnF3Gsy8Gd3n2Nmf3X3f5Qq\n+DIQTtyx3d1nlNH9Nrl7nTjOGwO0A54AOgKvufuLe/G8QcBEd18dbhtwF0EzwHxgqLs/HHN+V2Am\ncJ67v2hmjYGn3b3v7p6zV41w3H0OMMfM/gT0o+xmSBGpEvILnInzvmX4lCw+XbGe/Wslc22fNgzs\ncRAN61Sv0qcqJZ55oz9+CmYNC47FzhudlhlUTVfieaPXr1/Po48+GndyWJbMLMnd8wiSvLvC3ScD\nbcKlOzA0/LrLdQQJ5OFhQvhvgtEwbgdGESQTH5jZxcD1wN9iLr8feLNww92/BjqF900kmH715bJ9\n05KVR2JYCdwIvOfu/zKzG8PtG8rgvn8FKjw5JJiIYxMQd3IY87O9V8ysCdDV3VuH26P39l7AIOBL\ngj+iCrebA23dvcDMDoh5biJwDzCxcJ+7f29ma8ysp7tPL+khv6iFtrvnEvzDq7B/fCJRysnN54W5\nK3lsahZL126hRYNa3Hl6O87p0pyaNTTAcpVU7LzR83dtuxg7b3Tjw3atjq5E80bfeOONLF68mE6d\nOnHiiSdy7733cu+99/L888+zbds2+vfvzx133MHSpUs5+eSTAQ4ys3kESdTp7r7VzK4BLgfygPnu\nfl5YevQ4QUncFmCIu39uZrcDB4f7l5vZEKCDu38WhnQ6QUdGBz40s/3MrGmRaVEtXGqb2VqCodIW\nhccOAQrbtb8DvE2YHJrZGcASYHMJH0cfYLG7L9vdZ2ZmDYExQBpBCYvFHPsdcA1QA5gFXAkMBg52\n9+vDcwYRlMRdFVuKZGY3AL8DCoA33f1GMzuYYJzgxuHnONjdv9pdfKF8YF1438L/8PuG9x7p7v+N\nLREMa/fuc/dj9/B+4wkSi1TgIXcfUcyzTydIqCAYzm4yQXK4lSDJKpGZ1WRnSdlXQM1w/7+Ammb2\nKTAPWAysKyzhNbO7gWyCiTbuBDYCrYH3gSvDJOjXwB1ASnj9Re6+p3gyCH6288Pv7dXACoKf7UbA\n9+F9locJXA7QGZhuZrcC/wUyCUq473D3l2Li7Rd+Jqe7+3dFHj0RSAvf9+oiMfUB7iPIx2YDV7j7\ntvB5vwk/sxnAZcBZ4fOfNbOtQA/gCuB892DqKXfPjrn91cBLQNci8YwHLgBKTA5x9yq/dOnSxUXK\n09pN2/yBd772zndO9INueM1P++9Uf+2z1Z6XXxB1aFIRNq91/+Yd9/f/6f70me7/bO5+W71g+Ue6\n+5Onub/3d/ev33Lf9ENkYS5ZssTbtWu3Y/vtt9/2wYMHe0FBgefn5/upp57qH3zwgS9ZssQTExMd\nmOdB06LnCapyISiRSAnX9wu//he4LVw/Hvg0XL8dmAvUDLePA17y8Hcz8BrQK2b7PYIEZpff4cDZ\nwAZgDUEymBjunwGcEa7/CdgYrtchSHTqhDH8uZh7Pk5Qvb3b/z+AhwmqniEYncMJEoXDgFeB5PDY\nowS1ZI2BRTHXv1n4jsCm8OvJYey1wu0GMe/fJlzvDkwK1y8APi1mebGYeK8AXgSSitx7KdAoXM8E\nJu/u/YpcW5OgNKphuD2q8PsErI95tsVux/HZ/gl4PFzvQPAHR2bsZxWuZwAfh+sJBMleQ4KkNIfg\nj49Egj8Qzg6/P1OA2uE1N8S84wMlfJY3xvzM/jnm2a8CF4brFwPjw/XRBD+/hT+L9wAPxly3f/jV\ngd+E6/8Gbinmc8gAvozZHh2+RypBcnpIuP8pgslFdnxvwvWnY54xmZh/Q8Ba4GZgDsHPYuHPVxrB\n6LAJhc+LuSYN+GJ33zuN7SCyG8vXbmHUtCyen7OCnNwCjm97AEN6t6J7ywbqYFKd7HHe6Dkw9X7w\ncEiiwnmj08LhdJocAYnJFR72xIkTmThxIp07dwZg06ZNLFy4kBYtWtCyZUsWLVq0NTx1LsF/YACf\nE5RMjCcoYQDoRVBqgbtPMrOGZlYvPPaKuxfepylB6UvczCyZIOHpDGQRJKI3EVRNXww8bGZ/A14B\ntoeX3Q484O6bivt3aGY1gNPC++xJb+DM8N1eN7Mfw/19gC7A7PAZNYFsD6rlsszsV8BCoC0/L4E5\nAXjC3beE911nZnWAo4AXYmJOCY8/CzwbR6yF9x7mYTWnu6/by/cDuMbM+ofrzQmq/9e6+6XF3cjd\n3cxK01GhN0FyigclzZ+XcN+lZrY2bK96IPCJu68NP6eP3D0LdrTb60WQMB5OUKIHQcnuzPBefyxF\nfBCUvp0Zrj9NkOAVesG98B81JxD0syiMufBz3E6QRELw7+jEUjz7UGCJu38Tbj9JMPvcg8BxZvYX\noBbQgKCE9dVi7pEC5Lh7ppmdSfBH0dHhPW7woJS16DXZQLPdBabkUKQYn61Yz4gpWbz55RoSE4wz\nOqUxpHcr2hxYedubSQVKSIBGbYKl0/nBvu2bYfWnOxPGrA/g87BvRFIqNO20a3V0/bRyD9Pduemm\nm7jssst22b906VJSUnZpG5tPWOVHULrUm6BK62YzO2IPj4mt1t1KUBpSaBVB0lEoPdwXq1MY62IA\nM3ueoF0bHlS5/jrcf0gYGwSlbmeH7RP3AwrMLMfd/xceP5mgJKpo9V5pGPCkuxeXYI4FBhBUlb7s\nYXHMHiQQlLp1+tmDzC4gaE9Z1CJ3PzvOePPCZ8Cu34NihR0zTgB6uPuWsLNIcdd9V9gUIBy1JLuY\nc8rCKIL2c00IEpxCRT9bJ/jevOPuvy16EzN7gKAEu6ix7v6vUsZUUpOFWLkx3/98yiCvCocRfJSg\nhHBF2HyjpO/pSmBcuP4yQTU+BKXHY8PEsBFwipnlufv48F5bi94olpJDkVBBgTP5m2yGf5DFrCXr\nqJuaxJDeB3NRzwwOrLfH37VS3dWoDRk9gwWCoXQ2rNq17eJHI2FmmL/UbVpkKJ1Ov3je6Lp167Jx\n48Yd2yeddBJ/+9vfuOCCC6hTpw6rVq0iObnkEkwzSwCau/v7ZjaNoKSkDjCVoOrz72FS8YO7byim\nRGIB8P9itl8BrgonUehOMLLFmiLXrAION7PG7v49QcnLgjCeA9w9O4zrFoKey7j70TEx305QRfm/\nmHv+lqCdXey7XRVeG3seBNWT5wN3mdnJQOHIG+8BE8zsgTCGBkBdD9owvkxQldeZ4jtnvAPcambP\nholXg7D0cImZnePuL4S9TDu4+2elLDl8B7jMzN5397zCexNUK3chqFo8K473qw/8GMbXFvhVCc97\nhWB0kn+FXycUPSEsfexWTCJd+OxJZtaeoGq5UK6ZJXvQdwGCz/ROIDm8plA3M2sJLAPOBUYQDKP3\niJm1dvdFZlYbSHP3b+IoOdxI0K610AyCn/OnCX7Gp5Zw3TsEpXrXhe+8f0zp4d76GsgofA+C4QI/\nYGci+ENY4nw2QVOCwvhjSynGEyTDS4BjCMaixt1bFp4Qtp98LUwMIWjL++XuAlNyKNXetrx8Jny6\nmpFTsliYvYlm9VO55dTDOK9bC+qk6J+I7CUzqJ8eLO3CmruYeaN3JIwLwpqiwnmj02ISxoYHl2oo\nnYYNG9KzZ0/at2/PySefzL333suCBQvo0aMHAHXq1OGZZ54hMbHEzlOJwDMWTJFqwMPuvj5MwB4P\nqwW3ECQJP+PuX5lZfTOr6+4bCaZfPYWgg8kW4KKdH4996u6d3H21md0BTDGzXIIkYFB42m/N7A/h\n+jh2loqUKEwUTiRowB+ruOpfCDo1jAk75swAlofvMt/MbgEmhslpLkFysMyDoVwWEPSw/tmsYe7+\nlpl1IhjVY3v4OfyVIPkYGt43maAE8rOi1+/BKIL/3D8PP6+RwP/C93jMzP5O0C5tt+8HvAVcHr7H\n1wQJFwBmNoqg6noOQVL4vJldQvC9GVBMTAcTtBktaijwRPiMBQTVroVGhO/wsbtf4O7bzex9gtLV\n2CmjZofvV9gh5eWwqnRQ+F6FReC3ECZGe/Aq8KKZnU7QYePqMMbrCTuklHDdXQQJ6ZcEJYR3sLPE\n7mfM7DSCkr9bSzrH3XPM7CKCpgaFHVKGedAhZSRBAvdtuL/QaGBYTIeUfxE0A/kjQQehYpsEFHEc\n8PruTtircQ4rG41zKHvjp625PDdrOU9MX0L2xm20bVKXy45pRb8Ozar2VHNStUQ4b7SVzziHfyTo\nODKqLO/7S5nZa8CZ7r59jydLqZjZM8Afw5Lfvb1HAvAxcI67Lwz3HUvQeaRfmQQqAJjZFIJe1SWW\nfKpYRKqd1eu38vi0JYydvYJN2/Lo1boR953TkaPbNFInE6l4xc0b/cM3u3Z22WXe6EN2JouVc97o\noQQD8lYqSjDKj7v/7pdcb2aHE3TqeLkwMZTyYcEg2PfvqUpcJYdSbSxYs4ERU7J49bPVONCvQ1MG\nH92K9mn1ow5NZPd2mTd6bjhvdDjBRbfL4JR/7/76EpRHyaGIVH2V6s9NkbLm7kxftJbhUxYzdeEP\n1KqRyMAeGVzcK4P0/X9Z43+RCpNaD1odGyyw67zRDVpFFpaI7JuUHMo+KS+/gNe/WMOIKVnMW72B\nxnVTuP6kQ/ld94OoX6vix5sTKVNm0KBlsIiIlDElh7JP2bwtj7GzV/D4tCWsWr+VgxvX5p6zjuCM\nzmmkJGl6OxERkT1Rcij7hOyNOYyevpRnPlzGhpw8umU04I7T2nF82wNISFAnExERkXgpOZQqbVH2\nJkZNzWLcx6vILSigb7smDOndis4t9t/zxSIiIvIzSg6lynF35iz7keEfZPHugu9ISUpgQNd0Lu3V\nioxGtaMOT0REpEpTcihVRn6B8878bxk+JYtPlq9n/1rJXNunDQN7HETDOil7voGIiIjskZJDqfRy\ncvN5ce5KRk3NYunaLbRoUIs7T2/HOV2aU7OGOpmIiIiUJSWHUmmt27ydp2cu46mZS1m7eTsd0+vz\nyPlH0rd9ExLVyURERKRcKDmUSmf52i2MmpbF83NWkJNbwPFtD2BI71Z0b9lA09uJiIiUMyWHUml8\ntmI9I6Zk8eaXa0hMMM7olMaQ3q1oc2DdqEMTERGpNpQcSqQKCpzJ32Qz/IMsZi1ZR93UJIb0PpiL\nemZwYL3UqMMTERGpdpQcSiS25eUz4dPVjJySxcLsTTSrn8otpx7Ged1aUCdFP5YiIiJR0f/CUqF+\n2prLc7OW88T0JWRv3EbbJnV54NyO9OvQjOTEhKjDExERqfaUHEqFWL1+K49PW8LY2SvYtC2PXq0b\ncd85HTm6TSN1MhEREalElBxKuVqwZgMjpmTx6mercaBfh6YMProV7dPqRx2aiIiIFEPJoZQ5d2f6\norUMn7KYqQt/oFaNRAb2yODiXhmk718r6vBERERkNyo8OTSzvsBDQCIwyt3/VeR4C+BJYL/wnBvd\n/Y2KjlNKLy+/gNe/WMOIKVnMW72BxnVTuP6kQ/ld94OoXys56vBEREQkDhWaHJpZIvAIcCKwEpht\nZq+4+/yY024Bnnf3oWZ2OPAGkFGRcUrpbN6Wx9jZK3h82hJWrd/KwY1rc89ZR3BG5zRSkjS9nYiI\nSFVS0SWH3YBF7p4FYGZjgdOB2OTQgXrhen1gdYVGKHHL3pjD6OlLeebDZWzIyaNbRgPuOK0dx7c9\ngARNbyciIlIlVXRymAasiNleCXQvcs7twEQzuxqoDZxQ3I3MbAgwBKBFixZlHqiUbFH2JkZNzWLc\nx6vILSigb7smDOndis4t9o86NBEREfmFKmOHlN8Co939P2bWA3jazNq7e0HsSe4+AhgBkJmZ6RHE\nWa24O3OW/cjwD7J4d8F3pCQlMKBrOpf2akVGo9pRhyciIiJlpKKTw1VA85jt9HBfrEuAvgDuPtPM\nUoFGQHaFRCi7yC9w3pn/LcOnZPHJ8vXsXyuZa/u0YWCPg2hYJyXq8ERERKSMVXRyOBtoY2YtCZLC\n84Dzi5yzHOgDjDazw4BU4PsKjVLIyc3nxbkrGTU1i6Vrt9CiQS3uPL0d53RpTs0a6mQiIiKyr6rQ\n5NDd88zsKuBtgmFqHnf3eWZ2JzDH3V8B/h8w0sz+SNA5ZZC7q9q4gqzbvJ2nZy7jqZlLWbt5Ox3T\n6/PI+UfSt30TEtXJREREZJ9X4W0OwzEL3yiy79aY9flAz4qOq7pbvnYLo6Zl8fycFeTkFnB82wMY\n0rsV3Vs20PR2IiIi1Uhl7JAiFeizFesZMSWLN79cQ2KCcUanNIb0bkWbA+tGHZqIiIhEQMlhNVRQ\n4Ez+JpvhH2Qxa8k66qYmMaT3wVzUM4MD66VGHZ6IiIhESMlhNbItL58Jn65m5JQsFmZvoln9VG45\n9TDO69aCOin6URARERElh9XCT1tzeW7Wcp6YvoTsjdto26QuD5zbkX4dmpGcmBB1eCIiIlKJKDnc\nh61ev5XHpy1h7OwVbNqWR6/WjbjvnI4c3aaROpmIiIhIsZQc7oMWrNnAiClZvPrZahzo16Epg49u\nRfu0+lGHJiIiIpWcksN9hLszfdFahk9ZzNSFP1CrRiIDe2Rwca8M0vevFXV4IiIiUkUoOazi8vIL\neP2LNYyYksW81RtoXDeF6086lN91P4j6tZKjDk9ERESqGCWHVdTmbXmMnb2Cx6ctYdX6rRzcuDb3\nnHUEZ3ROIyVJ09uJiIjI3lFyWMVkb8xh9PSlPPPhMjbk5NEtowF3nNaO49seQIKmtxMREZFfSMlh\nFbEoexOjpmYx7uNV5BYU0LddE4b0bkXnFvtHHZqIiIjsQ5QcVmLuzpxlPzL8gyzeXfAdKUkJDOia\nzqW9WpHRqHbU4YmIiMg+SMlhJZRf4Lwz/1uGT8nik+Xr2b9WMtf2acPAHgfRsE5K1OGJiIjIPkzJ\nYSWSk5vPi3NXMmpqFkvXbqFFg1rceXo7zunSnJo11MlEREREyp+Sw0pg3ebtPD1zGU/NXMrazdvp\nmF6fR84/kr7tm5CoTiYiIiJSgZQcRmj52i2MmpbF83NWkJNbwPFtD2BI71Z0b9lA09uJiIhIJJQc\nRuCzFesZMSWLN79cQ2KCcUanNIb0bkWbA+tGHZqIiIhUc0oOK0hBgTP5m2yGf5DFrCXrqJuaxJDe\nB3NRzwwOrJcadXgiIiIigJLDcrctL58Jn65m5JQsFmZvoln9VG459TDO69aCOin6+EVERKRyUXZS\nTjbk5PLcrOU8MX0J323YRtsmdXng3I7069CM5MSEqMMTERERKZaSwzK2ev1Wnpi+hDEfrWDTtjx6\ntW7EvWd35Og2jdTJRERERCo9JYdlZMGaDYycksUrn63GgX4dmjL46Fa0T6sfdWgiIiIicVNy+Au4\nOzMWr2X4lCymfPM9tWokMrBHBhf3yiB9/1pRhyciIiJSakoO90JefgGvf7GGEVOymLd6A43rpnD9\nSYfyu+4HUb9WctThiYiIiOw1JYelsHlbHv83ewWPTVvCqvVbObhxbe456wjO6JxGSpKmtxMREZGq\nT8lhHLI35vDkjKU88+FyftqaS7eMBtxxWjuOb3sACZreTkRERPYhSg53Y1H2JkZNzWLcx6vILSig\nb7smDOndis4t9o86NBEREZFyoeSwCHdnzrIfGf5BFu8u+I6UpAQGdE3n0l6tyGhUO+rwRERERMqV\nksNQfoHzzvxvGT4li0+Wr2f/Wslc26cNA3scRMM6KVGHJyIiIlIhqn1ymJObz4tzV/LYtCUs+WEz\nLRrU4s7T23FOl+bUrKFOJiIiIlK9VOvkcNJX33H9C5+zdvN2OqbX55Hzj6Rv+yYkqpOJiIiIVFPV\nOjk8qGFtOjXfj8G9W9G9ZQNNbyciIiLVXrVODg9uXIfHBnWNOgwRERGRSiMh6gBEREREpPKo8OTQ\nzPqa2ddmtsjMbizhnAFmNt/M5pnZcxUdo4iIiEh1VaHVymaWCDwCnAisBGab2SvuPj/mnDbATUBP\nd//RzA6oyBhFREREqrOKLjnsBixy9yx33w6MBU4vcs5g4BF3/xHA3bMrOEYRERGRaquik8M0YEXM\n9spwX6xDgEPMbLqZfWhmfYu7kZkNMbM5Zjbn+++/L6dwRURERKqXytghJQloA/z/9u4+xo6qjOP4\n95e1vCO0tLRNebEmTUwl8pKmKUJ4CaFgA2lIUIuAYIwiLwkmWqOYQKgEjSZGTUQCghTKW1VeNhWk\nGBCMhEJLCrSFtitioBSbtrwI1cLSxz/O2ctwe293Fu7OLHt/n+RmZ86cO/P07Nncp+fMuXMCcBZw\nvaT9mytFxHURMSMiZkyYMKHiEM3MzMxGp6qTww3AwYX9g3JZ0ctAb0S8GxH/BNaRkkUzMzMzG2ZV\nJ4dPAtMkTZW0GzAP6G2qcw9p1BBJ40nTzC9UGaSZmZlZt6p0tXJE9Eu6BHgA6AFujIjVkhYAyyOi\nNx+bLWkN8B4wPyK27Oq8K1as2CzpXx8yrPHA5g/53uE0UuOCkRub4xoaxzU0ozGuQzsZiJmNDoqI\numOolaTlETGj7jiajdS4YOTG5riGxnENjeMys24xEhekmJmZmVlNnByamZmZWYOTQ7iu7gDaGKlx\nwciNzXENjeMaGsdlZl2h6+85NDMzM7P3eeTQzMzMzBqcHJqZmZlZw6hNDiXdKGmTpFVtjkvSryT1\nSXpG0lGFY+dJWp9f51Uc19k5nmclPSbp8MKxF3P5SknLOxlXydhOkPRGvv5KSZcXjp0qaW1uz+9X\nGNP8QjyrJL0naVw+NmztJelgSQ9LWiNptaRLW9SpvI+VjKvyPlYyrjr6V5m46upje0h6QtLTObYr\nW9TZXdKduV2WSfpU4dgPcvlaSad0MjYzG+UiYlS+gOOAo4BVbY7PAe4HBMwCluXycaQnsowDxubt\nsRXG9fmB6wFfGIgrMfQMMQAABxpJREFU778IjK+xzU4AlrQo7wH+AXwa2A14GpheRUxNdU8HHqqi\nvYDJwFF5e1/SYx6nN9WpvI+VjKvyPlYyrjr616Bx1djHBOyTt8cAy4BZTXUuAq7N2/OAO/P29NxO\nuwNTc/v1DEecfvnl1+h7jdqRw4h4FNi6iypzgZsjeRzYX9Jk4BTgwYjYGhGvAQ8Cp1YVV0Q8lq8L\n8Djp+dOVKNFm7cwE+iLihYh4B7iD1L5Vx3QWcHsnrjuYiNgYEU/l7f8AzwFTmqpV3sfKxFVHHyvZ\nXu0MZ/8aalxV9rGIiLfy7pj8al5BOBdYmLf/AJwkSbn8jojYHukZ9X2kdjQzG9SoTQ5LmAK8VNh/\nOZe1K6/D10kjTwMCWCpphaRv1hTT0Xma635Jn81ltbeZpL1ICdYfC8WVtFeeyjuSNLJTVGsf20Vc\nRZX3sUHiqq1/DdZedfQxST2SVgKbSP+haNvHIqIfeAM4gBHwN2lmH1+VPlvZypN0IumD+9hC8bER\nsUHSgcCDkp7PI2tVeQo4NCLekjQHuAeYVuH1d+V04O8RURxlHPb2krQPKVn4dkS82clzfxRl4qqj\njw0SV239q+TvsfI+FhHvAUdI2h+4W9JhEdHy/lszs07p5pHDDcDBhf2Dclm78spI+hzwW2BuRGwZ\nKI+IDfnnJuBuKp4miog3B6a5IuI+YIyk8YyANiPdb/WB6b7hbi9JY0gJxa0RcVeLKrX0sRJx1dLH\nBourrv5Vpr2yyvtY4TqvAw+z8+0HjbaR9AlgP2ALI+Nv0sw+pro5OewFvppXlM4C3oiIjcADwGxJ\nYyWNBWbnskpIOgS4Czg3ItYVyveWtO/Ado6r0hEESZPy/UxImknqP1uAJ4FpkqZK2o30IdpbYVz7\nAccD9xbKhrW9cjvcADwXET9vU63yPlYmrjr6WMm4Ku9fJX+PdfWxCXnEEEl7AicDzzdV6wUGVruf\nSVosE7l8Xl7NPJU0AvtEp2Izs9Ft1E4rS7qdtPpxvKSXgStIN3QTEdcC95FWk/YB24Cv5WNbJf2I\n9IEEsKBpGmm447qcdM/QNflzsj8iZgATSdNKkH5vt0XEnzsVV8nYzgQulNQP/BeYlz+I+iVdQkpw\neoAbI2J1RTEBnAEsjYi3C28d7vY6BjgXeDbfEwZwGXBIIbY6+liZuOroY2Xiqrx/lYwL6uljk4GF\nknpIifLiiFgiaQGwPCJ6SYntLZL6SAu35uW4V0taDKwB+oGL8xS1mdmg/Pg8MzMzM2vo5mllMzMz\nM2vi5NDMzMzMGpwcmpmZmVmDk0MzMzMza3ByaGZmZmYNTg6tK0k6X1K0eb1eY1w35a/sMTMzq8Wo\n/Z5Ds5K+SHrubFF/HYGYmZmNBE4OrdutjIi+uoMwMzMbKTytbNZGYer5OEn3SHpL0hZJv86PMyvW\nnSzpZkmbJW2X9Iykc1qcc6qkWyS9muu9IOmXLeodKelvkrZJWi/pW03HJ0laKOmVfJ6NkpZIOrDz\nLWFmZt3EI4fW7XokNf8d7IiIHYX9RcBi4BpgJunxc3sD50PjubqPAGNJj157CTiH9FizvSLiulxv\nKun5ttvyOdaTHtM2u+n6nwRuA34BLCA9du83ktZGxMO5zi3AocD8fL2JwEnAXh+2IczMzMDJodnz\nLcr+BJxW2L8vIr6bt5dKCmCBpKsjYh0peZsGnBgRf8317pc0EbhK0g35ubZXAnsCh0fEK4XzL2y6\n/r7ARQOJoKRHgVOAs4CB5PBo4LKIuLXwvt+X/lebmZm14eTQut0Z7LwgpXm18uKm/TuAq0ijiOuA\n44ANhcRwwCLgd8B04FnSCOGSpsSwlW2FEUIiYrukdaRRxgFPAvMlCXgIWBV+ULqZmXWAk0PrdqtK\nLEj5d5v9KfnnOGBji/e9WjgOcAA7J6KtvNaibDuwR2H/y8AVwPdI088bJV0LXNU0JW5mZjYkXpBi\nNriJbfY35J9bgUkt3jepcBxgM+8nlB9JRGyKiIsjYgrwGeAm0rT1BZ04v5mZdS8nh2aD+1LT/jxg\nB7As7z8CHCTpmKZ6XwE2AWvy/lLgNEmTOxlcRKyNiMtII46HdfLcZmbWfTytbN3uCEnjW5QvL2zP\nkfQzUnI3kzSde3NErM/HbwIuBe6S9EPS1PHZwMnABXkxCvl9c4DHJF0N9JFGEk+NiJ2+9qYdSfsB\nfwFuJS2oeReYS1otvbTseczMzFpxcmjdrt0K3wmF7XOA7wAXAu8A1wMDq5eJiLclHQ/8FPgJabXx\nWuDciFhUqPeipFmkxSw/BvYhTU3fO8SY/wc8BXyD9HU2O/L1zo6IoZ7LzMzsA+QFjmatSTqftNp4\nmp+iYmZm3cL3HJqZmZlZg5NDMzMzM2vwtLKZmZmZNXjk0MzMzMwanByamZmZWYOTQzMzMzNrcHJo\nZmZmZg1ODs3MzMys4f9XRWkl5RcORwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY6ih2k9hGy",
        "colab_type": "code",
        "outputId": "953d4854-a015-4117-af64-34de6a13f7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "base_real_results, baseline_predicted_ys = batch_wise_evaluate(baseline_model, \n",
        "         test_snopes_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlPE-kpx9riu",
        "colab_type": "code",
        "outputId": "3af0ce30-9cf4-4615-fc80-0d7ae8c22a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "evaluation_summary(\"baseline model\", baseline_predicted_ys.cpu(), base_real_results.cpu(), y_snopes_test)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: baseline model\n",
            "Classifier 'baseline model' has Acc=0.648 P=0.648 R=0.646 F1=0.646 AUC=0.727\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.646     0.702     0.673      1573\n",
            "         1.0      0.651     0.591     0.619      1477\n",
            "\n",
            "    accuracy                          0.648      3050\n",
            "   macro avg      0.648     0.646     0.646      3050\n",
            "weighted avg      0.648     0.648     0.647      3050\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1104  604]\n",
            " [ 469  873]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6484458164786033,\n",
              " 0.6464532882025342,\n",
              " 0.6481967213114754,\n",
              " 0.6461670648478739)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qhGP9Y-Cj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}