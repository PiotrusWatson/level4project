{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "a24aef30-f366-4249-a220-f5b22c073104",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-19 17:06:33--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  4.83MB/s    in 16s     \n",
            "\n",
            "2020-01-19 17:06:50 (5.71 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "495d1ba5-f83c-4005-cbce-3dc5128ea468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-19 17:06:59--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-01-19 17:06:59--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-01-19 17:07:00--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.91MB/s    in 6m 29s  \n",
            "\n",
            "2020-01-19 17:13:30 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "ef6a6f06-06ab-4538-e7a3-12dc752b16e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-19 17:13:56--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  2.21MB/s    in 2.1s    \n",
            "\n",
            "2020-01-19 17:13:59 (2.21 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "67ae9747-a9f6-4c72-edf9-2038e7e9ca50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "20a99b5a-ea72-450f-d40e-05416269102f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-19 17:14:11--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  2.20MB/s    in 2.4s    \n",
            "\n",
            "2020-01-19 17:14:14 (2.20 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "outputId": "2a048589-cd88-4d8d-ab65-e087507aa3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "outputId": "8d71110d-83aa-41d3-a05e-fe53a5cfdf25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "b9ba584a-fa86-475b-bfd2-25dc60c44dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "d44c7229-77aa-46f1-dc6f-d5159f5e5323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "outputId": "1ebfd6bb-c750-4006-8bb9-7dadd096010f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_id\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  train_unique, test_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_unique[\"claim_id\"])]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_unique[\"claim_id\"])]\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n",
        "train_facts.head(500)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>for firms moving overseas in order to create a...</td>\n",
              "      <td>foxnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>get a tax break specifically by outsourcing jo...</td>\n",
              "      <td>newslines.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>confusing clashes over taxes in wednesday s pr...</td>\n",
              "      <td>wsj.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>support on this bill in a time of tight budget...</td>\n",
              "      <td>senate.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>tax a lower rate for american manufacturing an...</td>\n",
              "      <td>archives.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>to have a different standard the senate will h...</td>\n",
              "      <td>thedailybeast.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>double standard for mcconnell to be less conce...</td>\n",
              "      <td>weaselzippers.us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>cory booker on government reform even billiona...</td>\n",
              "      <td>ontheissues.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>think are deeply committed to do and we are ob...</td>\n",
              "      <td>whitehouse.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>are deeply committed to do and we are obviousl...</td>\n",
              "      <td>haaretz.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cred_label  ...     article_source\n",
              "0             1  ...        foxnews.com\n",
              "1             1  ...      newslines.org\n",
              "2             1  ...            wsj.com\n",
              "3             1  ...         senate.gov\n",
              "4             1  ...       archives.gov\n",
              "..          ...  ...                ...\n",
              "554           1  ...  thedailybeast.com\n",
              "555           1  ...   weaselzippers.us\n",
              "556           1  ...    ontheissues.org\n",
              "557           1  ...     whitehouse.gov\n",
              "558           1  ...        haaretz.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "58a8b464-8bac-4cc1-fe45-2be0dc2d80f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>morning new tv advertisement argues that posit...</td>\n",
              "      <td>desmoinesregister.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>iowans could not support household on current ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>not budged in five years leaving many falling ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>are working to support themselves or their fam...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>prove that i had those good hardworking skills...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>cap is melting palin im not one to attribute e...</td>\n",
              "      <td>mysinchew.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2767</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>control the weapons the theocracy does secreta...</td>\n",
              "      <td>blastmagazine.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>be left with only one conclusion mccain was co...</td>\n",
              "      <td>chrisweigant.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2850</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>speech politifact called claim false that demo...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2851</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>covering conduct going back as far as 1994 was...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...              article_source\n",
              "85             1  ...       desmoinesregister.com\n",
              "86             1  ...  americanprogressaction.org\n",
              "87             1  ...  americanprogressaction.org\n",
              "88             1  ...           iowademocrats.org\n",
              "89             1  ...           iowademocrats.org\n",
              "...          ...  ...                         ...\n",
              "2766           0  ...               mysinchew.com\n",
              "2767           0  ...           blastmagazine.com\n",
              "2768           0  ...            chrisweigant.com\n",
              "2850           0  ...               democrats.org\n",
              "2851           0  ...               democrats.org\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "snopes_tokeniser = Tokeniser(x_train_snopes_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n",
        "x_snopes_train = snopes_tokeniser.do_everything(x_train_snopes_list)\n",
        "x_snopes_test = snopes_tokeniser.do_everything(x_test_snopes_list)\n",
        "y_snopes_train = np.array(y_train_snopes_list, dtype=np.float32)\n",
        "y_snopes_test = np.array(y_test_snopes_list, dtype=np.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "train_fact_source_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_source_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_train).type(torch.LongTensor))\n",
        "test_snopes_data= data_utils.TensorDataset(torch.from_numpy(x_snopes_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_test).type(torch.LongTensor))\n",
        "train_snopes_loader = data_utils.DataLoader(train_snopes_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "test_snopes_loader = data_utils.DataLoader(test_snopes_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(x)\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "    else:\n",
        "      x = self.linear1(x.reshape(self.hp.batch_size, -1))\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, unnormalised_predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(unnormalised_predictions.shape) == 1):\n",
        "    auc = roc_auc_score(true_labels, unnormalised_predictions)\n",
        "  else:\n",
        "    auc = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(real_results, 0), torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "39b7f4fe-9239-4a5d-bd44-b8224fcedb31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",fact_tokeniser.word_to_id,300)\n",
        "small_gloves = load_glove_embeddings(\"glove.6B.50d.txt\", fact_tokeniser.word_to_id, 50)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36905\n",
            "36905\n",
            "torch.Size([36905, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 20\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  dropout=0.3\n",
        "  C = 0.3\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "67761795-0e46-4d31-e1d1-a3004958a48c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "pass\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, small_gloves).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.639520\n",
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.638972\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.616035\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.555584\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.325535\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.274414\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.098194\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.054052\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 0.947530\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 0.958230\n",
            "Average loss is: tensor(1.3243, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.777601304945055\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 0.968892\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 0.952095\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 0.863345\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 0.909397\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 0.825055\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 0.879483\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 0.857953\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 0.842201\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 0.826494\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 0.861164\n",
            "Average loss is: tensor(0.8652, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9828725961538461\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 0.827450\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 0.794291\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 0.825372\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 0.787897\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 0.736739\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 0.753830\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 0.690758\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 0.682522\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 0.663791\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 0.633918\n",
            "Average loss is: tensor(0.7453, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9951493818681318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "da976e76-eb02-449d-b219-cba8683a222c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZmZmX/D/KfGBrMocBPAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "cc82364e-d475-4de6-ca79-c178d86c1c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "real_results, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "1b40745a-a4b4-462a-8b89-d1f5c63faa3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(predicted_ys.cpu().shape)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6102])\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.641 P=0.644 R=0.647 F1=0.640 AUC=0.675\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.718     0.605     0.657      3466\n",
            "         1.0      0.570     0.688     0.623      2636\n",
            "\n",
            "    accuracy                          0.641      6102\n",
            "   macro avg      0.644     0.647     0.640      6102\n",
            "weighted avg      0.654     0.641     0.642      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[2098  823]\n",
            " [1368 1813]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6440968666555241,\n",
              " 0.6465466176085573,\n",
              " 0.6409373975745657,\n",
              " 0.6401524079541081)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUa9XwZ-4Xny",
        "colab_type": "text"
      },
      "source": [
        "##Baseline Sentence Entailment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    combined = premise_embedding * hypothesis_embedding\n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fbaSIM4jhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineHyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 30\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  num_classes = 1\n",
        "  epochs = 4\n",
        "  C = 0.3\n",
        "  is_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKfpJ-Hk4ePj",
        "colab_type": "code",
        "outputId": "662e4d0e-b3db-4054-fcb1-d0ca809fa93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "baseline_model = BaselineSentenceEntailment(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(baseline_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "base_loss, base_accuracy = train(model=baseline_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.638929\n",
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.624252\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.596674\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.538264\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.461201\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.477378\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.308207\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.250510\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.146957\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.154636\n",
            "Average loss is: tensor(1.4086, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.7325721153846154\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.027873\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 0.982353\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 0.921543\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 0.923968\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 0.862426\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 0.832556\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 0.785594\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 0.772042\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 0.675489\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 0.677776\n",
            "Average loss is: tensor(0.8472, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9724845467032966\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 0.654367\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 0.647972\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 0.571463\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 0.561621\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 0.553467\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 0.549897\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 0.562760\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 0.624807\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 0.562133\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 0.545137\n",
            "Average loss is: tensor(0.5809, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9939903846153846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXQ16nQW6Xb7",
        "colab_type": "code",
        "outputId": "e6e7fbde-a824-428e-91f6-1f17c791fc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, base_loss, base_accuracy)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n786F2gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY6ih2k9hGy",
        "colab_type": "code",
        "outputId": "8fb05c27-e4da-411d-e503-887087c6361f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "base_real_results, baseline_predicted_ys = batch_wise_evaluate(baseline_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlPE-kpx9riu",
        "colab_type": "code",
        "outputId": "b68c698a-7057-4f70-d4e2-9db7e75d24d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "evaluation_summary(\"baseline model\", baseline_predicted_ys.cpu(), base_real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: baseline model\n",
            "Classifier 'baseline model' has Acc=0.607 P=0.606 R=0.606 F1=0.606 AUC=0.660\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.581     0.591     0.586      2870\n",
            "         1.0      0.631     0.621     0.626      3232\n",
            "\n",
            "    accuracy                          0.607      6102\n",
            "   macro avg      0.606     0.606     0.606      6102\n",
            "weighted avg      0.607     0.607     0.607      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1696 1225]\n",
            " [1174 2007]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6057783714736409,\n",
              " 0.6059592446613999,\n",
              " 0.6068502130449033,\n",
              " 0.6058262977795357)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gmzMChW2xxT",
        "colab_type": "text"
      },
      "source": [
        "##DECLARE BASELINE :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qhGP9Y-Cj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(101, 8)\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    mean_embeddings = torch.unsqueeze(torch.sum(embeddings, 1) / self.hp.max_length, 1)\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((mean_embeddings, added_embeddings), 1)\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    attention_weights = softmax(self.premise_linear(processed_premise))\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis,attention_weights.transpose(1,2))\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    avg = torch.sum(combined, 1)/self.hp.max_length\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    output = torch.sigmoid(self.linear_final(smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2AvWEFOBYMQ",
        "colab_type": "code",
        "outputId": "2e1fff70-b5c7-41a8-c850-9afa700d1ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "declare_model = BaselineDeclare(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(declare_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "declare_loss, declare_accuracy = train(model=declare_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.651421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.641765\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.638559\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.628893\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.606956\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.568986\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.497876\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.432505\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.461746\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.324651\n",
            "Average loss is: tensor(1.5458, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.6523008241758241\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.253174\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 1.206938\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 1.261887\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 1.180841\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 1.176351\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 1.190374\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 1.167203\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 1.274068\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 1.180295\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 1.158082\n",
            "Average loss is: tensor(1.2126, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.894273695054945\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 1.061891\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 1.068729\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 1.013288\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 1.031133\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 1.037676\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 1.017813\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 1.023457\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 1.045865\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 1.045053\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 1.020363\n",
            "Average loss is: tensor(1.0362, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9679344093406593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZweMG4WBnoY",
        "colab_type": "code",
        "outputId": "dbc94237-d3e7-4f0f-e6b8-681213a31c55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, declare_loss, declare_accuracy)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n64JVgFENAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6sN7kk2TqdE",
        "colab_type": "code",
        "outputId": "2d8f71db-2586-493c-f550-c34e23c17d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "declare_real_results, declare_predicted_ys = batch_wise_evaluate(declare_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJHn9s8T1bk",
        "colab_type": "code",
        "outputId": "912106d1-151d-4a2a-db9e-b6958b3cba37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "evaluation_summary(\"declare model\", declare_predicted_ys.cpu(), declare_real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: declare model\n",
            "Classifier 'declare model' has Acc=0.632 P=0.632 R=0.632 F1=0.632 AUC=0.679\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.653     0.607     0.629      3141\n",
            "         1.0      0.612     0.658     0.634      2961\n",
            "\n",
            "    accuracy                          0.632      6102\n",
            "   macro avg      0.632     0.632     0.632      6102\n",
            "weighted avg      0.633     0.632     0.632      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1907 1014]\n",
            " [1234 1947]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6324651428193826,\n",
              " 0.6323398062104397,\n",
              " 0.6315961979678794,\n",
              " 0.6315803666036004)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0JKeQxFT5kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}