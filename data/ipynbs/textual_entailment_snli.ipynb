{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "1352b020-2358-4c65-92d2-98db3563c7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-18 13:18:03--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  21.1MB/s    in 7.6s    \n",
            "\n",
            "2020-01-18 13:18:11 (11.9 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "d9a36f15-d206-4c86-8e56-6dccf97977c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-18 13:18:20--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-01-18 13:18:20--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-01-18 13:18:21--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.96MB/s    in 6m 29s  \n",
            "\n",
            "2020-01-18 13:24:50 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "4f06bd2a-f28d-42cd-b0b6-8a3087ff1cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-18 13:25:25--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  2.19MB/s    in 2.2s    \n",
            "\n",
            "2020-01-18 13:25:28 (2.19 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "288de94c-926e-4ec6-f7d9-607264fd530a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "1fe220c0-4c98-402b-88b7-f16df6f36d9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-18 13:25:37--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  2.46MB/s    in 2.2s    \n",
            "\n",
            "2020-01-18 13:25:40 (2.46 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20a16d44-d294-44d0-a2aa-d3c60f61a52b"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "outputId": "c3631441-0924-40b5-8623-242c4ceadc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "5b102fa6-eedd-4040-c885-29aae6d2fa50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "893af078-a3b1-4d83-add4-6077ab027024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "outputId": "da4c7018-5237-4d33-9377-30563f3823aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_id\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  train_unique, test_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_unique[\"claim_id\"])]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_unique[\"claim_id\"])]\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n",
        "train_facts.head(500)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>for firms moving overseas in order to create a...</td>\n",
              "      <td>foxnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>get a tax break specifically by outsourcing jo...</td>\n",
              "      <td>newslines.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>confusing clashes over taxes in wednesday s pr...</td>\n",
              "      <td>wsj.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>support on this bill in a time of tight budget...</td>\n",
              "      <td>senate.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>tax a lower rate for american manufacturing an...</td>\n",
              "      <td>archives.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>to have a different standard the senate will h...</td>\n",
              "      <td>thedailybeast.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>double standard for mcconnell to be less conce...</td>\n",
              "      <td>weaselzippers.us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>cory booker on government reform even billiona...</td>\n",
              "      <td>ontheissues.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>think are deeply committed to do and we are ob...</td>\n",
              "      <td>whitehouse.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>are deeply committed to do and we are obviousl...</td>\n",
              "      <td>haaretz.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cred_label  ...     article_source\n",
              "0             1  ...        foxnews.com\n",
              "1             1  ...      newslines.org\n",
              "2             1  ...            wsj.com\n",
              "3             1  ...         senate.gov\n",
              "4             1  ...       archives.gov\n",
              "..          ...  ...                ...\n",
              "554           1  ...  thedailybeast.com\n",
              "555           1  ...   weaselzippers.us\n",
              "556           1  ...    ontheissues.org\n",
              "557           1  ...     whitehouse.gov\n",
              "558           1  ...        haaretz.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "255c92fe-df90-4c9a-d3ba-6edb18747220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 844
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>morning new tv advertisement argues that posit...</td>\n",
              "      <td>desmoinesregister.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>iowans could not support household on current ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>not budged in five years leaving many falling ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>are working to support themselves or their fam...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>prove that i had those good hardworking skills...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>cap is melting palin im not one to attribute e...</td>\n",
              "      <td>mysinchew.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2767</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>control the weapons the theocracy does secreta...</td>\n",
              "      <td>blastmagazine.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>be left with only one conclusion mccain was co...</td>\n",
              "      <td>chrisweigant.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2850</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>speech politifact called claim false that demo...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2851</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>covering conduct going back as far as 1994 was...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...              article_source\n",
              "85             1  ...       desmoinesregister.com\n",
              "86             1  ...  americanprogressaction.org\n",
              "87             1  ...  americanprogressaction.org\n",
              "88             1  ...           iowademocrats.org\n",
              "89             1  ...           iowademocrats.org\n",
              "...          ...  ...                         ...\n",
              "2766           0  ...               mysinchew.com\n",
              "2767           0  ...           blastmagazine.com\n",
              "2768           0  ...            chrisweigant.com\n",
              "2850           0  ...               democrats.org\n",
              "2851           0  ...               democrats.org\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "snopes_tokeniser = Tokeniser(x_train_snopes_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n",
        "x_snopes_train = snopes_tokeniser.do_everything(x_train_snopes_list)\n",
        "x_snopes_test = snopes_tokeniser.do_everything(x_test_snopes_list)\n",
        "y_snopes_train = np.array(y_train_snopes_list, dtype=np.float32)\n",
        "y_snopes_test = np.array(y_test_snopes_list, dtype=np.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "train_fact_source_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_source_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_train).type(torch.LongTensor))\n",
        "test_snopes_data= data_utils.TensorDataset(torch.from_numpy(x_snopes_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_test).type(torch.LongTensor))\n",
        "train_snopes_loader = data_utils.DataLoader(train_snopes_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "test_snopes_loader = data_utils.DataLoader(test_snopes_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(x)\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "    else:\n",
        "      x = self.linear1(x.reshape(self.hp.batch_size, -1))\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, unnormalised_predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(unnormalised_predictions.shape) == 1):\n",
        "    auc = roc_auc_score(true_labels, unnormalised_predictions)\n",
        "  else:\n",
        "    auc = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(real_results, 0), torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "9fd8b436-2804-44e1-a1fd-60de87d255a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",snopes_tokeniser.word_to_id,300)\n",
        "small_gloves = load_glove_embeddings(\"glove.6B.50d.txt\", snopes_tokeniser.word_to_id, 50)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44784\n",
            "44784\n",
            "torch.Size([44784, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 20\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  dropout=0.3\n",
        "  C = 0.3\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "af05d4b8-eb59-4096-805f-cb1fe5ac2701",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "pass\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, small_gloves).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_snopes_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/11721 (0%)]\tLoss: 1.648630\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/11721 (22%)]\tLoss: 1.638962\n",
            "Train Epoch: 0 [5120/11721 (44%)]\tLoss: 1.632084\n",
            "Train Epoch: 0 [7680/11721 (67%)]\tLoss: 1.574296\n",
            "Train Epoch: 0 [10240/11721 (89%)]\tLoss: 1.322523\n",
            "Average loss is: tensor(1.5463, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.6313368055555556\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/11721 (0%)]\tLoss: 1.167410\n",
            "Train Epoch: 1 [2560/11721 (22%)]\tLoss: 1.087385\n",
            "Train Epoch: 1 [5120/11721 (44%)]\tLoss: 1.072713\n",
            "Train Epoch: 1 [7680/11721 (67%)]\tLoss: 0.977648\n",
            "Train Epoch: 1 [10240/11721 (89%)]\tLoss: 0.948597\n",
            "Average loss is: tensor(1.0152, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9750868055555556\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/11721 (0%)]\tLoss: 0.944805\n",
            "Train Epoch: 2 [2560/11721 (22%)]\tLoss: 0.916034\n",
            "Train Epoch: 2 [5120/11721 (44%)]\tLoss: 0.904790\n",
            "Train Epoch: 2 [7680/11721 (67%)]\tLoss: 0.902950\n",
            "Train Epoch: 2 [10240/11721 (89%)]\tLoss: 0.886463\n",
            "Average loss is: tensor(0.9077, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.99765625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "58d6b393-cd7d-481e-f4e6-5f25b08a5bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3hVVbrH8e+bRuhIQBRCLxYQEIMo\nqAjoCMqoqNhQsaLj2GbmesWxzOiUa5uioiIoYsUuOBbUodoV7GAhQKjSgjSBQJL3/rF34BCTcAJJ\ndsrv8zznyTm7nffsBPLLWnutbe6OiIiIiAhAQtQFiIiIiEjloXAoIiIiIjsoHIqIiIjIDgqHIiIi\nIrKDwqGIiIiI7KBwKCIiIiI7KByKVDFm1sbM3MySoq5FRESqH4VDEREREdlB4VCkElProIiIVDSF\nQ6lRzOwGM1tmZhvN7HszGxAuH29mf43Z7lgzWxrzOsvMbjSzuWb2k5k9ZmapxbzHhWb2npndE267\n0MwGxaxvaGaPmtmPYS1/NbPEmH3fN7N/mVk28GczSwyPtcbMFgAnFfF+C8LPtNDMhpXtWRMRkZpE\n4VBqDDM7ALgK6Onu9YETgKxSHGJYuE97oBNwcwnb9gK+B5oAdwGPmpmF68YDuUAH4FDgV8ClhfZd\nADQD/gZcBgwOt80Azoj5THWB+4BB4WfqDXxRis8kIiKyC4VDqUnygFrAwWaW7O5Z7j6/FPuPcvcl\n7r6WILSdU8K2i9x9rLvnAY8D+wPNzKwZcCJwnbv/7O6rgH8BZ8fsu9zd73f3XHffApwJ/Dvmvf+v\n0HvlA13MrLa7/+juc0rxmURERHahcCg1hrtnAtcBfwZWmdmzZta8FIdYEvN8EVDSviti3ndz+LQe\n0BpIBn40s3Vmtg54GNi3mPchfJ/C711w7J+Bs4ArwmO+bmYHxvdxREREfknhUGoUd3/G3Y8iCGkO\n3Bmu+hmoE7PpfkXs3jLmeStg+R6UsATIAZq4e6Pw0cDdO8eWWWifH4t4750bu7/l7scTtE5+B4zd\ng7pEREQAhUOpQczsADPrb2a1gK3AFoIuWQiu0zvRzBqb2X4ELYyF/dbM0s2sMXAT8Fxpa3D3H4G3\ngX+YWQMzSzCz9mbWt4TdngeuCd97H2BkzGdqZmanhNce5gCbYj6TiIhIqSkcSk1SC7gDWEPQ7bsv\ncGO47kngS4IBKm9TdPB7Jly3AJgP/LWIbeJxAZACzAV+Al4kaPUrzljgrbC+z4CXY9YlAL8naMVc\nC/QFfrOHdYmIiGDuhXuwRKQwM8sCLnX3/0Zdi4iISHlSy6GIiIiI7KBwKCIiIiI7qFtZRERERHZQ\ny6GIiIiI7JAUdQFloUmTJt6mTZuoyxARqVJmz569xt2bRl2HiFQu1SIctmnThlmzZkVdhohIlWJm\ni3a/lYjUNOpWFhEREZEdFA5FREREZAeFQxERERHZoVpccygi1df27dtZunQpW7dujbqUKis1NZX0\n9HSSk5OjLkVEqgCFQxGp1JYuXUr9+vVp06YNZhZ1OVWOu5Odnc3SpUtp27Zt1OWISBWgbmURqdS2\nbt1KWlqaguEeMjPS0tLU8ioicVM4FJFKT8Fw7+j8iUhp1Oxw+HM2vDkScjZFXYmIiIhIpVCzw+GC\nafDxaBjbD1Z9G3U1IlKJTZw4ETPju+++i7oUEZFyVbPD4SFnwAWTYMs6GNMPPn866opEpJKaMGEC\nRx11FBMmTCi398jLyyu3Y4uIxKtmh0OAdn3hivcgPQMmXQkTr4Rtm6OuSkQqkU2bNvHee+/x6KOP\n8uyzz+5Yfuedd3LIIYfQrVs3Ro4cCUBmZibHHXcc3bp1o0ePHsyfP5/p06czePDgHftdddVVjB8/\nHghu/3nDDTfQo0cPXnjhBcaOHUvPnj3p1q0bp59+Ops3B/8frVy5kiFDhtCtWze6devGBx98wK23\n3sq///3vHce96aabuPfeeyvgjIhIdaapbADqNwtaEKffATPvhmWfwZmPQ9MDoq5MRGLc9p85zF2+\noUyPeXDzBvzp151L3GbSpEkMHDiQTp06kZaWxuzZs1m1ahWTJk3i448/pk6dOqxduxaAYcOGMXLk\nSIYMGcLWrVvJz89nyZIlJR4/LS2Nzz77DIDs7Gwuu+wyAG6++WYeffRRrr76aq655hr69u3LK6+8\nQl5eHps2baJ58+acdtppXHfddeTn5/Pss8/yySeflMFZEZGaTOGwQEIi9L8JWh0BL48IupkH/wu6\nnRV1ZSISsQkTJnDttdcCcPbZZzNhwgTcnYsuuog6deoA0LhxYzZu3MiyZcsYMmQIEEw+HY+zztr5\n/8w333zDzTffzLp169i0aRMnnHACAFOnTuWJJ54AIDExkYYNG9KwYUPS0tL4/PPPWblyJYceeihp\naWll9rlFpGZSOCyswwC44l148RJ4ZQQseh8G3QnJtaOuTKTG210LX3lYu3YtU6dO5euvv8bMyMvL\nw8wYOnRo3MdISkoiPz9/x+vCcw7WrVt3x/MLL7yQiRMn0q1bN8aPH8/06dNLPPall17K+PHjWbFi\nBRdffHHcNYmIFEfXHBalQXMY/h846vfw2ePwyHGwJjPqqkQkAi+++CLnn38+ixYtIisriyVLltC2\nbVsaNmzIY489tuOawLVr11K/fn3S09OZOHEiADk5OWzevJnWrVszd+5ccnJyWLduHVOmTCn2/TZu\n3Mj+++/P9u3befrpnYPkBgwYwEMPPQQEA1fWr18PwJAhQ5g8eTKffvrpjlZGEZG9oXBYnMQkOO5P\nMOxF2LAcxvSFb16KuioRqWATJkzY0U1c4PTTT+fHH3/k5JNPJiMjg+7du3PPPfcA8OSTT3LffffR\ntWtXevfuzYoVK2jZsiVnnnkmXbp04cwzz+TQQw8t9v3+8pe/0KtXL/r06cOBBx64Y/m9997LtGnT\nOOSQQzjssMOYO3cuACkpKfTr148zzzyTxMTEcjgDIlLTmLtHXcNey8jI8FmzZpXfG6xfCi9eDEs+\nhoxL4IS/Q3J81xKJyN759ttvOeigg6Iuo9LKz8/fMdK5Y8eOxW5X1Hk0s9nunlHeNYpI1aKWw3g0\nTIcLX4fe18CsR+HR42HtgqirEpEabu7cuXTo0IEBAwaUGAxFREpDA1LilZgMv/oLtO4Nr1wBD/eF\nU0bBwadEXZmI1FAHH3wwCxboD1URKVtqOSytAwYFo5mbdITnL4A3/hdyc6KuSkRERKRMKBzuiUat\n4KLJcMSV8MnDMO4E+Ckr6qpERERE9prC4Z5KSoGB/wdnPQXZC+DhY+Db16KuSkRERGSvKBzurYN+\nDZfPgH3awnPDYPIfIXdb1FWJiIiI7BGFw7LQuC1c8jYcPgI+egAeGwTrFkddlYiUkXr16kVdgohI\nhVE4LCtJteDEu2HoeFj9PYw+Gr6fHHVVIiIiIqWicFjWOg8JupkbtYQJZ8Hbt0De9qirEpEylpWV\nRf/+/enatSsDBgxg8eKgt+CFF16gS5cudOvWjWOOOQaAOXPmcPjhh9O9e3e6du3KvHnzoixdRKRE\nmuewPKS1h0v+C2/dCB/cF9xZ5YzHoGGLqCsTqdreHAkrvi7bY+53CAy6o9S7XX311QwfPpzhw4cz\nbtw4rrnmGiZOnMjtt9/OW2+9RYsWLVi3bh0Ao0eP5tprr2XYsGFs27aNvLy8sv0MIiJlSC2H5SU5\nFQb/C05/FFbOgdFHwbx3oq5KRMrIhx9+yLnnngvA+eefz3vvvQdAnz59uPDCCxk7duyOEHjkkUfy\n97//nTvvvJNFixZRu3btyOoWEdkdtRyWt0POgP27wfPD4ekz4KjfQ7+bIFGnXqTU9qCFr6KNHj2a\njz/+mNdff53DDjuM2bNnc+6559KrVy9ef/11TjzxRB5++GH69+8fdakiIkVSy2FFaNIRLpsCPS6A\n9/4JT5wMG36MuioR2Qu9e/fm2WefBeDpp5/m6KOPBmD+/Pn06tWL22+/naZNm7JkyRIWLFhAu3bt\nuOaaazjllFP46quvoixdRKRECocVJbk2nHw/DBkDyz8PupnnT426KhGJw+bNm0lPT9/x+Oc//8n9\n99/PY489RteuXXnyySe59957Abj++us55JBD6NKlC71796Zbt248//zzdOnShe7du/PNN99wwQUX\nRPyJRESKZ+4edQ17LSMjw2fNmhV1GfFb/X3Qzbz6Ozjmejh2JCQkRl2VSKX07bffctBBB0VdRpVX\n1Hk0s9nunhFRSSJSSanlMApNDwi6mbufCzPvgidOgY0ro65KREREROEwMil14dQH4ZQHYemsoJt5\nwYyoqxIREZEaTuEwaocOg8umQu1G8OSpMOMuyNccaCKxqsPlL1HS+ROR0lA4rAyaHQyXTYNDhsK0\nv8FTp8Om1VFXJVIppKamkp2drYCzh9yd7OxsUlNToy5FRKoITbZXWdSqB0MehtZ94M3/DbqZzxgH\nbfpEXZlIpNLT01m6dCmrV+sPpj2VmppKenp61GWISBVRoeHQzMYBg4FV7t6lhO16Ah8CZ7v7ixVV\nX+TM4LDh0OIweP4CeHww9L8Z+vwOEtTIKzVTcnIybdu2jboMEZEao6ITx3hgYEkbmFkicCfwdkUU\nVCnt1wUunwGdh8CU2+GZofBzdtRViYiISA1QoeHQ3WcCa3ez2dXAS8Cq8q+oEqtVP7gv80n/hIUz\n4eGjYfFHUVclIiIi1Vyl6qs0sxbAEOChOLYdYWazzGxWtb0WyQx6XgKX/hcSU+CxE+H9eyE/P+rK\nREREpJqqVOEQ+Ddwg7vvNv24+xh3z3D3jKZNm1ZAaRHav1vQzXzQYHjnVnj2HNi8uwZYERERkdKr\nbOEwA3jWzLKAM4AHzezUaEuqJFIbwtDHYdDdkDkFHj4GlnwadVUiIiJSzVSqcOjubd29jbu3AV4E\nrnT3iRGXVXmYQa8RcMnbwfPHBsKHD4DmfxMREZEyUqHh0MwmEExRc4CZLTWzS8zsCjO7oiLrqPJa\n9IDLZ0KngfDWH+G582DLT1FXJSIiItWAVYe7DmRkZPisWbOiLqPiucNHD8E7t0CD5jB0fDBHoohI\nHMxstrtnRF2HiFQulapbWUrJDI68Ei6aHATFR0+Ajx9WN7OIiIjsMYXD6qBlz6CbucOA4NZ7LwyH\nreujrkpERESqIIXD6qJOYzh7Ahx/O3z7GjzcF5Z/EXVVIiIiUsUoHFYnCQnQ51q46A3IzYFHj4dP\nH1E3s4iIiMRN4bA6anUEXPEetD0GXv8DvHgx5GyMuioRERGpAhQOq6u6aXDuCzDgVpg7MehmXvF1\n1FWJiIhIJadwWJ0lJMDRf4Dhr8G2n+GR42D2eHUzi4iISLEUDmuCNn2CbuZWR8J/roVXLoecTVFX\nJSIiIpWQwmFNUa8pnPcS9LsJvn4BxvaDlXOjrkpEREQqGYXDmiQhEfr+L1wwCbasg7H94fOno65K\nREREKhGFw5qo7TFBN3N6Bky6EiZeCds2R12ViIiIVAIKhzVV/WZBC2LfG+CLZ4JWxNXfR12ViIiI\nREzhsCZLSIR+f4TzX4afV8OYfvDlc1FXJSIiIhFSOBRo3z/oZm7eHV4ZAa9eDdu3RF2ViIiIREDh\nUAIN9ocLXg3mRfzsiWBOxDWZUVclIiIiFUzhUHZKTAruqDLsJdiwHMb0ha9fjLoqERERqUAKh/JL\nHY8LupmbdYGXLoHXfgfbt0ZdlYiIiFQAhUMpWsMWcOFr0OdamDUOHj0esudHXZWIiIiUM4VDKV5i\nMhx/O5zzHKxbDGOOhTkTo65KREREypHCoezeAQODbuamB8ALw+GN6yE3J+qqREREpBwoHEp8GrWE\nC9+AI6+CT8bAuBPgp6yoqxIREZEypnAo8UtKgRP+Bmc9DdkLYPQx8O1rUVclIiIiZUjhUErvoMFw\nxUxIawfPDYPJf4TcbVFXJSIiImVA4VD2zD5t4OK34PDL4aMH4LFBwaAVERERqdIUDmXPJdWCE++C\noY/Dmh9g9NHw/eSoqxIREZG9oHAoe6/zqXD5DGjUCiacBW/fAnnbo65KRERE9oDCoZSNxu3gkncg\n4xL44D4YfxKsXxp1VSIiIlJKCodSdpJTYfA/4YxxsHJO0M08752oqxIREZFSUDiUstfldBgxAxo0\nh6fPgP/eBnm5UVclIiIicVA4lPLRpANc+l/oMRze+yc8cTJs+DHqqkRERGQ3FA6l/CTXhpPvg9PG\nwvIvYPRRMH9q1FWJiIhICRQOpfx1PRNGTIe6TeHJ02Dq3yA/L+qqREREpAhxhUMzm2pmBxazrpOZ\nqTlISta0E1w2FboPg5l3wROnwMaVUVclIiIihcTbcngs0KCYdfWBvmVSjVRvKXXg1Afg1Idg6ayg\nm3nBjKirEhERkRil6Vb2Ypa3BzbFcwAzG2dmq8zsm2LWDzOzr8zsazP7wMy6laI+qSq6nwsjpkHt\nfeDJU2H6nepmFhERqSSSilthZhcBF4UvHRhjZhsLbVYb6AJMifP9xgOjgCeKWb8Q6OvuP5nZIGAM\n0CvOY0tVsu9BQTfz63+A6X+HxR/AaY9AvaZRVyYiIlKjldRymA/khQ8r9LrgkQ08BFwSz5u5+0xg\nbQnrP3D3n8KXHwHp8RxXqqha9WDIaDj5flj8UdDNnPVe1FWJiIjUaMW2HLr748DjAGY2DfiNu39X\nUYURBM43i1tpZiOAEQCtWrWqqJqkrJlBjwugeQ94YTg8/mvodxMc9XtI0GB6ERGRihbXb19371eR\nwdDM+hGEwxtKqGmMu2e4e0bTpuqKrPL26xJMd9N5CEz9CzwzFH7OjroqERGRGqfYlsPCzKwBcCLQ\nCkgttNrd/S9lUZCZdQUeAQa5u9JBTVKrPpz+KLQ5Ct4cGXQzD30MWh0RdWUiIiI1Rlzh0Mz6AP8B\nGhWziQN7HQ7NrBXwMnC+u/+wt8eTKsgMMi6GFofB88PhsRNhwK3Q+xp1M4uIiFSAeH/b/hvIAnoC\nqe6eUOiRGM9BzGwC8CFwgJktNbNLzOwKM7si3ORWIA140My+MLNZpfs4Um3s3w0unwEHDYb//gkm\nnA2bix3LJCIiImXE3IubvjBmI7NNwJnu/kb5l1R6GRkZPmuWcmS15A6fjIW3b4J6zeCMx6Blz6ir\nEqkWzGy2u2dEXYeIVC7xthwuBmqVZyEiRTKDXiPg4rfAEuCxgfDhA0FoFBERkTIXbzi8DRgZDkoR\nqXgtesDlM6HTQHjrj/DsMNjy0+73ExERkVKJd7TyYKAZsNDMPuSXE1m7uw8v08pECqvdCM56Cj56\nCN65BR4+BoaODwaviIiISJmINxweRTAieQPQuYj16uOTimEGR14JLQ+HFy6ER0+AE/4Gh48I1omI\niMheiSscunvb8i5EpFTSM4Ju5olXwpv/G9x275RRkNow6spERESqNE0cJ1VXncZwzgQ4/i/w3evw\ncF9Y/kXUVYmIiFRpcYVDM2u1u0d5FypSJDPocw1c9CbkbYNHj4dPH9FoZhERkT0U7zWHWez+usK4\nJsIWKRetesHl78Irl8Prf4Cs9+Hk+4Jb8omIiEjc4g2HF/PLcJhGMIq5LWVw6zyRvVY3Dc59Ht7/\nN0z9K/z4JZz5OOx3SNSViYiIVBnxDkgZX8yqf5rZk0C7MqtIZG8kJMDRv4dWR8CLF8Mjx8GgO6HH\ncI1mFhERiUNZDEh5iqBlUaTyaN076GZu3Rv+c23Q3ZyzKeqqREREKr2yCIf7AqllcByRslWvKQx7\nCfrdDF+/AGP7wcq5UVclIiJSqcXVrWxmxxSxOAXoAtwIvFuWRYmUmYQE6Ht9MGDlpUthbH846R9w\n6LCoKxMREamU4h2QMp1fDkgpuIBrBvCbsipIpFy0PSboZn75Uph0JSx6H068B1LqRF2ZiIhIpRJv\nOOxXxLKtwCJ3X1GG9YiUn/rN4PyJMOMumHEnLPssGM3c9ICoKxMREak04h2tPKO8CxGpEAmJ0O/G\nYDTzy5fBmGNh8L+h21lRVyYiIlIplGpAipl1MbPfmtkt4dfO5VWYSLlq3y/oZm7eA14ZAa9eDdu3\nRF2ViIhI5OIdkJIEjAfOYee1hgBuZs8AF7p7XtmXJ1KOGuwPF0yC6f8H794TdDMPfRyadIi6MhER\nkcjE23L4J+BM4FaCO6LUDr/eCpwVfhWpehKTYMAtwZQ3G5bDmL7w9YtRVyUiIhKZeMPhecBf3f1v\n7r7I3XPCr38D/gpcUH4lilSAjsfBFe9Bsy7w0iXw2u9g+9aoqxIREalw8YbD5sAHxaz7IFwvUrU1\nbAEXvgZ9roVZ4+DR4yF7ftRViYiIVKh4w+FyoE8x63qH60WqvsRkOP52OOc5WL8EHu4LcyZGXZWI\niEiFiTccPg3cFI5Sbmdmtc2srZndCNwEPFl+JYpE4ICBwWjmfQ+EF4bDG9dDbk7UVYmIiJQ7cy98\n45MiNgpGKz8BnM2ud0oxYAIw3N1zy6XCOGRkZPisWbOienupznK3wZTb4MNR0PxQGDoe9mkTdVUi\nZcLMZrt7RtR1iEjlElc43LFxMK/hMUBjYC0w093nlFNtcVM4lHL33esw8TfBn0anPgAH/TrqikT2\nmsKhiBQl3tvnARAGwcjDoEiFO/AkuHwmvHARPHceHHElHHcbJKVEXZmIiEiZKlU4NLOWQEsgtfA6\nd59aVkWJVEr7tIGL34J3boGPHoQln8DQx6BRq6grExERKTPx3iGlHcGglMMLFoVfPXzuQGKZVydS\n2SSlwKA7oXVvmHQVjD4ahoyGAwZFXZmIiEiZiHe08iNAK+A6YCDQL3z0j/kqUnMcfApcPgP2aQ0T\nzoa3b4a87VFXJcLkyZM54IAD6NChA3fccccv1i9atIgBAwbQtWtXgAPMLL1gnZndaWbfhI+zYpa/\na2ZfhI/lZjYxZt2x4fI5ZjYjZnmWmX0drtvlonAzu9rMvgv3uStcdryZzQ73mW1m/WO2n25m38fU\nsG8ZnS4RKUK8o5U3Etw/+aXyL6n0NCBFIrN9K7x9E3z6CLTsBWeMg4bpu99PpBzk5eXRqVMn3nnn\nHdLT0+nZsycTJkzg4IMP3rHN0KFDGTx4MMOHD8fMfgA+cffzzewkggaAQUAtYDowwN03xL6Hmb0E\nTHL3J8ysEcGNEAa6+2Iz29fdV4XbZQEZ7r6m0P79CKZAO8ndcwr2MbNDgZXuvtzMugBvuXuLcJ/p\nwP+4u/6jF6kA8bYcLgW2lWchIlVSciqc9I8gFK6cG3Qzz3sn6qqkhvrkk0/o0KED7dq1IyUlhbPP\nPptJkybtss3cuXPp339Ho9xG4JTw+cEEM1DkuvvPwFcEPUU7mFkDgp6igpbDc4GX3X0xQEEw3I3f\nAHe4e07sPu7+ubsX3FBhDlDbzGrF+9lFpOzEGw7/DtxgZnXLsxiRKqvL6UE3c4MW8PQZ8N8/Q15k\nU39KDbVs2TJatmy543V6ejrLli3bZZtu3brx8ssvF7xsBNQ3szTgS2CgmdUxsyYElwy1ZFenAlNi\nWhM7AfuE3b6zzeyCmG0deDtcPiJmeSfgaDP72MxmmFnPIj7K6cBnBQEy9FjYpXyLmVkR+4hIGYlr\nQIq7P2lmBwJZZvYR8NMvN/HhZV6dSFWS1h4ufQcmj4T3/gWLP4YzHoUGuvW4VB733HMPV111FePH\njweoDywD8tz97TCofQCsBj4E8grtfg7BNegFkoDDgAFAbeBDM/vI3X8AjnL3ZeH1ge+Y2XfuPjPc\npzFwBNATeN7M2nl4jVM4n+6dwK9i3mdYeKz6wEvA+QQ3ZhCRchDvaOULgRsJ/qPowS+7mOOfSVuk\nOkuuDb++F1r3gf9cB6OPgo4nQJMOkNYRmnSExu0gSb1lUvZatGjBkiVLdrxeunQpLVq02GWb5s2b\n72g5NLNlwL7uvg7A3f8G/C1c9wzwQ8F+YWvi4cCQmMMtBbLDbuifzWwm0A34wd2XhcdcZWavhPvO\nDPd5OQyDn5hZPtAEWB0OjnkFuMDd5xe8ScyxNoZ1HY7CoUi5iXeew9sI/sFeUvCfyJ4ws3HAYGCV\nu3cpYr0B9wInApsJBsF8tqfvJxKZrmfC/t2DUcwLpsOXz+xcZwnB3IgFYTGtQ/i1I9TfD9RjJnuo\nZ8+ezJs3j4ULF9KiRQueffZZnnnmmV22WbNmDY0bNyYhIQFgf2AsgJklAo3cPdvMugJdgbdjdj0D\neM3dt8YsmwSMCm+xmgL0Av4VXoKUEIa5ugStgLeH+0wk6LKeZmadwv3WhINbXgdGuvv7BW8QHruR\nu68xs2SC3yH/3euTJSLFijccpgEP7k0wDI0HRlH8X3yDgI7hoxfwUPhVpOpp2gmGPR88z9kI2Zmw\nJhOy58GaecHXRe/D9s0790mpH3RPF4TFghbHtA6QUieazyFVRlJSEqNGjeKEE04gLy+Piy++mM6d\nO3PrrbeSkZHBySefzPTp07nxxhsJL9tLImwpBJKBd8PlG4Dz3D32wtmzgV3mxnH3b81sMsHglXzg\nEXf/Jpwb95WY93jG3SeHu40DxpnZNwS9UMPd3c3sKqADcKuZ3Rpu+yvgZ+CtMBgmEgTDsWV0ykSk\nCPFOZTOZ4C/GUXv9hmZtwmMV1XL4MDDd3SeEr78HjnX3H0s6pqaykSorPx82Lg/DYubO0LgmE9Yv\nYZcrNhqkB6GxcHBs0AIS4h1bJrKT7q0sIkWJt+XwWoKLhn8CJvPLASm4e34Z1NMCWBLzemm47Bfh\nMBz9NgKgVSvdvkyqqISEYF7EhunQvt+u67Zvgez5O8NiQYvjl89CTszUc0m1w67pDr/sqq5Vv2I/\nTw2Vn+/k5OaTk5sXfN0ePN+6PWZZbh452/PZGn4tcVluPlu373qsXZbl5pMTPr/s6Hb8zwkHRH0K\nRKQaiTccfht+LekC4Aq9fZ67jwHGQNByWJHvLVIhkmvDfl2CRyx32LRy11bG7Hmw/AuYOwli/06r\nt98vr2ts0gEatYaE6nXHy7x83zWQxYStEpcVG+aCALY1JojFBrrY423L27u/jRMMUpMTqZWUsONr\nraREaiUnUCspgbq1kmhcN1yWlBAuD9ZntNmnjM6giEgg3nB4OxUzInkZu86rlR4uE5ECZsHAlfr7\nQdujd12XmwNrF8Zc1xh2VfXW7NwAACAASURBVM+dCFtiGvwTU4JR07uExk5BcKy9Z2HD3cktaEEr\nKlQVE7TiDW45uwluufl7919UcqLtDF9JCdQqCGnh1/qpSTRJSiQ1edfgtkuYC4Nb6o71O4+XmlzM\nsqQEkhJ1WYCIVB7xznP45+LWmdmxwAXFrS+lV4GrzOxZgoEo63d3vaGI7OSJKWxr3JGcBu3JSf/V\nLkErd9MaErMzSfopk5R1C6i9YQF1l86h3veTSYgZd/Bz0j6sqdWKVSnp/JjckmWJLViSkM4ymrE5\nz0pscdvLfEZKYsKuASp8nhoGsUZ1UnYEttSkQtvGbFcrufCynWFul2Uxx0hM0ChxERGIv+VwF2bW\ngSAQng+0ArYAF8ex3wTgWKCJmS0F/kQwQg53Hw28QTCNTSbBVDYX7Ul9IpXF+s3b2bB1+553bRbX\n3VnM8XJy89n9GLM24SO4hVoiebS0VbS35bSzH+mYv4L2uT/S7uf36Mn6HXvlksiqpP1ZmZzO6pRW\nZNdvxU+1W7OxbltyUxtTKzlpZ8tZXK1puwa3lMQEEhTQREQiF3c4NLOGwFnAcIKZ7SG43dIdwIR4\njuHu5+xmvQO/jbcmkcrq+xUbGTUtk9e+Wh5HWNuVGTFB6pdBKzU5gUa1k4vtotzZarZrC1qJ3aDh\nspTEhIIpTgJb1u3omk7KnkfzNfNonp0J2ZNgfcydzVIb7joYpmHYVd24XXD/aRERqTJKDIdmlkBw\n4/XhwK+BVGA58ABBiLsuvB2SiADfLFvPqKmZTJ6zgjopiVx6VFs6Nasf0w0aE9wKWs6Sdw14SQm2\na0CLUu1GkJ4RPGLl5wVT7RSet3HBDPgy5m9FTfgtIlLlFBsOzewfwLnAvsBWgjukPE4wAWkD4KqK\nKFCkKvh88U+MmprJlO9WUb9WElf378DFfdqyT92UqEsrHwmJsE+b4NHxuF3X5WwKWht3mbfxB034\nLSJSRZTUcvg7ghHKbxDcxi67YIWZaeoYEeCThWu5f+o83p23hoa1k/n98Z0Y3rsNDWsnR11adGrV\ng+bdg0es4ib8XvwxfP0iv5zwu4h5Gxuka8JvEZFyVlI4fBQYCpwEfB+OIH7C3T+pkMpEKil354P5\n2dw3ZR4fL1xLWt0Ubhh4IOcf2Zp6tfZojFfNsCcTfn/1nCb8FhGpYMX+JnP3y8zsamAIwTWHlwO/\nMbMfCLqY1XooNYq7M/2H1dw/ZR6fLV7HvvVrcfNJB3Fur1bUSVEo3CslTvi96pfzNtbwCb+Ls27d\nOp555hmuvPLKyGows0OBq9z9Egsunr2XYBaKzQS9UJ8Vsc9ZwE0EN1N4zd1vCJfXIrj5wmFANnCW\nu2eZ2TDg+phDdAV6APOBd2OWpwNPuft1pah/OvA/7l7qe7Ka2RvAue6+rrT7xnHsLHdvUwbHmU4p\nPl8J34NjCb6fF5bivccTfH9fNLPrgDHuvnk3u5UpM+sONHf3N8roeFlAhruv2c12dxP8O3iD4H7h\nm9z9nj14v1OBH9x9bsyyqwnGgeQBr7v7/8asawXMBf7s7veYWQrB5YH9C907fRcl/kZz960EI5En\nmNn+BFPXXACMDDe5w8weBF4MtxWpdtydd+auZNS0TL5aup7mDVP5yymdGZrRktTkmhE6ImMG9ZsF\njzZH7bpuryb8DkNkncYV+3nK2bp163jwwQcjCYdmlhT+svkj8Ndw8SCgY/joBTwUfo3dLw24GzjM\n3Veb2eNmNsDdpwCXAD+5ewczOxu4kyCcPA08He5/CDDR3b8ID9k95tizgZfL5xP/krufWFHvVYGK\n/B6UwXGvA54i+KOhInUHMghCWlxifrb3xgigsbvnmdmf9+I4pwKvEQQ+zKwfcArQzd1zzGzfQtv/\nE3iz4IW7bzOzKQTfw6eLe5O4mzvCyajvAu4yswyC1sSzCf6iuB/QPZykWsnPd978ZgX3T53Hdys2\n0qpxHe447RBO65FOSpKue4tcUi3Y98DgUdjP2buOol6TGQyK+eEtyN++c7s6acGdYQoHx33aQGLV\nu2505MiRzJ8/n+7du3P88cdz9913c/fdd/P888+Tk5PDkCFDuO2228jKymLQoEEArc1sDsGdqE5x\n9y1mdg1wBZALzHX3s82sMTAOaEfwy3yEu38V/pJrHy5fHN7zvqu7fxmWdArB5UgOfGRmjcxs/0I3\nN2gHzHP31eHr/wKnA1PC/f8cLn8RGGVmFh6vwDnAs4XPhZl1IhhQ+W7hdYW2qw08BnQDvgNqx6z7\nFXAbUIugVfIi4CjgEncfGm5zLEFL3ODYViQzuwD4H4Jetq/c/XwzawqMJpgfGIIZP94vqb4YBecH\nM7sBOA/IB95095GxLYJm1gSY5e5tdvP5HgJ6hstedPc/FfG+RX4PgG0QMxFqEcLt7geOB5aE+xD+\njDUHppnZGuBJgp+b68L1lwEHE7Q6TwZmE7QMzwEucPfNZnYYQfCpB6whaMUs8aYZYavZ7UBtMzsK\n+D/gHeL72T6PIBgPJDjvY939/vDQV5vZrwnmbR7q7t8Vet9Xwzpnm9n/FVrXneBnog7Bz9jF7v5T\neA5GACkEcz+fTxBsTwb6mtnNBP9OfgPc4e45AO6+KubYpwILCVoqY00MP3ux4RB33+NHeCKGAK/s\nzXH29nHYYYe5SFnZnpvnr3y21Af8Y7q3vuE173f3NH9x1hLfnpsXdWmyt3K3u6/JdP/uTff373Of\ndLX7uEHud3Vw/1ODnY/bGrvf18P96bPc37rJfdZ496z33Teucs/Pj/pTFGvhwoXeuXPnHa/feust\nv+yyyzw/P9/z8vL8pJNO8hkzZvjChQs9MTHRgTke/F/+PHBe+Hw5UCt83ij8ej/wp/B5f+CL8Pmf\nCX5x1w5f9wNe8p2/I14Djop5PYUgPMX+HtkHWEowM3sS8BLwn3DdN0B6zLbzgSaF9p8PdPFCvxeA\nW4F7Ci8vYrvfA+PC510JQnEG0ASYCdQN190QHjMJWByz/KGYc5cV7tcZ+KGgVoIWI4BnCs4HQUD8\nNua8fVHE44Mi6h0EfADUKXTs6QXnNqwhq6TPV2jfxHD/ruHr24GT4/0elHBuTyMIX4kEYXAdcEbs\nuQqf1wuPmxy+/gA4JPyZcKBPuHwcQeBODrdpGi4/K+YzXl/MubwvXH8hMCqmxnh/tn9DEI6TCp27\nLODq8PmVwCPFnItNMc//TBDkAb4C+sac93+Hz9Nitv9rzHuMLziH4esvCP6A+RiYAfSMOacfhl93\nvF/M93t1Sd+7vbpQyt23E1x/+MreHEekMtiel88rny/jwWmZZGVvplOzetx3zqGcdMj+urVadZGY\nFEyfk9aeoAEgxpZ1MYNiftjZVT1/KuSVMOF3QYtjJZzw++233+btt9/m0EMPBWDTpk3MmzePVq1a\n0bZtWzIzM7eEm84m+EUMwS+rp81sIkELAwStZacDuPtUM0szswbhulfdveA4+xPTwhUPD1pJfgM8\nR9Ai8wFBi81umVkvYLO7f1PE6rMJWlt25xjgvrCWr8zsq3D5EQStV++H846mAB+6e66ZTQZ+bWYv\nEgza/N9Cx+wPvODhdWjuvjZcfhxwcMw8pg3MrJ67TyOmO3w3jgMe8/BavZhjl/bzAZwZtvYmEXzv\nDiZo5bw1zlp25xhggrvnAcvNbGpRG7n7pnDdYDP7liAkfm1mbYAlvrN19SngGoLWxC7AO+G5TAR+\nDI91N8FlCvGK92f7OGC0h93Lhc57waULswkCcVzCm4s0cvcZ4aLHgRfC513M7K9AI4KA91Yxh0kC\nGhP8vPYEnjezdgSB8F/hud1lBw+6treZWX1331jcQUVqtJzcPF6YtZSHps9n2botdG7egNHn9eBX\nB++n27nVJLUbQfphwSNWaSb8btgyCIuFu6ojmvDb3bnxxhu5/PLLd1melZVFrVq1YhflsbO78SSC\nX+q/Bm4Kr+krSWyX1RaCmyUUWAa0jHmdHi4rXOd/gP8AhGElr9D+S80sCWhIMCiiwNkUcYcuM+tG\n0MIzeze1l8SAd7zoO3s9SzDX71qC7tsif8EWIQE4wgtdox9eN/avIrbf7O694zx2bnh82PV7UCQz\na0vQCtczDOjji9lvd9+DsvIIwfWq3xF0gxcoPPjVCb43c9z9yMIHMbPrgWFFHH+mu19TypoKd8cW\np+CvxzzKLleNB0519y/N7EKCWw8XZSnwsgdNgp+YWT5By3Ev4Awzu4sgYOab2VZ3HxXuV4tgDusi\nKRxKjbV1ex4TPlnMwzMWsGLDVrq1bMTtp3Sm/4H7Vp47lEj0Sj3h9zxY9EEkE37Xr1+fjRt35pQT\nTjiBW265hWHDhlGvXj2WLVtGcnLx11KGd8Vq6e7TzOw9gvBVj+C6vWHAX8Jr7Na4+4Yi/p18C/wh\n5vWrwFXhVGi9gPVexHVhZravu68ys30IuubOjNl/OEH32BnA1PCXYEGtZwJHF/FRzqFQaDSzIcDh\n7n5joW1nEtzwYaqZdSHoegX4CHjAzDq4e6aZ1QVauPsPBN1344DLKOJ6R2Aq8IqZ/dPds82scdjS\n9DZwNWHLlpl1d/cvStly+A5wq5k97cG1dwXHziIYUfxJeK529/kaEISf9WbWjKC7enoR71fs96CA\nmR1OMEL9gkL7zgQuN7PHCa7/7EfQtQ6wEahPcL0g7v6xmbUkuLawa8wxWpnZke7+Yfg53gO+B5oW\nLDezZKCTu8+Jo+Ww4H0LxPuz/U74WaaFrccF532Puft6M/vJzI5293cJWroLWhHrAz+Gn20YO/+o\nKlz/RILzOi28zjYl/Aw7/l2E109uKgiG4SCwNWHvb5EUDqXG+Tknl6c/XsSYmQtZsymHnm324a4z\nunJ0xyYKhVI6xU347Q4blu8MixU04XdaWhp9+vShS5cuDBo0iLvvvptvv/2WI48MGljq1avHU089\nRWJisaPsE4Gnwu4uI7hOa134y2Vc2CW5mSAs/IK7f2dmDWO6q94gmL4jM9zvooJtzewLdy84cfeG\nrX0At4cBDIL5dp80s0yCVrqzY97uGIIuxwVFlHJm+L6x2gMbitj2IeCxsDvzW4KuQTwYOX0hwWwd\nBc2sNxNMI5JnZq8RXL/2i3Ph7nPM7G/ADDPLAz4Pt72GIHB+RfD7dybB4J+4ufvkcBDDLDPbRnCO\n/wjcQ9ClOAJ4PY7P96WZfU7QUrcE2DEwxsxuJ2gRfZWSvwcFWhG0Ghf2CkEX+1yC6zQ/jFk3Bphs\nZsvdvWDi0+eB7u4eM90A3wO/NbNx4XEe8mDE7RnAfeHPahLwb4IBK7szDRhpZl8QDMr4M3H8bBO0\nbHYCvjKz7cBYYFQx22LBwN0r3P3S3dQzHBhtZnWABez8N3ILwXWEq8OvBYHwWWBsOKjnDII/UsaZ\n2TcEA36GFw7vRejHrj8jv6x/98eo/DIyMnzWrFJPSSU1zMat23niw0U88u4Cftq8nd7t07hmQEeO\naJcWdWlSkxQ34Xd2ZhETfrf/5byNaR0htUHxxy8FM5vt7hm737JUx/wdsNHdHynL4+4tM3sK+J3v\nHBUtZcSCOfyedPevdrtxycd5jeA6uSnh6zYE8yJ2KWk/KR0zexkYGfNH2C+o5VCqvfWbtzPu/YU8\n9v5CNmzN5dgDmnJ1/w4c1rp6zXEnVURpJ/xe8RV8+2rxE34feBJ0PL5iP0PJHiK4u1al4u7nRV1D\ndeXu1+9+q+KZWSOC7vAvC4KhlA8LpvOZWFIwBIVDqcayN+Xw6HsLeeLDRWzKyeX4g5txdf8OdE1v\nFHVpIr9U4oTf2+CnhbvO25g9L7hLTP39KlU4DAdbPBl1HVJ1eHBHmU5FLM8iGJUsZcTdtxHMT10i\nhUOpdlZt2MrYdxfw1EeL2Zqbx4ld9ueq/h04aP+y6YoTqXBJKdD0gOBRWN7e3rhBRGRXCodSbfy4\nfgujp89nwqdLyM3L5+Ruzfltvw50bFZ/9zuLVFWJ+m9cRMqW/leRKm/J2s08OH0+L85egjuc1qMF\nvzm2A22b1I26NBERkSpH4VCqrIVrfuaBaZm88vkyEs04M6MlV/RtT8vGZTdvnIiISE2jcChVzryV\nGxk1LZP/fLmc5MQEzj+iNZf3bcf+DWvvfmcREREpkcKhVBlzl29g1LR5vPnNClKTErn06HZcenRb\n9q1fue5nKyIiUpUpHEql99XSddw3JZP/fruSerWSuPLY9lxyVDsa102JujQREZFqR+FQKq3Zi9Zy\n35RMZvywmgapSVx3XEcu6t2WhnWKvzesiIiI7B2FQ6lU3J2PFqzlvinz+HBBNo3rpnD9CQdwwZGt\nqZ+qUCgiIlLeFA6lUnB3Zs5bw6ip8/g06yea1KvFTScexLAjWlEnRT+mIiIiFUW/dSVS7s6Ub1dx\n/7RMvlyyjv0bpnLbyZ05q2dLUpMToy5PRESkxlE4lEjk5ztvzVnB/VMzmfvjBtL3qc3fhxzC6Ye1\noFaSQqGIiEhUFA6lQuXlO699tZwHpmXyw8pNtG1Sl7vP6Mqph7YgOTEh6vJERERqPIVDqRDb8/KZ\n9MVyHpyWyYI1P9Nx33rce3Z3BndtTmKCRV2eiIiIhBQOpVxty83npc+W8uD0TJas3cJB+zfgwWE9\nGNh5PxIUCkVERCodhUMpF1u35/Hcp0sYPWM+P67fSrf0hvxpcGcGHLQvZgqFIiIilZXCoZSpzdty\neebjxTw8cwGrN+aQ0Xof7ji9K8d0bKJQKCIiUgUoHEqZ2JSTyxMfZvHouwvJ/nkbR7ZL496zu3Nk\nuzSFQhERkSpE4VD2yvot2xn/fhbj3l/I+i3bOaZTU67p34GMNo2jLk1ERET2QIWHQzMbCNwLJAKP\nuPsdhda3Ah4HGoXbjHT3Nyq6TinZ2p+3Me69hTz+QRYbc3I57qB9uap/R7q3bBR1aSIiIrIXKjQc\nmlki8ABwPLAU+NTMXnX3uTGb3Qw87+4PmdnBwBtAm4qsU4q3emMOj7y7gCc/WsTmbXkM6rIfV/Xv\nQOfmDaMuTURERMpARbccHg5kuvsCADN7FjgFiA2HDjQInzcElldohVKkFeu3MnrGfCZ8spjtefkM\n7tqcq/p3oFOz+lGXJiIiImWoosNhC2BJzOulQK9C2/wZeNvMrgbqAscVdSAzGwGMAGjVqlWZFyqB\npT9t5qHp83lh1lLy3BlyaAuuPLY97ZrWi7o0ERERKQeVcUDKOcB4d/+HmR0JPGlmXdw9P3Yjdx8D\njAHIyMjwCOqs1rLW/MyD0zN5+bNlmMEZh7XkymPb07JxnahLExERkXJU0eFwGdAy5nV6uCzWJcBA\nAHf/0MxSgSbAqgqpsIbLXLWJB6ZlMumLZSQlJjCsVysu79ue5o1qR12aiIiIVICKDoefAh3NrC1B\nKDwbOLfQNouBAcB4MzsISAVWV2iVNdB3KzZw/9RM3vj6R1KTErm4T1tGHNOOfRukRl2aiIiIVKAK\nDYfunmtmVwFvEUxTM87d55jZ7cAsd38V+AMw1sx+RzA45UJ3V7dxOfl66XrunzqPt+eupG5KIlf0\nbc+lR7UlrV6tqEsTERGRCFT4NYfhnIVvFFp2a8zzuUCfiq6rppm96CdGTZ3HtO9XUz81iWsGdOTi\nPm1oVCcl6tJEREQkQpVxQIqUo48WZHP/1Hm8n5nNPnWS+Z9fdeKC3m1okJocdWkiIiJSCSgc1gDu\nznuZa7h/SiafZK2lSb1a/PHEAxnWqzV1a+lHQERERHZSMqjG3J1p36/ivimZfLFkHfs1SOVPvz6Y\ncw5vRWpyYtTliYiISCWkcFgN5ec7b89dyahp8/hm2QZaNKrNX0/twtCMdGolKRSKiIhI8RQOq5G8\nfOeNr39k1NRMvl+5kdZpdbjr9K4M6dGC5MSEqMsTERGRKkDhsBrIzcvn1S+XM2paJgtW/0z7pnX5\n11nd+HXX5iQpFIqIiEgpKBxWYdty83nl86U8OH0+i7I3c+B+9Xng3B4M7LIfiQkWdXkiIiJSBSkc\nVkFbt+fxwqwljJ6xgGXrtnBIi4aMOf8wjjuoGQkKhSIiIrIXFA6rkC3b8njmk8WMmTmflRty6NGq\nEX8d0oVjOzXFTKFQRERE9p7CYRWwKSeXpz5axCPvLmDNpm30atuYf57Znd7t0xQKRUREpEwpHFZi\nG7Zu5/H3s3j0/YWs27ydozs24er+HTm8beOoSxMREZFqSuGwElq3eRvj3lvIYx9ksXFrLv0P3Jer\n+3fg0Fb7RF2aiIiIVHMKh5XImk05PPLuQp78MIuft+VxQudmXN2/I11aNIy6NBEREakhFA4rgVUb\ntvLwzAU8/fEicnLzOemQ/bmqfwcO3K9B1KWJiIhIDaNwGKFl67Ywevp8npu1hLx855Tuzfltvw60\nb1ov6tJERESkhlI4jMDi7M08OD2Tlz5bCsDpPdL5zbHtaZ1WN+LKREREpKZTOKxA81dv4oFpmUz6\nYjmJZpzdsxVXHNueFo1qR12aiIiICKBwWCG+X7GRUdMyee2r5dRKSmD4kW24vG87mjVIjbo0ERER\nkV0oHJajb5atZ9TUTCbPWUHdlEQuP6Y9lx7dlib1akVdmoiIiEiRFA7LwRdL1nH/lHlM+W4V9VOT\nuKZ/By7q05Z96qZEXZqIiIhIiRQOy9CnWWu5b8o83p23hkZ1kvnD8Z24oHcbGtZOjro0ERERkbgo\nHO4ld+eD+dncN2UeHy9cS1rdFEYOOpDzjmhNvVo6vSIiIlK1KL3sIXdn+g+ruX/KPD5bvI5969fi\nlsEHc+7hraidkhh1eSIiIiJ7ROGwlNydd+auZNS0TL5aup7mDVP5yymdGZrRktRkhUIRERGp2hQO\n45Sf77z5zQrunzqP71ZspFXjOtxx2iGc1iOdlKSEqMsTERERKRMKh7uRm5fPa1/9yKhpmWSu2kS7\npnX5x9BunNK9OUmJCoUiIiJSvSgcFmN7Xj6vfL6MB6dlkpW9mQOa1ef+cw7lxEP2JzHBoi5PRERE\npFwoHBaSk5vHC7OW8tD0+Sxbt4XOzRsw+rzD+NXBzUhQKBQREZFqTuEwtHV7HhM+WczDMxawYsNW\nurdsxF9O7Uy/A/bFTKFQREREaoYaHw5/zsnl6Y8XMWbmQtZsyuHwNo25e2hXjurQRKFQREREapwa\nHQ6nfreSPzz/JT9t3k6fDmmM6n8oR7RLi7osERERkcjU6HDYJq0uh7bah9/268BhrfeJuhwRERGR\nyNXocNiuaT3GXdgz6jJEREREKg1N1CciIiIiOygcioiIiMgOFR4OzWygmX1vZplmNrKYbc40s7lm\nNsfMnqnoGkVERERqqgq95tDMEoEHgOOBpcCnZvaqu8+N2aYjcCPQx91/MrN9K7JGERERkZqsolsO\nDwcy3X2Bu28DngVOKbTNZcAD7v4TgLuvquAaRURERGqsig6HLYAlMa+XhstidQI6mdn7ZvaRmQ0s\n6kBmNsLMZpnZrNWrV5dTuSIiIiI1S2UckJIEdASOBc4BxppZo8IbufsYd89w94ymTZtWcIkiIiIi\n1VNFh8NlQMuY1+nhslhLgVfdfbu7LwR+IAiLIiIiIlLOzN0r7s3MkgjC3gCCUPgpcK67z4nZZiBw\njrsPN7MmwOdAd3fPLuG4q4FFe1hWE2DNHu5bniprXVB5a1NdpaO6Sqc61tXa3dX1IiK7qNDRyu6e\na2ZXAW8BicA4d59jZrcDs9z91XDdr8xsLpAHXF9SMAyPu8f/uZnZLHfP2NP9y0tlrQsqb22qq3RU\nV+moLhGpKSr89nnu/gbwRqFlt8Y8d+D34UNEREREKlBlHJAiIiIiIhFROIQxURdQjMpaF1Te2lRX\n6aiu0lFdIlIjVOiAFBERERGp3NRyKCIiIiI7KByKiIiIyA7VNhya2TgzW2Vm3xSz3szsPjPLNLOv\nzKxHzLrhZjYvfAyv4LqGhfV8bWYfmFm3mHVZ4fIvzGxWWdYVZ23Hmtn68P2/MLNbY9YNNLPvw/M5\nsgJruj6mnm/MLM/MGofryu18mVlLs/9v7/5jra7rOI4/X7vhD4QQRYFhFm1sjVypawzTYc4JxnTM\nzQoTGq2VqW22lW3RlpOYtdpa/ZGxyuKnIhYqIylokracqDFNQH7cmJsixgR/hBR2490fn885fT2c\nw/2S936/eM/rsZ3d7/dzPuf7ffO577vz4fM5n/PRRknbJG2VdEubOpXnWMm4Ks+xknHVkV9l4qor\nx06R9ISkZ3Jst7epc7Kke3O7bJL0gcJz38zlOyTNGMjYzGyIi4gh+QCmARcCWzo8PxNYBwiYCmzK\n5WcAu/PP0fl4dIVxfbxxP+CTjbjy+fPAmBrb7BPA2jblPcDfgA8CJwHPAJOriKml7tXAw1W0FzAe\nuDAfjyR9ufvkljqV51jJuCrPsZJx1ZFf/cZVY44JGJGPhwGbgKktdW4CFuXj2cC9+XhybqeTgYm5\n/XoGI04//PBj6D2G7MhhRDwKHDhGlVnA0kgeB06XNB6YAWyIiAMR8SqwAbiyqrgi4rF8X4DHSVsM\nVqJEm3UyBeiNiN0R8RawktS+Vcd0HXDPQNy3PxGxNyI25+N/AM8BE1qqVZ5jZeKqI8dKtlcng5lf\nxxtXlTkWEXEwnw7Lj9YVhLOAJfn418DlkpTLV0bE4UjbkPaS2tHMrF9DtnNYwgTghcL5i7msU3kd\nvkAaeWoIYL2kv0j6Uk0xXZSnudZJ+nAuq73NJA0ndbB+UyiupL3yVN4FpJGdolpz7BhxFVWeY/3E\nVVt+9ddedeSYpB5JTwP7SP+h6JhjEdEHvA6cyQnwN2lm716V75Bi5Ui6jPTGfUmh+JKI2CPpbGCD\npO15ZK0qm0l7sR6UNBN4AJhU4f2P5WrgzxFRHGUc9PaSNILUWfhqRLwxkNd+J8rEVUeO9RNXbflV\n8vdYeY5FxH+A8yWdDtwv6byIaPv5WzOzgdLNI4d7gPcVzs/JZZ3KKyPpI8AvgFlR2Fc6Ivbkn/uA\n+6l4migi3mhMc0XaPsgVNgAABR1JREFUBnGYpDGcAG1G+rzV26b7Bru9JA0jdShWRMTqNlVqybES\ncdWSY/3FVVd+lWmvrPIcK9znNWAjR3/8oNk2kt4DjAL2c2L8TZrZu1Q3dw7XAJ/LK0qnAq9HxF7g\n98B0SaMljQam57JKSDoXWA3MjYidhfLTJI1sHOe4Kh1BkDQuf54JSVNI+bMfeBKYJGmipJNIb6Jr\nKoxrFHAp8GChbFDbK7fDXcBzEfHDDtUqz7EycdWRYyXjqjy/Sv4e68qxs/KIIZJOBa4AtrdUWwM0\nVrtfS1osE7l8dl7NPJE0AvvEQMVmZkPbkJ1WlnQPafXjGEkvAreRPtBNRCwCHiKtJu0FDgGfz88d\nkPQd0hsSwIKWaaTBjuvbpM8M3ZnfJ/si4mPAWNK0EqTf290R8buBiqtkbNcCN0rqA/4JzM5vRH2S\nvkLq4PQAv4yIrRXFBHANsD4i3iy8dLDb62JgLvBs/kwYwHzg3EJsdeRYmbjqyLEycVWeXyXjgnpy\nbDywRFIPqaO8KiLWSloAPBURa0gd22WSekkLt2bnuLdKWgVsA/qAm/MUtZlZv7x9npmZmZk1dfO0\nspmZmZm1cOfQzMzMzJrcOTQzMzOzJncOzczMzKzJnUMzMzMza3Ln0LqSpHmSosPjtRrjWpy/ssfM\nzKwWQ/Z7Ds1K+hRp39mivjoCMTMzOxG4c2jd7umI6K07CDMzsxOFp5XNOihMPU+T9ICkg5L2S/pJ\n3s6sWHe8pKWSXpF0WNJfJc1pc82JkpZJejnX2y3px23qXSDpT5IOSdol6cstz4+TtETSS/k6eyWt\nlXT2wLeEmZl1E48cWrfrkdT6d3AkIo4UzpcDq4A7gSmk7edOA+ZBc1/dR4DRpK3XXgDmkLY1Gx4R\nP8v1JpL2tz2Ur7GLtE3b9Jb7vxe4G/gRsIC07d5PJe2IiI25zjLg/cCt+X5jgcuB4f9vQ5iZmYE7\nh2bb25T9FriqcP5QRHw9H6+XFMACSXdExE5S520ScFlE/DHXWydpLLBQ0l15X9vbgVOBj0bES4Xr\nL2m5/0jgpkZHUNKjwAzgOqDRObwImB8RKwqvu6/0v9rMzKwDdw6t213D0QtSWlcrr2o5XwksJI0i\n7gSmAXsKHcOG5cCvgMnAs6QRwrUtHcN2DhVGCImIw5J2kkYZG54EbpUk4GFgS3ijdDMzGwDuHFq3\n21JiQcrfO5xPyD/PAPa2ed3LhecBzuTojmg7r7YpOwycUjj/DHAb8A3S9PNeSYuAhS1T4mZmZsfF\nC1LM+je2w/me/PMAMK7N68YVngd4hf91KN+RiNgXETdHxATgQ8Bi0rT1DQNxfTMz617uHJr179Mt\n57OBI8CmfP4IcI6ki1vqfRbYB2zL5+uBqySNH8jgImJHRMwnjTieN5DXNjOz7uNpZet250sa06b8\nqcLxTEk/IHXuppCmc5dGxK78/GLgFmC1pG+Rpo6vB64AbsiLUcivmwk8JukOoJc0knhlRBz1tTed\nSBoF/AFYQVpQ829gFmm19Pqy1zEzM2vHnUPrdp1W+J5VOJ4DfA24EXgL+DnQWL1MRLwp6VLg+8D3\nSKuNdwBzI2J5od7zkqaSFrN8FxhBmpp+8Dhj/hewGfgi6etsjuT7XR8Rx3stMzOzt5EXOJq1J2ke\nabXxJO+iYmZm3cKfOTQzMzOzJncOzczMzKzJ08pmZmZm1uSRQzMzMzNrcufQzMzMzJrcOTQzMzOz\nJncOzczMzKzJnUMzMzMza/ovAzk/JE6dJFcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "63b56b80-7b07-4d5f-f312-6fc8d79284dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "real_results, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_snopes_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "4ac5159b-510e-4c61-dd28-1debf8baf42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "print(predicted_ys.cpu().shape)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), real_results.cpu(), y_snopes_test)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3050])\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.668 P=0.659 R=0.662 F1=0.659 AUC=0.739\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.737     0.691     0.713      1821\n",
            "         1.0      0.580     0.634     0.606      1229\n",
            "\n",
            "    accuracy                          0.668      3050\n",
            "   macro avg      0.659     0.662     0.659      3050\n",
            "weighted avg      0.674     0.668     0.670      3050\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1258  450]\n",
            " [ 563  779]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6585054289972323,\n",
              " 0.6623389360811329,\n",
              " 0.6678688524590164,\n",
              " 0.6594698656759534)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUa9XwZ-4Xny",
        "colab_type": "text"
      },
      "source": [
        "##Baseline Sentence Entailment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    combined = premise_embedding * hypothesis_embedding\n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fbaSIM4jhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineHyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 30\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  num_classes = 1\n",
        "  epochs = 4\n",
        "  C = 0.3\n",
        "  is_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKfpJ-Hk4ePj",
        "colab_type": "code",
        "outputId": "ce691bf1-d995-4cbf-f01a-5f53a7723b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "baseline_model = BaselineSentenceEntailment(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(baseline_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "base_loss, base_accuracy = train(model=baseline_model,\n",
        "                       train_loader=train_snopes_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/11721 (0%)]\tLoss: 1.638064\n",
            "Train Epoch: 0 [2560/11721 (22%)]\tLoss: 1.635532\n",
            "Train Epoch: 0 [5120/11721 (44%)]\tLoss: 1.606178\n",
            "Train Epoch: 0 [7680/11721 (67%)]\tLoss: 1.521407\n",
            "Train Epoch: 0 [10240/11721 (89%)]\tLoss: 1.315147\n",
            "Average loss is: tensor(1.5265, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.6458333333333334\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/11721 (0%)]\tLoss: 1.146979\n",
            "Train Epoch: 1 [2560/11721 (22%)]\tLoss: 1.073078\n",
            "Train Epoch: 1 [5120/11721 (44%)]\tLoss: 0.992127\n",
            "Train Epoch: 1 [7680/11721 (67%)]\tLoss: 0.989518\n",
            "Train Epoch: 1 [10240/11721 (89%)]\tLoss: 0.889023\n",
            "Average loss is: tensor(0.9945, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9665798611111112\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/11721 (0%)]\tLoss: 0.898469\n",
            "Train Epoch: 2 [2560/11721 (22%)]\tLoss: 0.797743\n",
            "Train Epoch: 2 [5120/11721 (44%)]\tLoss: 0.754567\n",
            "Train Epoch: 2 [7680/11721 (67%)]\tLoss: 0.731682\n",
            "Train Epoch: 2 [10240/11721 (89%)]\tLoss: 0.688653\n",
            "Average loss is: tensor(0.7647, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9956597222222222\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXQ16nQW6Xb7",
        "colab_type": "code",
        "outputId": "3da396d7-58aa-49d0-eaed-af0b81f74772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, base_loss, base_accuracy)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY6ih2k9hGy",
        "colab_type": "code",
        "outputId": "0e259cc1-cc63-4118-c342-b59d5c3d055a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "base_real_results, baseline_predicted_ys = batch_wise_evaluate(baseline_model, \n",
        "         test_snopes_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlPE-kpx9riu",
        "colab_type": "code",
        "outputId": "2362ce9d-83eb-4e25-e3cb-d973bc0621a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "evaluation_summary(\"baseline model\", baseline_predicted_ys.cpu(), base_real_results.cpu(), y_snopes_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: baseline model\n",
            "Classifier 'baseline model' has Acc=0.646 P=0.647 R=0.645 F1=0.644 AUC=0.726\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.637     0.702     0.668      1549\n",
            "         1.0      0.656     0.587     0.620      1501\n",
            "\n",
            "    accuracy                          0.646      3050\n",
            "   macro avg      0.647     0.645     0.644      3050\n",
            "weighted avg      0.647     0.646     0.644      3050\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1088  620]\n",
            " [ 461  881]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6467426016606345,\n",
              " 0.6446653382358823,\n",
              " 0.6455737704918033,\n",
              " 0.6439336644545243)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gmzMChW2xxT",
        "colab_type": "text"
      },
      "source": [
        "##DECLARE BASELINE :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qhGP9Y-Cj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(101, 8)\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    mean_embeddings = torch.unsqueeze(torch.sum(embeddings, 1) / self.hp.max_length, 1)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((mean_embeddings, added_embeddings), 1)\n",
        "    \n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    attention_weights = softmax(self.premise_linear(processed_premise))\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    combined = torch.bmm(processed_hypothesis,attention_weights.transpose(1,2))\n",
        "    avg = torch.sum(combined, 1)/self.hp.max_length\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    output = torch.sigmoid(self.linear_final(smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2AvWEFOBYMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "80151e07-8860-4f22-8641-f09b6d8e2cf1"
      },
      "source": [
        "declare_model = BaselineDeclare(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(declare_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "declare_loss, declare_accuracy = train(model=declare_model,\n",
        "                       train_loader=train_snopes_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/11721 (0%)]\tLoss: 1.653303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/11721 (22%)]\tLoss: 1.640685\n",
            "Train Epoch: 0 [5120/11721 (44%)]\tLoss: 1.637160\n",
            "Train Epoch: 0 [7680/11721 (67%)]\tLoss: 1.595957\n",
            "Train Epoch: 0 [10240/11721 (89%)]\tLoss: 1.547716\n",
            "Average loss is: tensor(1.6018, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5973958333333333\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/11721 (0%)]\tLoss: 1.398966\n",
            "Train Epoch: 1 [2560/11721 (22%)]\tLoss: 1.220920\n",
            "Train Epoch: 1 [5120/11721 (44%)]\tLoss: 1.194624\n",
            "Train Epoch: 1 [7680/11721 (67%)]\tLoss: 1.146359\n",
            "Train Epoch: 1 [10240/11721 (89%)]\tLoss: 1.106361\n",
            "Average loss is: tensor(1.1983, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9032118055555556\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/11721 (0%)]\tLoss: 0.990255\n",
            "Train Epoch: 2 [2560/11721 (22%)]\tLoss: 1.007548\n",
            "Train Epoch: 2 [5120/11721 (44%)]\tLoss: 1.076265\n",
            "Train Epoch: 2 [7680/11721 (67%)]\tLoss: 1.013550\n",
            "Train Epoch: 2 [10240/11721 (89%)]\tLoss: 0.987843\n",
            "Average loss is: tensor(1.0082, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9783854166666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZweMG4WBnoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "8517e6e8-f144-4704-a806-dbe011a3f34e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, declare_loss, declare_accuracy)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAkk/Yj2X5JrZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6sN7kk2TqdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1c245472-ace5-4e92-ad1b-d7479b6f89ff"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "declare_real_results, declare_predicted_ys = batch_wise_evaluate(declare_model, \n",
        "         test_snopes_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJHn9s8T1bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "9da3e242-b41a-4ba4-8c04-fec70c15b23b"
      },
      "source": [
        "evaluation_summary(\"declare model\", declare_predicted_ys.cpu(), declare_real_results.cpu(), y_snopes_test)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: declare model\n",
            "Classifier 'declare model' has Acc=0.668 P=0.671 R=0.668 F1=0.667 AUC=0.723\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.644     0.730     0.685      1506\n",
            "         1.0      0.697     0.606     0.649      1544\n",
            "\n",
            "    accuracy                          0.668      3050\n",
            "   macro avg      0.671     0.668     0.667      3050\n",
            "weighted avg      0.671     0.668     0.666      3050\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1100  608]\n",
            " [ 406  936]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6707472855013838,\n",
              " 0.6683146515836482,\n",
              " 0.6675409836065573,\n",
              " 0.6665769690038514)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0JKeQxFT5kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}