{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "c79b410e-d497-4a18-ae56-ab6b117a6007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-16 16:38:56--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip.1’\n",
            "\n",
            "snli_1.0.zip.1      100%[===================>]  90.17M  66.6MB/s    in 1.4s    \n",
            "\n",
            "2019-12-16 16:38:57 (66.6 MB/s) - ‘snli_1.0.zip.1’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "replace snli_1.0/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "1b5fe7a6-1521-4a15-fe39-71d5b16da473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-16 16:39:27--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-12-16 16:39:27--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-12-16 16:39:27--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1        6%[>                   ]  52.83M  35.2MB/s               "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8d23e0030bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget http://nlp.stanford.edu/data/glove.6B.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip glove*.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "4fbb5f29-2e4a-488d-91b7-aa1b76a96d80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "\n",
        "mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "facts = facts.replace({\"cred_label\": mapping})\n",
        "\n",
        "#get unique claims to divide dataset cleanly\n",
        "unique_claims = facts[\"claim_id\"].unique()\n",
        "\n",
        "#splitting the claims\n",
        "train_claims, test_claims = train_test_split(unique_claims, test_size=0.2, random_state=8)\n",
        "\n",
        "#recreating dataset\n",
        "test_facts = facts[facts[\"claim_id\"].isin(test_claims)]\n",
        "train_facts = facts[facts[\"claim_id\"].isin(train_claims)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 150\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "\n",
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with_sources = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "if (with_sources):\n",
        "#AND THE SAME FOR FACT CHECKING (CURRENTLY SET UP KINDA RIGIDLY FOR FIRST TEST :())\n",
        "  train_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "else:\n",
        "  train_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False)\n",
        "test_fact_loader.name = \"fact_data\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    #callback()\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    \n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, new_hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, _ = self.hypothesis_processor(hypothesis, new_hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding).reshape(self.hp.batch_size, -1)\n",
        "    return self.MLP(factorised_mush), better_mush(premise_attention, hypothesis_attention)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params \n",
        "\n",
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies\n",
        "\n",
        "def evaluate(model, test_premise, test_hypothesis, test_y):\n",
        "\n",
        "  model.hp.batch_size = test_hypothesis.shape[0] #why\n",
        "  model.initial_hidden_state = model.init_hidden()\n",
        "\n",
        "  premise_variable = Variable(torch.from_numpy(test_premise).type(torch.LongTensor)).cuda()\n",
        "  hypothesis_variable = Variable(torch.from_numpy(test_hypothesis).type(torch.LongTensor)).cuda()\n",
        "  y_actual_variable = Variable(torch.from_numpy(test_y).type(torch.DoubleTensor)).cuda()\n",
        "  y_predicted = model(premise_variable, hypothesis_variable)\n",
        "  y_predicted_rounded = torch.round(y_predicted.type(torch.DoubleTensor).squeeze(1))\n",
        "\n",
        "  test_data_count = premise_variable.size(0)\n",
        "\n",
        "\n",
        "\n",
        "  total_accuracy = torch.eq(torch.argmax(y_predicted,1), y_actual_variable).data.sum()\n",
        "  average_accuracy = total_accuracy.data.cpu().numpy().astype(int)/float(test_data_count)\n",
        "  return average_accuracy, torch.argmax(y_predicted,1)\n",
        "\n",
        "\n",
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "    \n",
        "  average_accuracy = total_accuracy.data.cpu().numpy()/float(batch_count * test_loader.batch_size)\n",
        "  return average_accuracy, torch.cat(all_results, 0)\n",
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)\n",
        "  \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 300\n",
        "  dense_dimension = 600\n",
        "  attention_hops = 30\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 600\n",
        "  num_classes = 1\n",
        "  epochs = 8\n",
        "  C = 0.1\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "b2c47465-ce9e-41d4-c9b9-1bec6963c330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",x_tokeniser.word_to_id,300)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34370\n",
            "torch.Size([34370, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "6a469736-8c95-4dec-b9af-f70ac8657d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, glove_embeddings).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adagrad(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n",
        "\n",
        "print(torch.cuda.memory_allocated)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.238985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 12.528360\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 15.010834\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 14.255298\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 11.341088\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 11.341088\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 14.255296\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 17.385372\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 15.658433\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 10.477616\n",
            "Average loss is: tensor(13.8272, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5037345467032966\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 12.744223\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 12.528356\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 15.010830\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 14.255293\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 11.341082\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 11.341078\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 14.260204\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 17.385371\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 15.658306\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 10.468680\n",
            "Average loss is: tensor(14.2594, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5037345467032966\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 12.736011\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 12.519155\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 15.001630\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 14.246093\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 11.331883\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 11.331903\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 14.246114\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 17.376171\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 15.649231\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 10.468416\n",
            "Average loss is: tensor(14.2509, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.5037345467032966\n",
            "Running EPOCH: 4\n",
            "Train Epoch: 3 [0/23454 (0%)]\tLoss: 12.735022\n",
            "Train Epoch: 3 [2560/23454 (11%)]\tLoss: 12.519118\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-22cb8aea56b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                        \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrms_optimiser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                        \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHyperparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                        using_gradient_clipping=True)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_allocated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-171-d7fde51405a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, loss_function, optimiser, hp, using_gradient_clipping)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0;31m#woah we gotta do this to do backprop!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_debug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "2ec781f4-38d2-448e-f213-6568312fe930"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAooAAAEbCAYAAABdpqX3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "91c3f6d5-62c8-41c7-894f-1bff2f12b998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "accuracy, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)\n",
        "print(predicted_ys.shape)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "6ceb8f75-6bfa-47c0-dc8e-aaa227599d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "print(accuracy)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), y_fact_test)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5177408854166666\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.521 P=0.500 R=0.261 F1=0.343\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.000     0.000     0.000         0\n",
            "         1.0      1.000     0.521     0.685      6102\n",
            "\n",
            "    accuracy                          0.521      6102\n",
            "   macro avg      0.500     0.261     0.343      6102\n",
            "weighted avg      1.000     0.521     0.685      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[   0 2921]\n",
            " [   0 3181]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.2606522451655195, 0.521304490331039, 0.3426693956695034)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}