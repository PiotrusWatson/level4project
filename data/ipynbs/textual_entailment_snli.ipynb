{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4NbGwIC9-z",
        "colab_type": "text"
      },
      "source": [
        "##HAHA ITS TIME TO SPEND 5 HOURS DOWNLOADING THINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "eac443b6-564c-428c-bfc9-bc0aceaa79a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 11:27:12--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  4.32MB/s    in 16s     \n",
            "\n",
            "2020-04-01 11:27:28 (5.65 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "6f524269-f38a-4d6c-f6b5-9f278bc366b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 11:27:36--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-04-01 11:27:36--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-04-01 11:27:37--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.01MB/s    in 6m 29s  \n",
            "\n",
            "2020-04-01 11:34:06 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "598a6593-351b-40b6-c65f-5b6bf43fd41a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 11:34:36--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  5.46MB/s    in 0.9s    \n",
            "\n",
            "2020-04-01 11:34:37 (5.46 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "09767cb2-0928-4980-d2f3-597888ba1a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "outputId": "d0dfc27c-63c7-4241-8c43-c990d2af1c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1-baseline.git\n",
        "import sys\n",
        "sys.path.insert(1, 'fnc-1-baseline/utils')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1-baseline'...\n",
            "remote: Enumerating objects: 121, done.\u001b[K\n",
            "Receiving objects:   0% (1/121)   \rReceiving objects:   1% (2/121)   \rReceiving objects:   2% (3/121)   \rReceiving objects:   3% (4/121)   \rReceiving objects:   4% (5/121)   \rReceiving objects:   5% (7/121)   \rReceiving objects:   6% (8/121)   \rReceiving objects:   7% (9/121)   \rReceiving objects:   8% (10/121)   \rReceiving objects:   9% (11/121)   \rReceiving objects:  10% (13/121)   \rReceiving objects:  11% (14/121)   \rReceiving objects:  12% (15/121)   \rReceiving objects:  13% (16/121)   \rReceiving objects:  14% (17/121)   \rReceiving objects:  15% (19/121)   \rReceiving objects:  16% (20/121)   \rReceiving objects:  17% (21/121)   \rReceiving objects:  18% (22/121)   \rReceiving objects:  19% (23/121)   \rReceiving objects:  20% (25/121)   \rReceiving objects:  21% (26/121)   \rReceiving objects:  22% (27/121)   \rReceiving objects:  23% (28/121)   \rReceiving objects:  24% (30/121)   \rReceiving objects:  25% (31/121)   \rReceiving objects:  26% (32/121)   \rReceiving objects:  27% (33/121)   \rReceiving objects:  28% (34/121)   \rReceiving objects:  29% (36/121)   \rReceiving objects:  30% (37/121)   \rReceiving objects:  31% (38/121)   \rReceiving objects:  32% (39/121)   \rReceiving objects:  33% (40/121)   \rReceiving objects:  34% (42/121)   \rReceiving objects:  35% (43/121)   \rReceiving objects:  36% (44/121)   \rReceiving objects:  37% (45/121)   \rReceiving objects:  38% (46/121)   \rReceiving objects:  39% (48/121)   \rReceiving objects:  40% (49/121)   \rReceiving objects:  41% (50/121)   \rReceiving objects:  42% (51/121)   \rremote: Total 121 (delta 0), reused 0 (delta 0), pack-reused 121\u001b[K\n",
            "Receiving objects:  43% (53/121)   \rReceiving objects:  44% (54/121)   \rReceiving objects:  45% (55/121)   \rReceiving objects:  46% (56/121)   \rReceiving objects:  47% (57/121)   \rReceiving objects:  48% (59/121)   \rReceiving objects:  49% (60/121)   \rReceiving objects:  50% (61/121)   \rReceiving objects:  51% (62/121)   \rReceiving objects:  52% (63/121)   \rReceiving objects:  53% (65/121)   \rReceiving objects:  54% (66/121)   \rReceiving objects:  55% (67/121)   \rReceiving objects:  56% (68/121)   \rReceiving objects:  57% (69/121)   \rReceiving objects:  58% (71/121)   \rReceiving objects:  59% (72/121)   \rReceiving objects:  60% (73/121)   \rReceiving objects:  61% (74/121)   \rReceiving objects:  62% (76/121)   \rReceiving objects:  63% (77/121)   \rReceiving objects:  64% (78/121)   \rReceiving objects:  65% (79/121)   \rReceiving objects:  66% (80/121)   \rReceiving objects:  67% (82/121)   \rReceiving objects:  68% (83/121)   \rReceiving objects:  69% (84/121)   \rReceiving objects:  70% (85/121)   \rReceiving objects:  71% (86/121)   \rReceiving objects:  72% (88/121)   \rReceiving objects:  73% (89/121)   \rReceiving objects:  74% (90/121)   \rReceiving objects:  75% (91/121)   \rReceiving objects:  76% (92/121)   \rReceiving objects:  77% (94/121)   \rReceiving objects:  78% (95/121)   \rReceiving objects:  79% (96/121)   \rReceiving objects:  80% (97/121)   \rReceiving objects:  81% (99/121)   \rReceiving objects:  82% (100/121)   \rReceiving objects:  83% (101/121)   \rReceiving objects:  84% (102/121)   \rReceiving objects:  85% (103/121)   \rReceiving objects:  86% (105/121)   \rReceiving objects:  87% (106/121)   \rReceiving objects:  88% (107/121)   \rReceiving objects:  89% (108/121)   \rReceiving objects:  90% (109/121)   \rReceiving objects:  91% (111/121)   \rReceiving objects:  92% (112/121)   \rReceiving objects:  93% (113/121)   \rReceiving objects:  94% (114/121)   \rReceiving objects:  95% (115/121)   \rReceiving objects:  96% (117/121)   \rReceiving objects:  97% (118/121)   \rReceiving objects:  98% (119/121)   \rReceiving objects:  99% (120/121)   \rReceiving objects: 100% (121/121)   \rReceiving objects: 100% (121/121), 23.99 KiB | 6.00 MiB/s, done.\n",
            "Resolving deltas:   0% (0/63)   \rResolving deltas:   3% (2/63)   \rResolving deltas:   4% (3/63)   \rResolving deltas:   6% (4/63)   \rResolving deltas:   7% (5/63)   \rResolving deltas:  19% (12/63)   \rResolving deltas:  22% (14/63)   \rResolving deltas:  25% (16/63)   \rResolving deltas:  33% (21/63)   \rResolving deltas:  34% (22/63)   \rResolving deltas:  42% (27/63)   \rResolving deltas:  52% (33/63)   \rResolving deltas:  53% (34/63)   \rResolving deltas:  82% (52/63)   \rResolving deltas: 100% (63/63)   \rResolving deltas: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "6ee4ff32-7966-45c9-ca40-597c0438d82f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-01 11:34:45--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  6.07MB/s    in 0.9s    \n",
            "\n",
            "2020-04-01 11:34:46 (6.07 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "outputId": "9aacf385-cf51-4ac4-c68e-2058b3982775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "!pwd\n",
        "from score import report_score"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJXKPPODFqp",
        "colab_type": "text"
      },
      "source": [
        "##LOOK AT ALL THIS CODE TO IMPORT DATA GOD THERE MUST BE SOMETHING WRONG WITH ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ce8172fe-4ca3-40db-ccab-bfbe36af2078"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "d8337d45-ea3b-4609-960c-38482370cc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "7df494b4-2b3c-491a-f0ef-487067733933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"agree\": 0, \"disagree\": 1, \"discuss\": 2, \"unrelated\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "\n",
        "def split_test(facts):\n",
        "   unique = facts.drop_duplicates(\"claim_text\")\n",
        "   train_unique, val_unique = train_test_split(unique, test_size=0.1, random_state=8)\n",
        "   val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "   train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "   return train_facts, val_facts\n",
        "\n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/competition_test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/competition_test_stances.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "\n",
        "train_challenge = train_challenge.rename(columns={\"articleBody\": \"article\", \"Headline\": \"claim_text\", \"Stance\": \"cred_label\"})\n",
        "test_challenge = test_challenge.rename(columns={\"articleBody\": \"article\", \"Headline\": \"claim_text\", \"Stance\": \"cred_label\"})\n",
        "print(train_challenge.head())\n",
        "train_challenge, val_challenge = split_test(train_challenge)\n",
        "print(1 / (train_challenge.groupby(\"cred_label\").count()/len(train_challenge)))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Body ID  ... cred_label\n",
            "0        0  ...          3\n",
            "1        0  ...          3\n",
            "2        0  ...          3\n",
            "3        0  ...          3\n",
            "4        0  ...          3\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "              Body ID    article  claim_text\n",
            "cred_label                                  \n",
            "0           13.580097  13.580097   13.580097\n",
            "1           59.600533  59.600533   59.600533\n",
            "2            5.590109   5.590109    5.590109\n",
            "3            1.368556   1.368556    1.368556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "challenge_mapping = {\"agree\": 0, \"disagree\": 1, \"discuss\": 2, \"unrelated\": 3}\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None, is_folding=False):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_text\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  \n",
        "  if is_folding:\n",
        "    results = []\n",
        "    folded = KFold(n_splits=10, shuffle=True)\n",
        "    splitted_object = folded.split(unique)\n",
        "    for train_result, test_result in splitted_object:\n",
        "      train_ilocs = unique.iloc[train_result][\"claim_text\"]\n",
        "      test_ilocs = unique.iloc[test_result][\"claim_text\"]\n",
        "      results.append((facts[facts[\"claim_text\"].isin(train_ilocs)], facts[facts[\"claim_text\"].isin(test_ilocs)]))\n",
        "\n",
        "    return results\n",
        "\n",
        "  train_unique, big_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "  val_unique, test_unique = train_test_split(big_unique, test_size=0.5, random_state=8)\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_text\"].isin(test_unique[\"claim_text\"])]\n",
        "  val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "  train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "  return train_facts, test_facts, val_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts, val_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes, val_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "3b756d0f-7c49-4cbb-fd71-0faaf70e9447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>vice news we dont have a timeline on the decis...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>a schedule i narcotic along with heroin and ec...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>now do you think you were maybe talking just a...</td>\n",
              "      <td>cnn.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>made to the new yorker that marijuana is no mo...</td>\n",
              "      <td>time.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jun_27_donald-trump_white-house-criticism...</td>\n",
              "      <td>obamacare signed law cbo estimated 23 million ...</td>\n",
              "      <td>donald trump</td>\n",
              "      <td>about the affordable health care act in its da...</td>\n",
              "      <td>eugeneweekly.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4849</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama to ban guns from 42 million social secur...</td>\n",
              "      <td>bearingarms.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4850</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama is looking to ban social security recipi...</td>\n",
              "      <td>rightwingnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>main navigation recent posts obama to ban 42 m...</td>\n",
              "      <td>downtrend.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>get news like this in your facebook news feed ...</td>\n",
              "      <td>thegatewaypundit.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>to prove everyone wrong yet again this time it...</td>\n",
              "      <td>zerohedge.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...        article_source\n",
              "187            1  ...            reason.com\n",
              "188            1  ...            reason.com\n",
              "189            1  ...               cnn.com\n",
              "190            1  ...              time.com\n",
              "526            1  ...      eugeneweekly.com\n",
              "...          ...  ...                   ...\n",
              "4849           0  ...       bearingarms.com\n",
              "4850           0  ...     rightwingnews.com\n",
              "4851           0  ...         downtrend.com\n",
              "4852           0  ...  thegatewaypundit.com\n",
              "4853           0  ...         zerohedge.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Beq65oTgcBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, train_loader, test_loader, val_loader, test_data, val_data, tokeniser, batch_size):\n",
        "    self.train_loader = train_loader\n",
        "    self.test_loader = test_loader\n",
        "    self.val_loader = val_loader\n",
        "    self.test_data = test_data\n",
        "    self.val_data = val_data\n",
        "    self.batch_size = batch_size\n",
        "    self.word_embeddings_small = load_glove_embeddings(\"glove.6B.50d.txt\", tokeniser.word_to_id, 50) \n",
        "    self.word_embeddings_large = load_glove_embeddings(\"glove.6B.300d.txt\", tokeniser.word_to_id, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts4lYd83j-c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"claim_text\", \"article\"]\n",
        "big_labels = [\"claim_text\", \"article\", \"article_source\"]\n",
        "\n",
        "def get_list(panda, labels):\n",
        "  label_to_data = {}\n",
        "  for label in labels:\n",
        "    label_to_data[label] = panda[label]\n",
        "\n",
        "  x_list = convert_to_lists(label_to_data)\n",
        "  if labels[0] == \"claim_text\":\n",
        "    y_list = panda[\"cred_label\"].tolist()\n",
        "  else:\n",
        "    y_list = panda[\"Stance\"].tolist()\n",
        "  return x_list, y_list\n",
        "\n",
        "def get_loader(x, y, vocab_size, max_length, batch_size, name, training=True, drop_last=True):\n",
        "  stuff = []\n",
        "  for key in x:\n",
        "    stuff.append(torch.from_numpy(x[key]).type(torch.LongTensor))\n",
        "  stuff.append(torch.from_numpy(y).type(torch.DoubleTensor))\n",
        "  tensorset = data_utils.TensorDataset(*stuff)\n",
        "  loader = data_utils.DataLoader(tensorset, batch_size=batch_size, drop_last=drop_last, shuffle=training)\n",
        "  loader.name = name\n",
        "\n",
        "  return loader\n",
        "\n",
        "  \n",
        "def get_dataset(train, test, val, vocab_size, max_length, batch_size, labels, name):\n",
        "  is_challenge = labels[0] == \"articleBody\"\n",
        "  train_list_x, train_list_y = get_list(train, labels)\n",
        "\n",
        "  test_list_x, test_list_y = get_list(test, labels)\n",
        "  val_list_x, val_list_y = get_list(val, labels)\n",
        "\n",
        "\n",
        "\n",
        "  #tokenising various stuff, setting up numpy dictionaries :)\n",
        "  tokeniser = Tokeniser(train_list_x, vocab_size, max_length)\n",
        "  x_train = tokeniser.do_everything(train_list_x)\n",
        "  x_test = tokeniser.do_everything(test_list_x)\n",
        "  x_val = tokeniser.do_everything(val_list_x)\n",
        "  y_train = np.array(train_list_y, dtype=np.float32)\n",
        "  y_test = np.array(test_list_y, dtype=np.float32)\n",
        "  y_val = np.array(val_list_y, dtype=np.float32)\n",
        "  \n",
        "  #datasets/loaders\n",
        "  train_loader = get_loader(x_train, y_train, vocab_size, max_length, batch_size, name, True)\n",
        "  test_loader = get_loader(x_test, y_test, vocab_size, max_length, batch_size, name, False, drop_last=False)\n",
        "  val_loader = get_loader(x_val, y_val, vocab_size, max_length, batch_size, name, False)\n",
        "  return Dataset(train_loader, test_loader, val_loader, y_test, y_val, tokeniser, batch_size)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MMrKlu6_jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "outputId": "a1160aa5-473d-4780-fa9e-63e52391b61e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 100\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "\n",
        "snopes_dataset = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "fact_dataset = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "challenge_dataset = get_dataset(train_challenge, test_challenge, val_challenge, VOCAB_SIZE, MAX_LENGTH, 500, labels, \"challenge_data\")\n",
        "big_snopes = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "big_fact = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39093\n",
            "39093\n",
            "33766\n",
            "33766\n",
            "27737\n",
            "27737\n",
            "44623\n",
            "44623\n",
            "37174\n",
            "37174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "outputId": "3814d3fa-2a4f-4db3-f439-d7088ad81f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx_train = x_tokeniser.do_everything(x_train_lists)\\nx_test = x_tokeniser.do_everything(x_test_lists)\\ny_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\\ny_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "outputId": "388d11cd-6c6c-4bce-bde4-c7d89806fa1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "\"\"\"we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we_shufflin = True\\nshufflin_test = False\\n#alright lets tensordataset textual entailment stuff\\ntrain_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\\ntrain_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\\ntrain_loader.name = \"entailment_data\"\\n\\ntest_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\\n                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\\ntest_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\\ntest_loader.name = \"entailment_data\"\\n\\n\\n#POLITIFACT/SNOPES W/ SOURCES\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smeSRlk30Ccq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTdDpyN44DQa",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL ENTAILMENT MODEL CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    \n",
        "    self.embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.normaliser = torch.nn.BatchNorm1d(self.embedding_size)\n",
        "    if hp.is_lstm:\n",
        "      self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    else:\n",
        "      self.cool_lstm = torch.nn.GRU(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x[:, 0:self.hp.max_length])\n",
        "    #embedding = self.normaliser(embedding.transpose(1,2))\n",
        "    embedding = self.dropout(embedding)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    tanh_W_H = self.dropout(tanh_W_H)\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.premise_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "    self.hp = hp\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    premise_factor = self.premise_dropout(premise_factor)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    hypothesis_factor = self.hypothesis_dropout(hypothesis_factor)\n",
        "    if self.hp.use_better:\n",
        "      return better_mush(premise_factor,hypothesis_factor)\n",
        "    else:\n",
        "      return premise_factor * hypothesis_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=hp.mlp_one)\n",
        "    self.linear2 = torch.nn.Linear(hp.mlp_one, hp.mlp_two)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(hp.mlp_two, hp.num_classes)\n",
        "    self.hp = hp\n",
        "    \n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "      x = self.dropout1(x)\n",
        "    elif self.hp.use_relu:\n",
        "      x = torch.relu(self.linear1(x.reshape(self.hp.batch_size, -1)))\n",
        "      x = self.dropout1(x)\n",
        "      x = torch.relu(self.linear2(x))\n",
        "      x = self.dropout2(x)\n",
        "    else:\n",
        "      x = self.linear1(x.reshape(self.hp.batch_size, -1))\n",
        "      x = self.dropout1(x)\n",
        "      x = self.linear2(x)\n",
        "      x = self.dropout2(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    if self.hp.is_lstm:\n",
        "      return (hidden_state, cell_state)\n",
        "    else:\n",
        "      return hidden_state\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    print(word_embeddings.shape)\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout)]\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    self.dropouts[1](premise_embedding)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    self.dropouts[3](hypothesis_embedding)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    self.dropouts[4](factorised_mush)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention*premise_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpWRHhOxCjFl",
        "colab_type": "text"
      },
      "source": [
        "##EVAL SUMMARY :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUhazL34GWZ",
        "colab_type": "text"
      },
      "source": [
        "##SHEENABASELINE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_UvQQWx4IcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout)]*5\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    processed_premise = self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    premise_embedding = self.dropouts[1](premise_embedding)\n",
        "    \n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    processed_hypothesis = self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    hypothesis_embedding = self.dropouts[3](hypothesis_embedding)\n",
        "    if self.hp.use_better:\n",
        "      combined = better_mush(premise_embedding, hypothesis_embedding)\n",
        "    else:\n",
        "      combined = premise_embedding * hypothesis_embedding\n",
        "    \n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    avg = self.dropouts[4](avg)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      output = softmax(self.linear_final(avg))\n",
        "    else:\n",
        "      output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWRCDtWR4Lcq",
        "colab_type": "text"
      },
      "source": [
        "##BAD DECLARE CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMmJP6kC4Th3",
        "colab_type": "text"
      },
      "source": [
        "## GOOD DECLARE CODE???\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRhCjK84VeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(RealDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(10000, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(100, 8)\n",
        "    self.linear_almost_there = torch.nn.Linear(8, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.dropout0 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.outer_dropout)\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    lengths = self.hp.max_length - (premise == 0).sum(dim=1)\n",
        "    lengths = lengths.repeat(50, 1).transpose(0,1)\n",
        "    summed_embeddings = torch.sum(embeddings, 1)\n",
        "    mean_embeddings = torch.unsqueeze(summed_embeddings / lengths, 1) #change to accurate size of lenfgth\n",
        "    flattened_embeddings = mean_embeddings.reshape(self.hp.batch_size, -1)\n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100]).reshape(self.hp.batch_size, -1)\n",
        "    #TODO: use repeat function to get 100*100 #DONE!\n",
        "    main_embeddings = torch.cat((flattened_embeddings.repeat(1, 100), added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    attention_weights = softmax(torch.tanh(self.premise_linear(main_embeddings)))#TODO: turn into row vector\n",
        "\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis, attention_weights.unsqueeze(2))\n",
        "    \n",
        "\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    new_lengths = lengths.repeat(1, 2)\n",
        "\n",
        "    avg = torch.sum(combined, 1)/new_lengths #todo: fix padding\n",
        "    avg = self.dropout0(avg)\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    smaller = self.dropout1(smaller)\n",
        "    even_smaller = F.relu(self.linear_almost_there(smaller))\n",
        "    even_smaller = self.dropout2(even_smaller)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      output = softmax(self.linear_final(even_smaller))\n",
        "    else:\n",
        "      output = torch.sigmoid(self.linear_final(even_smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "##TRAIN/TEST/HELPERS\n",
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "# given the losses, checks if it should stop (or not :))\n",
        "# this performs early stopping -\n",
        "def should_stop(losses, train_losses, limit, threshold=-0.01):\n",
        "  shouldnt_stop = False \n",
        "  is_learning = False\n",
        "  #print(\"losses:\",losses)\n",
        "  #print(\"train_losses:\", train_losses)\n",
        "  \n",
        "  if len(losses) < limit:\n",
        "    return False \n",
        "  \n",
        "  last = losses[-1]\n",
        "  last_train = train_losses[-1]\n",
        "\n",
        "  if limit == 2:\n",
        "    #print(\"Threshold: {}, result {}\".format(threshold, last-losses[-2]))\n",
        "    return last - losses[-2] >= threshold\n",
        "  \n",
        "  for i in range(-2,- limit-1,-1):\n",
        "    shouldnt_stop = (shouldnt_stop or last - losses[i] < threshold)\n",
        "    last = losses[i]\n",
        "  return not shouldnt_stop\n",
        "def get_l2(model, filters):\n",
        "  reg_loss = None\n",
        "  for param in model.parameters():\n",
        "    if param.shape[0] in filters:\n",
        "      if reg_loss is None:\n",
        "        reg_loss = torch.sum(param**2)\n",
        "      else:\n",
        "        reg_loss = reg_loss + param.norm(2)**2\n",
        "  return reg_loss\n",
        "\n",
        "def train(model=None, \n",
        "          dataset = None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(dataset.train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "  old_models = []\n",
        "  old_optimisers = []\n",
        "  \n",
        "  \n",
        "  is_binary = hp.num_classes == 1\n",
        "  is_validating = False\n",
        "  has_stopped = False\n",
        "  has_reset = False\n",
        "  has_decreased = False\n",
        "\n",
        "  if is_binary:\n",
        "    loss_function=torch.nn.BCELoss()\n",
        "  else:\n",
        "    loss_function=torch.nn.CrossEntropyLoss(hp.weights)\n",
        "  \n",
        "  if dataset.train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif dataset.train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  elif dataset.train_loader.name == \"challenge_data\" and hp.num_classes != 4:\n",
        "      raise ValueError(\"Four classes are needed for challenge fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  \n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    if epoch > 0:\n",
        "      old_val_results = copy.copy(val_results)\n",
        "    val_results = []\n",
        "    old_model = copy.deepcopy(model.state_dict())\n",
        "    old_optimiser = copy.deepcopy(optimiser.state_dict())\n",
        "    \n",
        "    for i in range(2):\n",
        "\n",
        "      total_loss = 0\n",
        "      batch_count = 0\n",
        "      correct = 0\n",
        "      penal = 0\n",
        "      l2 = 0\n",
        "\n",
        "      if is_validating:\n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.val_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 1\n",
        "      elif has_stopped:\n",
        "        \n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.train_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 10\n",
        "      else:\n",
        "        model.train(True)\n",
        "        #print(\"im trainin friends!!\")\n",
        "        loader = dataset.train_loader\n",
        "        torch.enable_grad()\n",
        "        debug_amount = 10\n",
        "      \n",
        "      for batch_index, train_data in enumerate(loader):\n",
        "      #setting everything up\n",
        "        model.hidden_state = model.reset_for_testing(train_data[0].shape[0])\n",
        "        train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "        predicted_y, attention = model(*train_data[:-1])\n",
        "        actual_y = train_data[-1]\n",
        "        squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "        if hp.C > 0:\n",
        "          attentionT = attention.transpose(1,2)\n",
        "          identity = torch.eye(attention.size(1))\n",
        "          identity = Variable(identity.unsqueeze(0).expand(loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "          penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "        if hp.decay > 0:\n",
        "          l2 = get_l2(model, hp.filters)\n",
        "\n",
        "      #get loss, accuracy\n",
        "        if is_binary:\n",
        "          loss = loss_function(squeezed_y, actual_y.double())\n",
        "          loss += hp.C * penal/loader.batch_size + hp.decay * l2\n",
        "          correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "          if is_validating:\n",
        "            val_results.append(torch.round(squeezed_y))\n",
        "          \n",
        "        else:\n",
        "          loss = loss_function(squeezed_y,actual_y.long())\n",
        "          loss += hp.C * (penal/loader.batch_size) + hp.decay * l2\n",
        "          correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "          if is_validating:\n",
        "            val_results.append(torch.argmax(squeezed_y, 1))\n",
        "        total_loss += loss.data\n",
        "\n",
        "        if using_gradient_clipping:\n",
        "          torch.nn.utils.clip_grad_norm(model.parameters(), hp.grad_clip_amount)\n",
        "      \n",
        "      #cleaning up regularisation\n",
        "        if hp.C > 0:\n",
        "          del(penal)\n",
        "          del(identity)\n",
        "          del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "        optimiser.zero_grad()\n",
        "      #makin sure we dont learn if validation/early stopping is on\n",
        "        if not is_validating and not has_stopped:\n",
        "          loss.backward()\n",
        "          optimiser.step()\n",
        "        \n",
        "      #PRINT ZONE BABY\n",
        "        if hp.is_debug and batch_index % debug_amount == 0:\n",
        "          print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, ISvAL: {}, HasStopped: {}\".format(\n",
        "              epoch, batch_index * len(train_data[0]), len(loader.dataset),\n",
        "              100. * batch_index / len(loader), loss.item(), is_validating, has_stopped\n",
        "          ))\n",
        "\n",
        "        \n",
        "        batch_count += 1\n",
        "      \n",
        "        free_data(train_data)\n",
        "      \n",
        "      correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "      accuracy = correct_but_numpy / float(batch_count * loader.batch_size)\n",
        "\n",
        "      #either recording validation loss or not depending :)\n",
        "      if (not is_validating):\n",
        "        losses.append(total_loss/batch_count)\n",
        "        accuracies.append(accuracy)\n",
        "      else:\n",
        "        val_losses.append(total_loss/batch_count)\n",
        "        val_accuracies.append(accuracy)\n",
        "      \n",
        "      #oh boy lets deal with some crap\n",
        "      if not has_decreased:\n",
        "        has_decreased = not (should_stop(val_losses, losses, 2, hp.early_threshold)) and len(val_losses) > 1\n",
        "      if hp.use_early_stopping and not has_stopped:\n",
        "        has_stopped = should_stop(val_losses,losses, hp.early_stopping, hp.early_threshold) and has_decreased\n",
        "        if has_stopped and not has_reset:\n",
        "          print(\"resetting model HERE\")\n",
        "          model.load_state_dict(old_model)\n",
        "          optimiser.load_state_dict(old_optimiser)\n",
        "          val_results = old_val_results\n",
        "          model.eval()\n",
        "          #losses[-1] = losses[-2]\n",
        "          #val_losses[-1] = val_losses[-2]\n",
        "          has_reset = True\n",
        "          \n",
        "      print(\"Average loss is:\",total_loss/batch_count, \"while validation_status:\", is_validating, \"and stopping_status\", has_stopped)\n",
        "      print(\"Accuracy of the model\", accuracy)\n",
        "     # print(\"batch count???\", batch_count)\n",
        "\n",
        "\n",
        "\n",
        "      is_validating = not is_validating\n",
        "  return losses, val_losses, accuracies, val_accuracies, torch.cat(val_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, val_losses, accuracies, val_accuracies, title=\"sup nerds\"):\n",
        "\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "  \n",
        "  ax1.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Train Accuracy\")\n",
        "  ax1.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax1.plot(range(1, epochs+1), val_accuracies, scalex=True, scaley=True, label=\"Val Accuracy\")\n",
        "  ax1.annotate(str(val_accuracies[-1]), xy=(epochs,val_accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  ax2.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Train Loss\")\n",
        "  ax2.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax2.plot(range(1, epochs+1), val_losses,scalex=True, scaley=True, label=\"Val Loss\")\n",
        "  ax2.annotate(str(val_losses[-1]), xy=(epochs,val_losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  ax1.legend()\n",
        "  ax2.legend()\n",
        "\n",
        "  ax1.set_xlabel(\"Epochs\", fontsize=16)\n",
        "  ax1.set_ylabel(\"Accuracy\", fontsize=16)\n",
        "  ax2.set_xlabel(\"Epochs\", fontsize=16)\n",
        "  ax2.set_ylabel(\"Loss\", fontsize=16)\n",
        "  plt.title(title)\n",
        "  fig.tight_layout()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwADakVSwJat",
        "colab_type": "text"
      },
      "source": [
        "NEW FUNCTIONS TO AUTOMATE THE RUNNING OF LOTS OF DATASETS/MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2DLo4OoUO4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels, is_binary):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  LABELS = ['agree', 'disagree', 'discuss', 'unrelated']\n",
        "  if (is_binary):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "    challenge_score = 0\n",
        "  else:\n",
        "    auc_full = 0\n",
        "    challenge_score = report_score([LABELS[int(e)] for e in true_labels], [LABELS[int(e)] for e in predictions])\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f Chal=%0.3f\" % (description,accuracy,precision,recall,f1, auc_full, challenge_score))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmSdvMewHrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model, dataset, hp, is_plot=True):\n",
        "  if hp.big_gloves:\n",
        "    runnable_model = model(hp, dataset.word_embeddings_large).cuda()\n",
        "  else:\n",
        "    runnable_model = model(hp, dataset.word_embeddings_small).cuda()\n",
        "  if hp.num_classes == 1:\n",
        "    optimiser = torch.optim.Adam(runnable_model.parameters(), lr=hp.lr)\n",
        "  else:\n",
        "    optimiser = torch.optim.Adagrad(runnable_model.parameters(), lr=hp.lr)\n",
        "  losses, val_losses, accuracies, val_accuracies, val_results = train(model=runnable_model,\n",
        "                       dataset = dataset,\n",
        "                       optimiser = optimiser,\n",
        "                       hp = hp,\n",
        "                       using_gradient_clipping=hp.grad_clip)\n",
        "  if is_plot:\n",
        "    plot_stuff(hp.epochs, losses,val_losses, accuracies, val_accuracies)\n",
        "  torch.cuda.empty_cache()\n",
        "  evaluation_summary(\"VALIDATION\", val_results.cpu().detach() ,dataset.val_data[:len(val_results)], hp.num_classes==1)\n",
        "  check_loader = dataset.test_loader\n",
        "\n",
        "  predicted_ys = batch_wise_evaluate(runnable_model, \n",
        "         check_loader,\n",
        "         hp)\n",
        "\n",
        "  return predicted_ys, runnable_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_results(model_name, dataset_name, predictions, true_labels):\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(predictions.shape) == 1):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  return {\"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc_full}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oMDNooNrMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_to_dict(results):\n",
        "  big_results = {\"model_name\": [],\n",
        "                 \"dataset_name\": [],\n",
        "                \"precision\": [],\n",
        "                 \"recall\": [],\n",
        "                 \"accuracy\": [],\n",
        "                 \"f1\": [],\n",
        "                 \"auc\": []}\n",
        "  for result in results:\n",
        "    for key in result:\n",
        "      big_results[key].append(result[key])\n",
        "\n",
        "  return pd.DataFrame.from_dict(big_results)\n",
        "\n",
        "def process_results(big_results):\n",
        "  return (big_results[\"model_name\"][0], big_results[\"dataset_name\"][0], big_results.mean(), big_results.std())\n",
        "  \n",
        "  \n",
        "def get_avgs(some_results):\n",
        "  avg_results = {\"model_name\": some_results[0][\"model_name\"],\n",
        "                 \"dataset_name\": some_results[0][\"dataset_name\"],\n",
        "                \"precision\": 0.0,\n",
        "                 \"recall\": 0.0,\n",
        "                 \"accuracy\": 0.0,\n",
        "                 \"f1\": 0.0,\n",
        "                 \"auc\": 0.0}\n",
        "  for result in some_results:\n",
        "    for key in result:\n",
        "      if type(result[key]) is float:\n",
        "        avg_results[key] += result[key]\n",
        "  \n",
        "  for key in avg_results:\n",
        "    if(type(avg_results[key] is float)):\n",
        "      avg_results[key] /= len(some_results)\n",
        "  \n",
        "  return avg_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "##RUNNING THE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datasets = {\n",
        "    \"politifact\": fact_dataset,\n",
        "    \"snopes\": snopes_dataset,\n",
        "    \"challenge\": challenge_dataset\n",
        "}\n",
        "models = {\n",
        "    \"my_model\": TextualEntailmentModel,\n",
        "    #\"my_model_better\": TextualEntailmentModel,\n",
        "    \"sheena_model\": BaselineSentenceEntailment,\n",
        "    #\"sheena_model_better\": BaselineSentenceEntailment,\n",
        "    \"real_declare\": RealDeclare\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N1ykUhFf7BCH",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  is_lstm = False\n",
        "  batch_size = datasets[\"snopes\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 50\n",
        "  mlp_one = 50\n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout = 0.5\n",
        "  outer_dropout = 0.5\n",
        "  C = 2\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.0001\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 1\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.00005\n",
        "  use_better=True\n",
        "  big_gloves=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3DuwQLD_iln",
        "colab_type": "code",
        "outputId": "3ef08754-00cd-45b2-f353-62c0325b74b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters_snopes)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([39093, 50])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:143: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss is: tensor(7.0179, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5014876033057851\n",
            "Average loss is: tensor(7.0200, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "Running EPOCH: 2\n",
            "Average loss is: tensor(7.0179, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.49553719008264463\n",
            "Average loss is: tensor(7.0196, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.442\n",
            "Running EPOCH: 3\n",
            "Average loss is: tensor(7.0178, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.502809917355372\n",
            "Average loss is: tensor(7.0182, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.442\n",
            "Running EPOCH: 4\n",
            "Average loss is: tensor(7.0054, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.5717355371900826\n",
            "Average loss is: tensor(6.9726, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6366666666666667\n",
            "Running EPOCH: 5\n",
            "Average loss is: tensor(6.9688, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6428099173553719\n",
            "Average loss is: tensor(6.9442, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6586666666666666\n",
            "Running EPOCH: 6\n",
            "Average loss is: tensor(6.9391, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6794214876033058\n",
            "Average loss is: tensor(6.9270, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.67\n",
            "Running EPOCH: 7\n",
            "Average loss is: tensor(6.8999, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.7207438016528925\n",
            "resetting model HERE\n",
            "Average loss is: tensor(6.9349, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6693333333333333\n",
            "Running EPOCH: 8\n",
            "Average loss is: tensor(6.8641, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.7296694214876033\n",
            "Average loss is: tensor(6.9270, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.67\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: VALIDATION\n",
            "Classifier 'VALIDATION' has Acc=0.670 P=0.662 R=0.665 F1=0.663 AUC=0.662 Chal=0.000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.728     0.695     0.711       876\n",
            "         1.0      0.597     0.635     0.615       624\n",
            "\n",
            "    accuracy                          0.670      1500\n",
            "   macro avg      0.662     0.665     0.663      1500\n",
            "weighted avg      0.673     0.670     0.671      1500\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[609 228]\n",
            " [267 396]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApYAAAEbCAYAAABgNMSRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3yUVfb48c9JJ5RAAoQSICC9lwAK\nFhAR26pUARv6tbA/RdHVXRVWseC6inXBXlCBoKhYUEBQ3FWRXgRCh0ACBDCBUEPa+f3xTOIYE5gZ\nJv28X695MfPcMmfCKCf3PvdeUVWMMcYYY4w5WwGlHYAxxhhjjKkYLLE0xhhjjDF+YYmlMcYYY4zx\nC0ssjTHGGGOMX1hiaYwxxhhj/MISS2OMMcYY4xeWWBpjjA9EZJSI/FTacRhjTFliiaUxxhhjjPEL\nSyyNMeYMRCSotGMwxpjywBJLY0yJE5F/iMgeETkqIptFpJ/r+lQRecqtXh8RSXZ7nSgiD4tIgogc\nEpH3RCSsiPcYJSI/icgkV92dInK5W3mEiLwjIvtcsTwlIoFubX8WkRdFJBWYICJRIvKliBwRkWXA\nOW59iavuAVf5OhFp7/+fnDHGlG32W7gxpkSJSCvgbqC7qu4VkVgg0IsurgcGAMeBr4DxrkdhegLv\nA7WBO4B3RKShOmfZTgUOAM2BqsAcIAl4w63tTCAaCAbeAzKA+kBTYD6w01X3UuBCoCWQDrQGDnvx\nmYwxpkKwEUtjTEnLAUKBtiISrKqJqrrdi/aTVTVJVdOAicCI09TdpapvqWoOToJZH4gWkWjgCmCs\nqh5X1QPAi8Bwt7Z7VfU/qpoNZAKDgUdd9de7+suTBVTHSShFVTeq6j4vPpMxxlQIllgaY0qUqm4D\nxgITgAMiMlNEGnjRRZLb813A6dqmuL3vCdfTakATnFHIfSJyWEQO44xU1i3ifergzPAUfO+8vr8H\nJgNTcD7TmyJSw+NPZIwxFYQllsaYEqeqM1T1fJwET4F/u4qOA+FuVesV0ryR2/PGwF4fQkgCTgG1\nVbWm61FDVdu5h+n2/CCQXch7/15Z9RVV7Qa0xZkSf9CHuIwxplyzxNIYU6JEpJWIXCwioTj3LJ4E\ncl3Fa4ArRCRSROrhjGwWdJeIxIhIJDAO+MjbGFzT1N8Cz4tIDREJEJFzROSiIurnAJ/hLOIJF5G2\nwM1un6m7iPQUkWCc5DjD7TMZY0ylYYmlMaakhQLPAL/hTFXXBR52lX0IrAUScRK/wpLGGa6yHcB2\n4KlC6njiJiAESAAOAZ/g3INZlLtxptFTcBb+vOdWVgN4y9XPLiAVeM7HuIwxptwSZ3GkMcaUfSKS\nCNymqgtLOxZjjDF/ZiOWxhhjjDHGLyyxNMYYY4wxfmFT4cYYY4wxxi9sxNIYY4wxxvhFhT7SsXbt\n2hobG1vaYZgKJj09naQkZ5/sU6dOHVfVau7lIvIi0Nf1Mhyoq6o1RaQz8BrOCuIcYKKqfuRqczEw\nCWeV8krg/1wnviAifYCXcDb0/k1VL7LvtilOK1eu/E1V65R2HMaY8qdCJ5axsbGsWLGitMMwFUhO\nTg4tW7YkISGBmJgYQkNDA0Skraom5NVR1fvynovIGKCL6+UJ4CZV3eo6aWaliMwHjuAcD9hPVbeI\nyBM4eyS+IyI1gVeBy1R1t4jUBftum+IlIrvOXMsYY/7MpsKN8cKyZcto3rw5zZo1IyQkBCANuOY0\nTUYA8QCqukVVt7qe7wUO4BwVGAVkquoWV5sFOOdSA4wEPlPV3a52B/z8kYwxxhi/scTSGC/s2bOH\nRo3cT/UjE2hYWF0RaQI0Bb4vpKwHzrT3dpyNwoNEJM5VPITfjw5sCdQSkR9EZKWI3OSXD2KMMcYU\nA0ssjSk+w4FPXMcB5hOR+jgnzNyiqrnqbM0wHHhRRJYBR3HuwQTndpVuwJXAAOCfItKypD6AMcYY\n440KfY9lYbKyskhOTiYjI6O0QzEeCAsLIyYmhuDg4NIOBYCGDRvmL9xxCQH2FFF9OHCX+wURqQF8\nDYxT1SV511X1F+ACV51LcUYqAZKBVFU9DhwXkf8BnfzwUYwxxhi/q3SJZXJyMtWrVyc2NhYRKe1w\nzGmoKqmpqSQnJ9O0adPSDgeA7t27s3XrVnbu3EnDhg0BIoEvC9YTkdZALeAXt2shwGzgA1X9pED9\nuqp6QERCgX8AE11FXwCTRSQIJ4ntCbzo/09mjDHGnL1KNxWekZFBVFSUJZXlgIgQFRVVpkaXg4KC\nmDx5MgMGDKBNmzYAaaq6QUSmiMgOEVkjImuAtcA2/eMJBMOAPsC/ReSkiGwWkc6ubYhWi8gpIB1I\nUtXvAVR1IzAP+BVYBrytqutL7AMbY4wxXqh0I5aAJZXlSFn8u7riiiu44oorABCRFABVzZ/yFpFA\nnOnx/yvQNA34FrgCZ+TxZVVd47pnsk+BbYhqquphV9/PAc8V88cyxhhjzlqlTCyNORNVZeuBY3y7\nIYXezWvTpXEtb5r3A7arasG9AK/BmQZXYImI1BSR+m7bDKGqe0Ukbxuiw14HvvJ9OLoPAkN+fwSF\n/PF1YAgEBkNQ6O/PA92fh7jKXNeDQrwOwxhjTOVkiWUJS01NpV+/fgCkpKQQGBhInTrOARfLli3L\n2xuxUCtWrOCDDz7glVde8eo916xZQ5cuXZg7dy6XXXaZ78FXcDm5yspdh1iQkMK3CfvZlXoCgMCA\nAG8Ty+G49q4soCHgvvIn2XVtX96FAtsQ/YGI3AHcAdC4cePC33ltPOz+pfAyXwVXhWp13R7RUNXt\ned71qnUhOMy/722MMaZcscSyhEVFRbFmzRoAJkyYQLVq1XjggQfyy7OzswkKKvyvJS4ujri4uELL\nTic+Pp7zzz+f+Pj4Yk0sc3JyCAwMLLb+i8PJzBx+3HqQBQn7+W7TAdKOZxISGMB550Rx+wXN6N82\nmuganidLrgU6VwMPexuL2zZEN6tqbsFyVX0TeBMgLi5OC5YDcOs8yM2BnCzIyfzjI9v9dRbknPr9\nefapItpkwMnDcGy/8/htKyT+DCfTCv8QoRFuCWcdVxLq+rNaNNRsBHXbePujMcYYU05YYlkGjBo1\nirCwMFavXk3v3r0ZPnw49957LxkZGVSpUoX33nuPVq1a8cMPPzBp0iTmzJnDhAkT2L17Nzt27GD3\n7t2MHTuWe+655099qyqzZs1iwYIFXHDBBWRkZBAW5iRK//73v5k2bRoBAQFcfvnlPPPMM2zbto3R\no0dz8OBBAgMDmTVrFklJSfnvC3D33XcTFxfHqFGjiI2N5brrrmPBggX8/e9/5+jRo7z55ptkZmbS\nvHlzPvzwQ8LDw9m/fz+jR49mx44dALz22mvMmzePyMhIxo4dC8C4ceOoW7cu9957b7H+vNOOZ/Ld\nxv18m7CfH7ceJCMrl+phQVzcui7920ZzUcs6VA/zeXujy4FVqrq/kLI9/L7xOUCM61qR2xB56x+f\n/ErCviMoTt6p6nrgfBfyONcUCEY1GCUc1bxWgKsNgAABAUKgiPNnOISGZ1OLI0TqYWrpISJzD1NL\nD1MzN42aJw8RcewwEbmJROQcokru8T/EeODaj6jb2UbOjTGmIqrUieXjX20gYe8Rv/bZtkENHvtL\nO6/bJScns3jxYgIDAzly5Ag//vgjQUFBLFy4kEceeYRPP/30T202bdrEokWLOHr0KK1ateKvf/3r\nn/Z7XLx4MU2bNuWcc86hT58+fP311wwePJi5c+fyxRdfsHTpUsLDw0lLc0agrr/+eh566CEGDhxI\nRkYGubm5Bfdt/JOoqChWrVoFOFP9t99+OwDjx4/nnXfeYcyYMdxzzz1cdNFFzJ49m5ycHI4dO0aD\nBg0YNGgQY8eOJTc3l5kzZ7Js2TKvf3ae2JV6nAUJTjK5IjGNXIX6EWFcF9eI/m3r0aNpJCFBftkk\nIf8Ix0J8CdwtIjNxFu+kq+q+021D5K2I8GBqVwtBRMhb9uSsfxJE+MM1cV1zf80f6jh95KqSq0pO\nrpKTS/7zUxpOcm40u3IVVchxXf+9rvM8MCeDiNzD1MpJ498ZT7Dk81epVbUbF7SoczYf1RhjTBlU\nqRPLsmTo0KH508jp6encfPPNbN26FREhKyur0DZXXnkloaGhhIaGUrduXfbv309MTMwf6sTHxzN8\n+HAAhg8fzgcffMDgwYNZuHAht9xyC+Hh4QBERkZy9OhR9uzZw8CBAwHyRzbP5Lrrrst/vn79esaP\nH8/hw4c5duwYAwYMAOD777/ngw8+ACAwMJCIiAgiIiKIiopi9erV7N+/ny5duhAVFeXpj+y0VJV1\ne9L5dsN+FiTsZ/P+owC0rledu/s259J29WjXoIZfV52LSFWgP3Cn27XRrnheB77BWRG+DTgB3OKq\nNgy4EIgSkVGua6NUdY23MTxyRdmeZj46cxX9Ns2h27s/M/ayDtx5YbMyufLfGGOMbyp1YunLyGJx\nqVq1av7zf/7zn/Tt25fZs2eTmJhInz59Cm0TGhqa/zwwMJDs7Ow/lOfk5PDpp5/yxRdfMHHixPwN\nx48ePepVbEFBQeTm/n7LX8F9Jd1jHzVqFJ9//jmdOnVi6tSp/PDDD6ft+7bbbmPq1KmkpKRw6623\nehVXYRL2HiF+2W4WJOwn5UgGAQLdYyP551VtubRtNI0iw8/6PYriOh0nqsC1192eKwVO4nFdnwZM\nK7bAypDqcdfBpo+5r+lu/jU3mHXJ6Tw7pCNVQyv1/4qMMabCqHQbpJcH6enpeae6MHXqVJ/7+e67\n7+jYsSNJSUkkJiaya9cuBg8ezOzZs+nfvz/vvfceJ044K5/T0tKoXr06MTExfP755wCcOnWKEydO\n0KRJExISEjh16hSHDx/mu+++K/I9jx49Sv369cnKymL69On51/v168drr70GOAlveno6AAMHDmTe\nvHksX748f3TTV3sOn+S6N3/hk5XJdGoUwfNDO7FyfH8+uvM8/u/8psWaVBoPNb0IqkRyR+RaHr68\nNXPX72Pgqz+z87fjZ25rjDGmzLPEsgz6+9//zsMPP0yXLl3+NArpjfj4+Pxp7TyDBw/OXx1+9dVX\nExcXR+fOnZk0aRIAH374Ia+88godO3akV69epKSk0KhRI4YNG0b79u0ZNmwYXbp0KfI9n3zySXr2\n7Env3r1p3bp1/vWXX36ZRYsW0aFDB7p160ZCQgIAISEh9O3bl2HDhp3VivLcXOWBj9eSm6vMH3sh\nb9wYx+BuMdSqanswlimBwdD2GmTzXO48rz4f3NqTg0dPcfXkn/h+U2HrnYwxxpQn8scT5yqWuLg4\nXbFixR+ubdy4Me8oPlMG5Obm0rVrV2bNmkWLFi0KrePJ39nbP+7gqa838uzgjgzr3ui0df1JRFaq\nqvd7QJ2lwr7b5cbO/8H7f4GhU6HdQJLSTjB62koS9h1hbL+WjLm4OQEBdt9laSqt77UxpvyzEUtT\nahISEmjevDn9+vUrMqn0xOaUozw7fzP920YzNC7mzA1M6WrS29nTcv1nADSKDOfTv/ZiYOeGvLhw\nC3d8uJIjGYUvWDPGGFO22R3zptS0bds2f19LX53KzmHsR2uoERbEvwZ1sBXG5UFAILS9Fla9D6eO\nQmh1woIDeX5YJzrGRPDU1xu5dvLPvHlTN5rXrV7a0RpjjPGCjViacu3FBVvZuO8I/x7ckdrVQs/c\nwJQN7Qc5p/psnpt/SUQY1bsp02/ryZGMLK6Z/DPz1u87TSfGGGPKGkssTbm1bGcab/xvOyN6NKZf\nm+jSDsd4I6YH1IiB9X/e+L9nsyjmjLmAFtHVGT1tFc/O20RObsW9F9wYYyoSSyxNuXQ0I4v7P15D\n48hwxl9pi7HKnYAAaHctbPsOTh76U3G9iDA+uvNcRvRoxKs/bOeWqcs5fCKzFAI1xhjjDUssTbn0\n+FcJ7D18kheGdbbNtcur9oMhNws2zim0ODQokH8N6si/BnVgyfZU/jL5J78fwWqMMca/LLEsYX37\n9mX+/Pl/uPbSSy/x17/+tcg2ffr0oaitZX777TeCg4N5/fXXCy2viOat38cnK5O5q29zujWpVdrh\nGF816AK1YmHDZ6etNqJHY2beeS6Z2bkMeu1nvlizp2TiM8YY4zVLLEvYiBEjmDlz5h+uzZw5kxEj\nRvjU36xZszj33HOJj4/3R3hFOpuN2v3pwNEMHv5sHR0aRnBPP9+3KDJlgAi0GwQ7/gvHfztt1a6N\na/HVmPPp2LAm985cw1NzEsjOyT1tG2OMMSWvxBNLEblMRDaLyDYReaiQ8hdFZI3rsUVEDruV3Swi\nW12Pm0s2cv8YMmQIX3/9NZmZzv1iiYmJ7N27lwsuuIC//vWvxMXF0a5dOx577DGP+ouPj+f5559n\nz549JCcn51//4IMP6NixI506deLGG28EYP/+/QwcOJBOnTrRqVMnFi9eTGJiIu3bt89vN2nSJCZM\nmAA4I6Vjx44lLi6Ol19+ma+++oqePXvSpUsXLrnkEvbvd05KOXbsGLfccgsdOnSgY8eOfPrpp7z7\n7ruMHTs2v9+33nqL++6776x+dqrKPz75lROZObx4XSeCA+33onKv/WDQHEj44oxV61YPY/rtPRnV\nK5a3f9rJje8sI/XYqRII0hhjjKdK9OY0EQkEpgD9gWRguYh8qaoJeXVU9T63+mOALq7nkcBjQByg\nwEpX2z/f+e+puQ9ByjqfmxeqXge4/JkiiyMjI+nRowdz587lmmuuYebMmQwbNgwRYeLEiURGRpKT\nk0O/fv349ddf6dixY5F9JSUlsW/fPnr06MGwYcP46KOP+Nvf/saGDRt46qmnWLx4MbVr1yYtLQ2A\ne+65h4suuojZs2eTk5PDsWPHOHTo9D++zMzM/Gn4Q4cOsWTJEkSEt99+m2effZbnn3+eJ598koiI\nCNatW5dfLzg4mIkTJ/Lcc88RHBzMe++9xxtvvOHtT/MPZizbzaLNB3n86na2v2FFEd0OareEDbOh\n+/+dsXpwYAATrm5Hh4YRPDJ7Hde++jML7ruIsGDfjwM1xhjjPyU95NMD2KaqO1Q1E5gJXHOa+iOA\nvDneAcACVU1zJZMLgMuKNdpi4j4d7j4N/vHHH9O1a1e6dOnChg0b8s/TLspHH33EsGHDABg+fHj+\ndPj333/P0KFDqV27NuAks3nX8+7lDAwMJCIi4oyxXnfddfnPk5OTGTBgAB06dOC5555jw4YNACxc\nuJC77rorv16tWrWoVq0aF198MXPmzGHTpk1kZWXRoUOHM/9wirDj4DGemrORC1rU5sZzm/jcjylj\nRJxRy8Sf4Ijne1YO7hbD6zd2IyntpN1zaYwxZUhJL6dtCCS5vU4GehZWUUSaAE2B70/TtuFZRXOa\nkcXidM0113DfffexatUqTpw4Qbdu3di5cyeTJk1i+fLl1KpVi1GjRpGRkXHafuLj40lJSWH69OkA\n7N27l61bt3oVS1BQELm5v9+rVvA9q1atmv98zJgx3H///Vx99dX88MMP+VPmRbntttt4+umnad26\nNbfccotXcblTVe77eC0hQQE8N6STnSNd0bQbBD/8y5kOP3e0x836tKxDq+jqTF28i2FxjezUJWOM\nKQPK8k1qw4FPVDXHm0YicoeIrBCRFQcPHiym0M5OtWrV6Nu3L7feemv+aOWRI0eoWrUqERER7N+/\nn7lz5562jy1btnDs2DH27NlDYmIiiYmJPPzww8THx3PxxRcza9YsUlNTAfKnwvv168drr70GQE5O\nDunp6URHR3PgwAFSU1M5deoUc+YUvvULQHp6Og0bOrn8+++/n3+9f//+TJkyJf913vR6z549SUpK\nYsaMGT4vTgI4eiqbtUmHmTiwPfUiwnzux5RRdVpCdPszrg4vSES4uVcsG/cdYXmi73fEGGOM8Z+S\nTiz3AI3cXse4rhVmOL9Pg3vcVlXfVNU4VY2rU6fOWYZbfEaMGMHatWvzE65OnTrRpUsXWrduzciR\nI+ndu/dp28fHxzNw4MA/XBs8eDDx8fG0a9eOcePGcdFFF9GpUyfuv/9+AF5++WUWLVpEhw4d6Nat\nGwkJCQQHB/Poo4/So0cP+vfvT+vWrYt8zwkTJjB06FC6deuWP80OMH78eA4dOkT79u3p1KkTixYt\nyi8bNmwYvXv3plYt37YFOpGZzdGT2VzbuQFXdWzgUx8lQURauS06WyMiR0RkbIE6IiKvuBau/Soi\nXd3Kyv3CtLPSfhAkLYXDSWeu6+baLg2oERbE+4sTiycuY4wxXhHVkjsqTUSCgC1AP5ykcDkwUlU3\nFKjXGpgHNFVXgK7FOyuBvH+MVwHdVDWtqPeLi4vTgvs/bty4kTZt7KSWknLVVVdx33330a9fP6/b\n5uQq2w4cY2/iNrp2ak9EleBiiPDsiMhKVY0rcC0Q5/vdU1V3uV2/AhgDXIFzC8jLqtrT9d1egdvC\nNJzvdpHDcIV9t8u1tJ3wSmfo/yT0vserphO/TuDdnxP56R99qR9RpZgCrFwK+14bY4wnSnTEUlWz\ngbuB+cBG4GNV3SAiT4jI1W5VhwMz1S3rdSWQT+Iko8uBJ06XVJrSdfjwYVq2bEmVKlV8SioBUtIz\nOJWdQ63w4DKZVJ5GP2C7e1Lpcg3wgTqWADVFpD4VaGGazyKbQoOuhZ4dfiY3nRdLrirTl+wuhsCM\nMcZ4o8TPwlPVb4BvClx7tMDrCUW0fRd4t9iCM35Ts2ZNtmzZ4nP7IxlZpB4/Re1qoaQfLXdbyRS8\njSNPUQvQ/L8wrTxqPwi+HQ+p2yHqHI+bNYoMp1/raGYs283dFze3rYeMMaYUleXFO8WmJKf/jfey\nc3JJPnSSsOBAoquHlnY4XhGREOBqYFYx9F3mF6adlXaue4a9XMQDMKpXLGnHM5nzq+dbFhljjPG/\nSpdYhoWFkZqaasllGaWq7Dl8kpxcJaZmGIcOpREWVq5Wgl8OrFLV/YWUFbUArUItTPNZRAw0OhfW\nz/a6ae/mUTSvW433Fyfaf9vGGFOKSnwqvLTFxMSQnJxMhRzxqQBOZGaTdjyLiCpB7DoSTFhYGDEx\nMaUdljfcN/Uv6EvgbhGZibN4J11V94nIfOBpEclbOn8p8HDxh1oGtR8Ec/8OBzZB3aJ3KChIRLj5\nvCb884sNrNp9mG5NfNuFwBhjzNmpdIllcHAwTZs2Le0wTCGS0k4w9OUfaVu/BvF3dCGwnG2ELiJV\ncY4rvdPt2mgAVX0d597iK4BtwAngFldZmojkLUyDyrwwre21MO8hZzq87iNeNR3UNYZn523m/cWJ\nllgaY0wpqXRT4aZsyslV/jZrLQDPD+tU7pJKAFU9rqpRqprudu11V1KJazX4Xap6jqp2UNUVbvXe\nVdXmrsd7pRF/mVA9Gpr0hvWfgZdT2lVDgxga14hv1u1j/5HTn1pljDGmeFhiacqEd37awbKdaTz2\nl7Y0igwv7XBOa968ebRq1YrmzZsD1CusjogME5EEEdkgIjNc1/oW2EQ9Q0SuLcnYy4X2gyF1K6Ss\n87rpTec1IUeV6Utt6yFjjCkNlliaUrdx3xEmzd/CgHbRDOlWtu+nzMnJ4a677mLu3LkkJCQARIpI\nW/c6ItIC5x7J3qraDhgLoKqLVLWzqnYGLsaZDv+2ZD9BOdDmapBAn1aHx9auSp+WdZixdDeZ2bnF\nEJwxxpjTscTSlKqMrBzu+2gNNaoE8/TADoiU7SnwZcuW0bx5c5o1a0ZISAhAGs7G5+5uB6bknZyj\nqgcK6WoIMFdVTxRrwOVR1Sho1sfZLN2HFd4394rlt2On+GadbT1kjDElzRJLU6r+PW8Tm1KO8uyQ\nDkRVK/t7Vu7Zs4dGjdx3BiKTP29m3hJoKSI/i8gSESnsFJ2iNlE34EyHH94Ne1Z53fTCFnVoVrsq\nU+38cGOMKXGWWJpS88WaPbz3cyKjesVycevo0g7Hn4KAFkAfnO2H3hKRmnmFrmMcO+AcbWoK0/pK\nCAzxaTo8IEC46bwmrEk6zJqkw8UQnDHGmKJYYmlKxaaUIzz06Tq6x9Zi3JVtSjscjzVs2JCkJPfT\nFwnhz5uZJwNfqmqWqu4EtuAkmnmGAbNVNatYgy3PqtSE5pc4q8Nzvb9XcnC3GKqGBPK+jVoaY0yJ\nssTSlLj0k1nc+eFKqoUFMWVkV4IDy8/XsHv37mzdupWdO3eSmZkJEImz8bm7z3FGKxGR2jhT4zvc\nyk+3ibrJ024QHN0LSUu9blo9LJgh3WKY8+teDh49VQzBGWOMKUz5+RfdVAi5ucr9H61hz6GTvHZ9\nV+rWKFfHNRIUFMTkyZMZMGAAbdq0AUhT1Q0i8oSIXO2qNh9IFZEEYBHwoKqmAohILM7xjf8t+ejL\nmVaXQVCYs4jHBzf1iiUrR4lfZlsPGWNMSbHE0pSoyYu28d2mA4y/sg1xsZGlHY5PrrjiCrZs2cL2\n7dsBUgBU9VFV/dL1XFX1flVt69oIfWZeW1VNVNWGqmp74ZxJaHVoOQASvoDcHK+bn1OnGhe2rMO0\nJbvIyrEftzHGlIRKd6SjKT2LNh/gxYVbuLZzA27uFQs52bD9O9i7GgKCnMUagSEQGFzEc0/qBDtb\n1ORkQU6m6+H2PDe78Oune96sDzTpVco/vUqq3SAnsUz8CZpd5HXzUb2acOvUFcxdn8LVnRoUQ4DG\nGGPcWWJpSsTu1BOMnbmGVtHVeaZfLWTR07B6mnMPXVkXHG6JZWlpcSmEVHOmw31ILPu0rEuTqHDe\nX5xoiaUxxpQASyxNsTuZmcPdHy6hn/7CxBqrCJviur2weT+4/Blo6drmMX+ksLDRwwLXcou4nn0K\nJKCQEc3gM490FvY8IAjK+KbtFVpIOLS6HDZ+CVc+7/zdeCEgQLjx3CY89fVG1u9Jp33DiGIK1Bhj\nDFhiaYqZ/raNX+In8e6hr6ktR+BwQ7jo79DlBqjZ+I+Vg8r+BummFLQfDOtmwY4foEV/r5sPjWvE\nCwu2MHVxIpOGdvJ/fMYYY/JZYmn8LyvDGWFa+T6y6ycu1AB2RV1A7cvucvYmDAgs7QhNeXLOxRAa\n4exp6UNiGVElmEFdG/LximQevrx1uTjhyRhjyitbFW78Z38CzP0HPN8KPrudU2m7mZRzHQ82iqfp\n3V84K3wtqTTeCgqFNlfBpqXGAYoAACAASURBVDnOLy0+uPm8WDKzc5m5POnMlY0xxvjMRizN2ck8\n7owkrXofkpc79yW2vopDbUZw2ecQWj2Yr0aeT0CA3adozkL7QbBmurOLQOsrvW7eIro6vZtHMW3J\nLu68sBlB5WhTfmOMKU/s/67GN3tXw1djYVIr+PJuyEiHSyfC/ZvIGvQOd/5UnfRTObxxYzciwr1b\ncGHMnzS9CKpEOr/E+Ojm82LZl57Btwn7/RiYMcYYdzZiabyzeyl88wCk/ApBVaDdQOh2MzTqmb96\n+l9fJbAsMY2XrutMm/o1SjngkiMiNYG3gfaAAreq6i9u5bWAd4FzgAxX+XpX2X3Aba5264BbVNW3\ned+KKDAY2l4Dv34MmSec1eJe6tcmmphaVZi6OJErOtQvhiCNMcbYiKXxjCr8MgWmXuGMTl4xCf62\nCQa+Bo3PzU8qv1izh3d/3smoXrFc26VhKQdd4l4G5qlqa6ATsLFA+SPAGlXtCNzkqo+INATuAeJU\ntT0QCAwvsajLi/aDIOs4bJ3vU/PAAOGm85qwbGcaG/cd8XNwxhhjwBJL44mMdPj4Rpj/iLPn5Ogf\nocftUKXmH6ptSjnCQ5+uI65JLR65ok0pBVs6RCQCuBB4B0BVM1X1cIFqbYHvXeWbgFgRiXaVBQFV\nRCQICAfKwc7xJaxJb6gW7fPZ4QDD4hoRFhzA+4sT/ReXMcaYfJZYmtPb9yu82Qc2fePcQ3ndNAj7\n8ybT6SezGP3hSqqFBfHq9V0JCap0X62mwEHgPRFZLSJvi0jVAnXWAoMARKQH0ASIUdU9wCRgN7AP\nSFfVbwu+gYjcISIrRGTFwYMHi/OzlE0BgdD2Wti6ADJ8G3GsGR7CwC4Nmb16D4eOZ/o5QGOMMSX+\nr7+IXCYim0Vkm4g8VESdYSKSICIbRGSG2/UcEVnjenxZclFXUqs+hHf6Q9ZJGPU19Lq70FNocnOV\nv328huRDJ3n1+q7UrRFWCsGWuiCgK/CaqnYBjgMFv9/PADVFZA0wBlgN5LjuvbwGJzltAFQVkRsK\nvoGqvqmqcaoaV6dOnWL8KGVY+0GQnQGb5/rcxc29YjmVnctHK2zrIWOM8bcSTSxFJBCYAlyOMy04\nQkTaFqjTAngY6K2q7YCxbsUnVbWz63F1ScVd6WSegM/vclZ7N+oJd/4ITc4rsvqURdtYuPEA469s\nQ/fYyBIMtExJBpJVdanr9Sc4iWY+VT2iqreoameceyzrADuAS4CdqnpQVbOAzwA7nLwwMT2gRgxs\n8H11eOt6NTi3WSQf/rKLnFz1Y3DGGGNKesSyB7BNVXeoaiYwE2ekxt3twBRVPQSgqgdKOMbKLXW7\nM0q5Zjpc+He4cTZUK3p07IfNB3hh4Rau7dyAm3vFllycZYyqpgBJItLKdakfkOBeR0RqikiI6+Vt\nwP9U9QjOFPi5IhIuIuJqW3DhjwEICIB218K27+DkIZ+7GdUrlj2HT7Jwo209ZIwx/lTSiWVDwH3+\nKdl1zV1LoKWI/CwiS0TkMreyMNc9ZktE5NrC3qDS34d2NjZ8Dm9cBEf2wvWfwMXjTntSzu7UE9w7\ncw2toqvzr0EdkUKmySuZMcB0EfkV6Aw8LSKjRWS0q7wNsF5ENuOM2t8L4Brl/ARYhbPVUADwZkkH\nX260HwS5WbBxjs9dXNImmgYRYbaIxxhj/Kws7mMZBLQA+gAxwP9EpINrhW0TVd0jIs2A70Vknapu\nd2+sqm/i+kc5Li7O5rk8kZ0JCx6Fpa9BTHcYOhUiYk7b5GRmDqOnrURVeePGblQJsaMaVXUNEFfg\n8utu5b/g/OJUWNvHgMeKL7oKpEFXqBXrTId3vdGnLoICA7jhvCY8O28zm1OO0qpedf/GaIwxlVRJ\nj1juARq5vY5xXXOXDHypqlmquhPYgpNo4lo9i6ruAH4AuhR3wBVeerKzN+XS16DnX2HUN2dMKlWV\ncZ+vI2HfEV4a3pkmUQUXPxtTjESg3SDY8V84/pvP3Qzv3piQoADe/yXRb6EZY0xlV9KJ5XKghYg0\ndd1rNhwouLr7c5zRSkSkNs4Izw4RqSUioW7Xe1PgHjbjpW0L4fUL4MBGZ5Ty8mcgKOSMzaYt2cVn\nq/Zwb78WXNw6+oz1jfG79oNBcyDhC5+7iKwawrWdGzB71R7ST2T5MThjjKm8SjSxVNVs4G5gPs7i\nhI9VdYOIPCEieau85wOpIpIALAIeVNVUnPvTVojIWtf1Z1TVEktf5ObAon/BtCFQvR7c8YNzNKMH\nEvYe4Yk5CfRtVYd7+7Uo1jCNKVJ0O6jdEjbMPqtubu4Vy8msHGattK2HjDHGH0r8HktV/Qb4psC1\nR92eK3C/6+FeZzHQoSRirNCO/waf3gY7FkGnEXDlC16du/zuzzsJCQzgxes6ExBQ6RfrmNIiAh2G\nwqKnIWU91GvvUzftGkTQPbYWH/yyi1t6NyXQvtPGGHNWKt3xKJXa7qXO1PeuxfCXV+Da17xKKtNP\nZPHV2r1c06UhNcPPPGVuTLHqcbtzCtTCs1vzdHOvWHannWDRJtvZzBhjzpYllpWBKvwyxVmkExQK\nty2AbjcXeorO6Xy2OplT2bmM7NG4mAI1xgtVasGFDzr3Cm9f5HM3A9rVo16NMFvEY4wxfmCJZUWn\nCp/+H8x/BFpe5txPWb+TD90o05fuplOjmrRv+Oezwo0pFT1uh5qNYcE/ITfXpy6CAwO44dzG/Lj1\nN7YdOObnAI0xpnKxxLKiS90G6z+F8+6G66ZBlZo+dbM88RDbDhzj+p42WmnKkKBQ6PcYpKyDdR/7\n3M3wHo0JCQywDdONMeYsWWJZ0aVuc/5sN9DrqW9305fuonpYEH/p2MBPgRnjJ+0GQYMu8N2TkHXS\npy5qVwvl2i4N+GhFEvvSfevDGGOMh4mliMwQkQuKOxhTDPISy8hmPneRdjyTuetSGNw1xk7YMWVP\nQAD0fxKOJMPS189cvwhjLm6BqvKf77f5MThjjKlcPB2xPBf4QUQ2iMg9IuLbfKopeanbITwKwiN9\n7uKTlUlk5uQy0qbBTVnV9ALnHuIfX4DjqT510SgynBE9GvPx8iQSfzvu5wCNMaZy8CixVNVmwBXA\nZmASsEdE3hORc4szOOMHqdsg8hyfm+fmKjOW7qZ7bC1aRtt5yqYMu+RxyDwG/3vO5y7u7tucoEDh\npYVb/BiYMcZUHh7fY6mq81V1ENAYeAboC/wsIqtFZLSIVCuuIM1ZSN0OUc19bv7LjlQSU09wfc8m\nfgzKmGJQtzV0uRGWvw1pO3zrokYYo3o15Yu1e9mUcsTPARpjTMXn9eIdVU1R1SeBXsCPQCfgVWCv\niDwnIlX9HKPx1aljcHQvRPk+Yjl96S5qhQdzWft6fgzMmGLS9xEIDIGFj/vcxeiLmlEtJIjnv7VR\nS2OM8ZbXiaWIXCwiHwM7cY5YfBEnyfwPMBr4wK8RGt/ljdr4OGJ54GgG327Yz5BuMYQF26IdUw5U\nrwe9xkDC55C8wqcuaoaHcMeFzViQsJ/Vuw/5OUBjjKnYPF0VHiUiD4jIFmAB0BQniWyoqn9T1SWq\nOg64Hbis+MI1XslbEe5jYjlrRTLZucoIO2nHlCe9xkDVuvDteOeAAB/ccn5ToqqGMOnbzX4Ozhhj\nKjZPRyz3AE8APwPnqmp3VX1PVTMK1NsE2IG7ZUXadudPH7YaynEt2ul1ThTN6tjts2ciIjVF5BMR\n2SQiG0XkvALltURktoj8KiLLRKS9p22Nl0KrQd+HYfcvsOlrn7qoFhrE/+vbnJ+3pfLztt/8HKAx\nxlRcniaWj+CMTt6iqsuLqqSqa1S1qX9CM2ctdTvUaAgh4V43/d/Wg+w5fNIW7XjuZWCeqrbGue94\nY4HyR4A1qtoRuMlV39O2xltdboLaLWHhY5CT5VMX1/dsTIOIMJ6bvxn1ceTTGGMqG0+3G3pBVe1m\no/ImdZvPC3emL9lN7Woh9G8b7eegKh4RiQAuBN4BUNVMVT1coFpb4HtX+SYgVkSiPWxrvBUY5Gw/\nlLoNVr3vUxdhwYHce0kL1iQdZuFGm4gxxhhPeHqP5Ysi8mERZR+KiO8bx5nik7rNp/sr96Wf5PtN\n+xkW14iQIDv10wNNgYPAe67tt94uZHeEtcAgABHpATQBYjxsi6vdHSKyQkRWHDx4sNg+TIXR6nJo\n0ht+eAZOHfWpi8FdY2hauyqT5m8mN9dGLY0x5kw8zRquBr4tomw+cK1/wjF+cyINTh7yKbGcuSwJ\nBVu047kgoCvwmqp2AY4DDxWo8wxQU0TWAGOA1UCOh20BUNU3VTVOVePq1KlTPJ+kIhFxjno8fhB+\nfsWnLoICA7i/f0s27z/KV7/u9XOAxhhT8XiaWDYEdhdRluwqN2VJqmvhjpeJZXZOLjOX7+bCFnVo\nFOn9vZmVVDKQrKpLXa8/wUkW86nqEdc9yp1x7rGsA+zwpK05CzHdoN0g+GUyHNnnUxdXdqhPm/o1\neGHBFrJycv0coDHGVCyeJpaHgKIylObAMf+EY/wmb6shL49z/H7TAfYfOWXngntBVVOAJBFp5brU\nD0hwr+Na+R3ienkb8D9XsnnGtuYs9XvUWcCzaKJPzQMChAcHtGRX6glmrUj2c3DGGFOxeJpYLgTG\ni8gfVnK4Xj+Cs7elKUtSt4EEQi3vVnVPX7qb6Bqh9Gtdt5gCq7DGANNF5FegM/C066jT0a7yNsB6\nEdkMXA7ce7q2JRh3xRfZFHrcAWumw37fcva+rerSrUktXvluKxlZOX4O0BhjKg5PE8t/AtWArSIy\nQ0SeFZHpwBagKjC+uAI0PkrdBrViITDY4yZJaSf439aDDO/emKBAW7TjDddWW3Gq2lFVr1XVQ6r6\nuqq+7ir/RVVbqmorVR3kvstCYW1L75NUUBc+ACHVne2HfCAiPDigFSlHMpi2ZJefgzPGmIrD0+2G\nEoHuwOdAX2Cs68/ZQA9V3VlcARofpW73+v7K+GW7EWB4j0bFE5MxpSU8Ei78G2z9Fnb816cuzm0W\nxQUtajNl0TaOZvi2N6YxxlR0Hg9LqWqiqt6kqvVVNURVG6jqKFW1X9/LGlXn1B0vEsvM7Fw+XpHE\nxa2jqR9RpRiDM6aU9LgTIho5Rz3m+rYI58EBrTh0Iot3f0r0b2zGGFNB2HxnRXR0H2Sd8Gpz9AUJ\n+/ntWCbX26IdU1EFh8HF/4SUX2H9Jz510TGmJpe1q8dbP+7g0PFMPwdojDHln8eJpYjUFZF7ReRV\nEXm3wOOd4gzSeClvRbgXieX0pbtoWLMKF7a0/RHzpKamlnYIxt86DIX6neC7JyArw6cu/nZpS45n\nZvP6f7f7OThjjCn/PD15pxWwCXgSuBO4ErgRGAVcg3O/pUdE5DIR2Swi20Sk0I2gRWSYiCSIyAYR\nmeF2/WYR2ep63Ozpe1Y6+YmlZ1PhOw4eY/H2VEb2bExggBRjYGXTW2+9xXPP/X541Lp164iJiaFu\n3brExcWRkpJSitEZvwoIcDZNT0+CZW/41EWL6OoM7NKQqYsTSUn3LTk1xpiKytMRy+eA5UA0IDjb\npVTB2Y/vBDDQk05EJBCY4mrfFhghIm0L1GkBPAz0VtV2OAuFEJFI4DGgJ9ADeExEankYf+WSuh2C\nqkD1Bh5Vj1+2m6AAYWhcTDEHVjb95z//oUqV3+8rvf/++6lZsyYvvfQS6enpPProo6UYnfG7ZhdB\n8/7wv+edE6p8cN8lLclV5T/fb/VzcMYYU755mlh2B14FTuW1U9VsVX0XmAy85GE/PYBtqrpDVTOB\nmTgjnu5uB6bkbbmiqgdc1wcAC1Q1zVW2ALjMw/etXFK3OdPgAWf+683IyuGTlclc2i6autXDSiC4\nsmfXrl20bt0agPT0dP773//y7LPPMmbMGB5//HHmz59fyhEav+v/BGQehf9N8ql5o8hwhndvzEfL\nk9iVetzPwRljTPnlaWJZDUhT1VwgHajtVrYcJ/H0REMgye11YcdBtgRaisjPIrJERC7zoi0icoeI\nrBCRFQcPHvQwrAomL7H0wLz1KRw6kcXIHt5tpF6R5ObmEuBKwn/66SdEhD59+gDQqFEjDhw4cJrW\nplyKbgudr4dlb0Kab7uljbm4OUGBwksLbdTSGGPyeJpYJgL1XM83A0Pdyq4CDvsxpiCgBdAHGAG8\nJSI1PW2sqm+6NpuOq1OnEi5EycmGQ4keH+U4fekuYqPC6XVOVPHGVYa1aNGCr7/+GoCZM2fSq1cv\nwsOdc9L37t1LZGRkaYZnikvfRyAgCL5/0qfmdWuEcXOvWD5fs4fNKUf9HJwxxpRPniaWC4D+rucv\nALe4FuBswDma7l0P+9kDuO++HeO65i4Z+FJVs1wbr2/BSTQ9aWsO74LcbI8W7mzZf5TliYcY2bMx\nAZVw0U6eBx54gJdeeonatWszY8YMxowZk1+2aNEiOnbsWIrRmWJTowH0uhvWfwp7VvrUxegLz6Fa\nSBDPf7vZz8EZY0z5FORhvYeBUABV/VhETgLXAeHAy8BbHvazHGghIk1xksLhwMgCdT7HGal8T0Rq\n40yN7wC245y/nLdg51JXXMZdqmsLFA8SyxlLdxMSGMCQbpX7pJ2RI0fSuHFjli5dSvfu3bnwwgvz\ny6Kjo7n66qtLMTpTrHrfCyveg2//CaO+BvHuF6xaVUO4/cJmvLBgC2uSDtO5kceTK8YYUyGdMbF0\nreRuDezNu6aqXwFfeftmqpotIncD84FA4F1V3SAiTwArVPVLV9mlIpIA5AAPqmqqK5YncZJTgCdU\n1bclnRWZh1sNnczM4dNVyVzeoR6RVUNKILCy7fzzz+f888//0/XHH3+8FKIxJSa0OvR5CL55ADbP\nhdZXeN3Frec3ZeriRCbN38y023oWQ5DGGFN+eDIVrsAKoIs/3lBVv1HVlqp6jqpOdF171JVUoo77\nVbWtqnZQ1Zlubd9V1eaux3v+iKfCSd0GYTWds5FP46tf93I0I5uRPeykncWLFzNnzpz816mpqYwY\nMYIOHTrwwAMPkJOTU4rRmWLXbZTzi9jCx5x7lL1ULTSI/9fnHH7a9huLt/3m//iMMaYcOWNi6VoJ\nngRULf5wzFlL3eb8I3mGKb3pS3fTvG41ejS1hSkPPfQQK1f+fo/dgw8+yDfffEPLli157bXXePrp\np0sxOlPsAoPhksfhty2w+gOfurjh3CbUjwjjuW83o6p+DtAYY8oPTxfvvAGMFRGbMy3r0naccauh\n9XvSWZt0mOt7Nka8vKesItq4cSNxcXEAZGVl8cknn/Diiy/y6aefMnHiRGbMmHGGHky51/pKaNzL\nuddy72qvm4cFB3JPvxas3n2Y7zba9lTGmMrL08SyOnAOsENE3haRJ0XkCbeH3YhWFmSddI6qO8P9\nlTOW7SY0KIBBXSrnSTsFHTt2jBo1agCwbNkyjh8/zlVXXQVA165d2b17d2mGZ0qCCAx5B6rUgmlD\nfl8E54Uh3WKIjQpn0rebyc21UUtjTOXkaWL5CNDA9bgVGAeML/AwpS1th/PnaUYsj53K5ovVe/hL\npwZEhAeXUGBlW8OGDVm7di0Ac+fOpX379tStWxeAQ4cO5e9paSq4Gg3ghs9Ac+HDgXB0v1fNgwMD\nuP/SVmxKOcpXv+49cwNjjKmAPEosVTXgDI/A4g7UeMCDFeFfrNnD8cwcRva0RTt5RowYwSOPPMKQ\nIUN44YUXuOGGG/LLVq1aRYsWLTzqR0RqisgnIrJJRDaKyHkFymuJyGwR+VVElolI+wLlgSKyWkTm\nYEpHnZZw/Sw4fhCmDYaMdK+aX9WhPq3rVefFBVvIysktpiCNMabs8nTE0pQHeYllEafuqCrTl+ym\nTf0adLH99vJNmDCBf/zjH5w6dYqHHnqI++67L79s7dq1DB069DSt/+BlYJ6qtgY6ARsLlD8CrFHV\njsBNrvru7i2kjSlpMXEw7EM4uBFmXg/ZpzxuGhAgPDigFYmpJ/hkZXIxBmmMMWWTpxukm/IgdTtU\nqweh1QotXpucTsK+Izx1bXtbtOMmMDCQcePGFVr2+eefe9SHiEQAFwKjAFQ1E8gsUK0t8IyrfJOI\nxIpItKruF5EY4EpgInC/Dx/D+FOLS+CaKTD7TvjsdhjyHgR4NjFzceu6dG1ck5cXbmVgl4aEBduE\njjGm8vBoxFJEckUk53SP4g7UeCB1+2mnwacv2UV4SCDXdG5QgkGVH+vXr2fKlCk8+eSTTJkyhQ0b\nNnjTvClwEOfEqNWuRW4Ft+haCwwCEJEeQBOco0kBXgL+DhQ5fyoid4jIChFZcfDgQW9iM77oNBwu\nfQoSvoC5/wAPtxESER4c0JqUIxnMWGoLv4wxlYunI5ZP4GyU7i4K51jFUGCqH2Myvkrd5mybUoj0\nk1l89eteBnaJoXqYLdpxl52dzahRo4iPj//DHoQiwsiRI5k6dSqBgWccdQoCugJjVHWpiLwMPAT8\n063OM8DLIrIGWAesBnJE5CrggKquFJE+Rb2Bqr4JvAkQFxdny45LQq8xcGw/LP4PVIuGix70qNl5\n50TRrUktpi3ZxS29Y22GwBhTaXiUWKrqhMKuu457/Arw7g53438nD8GJ34ocsZy9KpmMrFyut0U7\nf/L444/z8ccf88QTT3DDDTdQr149UlJSmDZtGo8//jjNmjXz5GjHZCBZVZe6Xn+Ck1jmU9UjwC0A\n4mQaO4EdwHXA1SJyBRAG1BCRaap6A6b0XfIEHDsIi56CanWck3o8MLJHY/42ay1Ld6ZxbrOo4o3R\nGGPKiLNavKOqOcCrwFj/hGN8lpq31dCfE0tVZfrS3XSKiaB9w4gSDqzsmzZtGuPHj2fcuHE0adKE\n0NBQmjRpwrhx4xg/fjwffHDm01hUNQVIEpFWrkv9gAT3Oq5V43mHDNwG/E9Vj6jqw6oao6qxwHDg\ne0sqy5CAALhmMjTvD3Pug42eLdq/smN9aoQFEb/MpsONMZWHP1aFhwJ2LmBpO81WQyt2HWLrgWNc\n37NJCQdVPuzdu5devXoVWtarVy/27vV4T8IxwHQR+RXoDDwtIqNFZLSrvA2wXkQ2A5fjrAI35UFg\nMAx7Hxp0gU9uhcSfz9gkLDiQQV1jmLsuhUPHC67jMsaYisnTxTuNC3k0F5Frce4bW1G8YZozSt0G\nEgC1Yv9UNH3JLqqHBnFVp/olH1c50KBBA37+ufBEYfHixTRo4NliJ1Vdo6pxqtpRVa9V1UOq+rqq\nvu4q/0VVW6pqK1UdpKqHCunjB1W96mw+jykmIVVh5Cyo2RjiR8D+My/uGt6jEZk5uXy66iy3Hkrd\nDv99DvasOrt+jDGmmHk6YpmIcz+Y+2Mz8Jmr/C6/R2a8k7bd+Qcv6I/Huacdz+Sb9SkM6tqQ8BDb\nXaow119/PRMnTuTJJ59kx44dnDx5kp07d/Kvf/2LiRMncuONN5Z2iKasqBoFN34GIeHw4SA4tOu0\n1VvXq0GXxjWJX7b7DwvDPJa2Ez7/fzC5u3OP51t9IX4k7PvVxw9QuMOHD/Pqq6/6tU9viUgXEXnH\n7XUfEVkjIhtE5L9FtLlYRFaJyHoReV9EglzXr3cdRLBORBaLSCfX9VauPvMeR0RkrKssUkQWiMhW\n15+1vIx/qogM8fGzvy0ibX1p60HfiX7qx6vPJ45XRGSb6++iq+t6rIj84OV7TxCRB1zPR4lIiW9t\n4op7pB/7O+ZhvXjXz+++s/yO/eHn5vr7mSgiW1wHetxToH53EcnOez8RqSMi8zx5L08Ty1sLeYwE\negGtVdU2dS5tqdsKnQb/eEUSmdm5XH+uTYMXZcKECQwZMoTHHnuMFi1aUK1aNZo3b864ceMYOnQo\njz76aGmHaMqSmo2dox+zT8K0QXA89bTVR/RozPaDx1mx608D1EU7vBu+HAOT42D9p9BzNIxZBX3H\nw66f4I0L4KMbYX/Cmfvy5O1KMbHMSwZxDhB4xXWtJs79+1erajvgT6cUiEgA8D4wXFXbA7uAm13F\nO4GLVLUD8CSu3RRUdbOqdlbVzkA34AQw29XmIeA7VW0BfEeBxXfFSVVvU1X//GWWHZcDLVyPO4DX\n/NTvKJzjpUtaLE7e4zG377ZPRKQe0N01C/bi2fTFn39uo4BGODlcG2Cm2/sGAv8Gvs27pqoHgX0i\n0vtMb+TpkY5TVfX9Ao+PVHWJawGPKU2qhe5hmZOrTFuyi55NI2kZXb2Ugiv7goKCmDFjBuvWrWPy\n5Mk88cQTTJ48mXXr1jFq1Ci6du1a2iGasia6LYz46P+3d+fhUVbn/8ffn4R9l4CyBAxaRQFZJKKI\nu23dxV1xQbCrv1awVqvW1qqtra1+W61aLVVwQ1FRrFqrVUFxAQVkX1Q2IQKKQfY14f79cU5gGCYk\nQMhMwv26rrmYedZ7njnD3DnPWWBFATx9IWwovfLhzM4taVi7Bs+UZ0zLFQWhg9DfD4fJw+CIH8LA\nyXDqHyHnwDDc0cApcPxNMPcdeOhoeL4/LP10t97OTTfdxJw5c+jatSs33BCGVJJ0g6Rxsbbk9rgs\nL9Zu/CvWJP5PUt24boCkGXH7YXFZU0kvxWVjJXWOy2+T9KSkD4AnJTUEOpvZ5BjSpcCLZrYAwMy+\nThF2DrDRzD6Lr98Ezo/bf5jQ1GQsW8eLTXQyMMfMSqqdexMSVeK/5+zomsUanwckfSrpLWDfhHXd\nJb0raYKkNyS1lHSIpI8TtsmTNDU+f0dSfnx+aqyFnSzp7bisvqTBClPBTpTUe0exJdky6K2kvvGz\nmCzpybhsm1qwkpq0Mt7frbFsTJM0SEo5nlZv4AkLxgJNJLUEioFlZQUt6ZZYm/Y+0D4uuwDIJ7Rl\nnyTpDEkvJezzPUkjSt6HpL/Fcvq2pOZx+YGSXo+fzXuSDinndbwLODae9xeS6kgaolArPlHSifH4\n/SS9LGkk8LakBgnbTZF0fkK8d8bPYqyk/VKc839A63jOY5Ouz8nxvFNj2agdl2/32aS4bnWBq4E7\nzGwzbPcduwZ4AUj+4Ef8sQAAIABJREFU3r0EXFbmlTKzMh/AwYS//lKtOw44qDzHqexH9+7dba+w\ncrHZ7xqZfTRom8VvzVhi+9/4qr06eVGaAqv6hg8fbllZWaWuB8abl+2918z/mN3WxOyJc82KNpa6\n2W9GTLWDbnnNvl2zIfUGKxaZ/ed6szuamd2eY/bqdWbLC3Z87jWFZm/dYXZnK7PfNTYb/kOzpZ/v\n0tuYN2+edezYcctr4DNCLZ8IFRCvxv/r84AioGvYjOeAy+PzRUDt+LxJ/Pd+4Hfx+UmEKU0BbgMm\nAHXj6xOBF2zr78q9wIPAO3G7vpb0HYixfQHkx9f3AVNTbHc98EiK5YOBnye8Xp507OXJ+yTtfx4h\nmc0m1AQtBy4AagIfAs3jdhcDg+PzSUC7+PxG4Dfx+TuEH/7mwMKEbZrGf/+YcJ2bxM+nPiHhmlTK\no0lSvB3jfs2Sjv0YcEHCdqt39P4S943PnwTOis9/Cvw0Pn8VOCZhu7dLPquyHoTa5KlAPaARMBu4\nPvFaJXxOsxKu9dMJsRhwWXx+K/BAQhwHxedHEkbhgJAwpbqOw+P6E4BXE2L8ZcLnegiwgDBcXD/C\n8HMl1/fPwL0J++2TEF9JrH8pKQtJ1yEPmJbw+jFCGasTy8nBcfkTwLVlfDZbrlt8XQjcQugj89+E\na9IaeJfwvU8uG61J8R1LfpS3mvZewtApqdq5nEmYqs47HKTLlh7h284R/sSYL9ivUW2+3zHVH0LO\nud12yOlw1n3htvW/fwbnPByGJ0rSp0dbnhz7BSMmfkn/Xu22rlj1FXxwL4wfDJuLoNvlcOwvw+32\nstRrCif/Fo76f/Dh3+HjQTBtOHS+JNRsNj1gd95ZI8IEGBPj6waEW5oLgHlmNikun0D48QOYQqgR\neYlQswFwDFtrEUdKypHUKK572czWxectSahZI4yx3J1Qq1gXGCNprG2tncTMTNIlwN9ibc3/CLVh\nW8RapB/EOBKX1wLOBm5O9ebjsctqFHsc8IyFu3aLYg0VhGSvE/BmrMjLBhbHdc8REs274r8XJx3z\nKMIwZPNiHCU1e98njHV7fXxdB2hroRla1zLiLHES8LyZfZN07J19fwAnSvoVIfFrCkwHXrHYUbEC\nHAuMMLO1AJJeTrVR/JyeBC6XNAToCfSNqzcDz8bnTwEvSmpAaML3fEIla+14rKHA0J2I8RjCH05Y\nmKL3C0IlHMCbCdf3u4Rh5EpiLqlJ30hIviF8j763E+duT/gelnwfHif0dbmXUj6bFMeoDaw3s3xJ\n5xH+0Do2HuNGM9ucoiL6a8rRDKG8iWU+UFqBGc3Wdi0uHUoSy6ZbE8v536zh3c+Wcu13D6JmdkWM\nKuWcS+nwvrD6axj5e6jfHE65c7tNOrRqRJfcxjzz8QL6HZ2H1haGhPLjR6B4I3TtA8fdkHJUhzLV\nz4Hv3Q49fx6OOe4RmPIsdL00HnOX21f/ycz+mbhAUh6wIWFRMSHxgzDX/XHAWcAtkg4r4/hrEp6v\nIyRLJQqAQjNbA6yRNBroQqhx28LMxhB+DJH0fbb+sKNw2/0R4DQzS24IexrwiZl9lbDsK0ktzWxx\nvGWb6vZ7eQiYbmY9U6x7lpDUvBjCt8934pjnm9k2bR4Uxs19NvUunGBmy8tx7CJisziFdqu1drSx\npDqE9q/5ZrZQ0m1s+9mV+JLQhq9EblxW0YYQEqf1hMS5qJTtjPA+l1toY7sNSZcBqabWmm1mO9th\nZk3Zm7DJYjUg4Xu0271rd+KzgfAdK+mAPYJwHSHke8NiUtkMOF1SkZm9FI+1LvlAycqbcTQkfGip\nbAJ81O10KpwD2bWh8dZmRE+N/YIaWeLSHj7TjnN73LG/hB4/gTEPwAd/T7lJnx5t+fqrxSx58Wa4\ntzOMeRA69Iafj4PeD+5aUpmoQUxqB06GHj+GKc/B/YfDK9eGtps70LBhQ1atWpW4aCVwVazhQVJr\nSfum3JktCUkbMxtFuMXbmFDL+R6xTZbCdKXfWJiBKtlMILGR+L+BYyTVkFSPcMtyu06iJTHFGssb\niRUgktoSfjSvSKzlTNAHeCZp2ctsrSS5MsaApB6SUs2SMBq4WFJ2TERPjMs/BZpL6hn3rympI4CZ\nzSEkEb8ldUI4FjhOUru4b8kY0W8A15S0ZZTULR5vS2ekFI/kpHIkcKGknKRjzyfUDkOoxS2Z87e0\n91eSqHwTy0dpSdfLQN/Yxu8oYIWZLU7cIJart1PsOxo4R1Jdhfa3ZyWsW0XISYjXYBGhGcZv2Joc\nQchvSmK7FHg/lr15ki6M55fiiAFmNrSU61hyjG3Oy7Zl+2CgLeGzT/YmCSPnaCdHGyjFp0CepJLv\nzBWEO8o7+myS43+JrZ/p8cQ/2sysnZnlWZiwYzjw/2JSCeEPt2llBVfeDHku4ZbE/1KsO4lQMF26\nFM4Jt72ywnzW6zYW8/yEAk7p1IJ9G5X2x8rebe7cueXabsmSJXs4ElctSHDqXbDma3jzt6Hmsmuf\nrevXfct5yx/jzNr/oN7U9dDpfDj+Rmh+cOnH3FUNW8Bpd0GvAfDeX2HCYzBpKBx+JRx7HTTa/k5W\nTk4OvXr1olOnTpx22mkQEsunCbegAVYDl5N0qzlBNvCUpMaE2rW/m9nyWGMyWGHSgLWUcncr3kps\nLKmhma0ys5kKQ5tMIdzSfMTMpgFIeg34YUwobpB0JiGJeMjMSm7X3kro3POPGH+RmZV0jqlPuO34\nk6Qw7gKek/QDQtvNi+LytqSupRlB+P2bQWgiMCa+l42xs8Tf4/WoQbi9WDLw6bPA3UC75AOa2VJJ\nPybcts0i1Jp+j9Cz/V5gSlw+j51sfmZm0yXdCbwrqZjQzKEf8C/g35ImA6+ztbattPe3XNK/CAnG\nEmBcyTkUJ4OIt8RfA04ntI9cS5zONklLQo1pcqyfSHoWmByvwbiE1Y8BD0taB/SMzSmGEtpZJv7x\nsQboIek38RglzQ4uAx6Ky2sSekNPpmxTgOJ4nR4j1Aw+pNABqwjoZ2YbUtw+/gPwoKRphO/P7Wyt\nKdyOpLMJNY6lDkdiZusl9SfUftcgXJ+H4/lTfjYkXTdCeR8q6ReE7/cPy3ENTgT+U9ZG2loTu4ON\npBsJBfsXhC/4hvgX4g+BvwK3mdmfyhFUpcrPz7fx4/eCsdsf6AHNDoJLQvOQ58Yt5FcvTGHYj4/y\nOYpLkZWVRYr/ALZjZkiiuDj176mkCSU/WJVprynbVU3RBhh6Icx/H/oMg7ZHwtiHQu3khpVMbXwi\nNy87naG/7k/jujXLPl5FWL4Q3vs/mPgkKBvyr4JjfgENS297nY5yHX/gVpnZI5V53rJIuht40swq\ndvBQh6SfAwvMLGUbyp04zgPARDNLHAd1tZk12N0Y3VaxSUpvSzG5R6Ly1ljeAxxBaKh6n6RlhEah\nWYQu6X/ejVjd7thcDMvmQvvTgJAIPTF2Pgfv14Aj2/lMm6UZMmRI2Rs5t7Nq1IaLn4LHz4Tn+oYJ\nC9avgEPOhBNuRsVtmHb/+/x70pf07ZlXOTE1aQNn3QvHXAuj7w6dfCY8Bkf8AI67HupWxJ25CvEQ\nKcarTDczS9XuzlUAM3tgd48haQKhdvKXux+RK43CcE1/LSuphHImlrFX2AWSTiJUy+cA3wD/M7N3\ndiNWt7uWL4DNm7b0CJ+4cDnTvlzJ78/pVK4aub3VlVd6fzO3h9RpBJcNh6EXQMNWcMJN0Cr0FegE\ndGrdiKc/WsAVR+1fud/RffJCW85jrgsJ5idPhucZwszWE4ZHca7czKx7Kcu9trICWRgg/aUyN2Qn\neyHF9isjy9zQVZ5lc8K/cXD0J8d8QYPaNTi3W+s0BuXcXq7BvvCT0SlX9enRlltGTGPSwuV0a5uG\n2sKcA+Hch2HdcqjbpPLP75yr1srVK1zSmbEtRKp1P5N0esWG5cqtcGtiWbh6A/+ZspjzD29Ng9o+\nL7hzmejsLq2oVyubYR8vTG8gnlQ65/aA8g439FvCKP+p1I3ry0VhuqpPFSam324uVoXpkJYqTDs0\nSdIPE9YVJyzfrca+1UbhbKjdCOo359nxC9lYvJkrevq84M5lqoZ1anJ2l1a8PHkRq9ZvSnc4zjlX\nocqbWB4CfFLKuknAoeU5iMLE5g8SBqftAPSR1CHFps8mjCGV2ENwXcLys8sZe/VWOBtyDqTYYOjY\nBfQ8IIfv7OvzgjuXyfr0aMu6TcX8e9KidIfinHMVqryJZRZhsNtUGrJ1QNWy9CCMYj/XzDYSxo/q\nXc59XSqFsyHnO4yc9TVfLl9HX6+tdC7jdc5tzKEtQyee8gz55pxzVUV5E8vJxBHmU7iMMHBoebQm\nTJxeoiAuS3a+pCmShktKnBKqjqTxksZKOifVCST9OG4zfunSpak2qT42rQ9j1DU9kCfGzKdFozp8\nr4PPC54OkprE8jpL0sySWTcS1u8jaUQs1x9L6hSXt5E0StIMSdMlDUzPO3CVSRKX9mjDjMUrmfrl\ninSH45xzFaa8ieX/AedJel7S9yV1kPQ9Sc8D5xJmEagorwB5ZtaZMBXS4wnr9o+D9l4K3CvpwOSd\nzWyQmeWbWX7z5s0rMKwM9O18wPiqVi7vff4Nlx7Zlho+L3i63Ae8bmaHEOY0Tp5+7tfApFiu+8bt\nIczY8Esz6wAcBfyslOYhrprp3a01dWpm8czHC9IdinPOVZhyZSFmNgIYCJwC/BeYSpi79BRggJmV\nOj1RkjInpTezQjPbEF8+wtY5TDGzL+O/c4F3gG7lPG/1VDgbgFcK6lEzW1zSo00ZO7g9IU7bdhzw\nKIQp3VLM09uBOFSXmc0izPO6n5ktNrNP4vJVhITUx4raCzSqU5OzOrfi5UmLWL1hu1ntnHOuSip3\n9ZaZ3U/4wTuDMOH5qUArYJqkweU8zDjgIEntJNUCLiFMVL+FwmT3Jc4m1vzEW4m14/NmQC/CHKZ7\nr5hYDp6ZxamdWrJvQ58XPE3aAUuBIZImSnokzkecaDJwHoCkHsD+hD+stpCUR/hj6aNUJ9mrmnns\nJfoc2ZY1G4t5ZbJ34nHOVQ87dd/UzFaZ2evAx8AxhJrLkcBF5dy/CPg5obZzJvCcmU2XdEeceB1g\nQGxrNhkYAPSLyw8Fxsflo4C7zGyvTyzX1cph0fpaXHGUd9pJoxrA4cBDZtaNML1Y8lBadwFNJE0C\nrgEmAlsmIJfUgDA96rVmtjLVSfaqZh57iW5tmtB+v4Z+O9w5V22UexTteLvvYuBKQlswCLUwdwHP\nlPc4ZvYa8FrSslsTnt8M3Jxivw+Bw8p7nr2BFc5mzuYWHNKiIUfkZcx8v3ujAqDAzEpqGoeTlFjG\nZLE/gMI8fvOAufF1TUJSOXQnmpW4akASfXq04bZXZjDtyxV0at043SE559xu2WGNpaQsSadLehZY\nDDxMuIX3YNzkWjP7Z2k1LG7PKlr6OdPXN+eKnpU857DbhpktARZKah8XnUxSM43Ya7xWfPlDYLSZ\nrYxJ5qPATDP7a6UF7TLGud1yqV3DO/E456qHUhNLSf9H6FjzCnAmMILQrrItcCvgmUw6rV9JzXXf\nsCi7Fed09b4eGeAaYKikKUBX4I+Sfirpp3H9oYT2yJ8SJggoGVaoF6HN8kkJs0r5FKl7kcb1anJG\n55b8e9Ii1ngnHudcFbejW+G/AIxw27qfmRWWrJDkI/qm2bcFs9gHaHngYdT3ecHTzswmAflJix9O\nWD8GODjFfu/jf6Tt9S7t0ZYXP/mS/0xZzEVH+OgOzrmqa0e3wh8FVhF6gX8q6YHYm9VlgHETPgbg\n6B5HpjkS59zu6r7/Pnxn3wY87bfDnXNVXKmJpZn9CGhBmFlnPPATYIykmcCNhNpMlwZFxZtZ8NkU\nNiPaHtgx3eE453ZT6MTTlkkLlzNjkTdZd85VXTvsvGNm683sGTMraVt5M2GIlJsIt+/uknS5JB9A\nsRK9Petrmm1cyIZ6raCmX3rnqoPzurWmVo0sho3zWkvnXNW1MwOkLzazv5hZJ6AHoWf4QcAThB7j\nrpI8OeYL2tf4itottmuy55yrovapX4vTO7VgxCdfsm5jcdk7OOdcBtqliaXNbLyZXUOYeed8wvSK\nrhLMWbqa92cv5YCsr8jK+U66w3HOVaA+PdqyakMRr07xmXicc1XTLiWWJcxsk5mNMLNzKyogt2NP\njf2C/bJXUbt4NXhi6Vy10qNdUw5oXp9h4xamOxTnnNslu5VYusq1dmMRwycUcOmBG8MCTyydq1Yk\n0eeItkz44ls+XbIq3eE459xO88SyCnlp4iJWrS+id5t1YUHOgekNyDlX4c7vnkutbJ+JxzlXNXli\nWUWYGU+Mmc+hLRuxP4shqyY09oGUnatumtavxSmdWvDiJwWs3+SdeJxzVYsnllXE+C++ZdaSVfTt\nuT8qnA1N20G2z7jjXHXUp0cbVq4v4rWpPuCGc65q8cSyinhyzBc0rFOD3l1bwbK53r7SuWqs5wE5\n5OXUY9jH3onHOVe1eGJZBSxdtYH/TlvMhd3bUK9GFhTO8faVzlVjkrikR1s+nr+M2V97Jx7nXNXh\niWUVMOzjBWwqNq7ouT+sLIDiDV5j6Vw1d0H3XGpmi2e81tI5V4V4Ypnhioo38/THCzj2oGa0a1Yf\nCmeHFZ5YOletNWtQm+93aMEL3onHOVeFeGKZ4d6a+RWLV6zniqP2DwsK54R/m/qtcOequz492rJ8\n7SbemL4k3aE451y5eGKZ4Z4Y8wWtm9Tl5EP3CwsKZ0PN+tCwRXoDc87tcUcfmEPbpvV4+iMf09I5\nVzV4YpnBZn+9ig/nFHLpkW3JzlJYWNJxR0pvcG47kppIGi5plqSZknomrd9H0ghJUyR9LKlTwrpT\nJX0qabakmyo/epeJsrLExUe04aN5y5i7dHW6w3HOuTJ5YpnBnhq7gFrZWVxyRMJA6IWzvX1l5roP\neN3MDgG6ADOT1v8amGRmnYG+cXskZQMPAqcBHYA+kjpUWtQuo12Yn0uNLPn84c65KsETywy1ZkMR\nL0wo4IzOLclpUDssLNoIy7/wxDIDSWoMHAc8CmBmG81sedJmHYCRcf0sIE/SfkAPYLaZzTWzjcAw\noHelBe8y2r4N6/DdQ/dj+IQCNhR5Jx7nXGbzxDJDjZj4Jas2FIUhhkp8Ox9ss49hmZnaAUuBIZIm\nSnpEUv2kbSYD5wFI6gHsD+QCrYHE6qiCuGwbkn4sabyk8UuXLt0T78FlqD5HtmXZmo28Ps078Tjn\nMpsnlhnIzHhyzBd0bNWIbm2abF3hQw1lshrA4cBDZtYNWAMkt5W8C2giaRJwDTARKHcVlJkNMrN8\nM8tv3rx5BYXtqoJjvxOGGxv8wfx0h+KcczvkiWUG+njeMj79Ks4LnthJZ1nJUEMHpCcwtyMFQIGZ\nfRRfDyckmluY2Uoz629mXQltLJsDc4EvgYSGtOTGZc4BoRNPv6PzmLxwOZ8s+Dbd4TjnXKkqPbEs\nq/erpH6SlkqaFB8/TFh3paTP4+PKyo18z1u1fhMjZ33F3W98SuO6NTm7S9Ld0MLZUC8H6jVNT4Cu\nVGa2BFgoqX1cdDIwI3Gb2Gu8Vnz5Q2C0ma0ExgEHSWoX118CvFxJobsq4oLuuTSsU4PB789LdyjO\nOVeqGpV5soTer98j1PCMk/Symc1I2vRZM/t50r5Ngd8B+YABE+K+O/3n+4dzvuGR9+bRObcxXXKb\n0Dm38dYOMpVozYYixs1fxpi5hYydU8jUL1ew2aBWdhY3n34IdWtlb7tD4Ry/DZ7ZrgGGxuRwLtBf\n0k8BzOxh4FDgcUkGTAd+ENcVSfo58AaQDQw2s+npeAMuc9WvXYNLjmjD4A/ms3jFOlo2rpvukJxz\nbjuVmliS0PsVQFJJ79fkxDKVU4A3zWxZ3PdN4FTgmZ0NYtX6IhYuW8uoT7/GLCxr3aQuXdo0pnNM\nNA9r3ZiGdWru7KF3aO3GIiZ88S1j5hQyZm4hUwpWULzZqJkturZpws9O/A49D8jh8P33oU7N7O0P\nUDgbDjypQmNyFcfMJhH+8En0cML6McDBpez7GvDanovOVQd9e+bx6PvzeGLMF9x46iHpDsc557ZT\n2Yllqt6vR6bY7nxJxwGfAb8ws4Wl7Juy5yzwY4C2bdumDOKUji04pWMLVm8oYtqXK5hSsJzJBeHf\n16YuiceBA5rV31Kj2blNEzq0bJQ64SvF+k3FfPLFt4yZW8iYOYVMLljOpmKjRpbonNuYnxx3AD0P\nzKH7/vtQr1YZH8WG1bBqsbevdG4v1qZpPb7foQVPf7SAAScdtP1dDeecS7PKTizL4xXgGTPbIOkn\nwONAuavpzGwQMAggPz/fdrRtg9o1OOqAHI46IGfLsmVrNjKlYDlTYqL53uxveHFi6EdRI0u0b9GQ\nzrlN6JIbajcP3q8BNbJDU9X1m4qZuGA5Y+eGGslJC5azsXgzWYLDcpvwg2MO4KgDmnJEXlPq197J\nS1/SccdvhTu3V+vfK4/Xpy9hxMQvufTI1H88O+dculR2Yllm71czK0x4+Qjwl4R9T0ja952KDrBp\n/Vqc0H5fTmi/b0k8LFm5nskLV2xJOP8zZRHPfBzm7q1TM4uOrRpTM1tMXLCcDUUhkezYqjH9euVt\nSSR3+7Z6oSeWzjno0a4pHVs1YvAH8+jTo822I0c451yaVXZiuaX3KyFRvAS4NHEDSS3NbHF8eTZb\np8V7A/ijpH3i6+8DN+/pgCXRsnFdWjauy6mdWgAh2ZxfuDbcQo8J55oNxVx+1P4cdUAOPdo1pXHd\nim2fuSWx9Fvhzu3VJHFVr3b88vnJvPf5Nxx3sI9p6pzLHJWaWJbW+1XSHcB4M3sZGCDpbKAIWAb0\ni/suk/R7QnIKcEdJR57KJol2zerTrll9enfdrpnnnlE4GxrlQq16lXM+51zGOrNLS/7031kM+WCe\nJ5bOuYxS6W0sU/V+NbNbE57fTCk1kWY2GBi8RwPMVIWzIcdrK51zULtGNpcf1ZZ73/qcOUtXc2Dz\nBukOyTnnAJ95p2owg8LPvX2lc26Ly47cn1rZWTz+4fx0h+Kcc1t4YlkVrF0G61d4Yumc26J5w9qc\n1aUVz48vYMXaTekOxznnAE8sqwYfasg5l0L/Xnms21TMs+MXpDsU55wDPLGsGgpnh389sXTOJejU\nujFHtmvK4x9+QVHx5nSH45xznlhWCYWzIasGNPHBkJ1z2+rfqx1fLl/HmzO+SncozjnniWWVUDgb\nmuwP2RU8NqZzrsr7Xof9yN2nLkM+mJ/uUJxzLiOndHTJCuf4bXBXpk2bNlFQUMD69evTHUq1UKdO\nHXJzc6lZM7P/oMvOEv2OzuMP/5nJ1IIVHJbbON0hOef2Yp5YZrrNm0Ni2e74dEfiMlxBQQENGzYk\nLy/Pp/nbTWZGYWEhBQUFtGvXLt3hlOmiI9rwtzc/Y8gH8/jrxV3THY5zbi/mt8Iz3arFULQOcg5M\ndyQuw61fv56cnBxPKiuAJHJycqpM7W+jOjW5ML8Nr0xZxNerqkbMzrnqyRPLTOc9wt1O8KSy4lS1\na3nl0XkUbTaeGutDDznn0scTy0zniaVzrhzaNavPSe33ZejYL1i/qTjd4Tjn9lKeWGa6wjlQoy40\nbJnuSFwZJDWRNFzSLEkzJfVMWt9Y0iuSJkuaLql/wrq/xGUzJf1dVa26DCgsLKRr16507dqVFi1a\n0Lp16y2vN27cuMN9x48fz4ABA3bqfHl5eXzzzTe7E3K1c9Ux7Shcs5FXJi9KdyjOub2Ud97JdIWz\nQ/vKLP8boAq4D3jdzC6QVAuol7T+Z8AMMztLUnPgU0lDgXygF9A5bvc+cDzwTuWEXTFycnKYNGkS\nALfddhsNGjTg+uuv37K+qKiIGjVS/5eTn59Pfn5+pcRZnR19YA7t92vI4A/mc0H33Cp3O985V/V5\nYpnpCmdDi07pjsKVQVJj4DigH4CZbQSSq+kMaBhrIxsAy4CiuLwOUAsQUBPYrdGub39lOjMWrdyd\nQ2ynQ6tG/O6sjju1T79+/ahTpw4TJ06kV69eXHLJJQwcOJD169dTt25dhgwZQvv27XnnnXe45557\nePXVV7nttttYsGABc+fOZcGCBVx77bXlrs2cP38+V111Fd988w3NmzdnyJAhtG3blueff57bb7+d\n7OxsGjduzOjRo5k+fTr9+/dn48aNbN68mRdeeIGDDjpoVy5NxpBE/1553PTiVD6at4yjDshJd0jO\nub2MJ5aZrHgTLP8COp6T7khc2doBS4EhkroAE4CBZrYmYZsHgJeBRUBD4GIz2wyMkTQKWExILB8w\ns5nJJ5D0Y+DHAG3bVp1ZmAoKCvjwww/Jzs5m5cqVvPfee9SoUYO33nqLX//617zwwgvb7TNr1ixG\njRrFqlWraN++PVdffXW5xpO85ppruPLKK7nyyisZPHgwAwYM4KWXXuKOO+7gjTfeoHXr1ixfvhyA\nhx9+mIEDB3LZZZexceNGiourR7vEc7q15s+vz2Lw+/M8sXTOVTpPLDPZ8gWwucg77lQNNYDDgWvM\n7CNJ9wE3Ab9N2OYUYBJwEnAg8Kak94B9gUOB3Ljdm5KONbP3Ek9gZoOAQQD5+fm2o2B2tmZxT7rw\nwgvJzs4GYMWKFVx55ZV8/vnnSGLTpk0p9znjjDOoXbs2tWvXZt999+Wrr74iNzc35baJxowZw4sv\nvgjAFVdcwa9+9SsAevXqRb9+/bjooos477zzAOjZsyd33nknBQUFnHfeeVW+trJEnZrZXHpkW/7x\nzhwWFK6lbU5yiwznnNtzvOFeJivpEd7Ux7CsAgqAAjP7KL4eTkg0E/UHXrRgNjAPOAQ4FxhrZqvN\nbDXwX6An1UT9+vW3PP/tb3/LiSeeyLRp03jllVdKHSeydu3aW55nZ2dTVFS0WzE8/PDD/OEPf2Dh\nwoV0796dwsJCLr30Ul5++WXq1q3L6aefzsiRI3frHJnkiqPyyJZ4fMz8dIfinNvLeGKZyXyooSrD\nzJYACyW1j4tf7LBJAAAZiUlEQVROBmYkbbYgLkfSfkB7YG5cfrykGpJqEjrubHcrvDpYsWIFrVu3\nBuCxxx6r8OMfffTRDBs2DIChQ4dy7LHHAjBnzhyOPPJI7rjjDpo3b87ChQuZO3cuBxxwAAMGDKB3\n795MmTKlwuNJlxaN63BG55Y8O24hq9anrhV2zrk9wRPLTFY4G+o0gXpN0x2JK59rgKGSpgBdgT9K\n+qmkn8b1vweOljQVeBu40cy+IdRuzgGmApOByWb2SuWHv+f96le/4uabb6Zbt267XQsJ0LlzZ3Jz\nc8nNzeW6667j/vvvZ8iQIXTu3Jknn3yS++67D4AbbriBww47jE6dOnH00UfTpUsXnnvuOTp16kTX\nrl2ZNm0affv23e14Mkn/Xu1YvaGI4RMK0h2Kc24vIrMdNtWq0vLz8238+PHpDmPXPX4WbFwLP3o7\n3ZG4UkiaYGaVPk5OqrI9c+ZMDj300MoOpVqr6tf0vH98QOGajYz65QlkZZV/6KF0lWvnXNXnNZaZ\nrHCu3wZ3zu2y/r3a8UXhWkbO+jrdoTjn9hKeWGaqjWthZYEnls65XXZqpxa0bFyHIR/OS3cozrm9\nhCeWmWrZ3PBvzgHpjcM5V2XVzM6ib888PphdyKwlFTtgvnPOpeKJZabyHuHOuQrQp0cb6tTMYsj7\n89MdinNuL+CJZabyMSydcxWgSb1anHd4LiMmfUnh6g0pt1m+fDn/+Mc/KjmybUnqJunRhNcnSJok\nabqkd0vZ52RJn8Tt3pf0nYR1F0maEfd/Omm/RpIKJD2QsOxOSQslrd7F+N+RtEsdniS9JqnJruxb\njmPPr6Dj7NT7k1Rb0rOSZkv6SFJeXH6CpMd28tyPSbogPr9WUqWP+i+pq6TTK+hYeZKmlWO72pLe\niuX74t0sY9tcN0m1JA2S9JmkWZLOT9r+fElWcj5Jh5X3c6v0xFLSqZI+jYXtph1sl/ym8iStixd4\nkqSHKy/qNCicAw1bQu0G6Y7EOVfF9T86j41Fm3nm4wUp16czsZRUMgPcr4G/x2VNgH8AZ5tZR+DC\nUnZ/CLjMzLoCTwO/ifsfBNwM9Ir7X5u03++B0UnLXgF67N672TVmdrqZLU/HufegHwDfmtl3gL8B\nf66g414LpGM6qa7ATiWWCWV7V3UDMLOuZvbsbh4r+brdAnxtZgcDHYAtf7xJaggMBEom/MDMpgK5\nksqcT7hSE0tJ2cCDwGmEN9JHUocU2233pqI58QJ3NbOfJu9XrSyb47fBXZVy4okn8sYbb2yz7N57\n7+Xqq68udZ8TTjiBVEOClbbc7ZqD9mvIsQc144kxX7CxaPN262+66SbmzJlD165dueGGGwCQdIOk\ncZKmSLo9LsuTNFPSv2JN4P8k1Y3rBsQawimShsVlTSW9FJeNldQ5Lr9N0pOSPgCejP/ndzazyTGk\nSwmzVC0AMLPSurUb0Cg+bwwsis9/BDxoZt8m7y+pO7Af8L9tDmQ21swWl/eaSqoraVi8HiOAugnr\nvi9pTKxNfV5Sg1ip8nzCNidIejU+ny+pWXzeN16vyZKejMuaS3ohfh7jJPUqb5zA0oRz3ihpajz2\nXXHZllowSc1KajjLeH8PSRofy8DtpZy3N/B4fD4cOFmSgI3Aih0FrOCBWAn1FmHaWyQNAFoBoySN\nknSVpHsT9vuRpL/FcjpL0tAY//CS2jpJ3SW9K2mCpDcktSzrAkqqBdwBXKyttYflLdv7SRoRr/lk\nSUfHw2an+h4lnHNf4CngiHjOA5PW94mf5TRJf05Yvt1nk3zd4qZXAX8CMLPNcUzlEr8n/CGQPDXa\nK8AlZV0vzKzSHoRp6t5IeH0zcHOK7e4FzgDeAfLjsjxg2s6cr3v37lZl/bmd2csD0h2FKwMw3irx\nO2Q7KNszZszYM2+ynP75z39av379tll25JFH2rvvvlvqPscff7yNGzeu3MsrW7qvaUUaOesr2//G\nV+2liQXbrZs3b5517Nhxy2vgM8K89CJUQLwKHBf/Hy4CuobNeA64PD5fBNSOz5vEf+8HfhefnwRM\nis9vAyYAdePrE4EXbNvfgAfjb8AEoK+l+B4AxwKFhClVZwCN4vKXgL8AHwBjgVPj8qx4zFygH/BA\nimOuTnWuFNtdBwyOzzvH65IPNCPUhtaP624EbgVqEGbZKln+UMK1mx/36xivfbO4vGn892ngmPi8\nLTAz4bpNSvH4MEW8pwEfAvWSjp34O9sMmL+j95e0b3bcv3N8fQehlhlgGpCbcP45Je+rHNf2PODN\nePxWwHLggsRrFZ83iMetGV9/CBxGKKdGqLEGGAxcD9SM2zSPyy9OeI83lHIt/x7Xb1NeKH/Zfha4\nNuF6NWYH36Ok63AC8GrC63cIZawVoSw1J5SrkcA5ZXw2idetCbAQ+CvwCfA8sF9cdzjxu0hC2Yiv\newGvlPX57W417c5qHd9MiQLgyMQNJB0OtDGz/0i6IWn/dpImAiuB35jZe8knkPRj4McAbduWWWOb\nmdYug7WF3r7S7br/3gRLplbsMVscBqfdVerqCy64gN/85jds3LiRWrVqMX/+fBYtWsSxxx7L1Vdf\nzbhx41i3bh0XXHABt99eWiVH6ZYtW8ZVV13F3LlzqVevHoMGDaJz5868++67DBw4EABJjB49mtWr\nV3PxxRezcuVKioqKeOihh7ZM77i3Ov6g5hzQvD6D35/H2V1aESqPStUI+D4wMb5uABxE+DGbZ2aT\n4vIJhB9JgCmEmadeIiR2AMcA5wOY2UhJOZJKahhfNrN18XlLEmrWCD+W3QlToNYFxkgaa2afJcX5\nC+B0M/so/l78Ffhh3P8gwg9zLjBa0mHA5cBrZlZQxvsvj+OIt+7NbIrCjFsARxHuyH0Qz1ELGGNm\nRZJeB86SNJxQefKrpGOeBDxvsfbIzJbF5d8FOiTE3EhSAzMbRbhFWx7fBYaY2dqkY+/s+wO4KP7W\n1iB8dh2AKWZ2azljKctxwDNmVgwskjQy1UZmtjquO1PSTEKCOVWhPedCM/sgbvoUMAB4HegEvBmv\nZTawOB7rbuDunYixvGX7JKBv3K4YWCFpH0r/HpXHEcA7ZrYUQNJQwjV7iVI+m6T9axC+Fx+a2XWS\nrgPukXQl4TvUr5Tzfk1IaneoshPLHZKURelvajHQ1swKFW5lvCSpo5ltM4aGmQ0i/KVNfn5+1ZxW\naMtQQ34r3FUdTZs2pUePHvz3v/+ld+/eDBs2jIsuughJ3HnnnTRt2pTi4mJOPvlkpkyZQufOnXfq\n+L/73e/o1q0bL730EiNHjqRv375MmjSJe+65hwcffJBevXqxevVq6tSpw6BBgzjllFO45ZZbKC4u\nZu3atXvoXVcdWVmi/9F5/Pbf0/lkwXK6779PWbv8ycz+mbgg/mAn9gAqZust0jMIP25nAbfERG5H\n1iQ8XwfUSXhdABSa2RpgjaTRQBdCbV5JLM2BLmZW0mTqWULiULL/R2a2CZgn6TNCotkTOFbS/yMk\ny7UkrTazUtv77wIBb5pZnxTrhgE/B5YR7nasKucxs4CjzGybW5OSTiS0X0y21syOTrE8lSK2Nour\ns6MN4znbEWr/jjCzbxU6dKTa70ugDVCg0NawMaF2uaI9QmifOwsYkrA8+fffCJ/NdDPrmXyQ+IfJ\nZSmOP9rMBuxkTGvK3qTU79Eu24nPphBYC7wYXz9PaBPbkJB4vxMT7xbAy5LONrPx8Vjrtj/ctio7\nsSwpaCVy47ISZb2pDQBmNkHSHOBgoPo1xPKhhtzu2kHN4p7Up08fhg0btiWxfPTR0Mn3ueeeY9Cg\nQRQVFbF48WJmzJix04nl+++/zwsvvADASSedRGFhIStXrqRXr15cd911XHbZZZx33nnk5uZyxBFH\ncNVVV7Fp0ybOOeccunYtb6VO9Xbe4bnc/canDP5g3jaJZcOGDVm1apscZyVwlaShsVaoNbCptOPG\nSoE2ZjZK0vuEdlgNgPcIP9a/l3QC8I2ZrUxRWzgT+GXC638DD8SEpBbhzlZyAvUt0FjSwbEm83vx\nOBBqbvoAQxTaLh4MzDWzLYmDpH6E23w7TColnQv0MLObk1aNJrQFHSmpE+F2MYRb7w9K+o6ZzZZU\nH2gdY3yXcFv2R4QkM9lIYISkv8ZKlKaxZvF/wDXEGjVJXc1s0k7WWL4J3Bo/07UJx55PqB3+GLig\nHO+vESFxWiFpP8It9ndSnO9l4EpgTDzuSIv3U0tI6gH83Mz6Ju07GviJpMcJ7StPJDQHAFhFyBVK\nanU/ktSGcAs38T+VtpJ6mtmY+D7eBz4Fmpcsl1QTONjMppejxrLkvCXKW7bfBq4G7lXoZ1IRPXI/\nBv4ey/a3hLJ+Pzv+bLZcNzMzSa8QavRHEu4MzDCzFYTmEEBofwtcH/MvCN+jMnuzV3av8HHAQZLa\nxcawlxAKHwBmtsLMmplZnpnlEb6gZ5vZeIXGy9kAkg4g/PU5t5LjrxyFc0BZsE9euiNxbqf07t2b\nt99+m08++YS1a9fSvXt35s2bxz333MPbb7/NlClTOOOMM1i/PrlN+K676aabeOSRR1i3bh29evVi\n1qxZHHfccYwePZrWrVvTr18/nnjiiQo7X1VWv3YNLunRltenLWHR8q0VDzk5OfTq1YtOnTqVdN5Z\nSfghHyNpKqHzRcOUBw2ygafithMJ7dKWE9qbdY+3Ue8iJBrbMbNZhCSxYXw9k1D7OIXwI/qImU2D\nLUPztDKzIkKC9oKkycAVhHZyAG8AhZJmAKOAG8xsh7Vlkv4iqQCopzAU0W1x1YHxeiR7CGgQb8He\nQbidSbw92Q94Jr7vMcAhcV0xob3qafHf5OswHbgTeDe+p7/GVQOAfIWOIjOAne68amavE35vx0ua\nRKjZArgHuDo2M2uWsEtp728y4TOeRSgjJbebkXSHpLPjy0eBHEmzCe01UyXwbUldAzYC+JzQbvYJ\nwjUsMQh4PaETCoQ2ih9Y7KwVfQr8LMa/D/CQmW0kJLl/jtd3ElDemt1RhOYIkyRdTDnLNqEj8onx\nuzGBcGu6VJJ+KmmHn6+FTmY3xZgmAxPM7N87+mzY/rrdCNwW47+Cbf+wK82JwH/K3KqsRpgV/SB0\n1/+M0OD2Fktq8Ju07TtsbSx8PjCdUBA+Ac4q61xVtvPOc/3M7u2S7ihcOeCdd7Zz0UUXWZcuXezW\nW281M7NJkyZZ586drbi42JYsWWL77ruvDRkyxMx2rvPONddcY3fccYeZmY0aNcq6du1qZmazZ8/e\nss35559vI0aMsPnz51tRUZGZmd1///02cODAXXovmXJNK9LCZWus3U2v2p9em1nqNuko14T2kj+s\n7POWI66niJ09/FHh1/ZuYueS3TzOq8DJCa/z2MnOvv4o8xrXJlT21Shr20pvY2lmrwGvJS1L2eDX\nzE5IeP4C8EKFBDHjZRh1Z4Ucao9YvgD2L+8fUc5llj59+nDuuecybFi409elSxe6devGIYccQps2\nbejVq3wjpZxxxhnUrFkTgJ49e/LPf/6Tq666is6dO1OvXj0efzyMZHLvvfcyatQosrKy6NixI6ed\ndhrDhg3j7rvvpmbNmjRo0MBrLBPk7lOPUzu14JmPFzDg5O9Qr1bGNLV/iNLHq0wbM7s83TFUV2aW\n3EF3pyiMd/oxMNnM3q6YqFwp2gI3WbhTsEOKmWi1lJ+fbynHwpv7Lox/dPvlmaRbXzjou+mOwpVB\n0gQz26WZEHZHqrI9c+ZMDj300MoOpVqrrtd0/PxlDPlwPree2YH9Gm3ftj9d5do5V/VlzJ+qleqA\n48PDOef2Qvl5TcnPa5ruMJxz1ZDPFe5cBZHURGGGh1kKsz30TFrfWNIrCrMvTJfUP2FdW4XZF2Yq\nzF6SV9nxO+ecc7tr76yxdG7PuA943cwuiKMeJM9n+zPCkA5nxTH4Po1Df2wk9Hy808zelNQA2H7e\nvXIws7IGvnblVJ2bCTnn3J7iNZbOVQBJjQmDQz8KYGYbLQy3ksiAhgqZXwPCIMlFkjoQetq9Gfdd\nbXF2jJ1Rp04dCgsLPSGqAGZGYWEhdeqUOV60c865BF5j6VzFaEeYkm6IpC6E8coGWpg5pMQDhHHk\nFhHGBLzYzDZLOhhYLunFeJy3CL3vihNPoDKmK83NzaWgoIClS5dut87tvDp16pCbm5vuMJxzrkrx\nxNK5ilGDMPPDNRZmgriPMIDtbxO2OYUwDutJhEGX35T0Xtz3WKAbYS7mZwkDLG8zdIGVMV1pzZo1\nadeuXcW+K+ecc24n+K1w5ypGAVBgW+ctHk5INBP1B160YDYwjzAjRwEwyczmxjHCXkqxr3POOZfx\nPLF0rgKY2RJgoaT2cdHJhOnIEi2Iy4nzuLYnTEs6DmgSO/RAqNFM3tc555zLeH4r3LmKcw0wNPYI\nnwv0L5nz1cweBn4PPBbnjBVwo5l9AyDpeuDt2LFnAvCvdLwB55xzbndU65l3JC0Fvqik0zUDvqmk\nc+2KTI4vk2ODHce3v5k1L2XdHuNle4tMjg0yO76MK9fOuaqvWieWlUnS+EyeAi2T48vk2CDz49vT\nMvn9Z3JskNnxZXJszrmqy9tYOuecc865CuGJpXPOOeecqxCeWFacQekOoAyZHF8mxwaZH9+elsnv\nP5Njg8yOL5Njc85VUd7G0jnnnHPOVQivsXTOOeeccxXCE0vnnHPOOVchPLHcTZLaSBolaYak6ZIG\npjumZJKyJU2U9Gq6Y0kmqYmk4ZJmSZopqWe6Yyoh6RfxM50m6RlJddIdU2WpCuUaMrdsZ3K5hr27\nbDvn9ixPLHdfEfBLM+sAHAX8TFKHNMeUbCAwM91BlOI+4HUzOwToQobEKak1MADIN7NOQDZwSXqj\nqlRVoVxD5pbtjCzX4GXbObdneWK5m8xssZl9Ep+vIvyAtE5vVFtJygXOAB5JdyzJJDUGjgMeBTCz\njWa2PL1RbaMGUFdSDaAesCjN8VSaTC/XkLlluwqUa9iLy7Zzbs/yxLICScoDugEfpTeSbdwL/ArY\nnO5AUmgHLAWGxNuZj0iqn+6gAMzsS+AeYAGwGFhhZv9Lb1TpkaHlGjK3bGdsuQYv2865PcsTywoi\nqQHwAnCtma1MdzwAks4EvjazCemOpRQ1gMOBh8ysG7AGuCm9IQWS9gF6E5KEVkB9SZenN6rKl4nl\nGjK+bGdsuQYv2865PcsTywogqSbhx3eomb2Y7ngS9ALOljQfGAacJOmp9Ia0jQKgwMxKasKGE36Q\nM8F3gXlmttTMNgEvAkenOaZKlcHlGjK7bGdyuQYv2865PcgTy90kSYS2VDPN7K/pjieRmd1sZrlm\nlkdonD/SzDKmZsLMlgALJbWPi04GZqQxpEQLgKMk1Yuf8clkUAeMPS2TyzVkdtnO8HINe3nZds7t\nWTXSHUA10Au4ApgqaVJc9mszey2NMVUl1wBDJdUC5gL90xwPAGb2kaThwCeEHtIT2bumwPNyvXsy\nslyDl23n3J7lUzo655xzzrkK4bfCnXPOOedchfDE0jnnnHPOVQhPLJ1zzjnnXIXwxNI555xzzlUI\nTyydc84551yF8MQyw0nqJ8lKeaRt/mFJj0kqSNf5XdXnZds556ofH8ey6riQMKNHoqJ0BOJcBfOy\n7Zxz1YQnllXHJDObne4gnNsDvGw751w14bfCq4GEW4rHSXpJ0mpJhZIelFQ3aduWkp6Q9I2kDZKm\nSNpuKjxJ7SQ9KWlJ3G6upPtSbNdN0nuS1kr6XNJPk9a3kPS4pEXxOIslvSpp34q/Eq668bLtnHNV\ni9dYVh3ZkpI/r81mtjnh9VPAc8A/gB7ArUB9oB+ApPrAu8A+wK+BhcDlwJOS6pnZoLhdO+BjYG08\nxudAW+D7SedvBDwN3AvcQZi27iFJn5rZqLjNk8D+wA3xfPsR5iaut6sXwlU7Xradc666MDN/ZPCD\n8MNppTxeTdrm4aR9bwGKgYPj65/H7U5I2u4t4GsgO75+AlgNtNpBXI/FY52YsKw2UAgMSli2GhiQ\n7uvoj8x7eNn2hz/84Y/q9/Aay6rjXLbv4JDcc/a5pNfDgD8Qang+A44DvjSzd5K2ewoYAnQAphJq\nb141s0VlxLTWttbeYGYbJH1GqAEqMQ64QZKAkcA0M/MJ6l0iL9vOOVdNeGJZdUyzsjs4fFXK69bx\n36bA4hT7LUlYD5DD9j/0qXybYtkGoE7C64uB3wG/ItxWXCzpYeAPtu2tTrf38rLtnHPVhHfeqV72\nK+X1l/HfZUCLFPu1SFgP8A1bf7B3i5l9bWY/M7PWwCGE24y3Az+piOO7vYaXbeecqwI8saxeLkp6\nfQmwGfgovn4XyJXUK2m7Swnt0GbE1/8DzpTUsiKDM7NPzezXhNqgThV5bFftedl2zrkqwG+FVx1d\nJTVLsXx8wvPTJd1N+PHsQbhN94SZfR7XPwYMBF6UdAvhluBlwPeAn5hZcdzud8DpwIeS/gjMJtTy\nnGpm2w3fUhpJjQmdJ4YCs4BNQG9Cz93/lfc4rtrzsu2cc9WEJ5ZVx/OlLG+e8Pxy4JfA1cBG4F/A\n9SUrzWyNpOOBvwB3AQ2BT4ErzOyphO3mSzqK0DniT0ADwi3Hf+9kzOuBT4AfEYZl2RzPd5mZ7eyx\nXPXlZds556oJeSfGqk9SP0LP14PK0QnCuSrDy7ZzzlUt3sbSOeecc85VCE8snXPOOedchfBb4c45\n55xzrkJ4jaVzzjnnnKsQnlg655xzzrkK4Ymlc84555yrEJ5YOuecc865CuGJpXPOOeecqxD/H35P\nOFTa0wNjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfdUujkbvIT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Njt1FiPx6FfO",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_challenge:\n",
        "  lstm_hidden_size = 300\n",
        "  dense_dimension = 150\n",
        "  attention_hops = 30\n",
        "  is_lstm = False\n",
        "  batch_size = datasets[\"challenge\"].batch_size\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 200\n",
        "  mlp_one = 4000\n",
        "  mlp_two = 1000\n",
        "  num_classes = 4\n",
        "  avg=False\n",
        "  weights = torch.tensor([13.580097, 59.600533, 5.590109, 1.368556], dtype=torch.double).cuda()\n",
        "  epochs = 9\n",
        "  inner_dropout = 0.1\n",
        "  outer_dropout = 0.3\n",
        "  C = 0.3\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.01\n",
        "  grad_clip = False\n",
        "  grad_clip_amount = 1\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.0005\n",
        "  use_better=True\n",
        "  big_gloves=True\n",
        "  use_relu = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYJ_FyWx36Sr",
        "colab_type": "code",
        "outputId": "4714a7c2-6db5-4395-c466-54cbe9c7def1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"challenge\"], Hyperparameters_challenge)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([27737, 300])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-e012c4c42f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"challenge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHyperparameters_challenge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-126-45aa3db07545>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, dataset, hp, is_plot)\u001b[0m\n\u001b[1;32m     12\u001b[0m                        \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                        \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                        using_gradient_clipping=hp.grad_clip)\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplot_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-122-ad1fe9d88d7e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, optimiser, hp, using_gradient_clipping)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0;31m#get y values - do forward pass and process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mpredicted_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mactual_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0msqueezed_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-9f00b1662b7d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, premise, hypothesis)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mpremise_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpremise_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpremise_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_premise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremise_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mprocessed_hypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypothesis_processor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_hypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mhypothesis_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypothesis_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_hypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0661d3992b7a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden_layer)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     return self.cool_lstm(embedding,\n\u001b[0;32m---> 35\u001b[0;31m                           hidden_layer)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 716\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.35 GiB (GPU 0; 15.90 GiB total capacity; 10.90 GiB already allocated; 1.59 GiB free; 13.53 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdlajIzawdWz",
        "colab_type": "code",
        "outputId": "6fbf3a7d-a48e-4c88-d166-4480ddf2ae68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        }
      },
      "source": [
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu() ,datasets[\"challenge\"].test_data, False)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: textual entailment model\n",
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    716    |    339    |    560    |    288    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    190    |    181    |    242    |    84     |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    697    |    393    |   2797    |    577    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |   3103    |   1338    |   3712    |   10196   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6848.25 out of 11651.25\t(58.77695526231091%)\n",
            "Classifier 'textual entailment model' has Acc=0.547 P=0.455 R=0.382 F1=0.376 AUC=0.000 Chal=58.777\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.376     0.152     0.217      4706\n",
            "           1      0.260     0.080     0.123      2251\n",
            "           2      0.627     0.383     0.475      7311\n",
            "           3      0.556     0.915     0.691     11145\n",
            "\n",
            "    accuracy                          0.547     25413\n",
            "   macro avg      0.455     0.382     0.376     25413\n",
            "weighted avg      0.517     0.547     0.491     25413\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[  716   339   560   288]\n",
            " [  190   181   242    84]\n",
            " [  697   393  2797   577]\n",
            " [ 3103  1338  3712 10196]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4545427750219154,\n",
              " 0.3824947038077746,\n",
              " 0.5465706528154881,\n",
              " 0.37648462934761223)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_politi:\n",
        "  lstm_hidden_size = 30\n",
        "  dense_dimension = 10\n",
        "  attention_hops = 5\n",
        "  batch_size = datasets[\"politifact\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 50\n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.5\n",
        "  C = 0.5\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  is_lstm=False\n",
        "  lr=0.00008\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 1\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = 0\n",
        "  use_better=True\n",
        "  big_gloves=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXeIuPBZF8Ml",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "483b9dd8-ec9c-482b-f556-c04f2f679580"
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"politifact\"], Hyperparameters_politi)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([33766, 50])\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:143: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss is: tensor(1.8129, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5022268907563026\n",
            "Average loss is: tensor(1.8101, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5189285714285714\n",
            "Running EPOCH: 2\n",
            "Average loss is: tensor(1.7982, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.56609243697479\n",
            "Average loss is: tensor(1.7822, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6014285714285714\n",
            "Running EPOCH: 3\n",
            "Average loss is: tensor(1.7630, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6396218487394958\n",
            "Average loss is: tensor(1.7764, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6060714285714286\n",
            "Running EPOCH: 4\n",
            "Average loss is: tensor(1.7391, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6679411764705883\n",
            "Average loss is: tensor(1.7743, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6035714285714285\n",
            "Running EPOCH: 5\n",
            "Average loss is: tensor(1.7127, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status tensor(False, device='cuda:0')\n",
            "Accuracy of the model 0.6964705882352941\n",
            "resetting model HERE\n",
            "Average loss is: tensor(1.7955, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6085714285714285\n",
            "Running EPOCH: 6\n",
            "Average loss is: tensor(1.7118, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.6928571428571428\n",
            "Average loss is: tensor(1.7743, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6035714285714285\n",
            "Running EPOCH: 7\n",
            "Average loss is: tensor(1.7118, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.6930252100840336\n",
            "Average loss is: tensor(1.7743, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6035714285714285\n",
            "Running EPOCH: 8\n",
            "Average loss is: tensor(1.7117, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.6930252100840336\n",
            "Average loss is: tensor(1.7743, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6035714285714285\n",
            "Evaluation for: VALIDATION\n",
            "Classifier 'VALIDATION' has Acc=0.604 P=0.602 R=0.603 F1=0.602 AUC=0.602 Chal=0.000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.572     0.591     0.581      1303\n",
            "         1.0      0.633     0.615     0.624      1497\n",
            "\n",
            "    accuracy                          0.604      2800\n",
            "   macro avg      0.602     0.603     0.602      2800\n",
            "weighted avg      0.605     0.604     0.604      2800\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[770 577]\n",
            " [533 920]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Tight layout not applied. tight_layout cannot make axes width small enough to accommodate all axes decorations\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApwAAAEbCAYAAAB3FlRYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3xV9f348dc7g4S9kiAQ9ggyQoAA\nSgQDDlCsWEUEW/f41p/WQcXVqmhrq5UqVRx1gVoVUatSAVErWxACEvaeYRP2zHr//vicwCXcLEhy\nc8P7+XjcR+4953M+53NuTnLf9zNFVTHGGGOMMaa0hAS6AMYYY4wxpmKzgNMYY4wxxpQqCziNMcYY\nY0ypsoDTGGOMMcaUKgs4jTHGGGNMqbKA0xhjjDHGlCoLOI0xpgSJyK0iMjPQ5TDGmPLEAk5jjDHG\nGFOqLOA0xpgzJCJhgS6DMcYEAws4jTHlhog8KiJbROSgiKwUkUu87WNE5C8+6ZJFJM3n9QYReVxE\nlonIXhEZLSKR+ZzjVhGZKSIjvLTrReQKn/01ReRdEdnmleUvIhLqc+wsEXlZRNKB4SJSV0TGi8gB\nEZkLtPDJS7y0O739i0Wkfcm/c8YYU77Zt3NjTLkgInHAfUBXVd0qIk2B0GJk8RugL3AY+C/wJ+/h\nT3fgfSAKuBt4V0QaqlvrdwywE2gJVAW+ATYD//I5dixQDwgHRgPHgPpAM2AysN5LeznQC2gN7Afa\nAPuKcU3GGFMhWA2nMaa8yAYigLYiEq6qG1R1bTGOH6Wqm1V1D/AcMKSAtBtV9W1VzcYFnvWBeiJS\nD7gSeFBVD6vqTuBlYLDPsVtV9VVVzQIygOuAp7z0S7z8cmUC1XGBpqjqclXdVoxrMsaYCsECTmNM\nuaCqa4AHgeHAThEZKyINipHFZp/nG4GCjt3uc94j3tNqQBNcreU2EdknIvtwNZsx+ZwnGtdSlPfc\nuXn/CIwCXsNd01siUqPIV2SMMRWEBZzGmHJDVT9W1YtwgZ8CL3i7DgNVfJKe5+fwRj7PGwNbz6AI\nm4HjQJSq1vIeNVS1nW8xfZ7vArL8nPtkYtVXVLUL0BbXtD7sDMpljDFBzQJOY0y5ICJxItJHRCJw\nfSKPAjne7oXAlSJSR0TOw9WE5nWviMSKSB3gj8CnxS2D19z9HfAPEakhIiEi0kJELs4nfTbwH9zg\noSoi0ha4xeeauopIdxEJxwXNx3yuyRhjzhkWcBpjyosI4HlgN67JOwZ43Nv3IZAKbMAFhP6CyY+9\nfeuAtcBf/KQpipuBSsAyYC/wOa6PZ37uwzXHb8cNOBrts68G8LaXz0YgHXjxDMtljDFBS9ygTGOM\nCV4isgG4U1V/CHRZjDHGnM5qOI0xxhhjTKmygNMYY4wxxpQqa1I3xhhjjDGlymo4jTHGGGNMqTpn\nl7aMiorSpk2bBroYpoKaP3/+blWNLuvz2n1tSlug7m1jTHA7ZwPOpk2bkpKSEuhimApKRDYWnqrk\n2X1tSlug7m1jTHCzJnVjjDHGGFOqyjzgFJF+IrJSRNaIyGN+9r8sIgu9xypvLePcfbeIyGrv4bua\nRxcRWezl+YqISFldjzHGGGOMKViZBpwiEgq8BlyBW1d4iLcU3Amq+pCqJqhqAvAqbtk4vOXqnga6\nA92Ap0WktnfYG8BdQCvv0a8MLseY03z77bfExcUBtPf3hQpARAaJyDIRWSoiH/tsf0FElniPG3y2\nvysiqSKySEQ+F5Fq3vYIEfnU+6L1s4g0Ld2rM8YYY85MWffh7AasUdV1ACIyFhiAW0LOnyG4IBOg\nL/C9qu7xjv0e6CciU4EaqjrH2/4BcA0wqbQuwhh/srOzuffee/n+++9p0aLFUtwXqvGqeuL+FpFW\nuOUak1R1r4jEeNv7A52BBNwSj1NFZJKqHgAe8n4iIi/hllJ8HrgD2KuqLUVkMPBCGV5uuZOZmUla\nWhrHjh0LdFEqhMjISGJjYwkPDw90UYwxFUBZB5wNgc0+r9NwNZanEZEmQDPgxwKObeg90vxsN6ZM\nzZ07l5YtW9K8eXMABfx9oboLeE1V9wKo6k5ve1tguqpmAVkisghXUz/OJ9gUoLKXN17ew73nnwOj\nSunSgkJaWhrVq1enadOmWK+as6OqpKenk5aWRrNmzQJdHGNMBVCeBw0NBj5X1eySylBE7haRFBFJ\n2bVrV0llawwAW7ZsoVGjRr6b/H35aQ20FpFZIjJHRHK7f6TiauyriEgU0Bs4kZmIjAa2A21wXU3A\n50uYF6juL+FLCirHjh2jbt26FmyWABGhbt26VltsjCkxZR1wbsHnQxSI9bb5Mxj4pAjHbvGeF5qn\nqr6lqomqmhgdbdPImYAIw/UzTsZ1GXlbRGqp6nfAROAn3H0/GzjxZUtVbwMaAMuBGzB+WbBZcuy9\nNMaUpLIOOOcBrUSkmYhUwgWV4/MmEpE2QG3ch26uycDlIlLbGyx0OTBZVbcBB0TkAq/J8Wbg69K+\nEHO6rxduYezcTSxK28exzBKrmA4aDRs2ZPNm314ffr/8pAHjVTVTVdcDq3ABKKr6nDdg7jJAvH0n\neLX9Y4HrvE0nvoSJSBhQM7+ybd5zhL98s4ycHFvK1hhjTNkr0z6cqpolIvfhgsdQ4D1VXSoizwIp\nqpobfA4GxqrPQu+qukdE/owLWgGezR1ABPw/YAyuf9skbMBQmZuyYicPjF144nVoiNA8qiptG9Tg\n/Po1aFu/Bm0b1CCqWkQAS1m6unbtyurVq1m/fj24gHEwcGOeZF/hajZHe03nrYF13gwOtVQ1XUTi\ngXjgO+9LVAtVXeM9vxpY4eU1HrgF98VsIK6/8/X+yjZnXTrvzFxPvRqR3NWreQletcmVnp7OJZdc\nAsD27dsJDQ0ltyVl7ty5VKpUKd9jU1JS+OCDD3jllVeKfL7cSf6joqLOruDGGFMGynylIVWdiGs6\n9N32VJ7Xw/M59j3gPT/bU4D2JVdKUxz7jmTw6BeLaHNedV77TWdW7zjIsq0HWLbtACkb9vL1wq0n\n0kZXjzgRfOYGos2iqhIaEvzNd2FhYYwaNYq+ffsCtAP+7OcLVW5N/TJck/kwL8iMBGZ4zZgHgN96\nX9BCgPdFpAYuiE0F7vFO+S7woYisAfbgAly/AefALrF8t2wHL05eSa/W0cSdV72U3oVzV926dVm4\n0H3pGj58ONWqVePhhx8+sT8rK4uwMP//chMTE0lMTCyTchpjTCCITyXiOSUxMVFtCcCScf8nvzBx\n8Ta+vi+Jdg1Ob9XddySDZdsOsHzbyUB0zc6DZGa7ey8yPIS487xa0PrVadugBm3Oq0HViOBdeVVE\n5qtqmUcQBd3Xuw8dp9/I6URXj+Tre5OoFFaexwwW3/Llyzn//PMDXQzgZMC5ZMkSIiMj+eWXX0hK\nSmLw4ME88MADHDt2jMqVKzN69Gji4uKYOnUqI0aM4JtvvmH48OFs2rSJdevWsWnTJh588EHuv//+\n087hr4Zzw4YN3H777ezevZvo6GhGjx5N48aN+eyzz3jmmWcIDQ2lZs2aTJ8+naVLl3LbbbeRkZFB\nTk4OX3zxBa1atTrlHP7e00Dd28aY4Ba8n+imXJiwaBvjU7fyh8ta+w02AWpVqUSPFlH0aHHygzEj\nK4c1Ow95gegBlm09wMTF2/hk7iYARCC2dmUqhYagCjmq5OT+zPF5fuKn264K2bmv1U3vku2lL2kt\noqvyvz8kl3zGpSSqWgR/uzaeuz5IYeQPq3ikX5tAF6nUPPPfpSzbeqBE82zboAZP/6pdsY9LS0vj\np59+IjQ0lAMHDjBjxgzCwsL44YcfeOKJJ/jiiy9OO2bFihVMmTKFgwcPEhcXxz333FOk+TB///vf\nc8stt3DLLbfw3nvvcf/99/PVV1/x7LPPMnnyZBo2bMi+fW7xtjfffJMHHniA3/zmN2RkZJCdfe71\nuzbGlB0LOM0Z23XwOH/6ajEdY2tyT3KLYh1bKSyEtg1c03ouVWXb/mM+taCHyM5RQkKEEIEQEUQg\nVIQQEUJC3Eha99o9D/Geh4aI9xovrVDSjfZ1qubfJ6/cycmBHYu5rG1HBiXG8ua0tVxyfgxdmtQJ\ndMkqvOuvv57Q0FAA9u/fzy233MLq1asRETIzM/0e079/fyIiIoiIiCAmJoYdO3YQGxvrN62v2bNn\n85///AeAm266iUceeQSApKQkbr31VgYNGsS1114LwIUXXshzzz1HWloa11577Wm1m8YYU5Is4DRn\nRFV5/D+LOZyRzT8GdSQs9OybZ0WEBrUq06BWZS5tW68ESmlO+PkNmPwEPLCIJ69qy09r03no01Qm\nPdAzqLsu5OdMaiJLS9WqVU88f/LJJ+nduzdffvklGzZsIDk52e8xEREnB9eFhoaSlZV1VmV48803\n+fnnn5kwYQJdunRh/vz53HjjjXTv3p0JEyZw5ZVX8q9//Ys+ffqc1XmMMSY/FasTlykzXyzYwg/L\nd/BI3zhaxtgAlHKvzVXu5+JxVI8M5x/Xd2Tz3iP8ZcLywJbrHLN//34aNnRrAYwZM6bE8+/Rowdj\nx44F4KOPPqJnz54ArF27lu7du/Pss88SHR3N5s2bWbduHc2bN+f+++9nwIABLFq0qMTLY4wxuSzg\nNMW2dd9Rnhm/lG7N6nB7ki17FxRqN4EmSZD6KajSvXld7urZnE/mbuLHFTsCXbpzxiOPPMLjjz9O\np06dzrrWEiA+Pp7Y2FhiY2MZOnQor776KqNHjyY+Pp4PP/yQf/7znwAMGzaMDh060L59e3r06EHH\njh0ZN24c7du3JyEhgSVLlnDzzTefdXmMMSY/NkrdFIuqctO7c1mwaS/fPtCLxnWrBLpI5VJ5HKXO\n/DHw3wfgrh+hYReOZWYzYNQs0g9n8N1DvYKrT6of5WmUekVho9SNMSXFajhNsfx7zkZmrtnNH/uf\nb8FmsGl7DYRGuFpOIDI8lJdvSGD/0Qz++OViztUvn8YYY0qfBZymyDbsPsxfJ66gV+tobuzWONDF\nMcVVuRbE9YMlX0C2Gx3dtkENHrqsNZOWbOerhXlX4TTGGGNKhgWcpkiyc5SHP0slPFT4+3XxeCvi\nmGATPxiO7Ia1P57Y9H+9WpDYpDZPfb2UrfuOBrBwxhhjKioLOE2RvDtzHSkb9/LMgHacVzMy0MUx\nZ6rlpVC5DqSOPbEpNET4x6COJ75U5JTGLPnGGGPOaRZwmkKt2nGQEZNX0bddPa5JaBjo4pizEVYJ\n2l8HKyfCsf0nNjepW/XE/JxjftoQuPIZY4ypkCzgNAXKzM5h6LiFVI8M47lfd7Cm9Iog/gbIOgbL\nxp+yeXDXRlzSJoYXvl3Bmp0HA1Q4Y4wxFZEFnKZAr01Zw5ItB3ju1+2JqhZR+AGm/ItNhDotYNGn\np2wWEf52XQeqVArloU9TyczOCVABg1Pv3r2ZPHnyKdtGjhzJPffck+8xycnJ+JvGKr/txhgTrCzg\nNPlanLafUT+u4dedGtKvff1AF8eUFBFXy7lhBuzbfMqumOqR/O3aDizesp9X/7c6QAUMTkOGDDmx\nyk+usWPHMmTIkACVyBhjyg8LOI1fxzKzGTpuIVHVIhhejtalNiUkfpD7ufiz03b1a1+fazs35LWp\na/ll094yLljwGjhwIBMmTCAjIwOADRs2sHXrVnr27Mk999xDYmIi7dq14+mnnz6j/Pfs2cM111xD\nfHw8F1xwwYmlKKdNm0ZCQgIJCQl06tSJgwcPsm3bNnr16kVCQgLt27dnxowZJXadxhhzJsICXQBT\nPr38/SpW7zzE+7d3o2aV8EAXx5S0Os2g0QWuWf2ih1ytp4/hV7fj53V7GDoulQn3X0SVSkH2r2LS\nY7B9ccnmeV4HuOL5fHfXqVOHbt26MWnSJAYMGMDYsWMZNGgQIsJzzz1HnTp1yM7O5pJLLmHRokXE\nx8cX6/RPP/00nTp14quvvuLHH3/k5ptvZuHChYwYMYLXXnuNpKQkDh06RGRkJG+99RZ9+/blj3/8\nI9nZ2Rw5cuRsr94YY85Kmddwikg/EVkpImtE5LF80gwSkWUislREPva29RaRhT6PYyJyjbdvjIis\n99mXUJbXVNGkbNjDWzPWcWP3xlzcOjrQxTGlpeMNsGsFbEs9bVeNyHBevD6e9bsP87eJKwJQuODk\n26zu25w+btw4OnfuTKdOnVi6dCnLli0rdt4zZ87kpptuAqBPnz6kp6dz4MABkpKSGDp0KK+88gr7\n9u0jLCyMrl27Mnr0aIYPH87ixYupXr16yV2kMcacgTKtthCRUOA14DIgDZgnIuNVdZlPmlbA40CS\nqu4VkRgAVZ0CJHhp6gBrgO98sh+mqp+XzZVUXIePZ/GHz1KJrV2ZJ660dakrtLbXwKRHXS1ng9O/\no/VoEcUdFzXj3ZnrubRtveD68lFATWRpGjBgAA899BALFizgyJEjdOnShfXr1zNixAjmzZtH7dq1\nufXWWzl27FiJnfOxxx6jf//+TJw4kaSkJCZPnkyvXr2YPn06EyZM4NZbb2Xo0KHcfPPNJXZOY4wp\nrrKu4ewGrFHVdaqaAYwFBuRJcxfwmqruBVDVnX7yGQhMUlVrJyphz09awaY9RxgxsCPVIoKsGdUU\nT5U60OpyWPw5ZGf5TTKsbxytYqox7LNU9h3JKOMCBp9q1arRu3dvbr/99hO1mwcOHKBq1arUrFmT\nHTt2MGnSpDPKu2fPnnz00UcATJ06laioKGrUqMHatWvp0KEDjz76KF27dmXFihVs3LiRevXqcddd\nd3HnnXeyYMGCErtGY4w5E2UdcDYEfIfFpnnbfLUGWovILBGZIyL9/OQzGPgkz7bnRGSRiLwsIn7n\n7xGRu0UkRURSdu3adabXUGHNWL2LD+ds5I6kZnRvXjfQxakQROQ9EdkpIkvy2V9TRP4rIqleF5Lb\nfPbdIiKrvcctpVLAjoPh8E5YN9Xv7sjwUF6+IYE9hzP401d+L8HkMWTIEFJTU08EnB07dqRTp060\nadOGG2+8kaSkpCLl079/f2JjY4mNjeX6669n+PDhzJ8/n/j4eB577DHef/99wE291L59e+Lj4wkP\nD+eKK65g6tSpJ8776aef8sADD5Ta9RpjTFGIatktYyciA4F+qnqn9/omoLuq3ueT5hsgExgExALT\ngQ6qus/bXx9YBDRQ1UyfbduBSsBbwFpVfbagsiQmJqrNc3fSgWOZ9H15OlUqhTLh/p5EhocGukhB\nTUTmq2qiiPQCDgEfqGp7P+meAGqq6qMiEg2sBM4DqgEpQCKgwHygS27Nf36KfV9nHYcRraHVZXDd\nO/kmG/XjakZ8t4p/Dk5gQDldbWr58uWcf751AylJ/t7T3Hs7QEUyxgSpsq7h3AI08nkd623zlQaM\nV9VMVV0PrAJa+ewfBHyZG2wCqOo2dY4Do3FN96YYnhm/jJ0Hj/PSoAQLNkuQqk4H9hSUBKgubgmn\nal7aLKAv8L2q7vGCzO8Bf7X9ZycsAtpfC8u/geP5ry70u4tb0KlxLZ78agnb95dc/0NjjDHnhrIO\nOOcBrUSkmYhUwjWNj8+T5isgGUBEonBN7Ot89g8hT3O6V8OJ96F9DWBtf8Xw3dLtfLEgjXuTW9Cx\nUa1AF+dcMwo4H9gKLAYeUNUcitb9BCiBriLxgyHrKCz/b75JwkJDeHlQApnZyrDPUynLlhFjjDHB\nr0wDTlXNAu4DJgPLgXGqulREnhWRq71kk4F0EVkGTMGNPk8HEJGmuBrSaXmy/khEFuM+sKOAv5T2\ntVQUew5n8MSXi2lbvwb39WlV+AGmpPUFFgINcLMwjBKRGsXJQFXfUtVEVU2Mjj6DkeSNukHtppA6\ntsBkTaOq8sf+5zNj9W4+nLOx+OcpAxYIlxx7L40xJanMhyGr6kRgYp5tT/k8V2Co98h77Ab81PKo\nap8SL+g5QFX501eL2X80k3/f2Z1KYbbwVADcBjzv3fdrRGQ90AbX1STZJ10sMLVUSpC71OW0v8OB\nrVCjQb5Jf9O9MT8s38FfJy4nqWUULaKrlUqRzkRkZCTp6enUrVsXyTORvSkeVSU9PZ3IyMhAF8UY\nU0HYvDfnsPGpW5m4eDuP9IujzXnFqlQzJWcTcAkwQ0TqAXG4LiRrgL+KSG0v3eW4+WlLR/wNMO0F\nt9RlUv4jmkWEv18Xz+Ujp/PEfxbz6f9dWGpFKq7Y2FjS0tKwGShKRmRkJLGxsYEuhjGmgrCA8xy1\n48Axnvp6KZ0a1+L/erUIdHEqLBH5BFdTGSUiacDTQDiAqr4J/BkY43UJEeBRVd3tHftnXL9ngGdV\ntaDBR2enbguI7QqpnxYYcALE1Ijkrp7NeXHySnYeOEZMjfJRCxYeHk6zZs0CXQxjjDF+WMB5DlJV\nHvl8ERlZObw0KIHQEGt+LC2qOqSQ/VtxtZf+9r0HvFca5fIr/gaY+LBbg/y8DgUm7R0Xw4uTVzJ1\n1S4GJTYqMK0xxhhjnfbOQR/P3cS0Vbt4/Mo2NIuqGujimPKi3bUQElbo4CGA8+tXp16NCKau9LcQ\nmDHGGHMqCzjPMRvTD/PchOX0bBXFb7s3CXRxTHlSte7JpS5zsgtMKiIkt45hxurdZGbnlFEBjTHG\nBCsLOM8h2TnKH8alEhoi/H1gPCHWlG7yir8BDm2H9XlnHjtd7zbRHDyWxYKNBS5+FPyO7IFZr0CW\nrSVvjDFnygLOc8jbM9aRsnEvzw5oR/2alQNdHFMete4HETXd4KFCJLWMIixEmLqqgo8Kn/YCfP8k\npH4c6JIYY0zQsoDzHLFi+wFe+m4VV7Q/j2vK6VrYphwIj4R217hVhzIOF5i0emQ4iU1rM2VFBe7H\neWgXzH/fPZ85ErKzAlseY4wJUhZwngMysnJ46NNUalQO4y/XtLdJsU3BOg6GzMNuffVCJMfFsGL7\nwYq7vvqc1yHrGFw6HPauh6VfBrpExhgTlCzgPAe88r/VLN92gL9dG0/dahGBLo4p7xpdADUbw6LC\nR6v3josBqJij1Y/ug3nvQNsB0OMBiD4fZr4EOTZIyhhjissCzgpuwaa9vD51Ddd3ieWytvUCXRwT\nDEJCIH4QrJsKB7cXmLR1vWo0qBnJ1JUVsB/nvLfh+AHoOdS9Jz2Hws5lsGpSoEtmjDFBxwLOCuxo\nRjZ/GJdK/ZqVeepXbQNdHBNMOg4GzXFTJBVARLg4LoaZa3aTkVWBav4yDsOcN6DlZVC/o9vW7lqo\n3RRm/ANUA1o8Y4wJNhZwVmDPT1rO+t2HefH6eKpHhge6OCaYRLWCBp2L2KwezaHjWcyvSNMjLfgA\njqRDr4dPbgsNg6QHYcv8Ik0bZYwx5iQLOCuomat38/7sjdye1IweLaICXRwTjDoOdstc7lhWYLIe\nLaMID5WK048z67ibd7NJEjS+4NR9CTdCtfNg+ojAlM0YY4KUBZwV0P6jmQz7PJUW0VV5pF9coItj\nglX760BCC63lrBYRRrdmdSpOP87UsXBwK/T8w+n7wiKgx+9hwwzYPLfsy2aMMUHKAs4K6JnxS9l5\n8Dgv35BAZHhooItjglXVKGh5KSz6rNClLpNbx7Byx0G27jtaRoUrJdlZMPNlqJ8ALfr4T9PlVqhc\nB2a8VKZFM8aYYFbmAaeI9BORlSKyRkQeyyfNIBFZJiJLReRjn+3ZIrLQe4z32d5MRH728vxURCqV\nxbWUR98u2cZ/ftnCfb1bEh9bK9DFMcGu4w2utm/DzAKT9W4TDRD8tZzLvnLzbfb8A+Q3X21ENbjg\nHjdaffuSsi2fMcYEqTINOEUkFHgNuAJoCwwRkbZ50rQCHgeSVLUd8KDP7qOqmuA9rvbZ/gLwsqq2\nBPYCd5TmdZRXuw4e54kvl9ChYU3u69My0MUxFUHclRBRAxYVvNRli+hqNKxVmSnB3I8zJ8eNQI+K\ngzZXFZy2211Qqbqbl9MYY0yhyrqGsxuwRlXXqWoGMBYYkCfNXcBrqroXQFUL/AQTt2xOHyB3/pb3\ngWtKtNRBQFV54svFHDqexUuDOhIear0lTAkIrwxtr4ZlX0PGkXyTiQi920Tz05rdHM8quPm93Fo9\n2c2zmTvvZkEq14aud7iVh9LXlk35jDEmiJV1VNIQ2OzzOs3b5qs10FpEZonIHBHp57MvUkRSvO25\nQWVdYJ+q5i5y7C/PCu/z+Wl8v2wHj/SNo1W96oEujqlI4gdDxiFYObHAZMmtYzickU3KhiCcHknV\njTyv1RjaDyzaMRfeC6GVXJ9PY4wxBSqP1WBhQCsgGRgCvC0iuZ0Rm6hqInAjMFJEWhQnYxG52wtY\nU3btCvK+Zj7S9h7hmf8uo3uzOtye1CzQxTEVTZMkqBHrRm8XoEfLulQKDQnO6ZHWT4ctKW6ezdCw\noh1TLQY63+zel/1ppVs+Y4wJcmUdcG4BGvm8jvW2+UoDxqtqpqquB1bhAlBUdYv3cx0wFegEpAO1\nRCSsgDzxjntLVRNVNTE6OrpkrijAcnKUYZ8tQlUZcX1HQkLyGehgzJkKCYH462Htj3Ao/2CySqUw\nujevw5RgHDg0Y4SbXzPhN8U7rsfvAYWfXi2VYhljTEVR1gHnPKCVN6q8EjAYGJ8nzVe42k1EJArX\nxL5ORGqLSITP9iRgmaoqMAXIbQe7Bfi6tC+kvBjz0wZmr0vnqV+1pVGdKoEujqmo4geDZsOSLwpM\nlhwXw5qdh9i8J//+nuXO5nmuhrPHfRAeWbxjazWG+Btg/vtwKAgDbWOMKSNlGnB6/SzvAyYDy4Fx\nqrpURJ4VkdxR55OBdBFZhgskh6lqOnA+kCIiqd7251U1dwmUR4GhIrIG16fz3bK7qsBZs/MQL3y7\ngj5tYhiU2KjwA4w5UzFt3JrihTSrJ8d50yOtCqLga+ZLbhBQl9vO7PiLHoKsY/DzGyVbLmOMqUCK\n2Fmp5KjqRGBinm1P+TxXYKj38E3zE9AhnzzX4UbAnzOysnP4w7iFVKkUyvPXdUDymzPQmJISPxgm\nPw67VkK0/xWsmkdVpXGdKkxbuZObLmhSxgU8AzuWusFQyU+4+TXPRFQraDsA5r4NPe6Hyjb/rTHG\n5FUeBw2ZInh96lpS0/bz3K87EFO9mM2AxpyJDgPdUpcF1HKKCMlx0cxak86xzCCYHmnGS1CpmptX\n82z0/AMcPwDz3imZchljTMmSSJ8AACAASURBVAVjAWcQWpy2n1f+t5oBCQ24skP9QBfHnCuqxUCL\n3rD4MzdJej56x8VwNDObeRv2lGHhzkD6Wlj6H0i8HarUObu86sdDq8thzusFzldqjDHnKgs4g8yx\nzGyGjltI3WqVePbq9oEujjnXxA+G/Zth46x8k1zQvC6VwkKYsqKc9+OcNRJCwuHC+0omv55/gCPp\nsOD9ksnPGGMqEAs4g8w/vlvJ6p2H+PvAjtSsEh7o4phzTZv+rgm6gKUuK1cK5cLmdZm6qhzPx7l/\nCyz8BDrfBNXrlUyejS+AJhfBrFcgK6Nk8jTGmArCAs4gMn/jHt6ZuZ7fXtCYi1tXjHlETZCpVAXO\n95a6zDyab7LkuGjW7TrMpvRy2rw8exSgkPRAyebbcygc3Aqpn5RsvsYYE+Qs4Awin87bTPWIMB6/\n4vxAF8Wcyzre4AbIrJyUb5LecTEA5bOW8/BuSBkNHQa5eTRLUos+UD/BLXeZnVV4emOMOUdYwBkk\nVJVZa9JJahlF1Ygyn83KmJOa9oTqDdw0QMcO+E8SVZWmdaswZUU5DDjnvOHmzbzooZLPWwR6PQx7\n18Oyr0o+f2OMCVIWcAaJjelH2LLvKD1aRgW6KOZcFxLqgrVNs+HVzm6VnZzTp0BKjoth9rpyNj3S\nsf0uUG57NUS3Lp1zxPWH6DZuyqUCRvMbY8y5xALOIDFzzW4ALrKAM6iIyHsislNEluSzf5iILPQe\nS0QkW0TqePseEpGl3vZPRKT8TLja/W64ewrUaQH/vR/euhg2zDwlSXJcNMcyc5izLj1AhfRj3jtw\nfL8bUV5aQkLgoqGwcymsnlx65zHGmCBiAWeQ+GntbhrWqkzTurZeepAZA/TLb6eqvqiqCaqaADwO\nTFPVPSLSELgfSFTV9kAoMLgsClxkDTrB7d/CwPfg6D4Y0x8+vQn2bgDc9EiR4SFMXVlOpkfKOAKz\nX4eWl7llOktT++tc/9DpI0C1dM9ljDFBwALOIJCdo/y0Np0eLeraEpZBRlWnA0WdAX0I4Du8OQyo\nLCJhQBVgawkX7+yJuODqvnnQ+4+w5gcY1Q1+eIbInCNueqSV5aQf54IP4Mju0q3dzBUaBkkPwpYU\nWD+99M9njDHlnAWcQWDZ1gPsO5LJRa2sOb2iEpEquJrQLwBUdQswAtgEbAP2q+p3+Rx7t4ikiEjK\nrl0Bqk0MrwwXPwK/nw/tfg0zX4JXu3Bn9dlsTD/E+t2HA1OuXFkZ8NMr0LgHNLmwbM6Z8Buodh7M\n+EfZnM8YY8oxCziDwKy1rv/mhS3qBrgkphT9CpilqnsARKQ2MABoBjQAqorIb/0dqKpvqWqiqiZG\nRwd4ftYaDeDaf8Gd/4NajUla8hRfV3qSZXMC3Jdx0adwYAv0KoPazVzhkdDjPlg/DdJSyu68JWzf\nvn28/vrrAS2DiHQSkXe9521EZLaIHBeRhws4ZoZP/+itIvKVtz3fftPe/lAR+UVEvvHZ9q6IpIrI\nIhH5XESqFbP8U0UksfhXDiIyUURqncmxRch7QwnlU6zrE5EIEflURNaIyM8i0tTbniwiY4p57jEi\nMtB7/qD35b1MiUiCiFxZQnk1za/Pf550ESLyg3cf33CW99gp75uIVBKRt0RklYisEJHr8qS/TkQ0\n93wi0qEov7ciBZwi8rGI9CzmNZgSMmvNbuLqVSemevkZM2JK3GBObU6/FFivqrtUNRP4D9AjICU7\nE7GJcMf3cO3b1A89QP+U2+Cz22Df5rIvS062mxezfgK0uKRsz93lNqhcO6hrOQMZcHrdSQCeAF7x\nnu/B9W8eUdCxqtrTp3/0bNzfUL79pn0OfQBYnie7h1S1o6rG41odSmg91MKp6pWquq+szldG7gD2\nqmpL4GXghRLK90Fc96OylgAUK+D0ubfPVCcA717Of+m3osn7vv0R2KmqrYG2wLTcHSJSHfc38nPu\nNlVdDMSKSIETGxe1hvMCYKo3Yvb+0vq2ZU53LDObeRv2kGSj0yssEakJXAx87bN5E3CBiFQR13H3\nEk7/ECzfRCB+EO90/IxROdehKyfCqET48TnIKMMm9mVfwZ61ru9mWfeBjqgG3e+BlRNhx9KyPXcJ\neeyxx1i7di0JCQkMGzYMOFFLOM+r8XvG29ZURJaLyNveZ8V3IlLZ23e/iCzz0o/1ttURka+8bXNE\nJN7bPlxEPhSRWcCH3gdcvKqmAqjqTlWdB2QWpfwiUgPoA/ibGPWUftMiEgv0B97xTaSqB7z9AlQG\nChwJJiKVRWSs93586R2Tu+9yr4Z2gYh8JiLVRKSfiHzmkyY5t4ZVRDaISJT3/Gbv/UoVkQ+9bdEi\n8oX3+5gnIklFeV88J/rgiMijIrLYy/t5b9uJWjMRicqtES3k+t4Q18Vnae694ccA4H3v+efAJd57\nmwHsL6jA4owSkZUi8gMQ422/H9caNEVEpojI7SIy0ue4u0TkZe8+XSEiH3nl/zy3dk9EuojINBGZ\nLyKTRaR+YW+giFQCngVu8KltLOq9XU9EvvTe81QRya1UCPX3d+Rzzhjg30BX75wt8uwf4v0ul4jI\nCz7bT/vd5H3fvKS3A38DUNUcVd3tk/2fcV8QjuV5K/5LYQNbVbVID6Av7htiBnAYGA1cUNTjy9uj\nS5cuGgxmrdmlTR79Rn9Ytj3QRTHFAKS4H3yC64OZCaThvtn/DvidnvzbuhUYq3nuUeAZYAWwBPgQ\niMibJu+jPN7X01ft1CaPfqMzUxaofna76tM1VEe0UV04VjU7u3RPnpOj+noP1VcTS/9c+Tmcrvpc\nA3ftQWj9+vXarl27E6+BVcBbgOAqLb4BegFNgSwgwSVjHPBb7/nW3PsXqOX9fBV42nveB1joPR8O\nzAcqe697A1/o6X8fw4GH8273k+5m4HM/26vgakvr+Gz7HOgCJAPf5Ek/GtgBTAGqFHLOocB73vN4\n731JBKKA6UBVb9+jwFO4AYKbfLa/4fPebfCOa+e991He9jrez4+Bi7znjYHlPu/bQj+Pn/yU9wrg\np9zr8sl7Km6mDLwybCjo+vIcG+odH++9fha42nu+BIj1Of/a3Osqwu/zWuB7L/8GwD5goO975T2v\n5uUb7r3+CeiAu08VSPK2vwc8DIR7aaK97Tf4XOOwfN7LV/Tk//BRPmUs6r39KfCgz/tVkwL+jvK8\nD8n43KO5vyvvPdkEROPuqx+Bawr53fi+b7WAzcBLwALgM6Cet68z3t8iPveG9zoJ+G9Bv7si9+FU\n1cmqei3uhn4edzPPEtfX5XdSzD4tpmhmrdlNaIjQvbn13wxGqjpEVeurariqxqrqu6r6pqq+6ZNm\njKqe9s1QVZ9W1Taq2l5Vb1LV42Vb+pLRrVkdKoeHMjktHAa+C7d/B9XrwZd3w7uXweZ5pXfyVZNh\nxxI3L2ZIgLqsV6kDXe+Apf+B9LWBKUPJqgFcDvyC+0BqA7Ty9q1X1YXe8/m4D0+ARcBH4voh5675\neRHuixSq+iNQ16uNBBivqke95/XxqYk7A3lnf8iVt9/0VbhmxPn+MlHV23Af5stxwUhBeuFqoFDV\nRbjrB9da2Bb32bkQuAVooqpZwLfAr8Q1tfbn1BYPcIHLZ+rVNunJbgCXAqO8/MYDNUSkmqpOUa/r\nQJ6Hv645lwKjVfVInryLe30Ag0RkAe7+aOddL6r6lKqOLyTfougFfKKq2aq6FRdQnUZVD3n7rhKR\nNrjAc7G3e7OqzvKe/xt3L8YB7YHvvffyT0Csl9eL+byX9+dTxqLe231wXy7wrie3dje/v6Oi6ApM\nVdcdKwv4CPeeQT6/mzzCvOv+SVU747qjjBCREFwQml9H+J24v498Ffs/sKpuV9U/4/qTzQA6Aq8D\nW0XkRRGpWtDxXtPBSnGdhR/LJ80gcc0vS0XkY29bgtcMsdSrpr7BJ/0YEVkvJzuCJxT3usqrWWvS\n6dSoFtVsOUsTpCLCQklqWZcpK3e6b8KNu8OdP8I1b8L+NHj3UvjiLtj6C2QXqZW0aFRhxgg3H2aH\ngSWX75m44F4ICYdZ/wxsOUrO33w+dFuq6rvedt8vRdm4Dy9wAdRruBqSeVJ4/zXfPhdHgTPqwO41\nRXcDJvjZnbffdBJwtddsPBboIyL/9j1AVbO9facMoihOkYDvfd67tqp6h7dvLDAIF4SkqOrBIuYZ\ngmttzM2zoaoeEpHePp+Jvo+filHeLE7GCYX+DkSkGa628BJ1/V0n5HPcFqCRd0wYrmavNFaIeAdX\n+3gbroY6V94uEYr73Sz1eR87qOrlXhmH5fNevkLxFaU/UX5/R2esGL+bdOAIXp9nXA1nZ6A6LiCf\n6v2NXACMl5MDlSJxf6v5KnbAKSJ9RGQcsB5XPf0yLvh8FddU+EEBx4bi/ulcgYush4hI2zxpWuE6\nciepajtcZ1Zwb8DN3rZ+wEg5tS/pMJ8bZSEVwP6jmSxK22fLWZqgd3FcDJv3HGVd7vRIISGQMMRN\no9TzYVj2NbyVDH9tCG9fAhOHwcJPYNfKM18ecsMMSJsHSQ9AaHiJXcsZqV4POt8ECz+G/VsCW5Zi\nql69OgcPnhL7HABuz23VEpGGXp8yv7yakUaqOgXXhFwT19w5A/iNlyYZ2K1eX8k8lgMtz7D4A3HN\njqf0NxM//aZV9XGvFaIpLhj9UVV/K05L7zgBrsZ1dUFEfi0if/Nz3unAjV6a9rhmZ4A5QJJPflVF\nJHeN1Wm4D/a7cMFnXj8C14tIXe/Y3JH13wG/97m2BO96ilPD+T1wm5zsy5ib9wZcFwNw72Vh11cD\nF1DtF5F6uM96f8bjandz8/1RvXZZn+voJiL+4onpuP6SoeL6WPb22XcQFxjhvQc/4wLbGzn1y0Vj\nEcmdH+1GYCawEojO3S4i4SLSzsunsBrOU85L0e/t/wH3eOlCvfvybM0FLhbX5zYUV8M/jYJ/NyfK\n7/0e/otrsgc3fmCZqu5X1ShVber9jczBdZHInYKjNa6rRL6KFDV7N/htwN1AC1wzyu9w1dq5f8hz\nRGQx8K7/XAD3TXONqq7z8h2L6zy8zCfNXcBrqroXXAdx7+eq3ASqulVEduL6KFS00XsnzFmXTo7a\ncpYm+CW3dtM1TVmxkxbRPr1vIqrBJU9Ct7tg4yzYssDVdP7yEcx9y6WpVB0aJHiPztCwM9RqUvgA\noBn/gGr1IMHvbFJlL+kBmD8GZo+Cfv5ilPKpbt26JCUl0b59e6644gpwAefHwGwXf3EI+C2uJsaf\nUODf3oep4Pq97ROR4cB7IrIIV6Fwi7+DVXWFiNQUkeqqelBEzgNScB+gOSLyINBWVQ+IyETgTq+p\nFVzg+LyfbH8NfKeqRaltEuB9r0lUgFS8IAH3eegvkHgDGC0iy3EB83zvWnaJyK3AJyIS4aX9E7BK\nVbPFDRS61d97oapLReQ5YJqIZOOaRW/Fjdh/zXsfw3AB2e+KcF2+eX/rBaopIpIBTMTNDDACGCci\nd3NqLXF+15cqIr/gAvLNQG6zNSLyLK7mdjwuTvhQRNbg+tH6G2zSGP81Zl/iaoGX4foqzvbZ9xbw\nrYhsVdXcQHQcrj/kXp90K4F7ReQ9L583VDVD3PRKr3j3ahgwEijKaL8pwGPimuL/huurWei9jRvt\n/ZaI3IH7+7kH1+ffLxH5HYD6dMnKS1W3ea3HU3D36wRV/do73u/vhtPft0dxv5+RuO4stxV8+YAL\n/P21JJwsf54vFf4TiRwDcnAdXF9XN0LQX7oE4EtVbZbP/oFAP1W903t9E9BdVe/zSfMVrmN0Eu4f\n1XBV/TZPPt1wI9zaqWqOuPmfLsRVQ/8PeEz99Hfz/mjuBmjcuHGXjRs3FnrtgfT010sYl5JG6tOX\nUynMpkwNJiIyX1XPaE60s5GYmKgpKeVzzsdLX5pG/ZqRfHhH98IT52TD7lVeALrA/dyxBLIz3P4q\ndd3SmrkBaIPOrhYxV9p8eKcPXPZnSMqvm1UAfHmPGzX/4GKoGpxfJANxb4vIQ8BBVX2n0MRlyGty\nf0hVy8n6rRWHiLwIfOj1ET2bfL4BXlbV/3mvm+JqvdufdSEN4OYExdWiXuT1G/WrqP0CnsB1KN5b\nUCKvKdtvsFkMYbgO6Mm4jqvTRaSDevOQeVXoHwK3qGpuW9vjwHagEi5SfxQ3Ii5v+d7y9pOYmFju\nFzieuWY33ZvXsWDTVAi946J5/6eNHD6eRdXC+iSHhELM+e7R6TduW9ZxN7XQ1gWw5RdXE7p2BOT+\nG6jR0AtCO8G6qRBZCxKL8sW8DF30EKR+AlP/Bh2HBLo0+avREGoUOiNMWXoDuD7QhchLVctJ9XnF\no6rDzuZ4r8vdXCA1N9g0paYxrqIv32ATihhwqupLJVIkn47Cnlhvm6804Gd1k12vF5FVuAB0ntek\nMQH4o6rO8SlfbhX0cREZjesYG9S27z/G2l2HGdKtwHlUjQkayXExvD1jPbPXpnNp23qFH5BXWISr\nzWzY2Y3DBDef57ZFJ2tBty6AFd4CMclPQET1fLMLiOjW0HYAzHvHPcqry551XQDKCa/r1oeBLocJ\nHl4lVWs/2zfgBr+YEqKqq4HVhaUrah/Ol3FzNN3kZ9+HwPYifhuZB7TyRkttwfXbuDFPmq9wnVxH\nixth2BpYJ25y1S+BD1T18zxlqO/1WxDgGgrpuBoMZq1x86z2aBGczW7G5JXYtDZVK4UyZeXOMws4\n/alU1a2N7rs++tG9brBRwy75HxdIV78CnW6ikLnDA6vumY7RMcYY/4rapH41rhOsP5OBp3EToxZI\nVbNE5D7vmFDcpKpL83QmngxcLiLLcJ1oh6lqurj523rh5rO61cvyVq8Z/yMRicZ1kF1IMTtMl0ez\n1uymbtVKtDmvnNXQGHOGIsJC6dEyiqkrd6GqSGmt+lO5NjS+oHTyLgmRNaHVpYEuhTHGlKmiBpwN\ncaPB/Enz9heJqk7EjYDz3faUz3PFrWIwNE+af+NNNOsnzz5FPX8wUFVmrd3NhS3qEhJSxkvxGVOK\nesfF8P2yHazZeYhW9ezLlDHGnCuKOhplL/nPg9YSNy2GKSFrdx1ix4HjNh2SqXCS49z0SFNX2qBe\nY4w5lxQ14PwB+JM3WegJ3usncJPGmhIyc7Xrv5lkAaepYBrUqkxcvepMWbkz0EUxxhhThooacD6J\nWxlitYh8LCJ/F5GPcPNlVsVNXGtKyKy16TSuU4VGdaoEuijGlLjkuGjmbdjDoeMFzqBhjDGmAilS\nwOlNI9AVN4K8N265yd64UePdVHV9aRXwXJOVncOctelWu2kqrOS4GDKz9cRMDMYYYyq+Ii8I7wWd\nN5deUQzA4i37OXg8y/pvmgorsWltqkWEMXXlLvq2Oy/QxTHGGFMGbAmbcia31ufCFnUDXBJjSkd4\naAgXtYxi6sqdFGVpXWOMMcGvyAGniMSIyAMi8rqIvJfn8W5pFvJcMnPNbto1qEGdqpUCXRRTgPT0\ndL/bv/32W+Li4gDai8hj/tKIyCARWSYiS0XkY5/tt4jIau9xi8/2b0Uk1Uv/poiEetuHi8gWEVno\nPa4s0YssRclx0Wzbf4xVO2yCC2OMORcUKeAUkThgBfBn4P+A/sBNwK3AAFx/TnOWjmZks2DjPuu/\nWY68/fbbvPjiiydeL168mNjYWGJiYkhMTGT79u0n9mVnZ3PvvfcyadIkgKXAEBFp65ufiLQCHgeS\nVLUdrj80IlIHt4BCd6Ab8LSI1PYOG6SqHXHLsUVz6prSL6tqgvc4ZX7b8iw5LgbARqsbY8w5oqg1\nnC/ilqWsh1vN5wqgMnAncAT4damU7hwzb8MeMrJzLOAsR1599VUqV6584vXQoUOpVasWI0eOZP/+\n/Tz11Ik1C5g7dy4tW7akefPm4NYtHIv7QubrLuA1Vd0LoKq5EVdf4HtV3ePt+x7o56U54KUJAypR\nrtdELJrzakbS5rzqTLWA0xhjzglFDTi7Aq8Dx3OPU9UsVX0PGAWMLI3CnWtmrdlNpdAQujatXXji\n8ig7CypYn7yNGzfSpk0bAPbv38+0adP4+9//zu9//3ueeeYZJk+efCLtli1baNSoke/h/lbhag20\nFpFZIjJHRPp52xsCm/M7VkQmAzuBg8DnPunuE5FFXteWoLpxereJIWXDXg4eywx0UYwxxpSyogac\n1YA9qpoD7Ad8q+Dm4QJSc5Zmrd1Np8a1qFKpyJMHBFZWBmycDVNfgNH94a/14R9x8MWdsOAD2Lsh\n0CU8azk5OYSEuD+TmTNnIiIkJycD0KhRI3buLHYNXRjQCkgGhgBvi0itwg5S1b5AfSACyF3K9Q2g\nBZAAbAP+UdzCBFJy62iycmx6JGOMORcUNbLZAOTOX7IS14fsW+/1VcC+ki3WuWfv4QyWbj3A0Etb\nB7oo+cvJhm2psH66e2yaDZlHAIH68dD1Tji0E9ZNg8WfuWNqNYZmvaDZxdC0J9SoH9BLKK5WrVox\nYcIE+vTpw9ixY+nRowdVqrgJ+bdu3UqdOnVOpG3YsCGbN/tWUhILbMmTZRrws6pmAutFZBUuAN2C\nC0J9j53qe6CqHhORr3HN9N+r6o7cfSLyNvDN2VxrWevcpDbVI8OYsmIX/doH131hjDGmeIoacH4P\nXAZ8BrwEjBWRi4AsoA3wXOkU79wxe106qtAjv/6b+9NcbeK+jVAzFmo1gdpNoNp5EFJKs1vl5MCu\n5V6AOQM2zITj+92+6DbQ6bcumGySBFVOBl6owq6V7rgN02H5N/DLv92+qNYu8GzWy/2sWr6nf3r4\n4Ye56aabeP/999m7dy+fffbZiX1TpkwhPj7+xOuuXbuyevVq1q9fD66v82DgxjxZfoWr2RwtIlG4\nJvZ1wFrgrz7N4pcDj4tINaC6qm4TkTDcgL0ZACJSX1W3eel/DSwB2pXg5Zeq8NAQeraKYuoqNz2S\niAS6SMYYY0pJUQPOx3FNeajqOBE5CtwAVAH+CbxdOsU7d8xcs5tqEWF0jK3pArbdq2HjLFeLuHE2\n7N/k/8DQCKjV6GQAesrPplC5NhT1g1wV9qyD9dNOBplHvObO2s2g3TUnA8Xq9fLPRwRi2rhH97td\nzeiOJSdrRhd9CineTFr1Ong1oL2gSQ+IrFHk96ws3HjjjTRu3Jiff/6Zrl270qtXrxP76tWrx9VX\nX33idVhYGKNGjaJv377gAr8/q+pSEXkWSFHV8cBk4HIRWQZkA8NUNR1ARP6M66IC8Kyq7hGResB4\nEYnAdYGZArzppfm7iCTgBhFtwM0gcUPpvBOlIzkuhomLt7N820HaNihfv3tjjDElRwqbeNmb8689\nsFVVd5VJqcpAYmKipqSkBLoYTnYWd704mkurrOWGmM2wac7JQK9qNDS+0AVjjS+EqFZwYCvs3Qj7\nNng/N578eXTvqXlXqu6atU8LRr2fR/fChhkng8EDXgtw9QYnA8FmPV0eJXa9mbD1l5OB7aafIfs4\nSCg06HTynI0ugErBuZ68iMxX1cSyPm+5uq+LYOeBY3T76/94pF8c/y+5ZaCLY4ogUPe2MSa4FSXg\nDMGNTu+vqt+VSanKQEA/mDOPwpb5ruZy00/kbPqZkMzDbl+tJieDyyZJULdF0WsoAY4dODUAzfsz\n84j/46rUPVl72ezi4p/3bGQeg7R5J4PeLSmQkwUSAiHhZVOGfPy0KZM9R3O4Ki4CgPQjOdw34RBL\ndmTRt0M9Xpi8idDQ0NOOs4Cz6Pq/MoOqlcIY97sLA10UUwQWcBpjzkShTeqqmiMim4GqJXFCbxqY\nfwKhwDuq+ryfNIOA4bimwlRVvdHbfgvwJy/ZX1T1fW97F2AMbm7QicADWp7WzDu239XibfrJBZlb\nF0B2htsX05Z19a/in2uieeiOW2je4iwHDUXWgPM6uEdeqnB4txeAbnA/w6u4QDP6/NLrC1qY8EhX\no9msJ/BHOH7I1fKmzYWs44UeXpoeGzeGSzo146oLLgZg2D/GM3Htci7t3Io3Zq2j5l//ypNPPhnQ\nMga75Lho3py2jv1HM6lZObBfMIwxxpSOQms4AUTkUeBK4DJVzTjjk7nm+VW4AUhpuP5qQ1R1mU+a\nVsA4oI+q7hWRGFXd6a3EkgIk4gLR+UAXL81c4H7gZ1zA+YqqTiqoLGVSE3RwO3wyGLYudEUOCXNN\nxrlN5I26Q5U63P/JL8xZl87PT1xiAyfKmejoaMaMGUP//v3JzMykbt26jBw5kttvv52RI0fyr3/9\ni+XLl592nNVwFl3Khj0MfHM2r93Ymf7xNlq9vLMaTmPMmSjqoKHquPn+1onIt7g5/3wjVVXVp4uQ\nTzdgjaquAxCR3JVYlvmkKXQlFu/Y74F+IjIVqKGqc7ztHwDXAAUGnGVi1WTXV/Gih6B5b4hNhEqn\nVhTnePMQ9modbcFmOXTo0CFq1HCDWebOncvhw4e56qqrAOjcuTObNuUzmMsUWUKjWtSsHM53y7Zb\nwGmMMRVUUQPOJ3ye3+5nv+LWgS6Mv9VUuudJ0xpARGbhmt2Hq+q3+Rzb0Huk+dl+GhG5G7gboHHj\nEhwEk59Ns92gn0uezrc/5ModB0k/nGHLWZZTDRs2JDU1lZ49ezJp0iTat29PTIxbB3zv3r0n5uQ0\nZy4sNIQBCQ0YO3czT151nKhqEYEukjHGmBJWpE57qhpSyOP0URNn7oxWYikKVX1LVRNVNTE6Orok\nsizYptnQ+IICB9/krrKS1LJ8z0d5rhoyZAhPPPEEAwcO5KWXXuK3v/3tiX0LFiygVatWASxdxXHz\nhU3JyM7h03mbC09sjDEm6JT1KJEtgO9i0/mtxDJeVTNVdT2uz2erAo7d4j0vKM+yd2CbG5jTuOCR\nt7PW7KZ5dFXq16xcNuUyxTJ8+HAeffRRjh8/zmOPPcZDDz10Yl9qairXX399gcd7a5zvFJEl+ewf\nJiILvccSEcn2+isjIrVE5HMRWSEiy0Wkwg7jbhlTjYtaRvHvORvJys4JdHGMMcaUsLJetHse0EpE\nmuGCwrNeicWbHPuAP68WPgAAIABJREFUiFyAGzR0M/Bq6V9KIf5/e3ceHlV5Nn78e2cSEnZI2ElY\nRGQRWSQigguLVmwVRWSTVrC1vviroravVgtVtNrXVvpW+7bVWlREaUBU0Fo3EHADlMgmJGyyJIEQ\nQsIOSUhy//44J2FIZpIJWWaS3J/rmiszzznnOXdmTpib5zxL6hrnZ6fBfnfJyy/k693Z3DYw1u8+\nJrg8Hg8zZszwuW3JkiWBVDEX+Cswz9dGVX0WeBZARG4CHizqp4wzm8NHqnqbiDTAWWihzpoypAs/\nn5fI0qQMbrjE+nIaY0xdElDCKSKFnDtIqJRAbqurar6I3Iuz2ooHeKWyK7G4z/8fZ6dF+pBQGDC0\nd7Uz5VC7vn532Zh2hFN5BQzpZv03Q93mzZv57LPPyM7OJjo6mmHDhnHxxeWvIqmqn4tIlwBPMwlI\nABCR5sDVwFS3njzgvGeIqA1G9GxDbMuGvLZ6jyWcxhhTxwTawvkkpRPOGJxWxkicZC8gqvoBztRF\n3mWPeT1X4Jfuo+SxrwCv+ChPxFkNKXSkrIbYy8Djf17BL3ccIkzgigus/2aoys/PZ+rUqSQkJOA9\nhZiIcPvttzN37lyfE79XlIg0AkYB97pFXYFMnJb+fjjTgN2vqicrfbIQ5QkTfjK4M//z4Va2HjhG\nz3a21KUxxtQVgQ4amqWqT5R4TMdZLzoZOFqtUdY2OcectcPL6b+56vtDXBLbguaNbLLrUPXEE0/w\n5ptv8uSTT7J7925Onz7N7t27efLJJ1m4cCFPPvlkVZ3qJuArr1b7cOBS4AVVHQCcBB7xdaCI3C0i\niSKSmJlZu1efHR8fR2R4GPNW7w12KMYYY6pQpQYNqWoB8HfggaoJp45IWwtaWGb/zRO5+axPOcLQ\nbta6GcreeOMNZs6cyYwZM+jcuTORkZF07tyZGTNmMHPmTObN89k183xMxL2d7koD0lT1a/f1WzgJ\naCk1PvtCNWrZuAE39+/A4nX7OHrqTLDDMcYYU0WqYpR6JBBdBfXUHSmrQTzOLXU/vtmdRX6hcqXN\nvxnS9u/fz5AhQ3xuGzJkCPv376/0Odz+mtcA7xaVqeoBIFVEerhFIzl3gYQ6644runD6TAGLvrUp\nkowxpq4IKOEUkU4+HheKyC3AMzhLTpoiKWugfV+IbOJ3l692ZhEZHsalnVv63ccEX4cOHfjqq698\nblu1ahUdOnQo83gRSQBWAz1EJE1EfiYi00RkmtduY4BPfPTPvA+YLyKbgP7A78/396hN+nRsTnzn\nlry+Zi+FheUvvWuMMSb0BTpoaA++R6kLznRFv6iqgGq9/DxIS4T4O8vc7audh7isSzRREVU5Z76p\napMnT+bpp58mLCyMyZMn0759ew4cOMCCBQt4+umn+fWvf13m8ao6qbxzqOpcfAy8U9UNQL1cs3rK\nkC7cl7Cez7ZnMrxnm2CHY4wxppICTTh/SumEMwfYC6x1+3IagPSNkH+6zP6bmcdz2XrgOL8e5XMF\nThNCZs2axa5du3j88ceZNWtWcbmqcvvtt/PYY4/5P9ict1F92tGmaSSvrd5jCacxxtQBASWcbguM\nCUTKaudnGSPUV31vy1nWFuHh4fzrX/9ixowZfP7558XzcF599dWkp6dz6aWXsmnTpmCHWedEeMKY\nfHln/rxsO7sPnaRrq8bBDskYY0wlBDrx+0VAe1X9zMe2q4F0Vd1R1cHVSilrILobNPHfKvPVzkM0\nbxjBxR2a12BgpjIuvvjiUhO9b926lS1btgQporpv0uVx/HXFDl5fvZfHbuod7HCMMcZUQqCj1J/D\nmSfQlxuBP1dNOLWcqtPCWUbrpqry1c4srrggBk+Y1GBwxtQubZpG8cNL2rMoMZWTufnBDscYY0wl\nBJpwxgOf+9n2OeB//p/65NB2OJ1dZv/NvVmn2HfkNEO723RIxpTnjiu6cDw3n8Xr9wU7FGOMMZUQ\naMLZFGeQkC9nALs3DGf7b3b2PW8jwJc7nf6bNv+mMeW7tFML+nRsxrzVe85ZWtQYY0ztEugo9V04\nE09/4mPbCJxpk0zKGmjcGqIv8LvLqu8P0aF5FF1iGtVgYKYidu3aFdB+Bw4cqOZIjIgw5YouPPTW\nJlbvymJIN/uPmjHG1EaBJpzzgN+JSAowR1VzRSQSuAtnWctZ1RRf7ZKy2rmdLr77ZhYUKqu+z+K6\nXm0RP/uY4LvwwgsD+nxU1T7HGnBTvw78/oNkXlu1xxJOY4yppQJNOGfj9NP8P+B5EcnGWc4yDHgb\n+EP1hFeLHEuHw3tg0N1+d0naf4wjp85wpfXfDGmvvvpqsEMwXqIiPEwc1Il/fPY9+46cpmOLhsEO\nyRhjTAUFOg9nAXCbiIwArgNigEM4y/GtrL7wapEA5t/8yp1/84puNv9mKJsyZUqwQzAlTL7cSTjn\nr9nLw6N6BjscY4wxFRRoCycAqrocWF5NsdRuKWsgojG06+t3l692HqJH26a0aRpVg4EZU/vFtmzE\ndb3bsmBtKtNHdrclYY0xppYJaJS6iNwoIvf62fYLEflh1YZVC6Wshth48PjO4XPOFLB2TzZDbHUh\nY87LlCu6kH0yj/c3pQc7FGOMMRUU6LRIvwX8rS3X0N0eEBEZJSLbRGSniDziY/tUEckUkQ3u4y63\nfLhX2QYRyRGRW9xtc0Vkt9e2/oHGUyVyjkHG5jJvp69LOUzOmUKbDsmY83RFtxi6t2nCa6tsiiRj\njKltAk04ewLr/GzbAPQKpBIR8QB/A24AegOTRMTXmnULVbW/+5gDoKorispwpmI6xbnTND3kdcyG\nwH6tKpL2DWghdC6j/+bOQ3jChMsvsBZOY86HiHDHkC58t+8o61OPBDscY4wxFRBowhkGNPGzrSkQ\nEWA9g4CdqrpLVfOABcDNAR7r7TbgQ1U9dR7HVr2UNSAe6Bjvd5evdmbRP64FTSIr1G3WGOPl1gEd\naRoZzmur9gQ7FGOMMRUQaMK5EZjsZ9tkYFOA9XQEUr1ep7llJY0VkU0i8paIxPnYPhFIKFH2tHvM\nn905QksRkbtFJFFEEjMzMwMMOQB7V0P7vhDpOyc/evoMm9KOMNRupxtTKY0jw7ktPpYPvkvn4HF/\ni58ZY4wJNYEmnH8CbhWRRSLyAxHpLSLXicgiYAzwbBXG9G+gi6r2BZYCr3lvFJH2wCXAx17Fj+Lc\n9r8MZ37QX/uqWFVfUtV4VY1v3bp11USbnwf7Esvsv7lmVxaFCkNtOiRjKu0ngztzpkBJ+Dq1/J2N\nMcaEhIASTlVdDNwPXA98CHyHk/BdD0xX1XcCPN8+wLvFMtYt8z5Xlqrmui/nAANL1DEeWKyqZ7yO\nSVdHLvAqzq37mpG+EfJzykw4V+08RMMIDwM6tayxsIypqy5o3YRrLmrN/K/3cqagMNjhGGOMCUCg\nLZyo6v/h3P7+EfATYBTQAdgsIq8EWM1aoLuIdBWRBji3xt/z3sFtwSwyGkguUcckStxOLzpGnHUG\nbwE2BxhP5RVP+D7Y7y5f7jzE5RdE0yA84LfbGFOGKUM6c/B4Lh9vsfXsjTGmNqhQBqSqx1X1I+Ab\n4Eqcls7lOK2OgRyfD9yL0zqaDLypqltE5EkRGe3uNl1EtojIRmA6MLXoeBHpgtNC+lmJqueLyHdu\nPK2Apyrye1VKymqI7gZN2vjcfOBoDt9nnmSorQFtTJUZdlEbOkU3ssFDxhhTSwQ8ZFpEmgMTgClA\nUXPeRuAZSg/g8UtVPwA+KFH2mNfzR3H6ZPo6dg8+Bhmp6ohAz1+lCgudEeo9/c97/9VOZzlLGzBk\nTNUJCxPuuKIzT/0nmS37j3Jxh+bBDskYY0wZymzhFJEwEfmhiCwE0oEXgc44c2kCPKCq/1DVY9Uc\nZ2jK2gGns8teP33nIWIaN6Bnu6Y1GJgxdd+4gXE0jPAwb9XeYIdijDGmHH4TThH5E86Ann8DNwKL\ncfptdgIeA6QmAgxpxf03fSecqspX3x/iim4xhIXZ22VMVWreKIJbBnRkyYZ9HDmVF+xwjDHGlKGs\nFs4HgTY4t787qepkVf1EVQsBW1cOnPk3G7eG6At8bv4+8wQZx3JtOUtjqsmUIZ3JzS9k4VqbIskY\nY0JZWQnny8BxnFHp20TkryJSc9MN1QYpq53WTfHderl860EArrqoiub8NMaco2e7ZlzeNZrX1+yl\noND+H2yMMaHKb8Kpqj8H2uGsJJQI/BewWkSScSZWr9//uh/bD0f2ltl/c1nSQXq3b0bHFg1rMDBj\n6pcpQ7qQdvg0K9z/4BljjAk9ZQ4aUtUcVU1Q1aK+m48CBcAjOH04nxGRH4tIVPWHGmLKmX8z+2Qe\niXuzubZ32xoMypj65we929K+eRSvrd4T7FCMMcb4UZGJ39NV9Y+q2gdnJZ+/Ad2BeTgj2OuXlDUQ\n0Rja9fW5ecXWgxQqXNfLEk5jqlO4J4zJl3fiix2H2HnwRLDDMcYY48N5LX2jqomqeh/OSkNjgZVV\nGVStkLIa4i4Dj++pTJclZ9C2WSR9Ojar4cCMqX8mDupEA08Yr6/eE+xQjDHG+FCptRZV9YyqLlbV\nMVUVUK2QcxQytvjtv5lzpoDPtmdyba+2iJ8BRcaYqtOqSSQ39m3PW9+mcTznTLDDMcYYU4It7n0+\nUteCFvrtv7lmVxan8gq41m6n13si8oqIHBSRzX62PyQiG9zHZhEpEJFor+0eEVkvIu/XXNS105Qh\nXTiZV8A76/YFOxRjjDElWMJ5PlJWg3igY7zPzZ8mH6RhhIcrusXUcGAmBM3FWTDBJ1V9VlX7q2p/\nnEF5n6lqttcu9wPJ1Rti3dAvrgX94lrw2uo9qNbvSTSMMSbUWMJ5PlLWQPt+ENmk1CZVZVlyBldf\n1IqoCE8QgjOhRFU/B7LL3dExCUgoeiEisTjz4M6phtDqpKlDOrMr8yRf7jwU7FCMMcZ4sYSzovLz\nYF+i3/6bW/YfI/1ojt1ONxUiIo1wWkLf9ip+DngYKAxKULXQDy9pT0zjBrxm66sbY0xIsYSzotI3\nQH6O3/6by5IzEIERPdvUcGCmlrsJ+KrodrqI3AgcVNVvyztQRO4WkUQRSczMzKzuOENaZLiHSYM6\n8enWDFKzTwU7HGOMMS5LOCuqnAnflyVnMLBTS2KaRNZgUKYOmIjX7XRgKDBaRPYAC4ARIvKGrwNV\n9SVVjVfV+NatbRnVyYM7IUDCNynBDsUYY4zLEs6KSlkDMRdCk9ItmOlHT7N53zFG2u10UwEi0hy4\nBni3qExVH1XVWFXtgpOMLlfVHwcpxFqlffOGDOvRhrfXpdn66sYYEyJqPOEUkVEisk1EdorIIz62\nTxWRTK+pYu7y2lbgVf6eV3lXEfnarXOhiDSoluALC50WTr+tm85aztf1ttvpxiEiCcBqoIeIpInI\nz0RkmohM89ptDPCJqp4MTpR1z/j4WDKO5fL5jvrdxcAYY0KF72VyqomIeHCWxLwOSAPWish7qppU\nYteFqnqvjypOu9PHlPQH4M+qukBEXgR+BrxQlbEDcGg7nD7sd8DQp8kZdIlpRLfWpUevm/pJVScF\nsM9cnOmT/G1fSX1czasSRvRsS3TjBixKTGV4D/sPoDHGBFtNt3AOAnaq6i5VzcPpm3ZzZSoUZymf\nEcBbbtFrwC2VitKf4v6bpRPOk7n5rNqZZasLGRMCGoSHMWZAR5YmZZB9Mi/Y4RhjTL1X0wlnRyDV\n63WaW1bSWBHZJCJviUicV3mUOxp3jYgUJZUxwBFVzS+nzsqP5k1ZA43bQPQFpTZ9sSOTvIJCru1t\n/TeNCQXj4+M4U6AsWW8rDxljTLCF4qChfwNdVLUvsBSnxbJIZ1WNB24HnhORbhWpuNKjeVNWOf03\nfbRgLk06SPOGEcR3blnxeo0xVa5Hu6b0i23Om4mptvKQMcYEWU0nnPsA7xbLWLesmKpmqWqu+3IO\nMNBr2z735y6cPm0DgCyghYgU9UctVWeVOLoPjqT4vJ1eUKgs35rB8B6tCfeEYg5vTP10W3wcWw8c\nZ8v+Y8EOxRhj6rWazo7WAt3dUeUNcKZ7ec97BxFp7/VyNO460iLSUkQi3eetcOYpTFKn6WIFcJt7\nzBS8ppepMqlrnJ+dSyec61IOc/jUGbudbkyIGd2vA5HhYbyZmFr+zsYYY6pNjSacbj/Le4GPcRLJ\nN1V1i4g8KSKj3d2mi8gWEdkITAemuuW9gES3fAXwjNfo9l8DvxSRnTh9Ol+u8uBT1kBEY2h7SalN\ny5IyiPAIV19kk24bE0qaN4xgVJ92LFm/j5wzBcEOxxhj6q0anRYJQFU/AD4oUfaY1/NHgUd9HLcK\nKJ3tUXyLfVDVRlrC3tUQdxl4Sr9ly5IzGHxBDM2iIqo1BGNMxY2Pj+PdDfv5JCmD0f06BDscY4yp\nl6zDYSByjkLGZp/9N3dlnuD7zJNca6sLGROSrrggho4tGrLIbqsbY0zQWMIZiNS1gPpMOD91Vxca\n2csmlzYmFIWFCePiY/ly5yHSDp8KdjjGGFMvWcIZiJRVIB6IjS+1aWlyBr3aNyO2ZaMgBGaMCcRt\nA2MBePtbm5PTGGOCwRLOQKSsgfb9oEHjc4oPn8wjcU8211rrpjEhLbZlI4Z2a8Wib1MpLLQ5OY0x\npqZZwlme/FzY963P2+krth2kULH+m8bUAuPiY0k7fJo1u7KCHYoxxtQ7lnCWJ30j5Of4nH9zWXIG\nbZpGcknH5kEIzBhTEddf3I5mUeE2J6cxxgSBJZzl2bvK+Rk3+Jzi3PwCPt9+iJG92hIWVnqpS2NM\naImK8DC6fwc+3HyAo6fPBDscY4ypVyzhLE/KGoi5EJqcO6n717uyOZGbz3W9rf+mMbXF+Pg4cvML\neX/T/mCHYowx9YolnGUpLHSWtOw0uNSmZckZNIzwMKRbqyAEZow5H5d0bE7Pdk15MzEt2KEYY0y9\nYglnWQ5th9OHodOQc4pVlWVJGVzZvRVREZ4gBWeMqSgRYVx8HBtTj7DtwPFgh2OMMfWGJZxlSXH7\nb5Zo4UxKP8b+ozlcZ6PTjal1bunfgQiP2MpDxhhTgyzhLEvKGmjcBqIvOKd4WdJBRGB4T+u/aUxt\nE9Mkkmt7tWXx+n3k5RcGOxxjjKkXLOEsS8pqp3VTzh2Fviw5gwFxLWjdNDJIgRljKmN8fBxZJ/NY\nvvVgsEMxxph6wRJOf47ugyMp0Pnc/psHjubw3b6jXNvbbqcbU1td1b0VbZtF2m11Y4ypIZZw+pOy\n2vlZov/mp1szAKz/pjG1WLgnjLGXxrJi20EyjuUEOxxjjKnzwoMdQMhKWQMRjaHtJecUL0vKoFN0\nIy5s06RaTnvmzBnS0tLIybEvwdogKiqK2NhYIiIigh2KqaBx8XH8feX3vLNuH/cM6xbscIwxpk6z\nhNOflDUQdxl4zr5FJ3Pz+er7LH58eWdEqmd1obS0NJo2bUqXLl2q7RymaqgqWVlZpKWl0bVr12CH\nYyqoa6vGXNalJYsSU5l2zQX292aMMdWoxm+pi8goEdkmIjtF5BEf26eKSKaIbHAfd7nl/UVktYhs\nEZFNIjLB65i5IrLb65j+lQry9BHI2Fxq/s0vdhwiL7+Qa6txdaGcnBxiYmLsy68WEBFiYmKsNboW\nGxcfx65DJ/l27+Fgh2KMMXVajSacIuIB/gbcAPQGJolIbx+7LlTV/u5jjlt2CrhDVS8GRgHPiUgL\nr2Me8jpmQ6UCTVsLaKn+m8uSM2gWFc5lXaIrVX15LNmsPeyzqt1+dEl7GjXw8KYNHjLGmGpV0y2c\ng4CdqrpLVfOABcDNgRyoqttVdYf7fD9wEGhd9lHnKWU1hIVDbHxxUUGhsnzrQYb3bEOEx8ZaGVMX\nNI4M58a+7fnPpnRO5uYHOxxjjKmzajpz6gh4NyWkuWUljXVvm78lInElN4rIIKAB8L1X8dPuMX8W\nEZ8TZIrI3SKSKCKJmZmZ/qNMWQPt+0GDxsVFG1IPk30yj2vr+Oj0rKws+vfvT//+/WnXrh0dO3Ys\nfp2Xl1fmsYmJiUyfPr3C59ywYQMiwkcffXS+YRtz3sbHx3Eyr4APvksPdijGGFNnhWJT3b+BLqra\nF1gKvOa9UUTaA68Dd6pq0TIhjwI9gcuAaODXvipW1ZdUNV5V41u39tM4mp8LaYnQ6YpzipcmHSQ8\nTLimR/U0qoaKmJgYNmzYwIYNG5g2bRoPPvhg8esGDRqQn++/FSg+Pp6//OUvFT5nQkICV155JQkJ\nCZUJvVwFBQXVWr+pnQZ2bskFrRqzKDEt2KEYY0ydVdOj1PcB3i2WsW5ZMVXN8no5B/hj0QsRaQb8\nB5ihqmu8jilqmsgVkVeB/z7vCPdvgIJcn/03L78gmmZRNTf9zRP/3kLS/mNVWmfvDs14/KaLK3TM\n1KlTiYqKYv369QwdOpSJEydy//33k5OTQ8OGDXn11Vfp0aMHK1euZPbs2bz//vvMmjWLlJQUdu3a\nRUpKCg888IDP1k9VZdGiRSxdupSrrrqKnJwcoqKiAPjDH/7AG2+8QVhYGDfccAPPPPMMO3fuZNq0\naWRmZuLxeFi0aBGpqanF5wW49957iY+PZ+rUqXTp0oUJEyawdOlSHn74YY4fP85LL71EXl4eF154\nIa+//jqNGjUiIyODadOmsWvXLgBeeOEFPvroI6Kjo3nggQcAmDFjBm3atOH++++vzEdgQoyIMC4+\njj98tJVdmSe4oHX1THlmjDH1WU0nnGuB7iLSFSfRnAjc7r2DiLT3SiBHA8lueQNgMTBPVd/ydYw4\nIzhuATafd4RFE77HnU04dx86yc6DJ5h8eafzrra2S0tLY9WqVXg8Ho4dO8YXX3xBeHg4y5Yt4ze/\n+Q1vv/12qWO2bt3KihUrOH78OD169OCee+4pNV/lqlWr6Nq1K926dWPYsGH85z//YezYsXz44Ye8\n++67fP311zRq1Ijs7GwAJk+ezCOPPMKYMWPIycmhsLCQ1NSyB3zExMSwbt06wOky8POf/xyAmTNn\n8vLLL3Pfffcxffp0rrnmGhYvXkxBQQEnTpygQ4cO3HrrrTzwwAMUFhayYMECvvnmm6p4O02IGXtp\nR2Z/so23vk3j4VE9gx2OMcbUOTWacKpqvojcC3wMeIBXVHWLiDwJJKrqe8B0ERkN5APZwFT38PHA\n1UCMiBSVTXVHpM8XkdaAABuAaecdZMpqiOkOTc7eOv802VldqKb7b1a0JbI6jRs3Do/HA8DRo0eZ\nMmUKO3bsQEQ4c+aMz2N+9KMfERkZSWRkJG3atCEjI4PY2Nhz9klISGDixIkATJw4kXnz5jF27FiW\nLVvGnXfeSaNGjQCIjo7m+PHj7Nu3jzFjxgAUt4SWZ8KE4hm02Lx5MzNnzuTIkSOcOHGC66+/HoDl\ny5czb948ADweD82bN6d58+bExMSwfv16MjIyGDBgADExMYG+ZQCIyCvAjcBBVe3jY/tDwGT3ZTjQ\nC2cwXGNgHtAWUOAlVX2+Qic3AWvTLIphF7Xm7XVp/PK6iwi3gYHGGFOlanzid1X9APigRNljXs8f\nxemTWfK4N4A3/NQ5okqCKyx0Bgz1uumc4qVJGfRs15S46EZVcpraqHHjswOofvvb3zJ8+HAWL17M\nnj17GDZsmM9jIiPPjt3yeDyl+n8WFBTw9ttv8+677/L0008XT6R+/PjxCsUWHh5OYWFh8euS82J6\nxz516lSWLFlCv379mDt3LitXriyz7rvuuou5c+dy4MABfvrTn1YoLtdc4K84yWMpqvos8CyAiNwE\nPKiq2e7At1+p6joRaQp8KyJLVTXpfIIw5RsXH8enbxzkix2HGN6z+ubaNcaY+sj+G+8t7wT0uAEu\nur646PDJPBL3Hq7zo9Mr4ujRo3Ts6EwuMHfu3POu59NPP6Vv376kpqayZ88e9u7dy9ixY1m8eDHX\nXXcdr776KqdOnQIgOzubpk2bEhsby5IlSwDIzc3l1KlTdO7cmaSkJHJzczly5Aiffvqp33MeP36c\n9u3bc+bMGebPn19cPnLkSF544QXASYSPHj0KwJgxY/joo49Yu3ZtcWtoRajq5zgt9YGYBCS4x6Wr\n6jr3+XGcriW+ZnQwVWREzzZEN25gc3IaY0w1sITTW1QzGPPiOS2cK7cfpKBQuba3JZxFHn74YR59\n9FEGDBhQ5qj18iQkJBTfHi8yduxYEhISGDVqFKNHjyY+Pp7+/fsze/ZsAF5//XX+8pe/0LdvX4YM\nGcKBAweIi4tj/Pjx9OnTh/HjxzNgwAC/5/zd737H5ZdfztChQ+nZ82xfveeff54VK1ZwySWXMHDg\nQJKSnIbEBg0aMHz4cMaPH1/cpaA6iEgjnAUNSnWGFZEuwADgaz/HBjbdlylTg/AwxgzoyLLkDLJO\n5AY7HGOMqVNEVYMdQ1DEx8drYmJiufv94l/r+GZ3Nl8/OpKwsOpfVSY5OZlevXpV+3lMYAoLC7n0\n0ktZtGgR3bt397mPr89MRL5V1Xj3eRfgfV99OL32nwD8WFVvKlHeBPgMeFpV3ykv3kCva+PbtgPH\nuf65z/ntjb352ZVdgx1OSPK+to0xJlDWwlmGvPxCPtuWyciebWok2TShJSkpiQsvvJCRI0f6TTar\n0ETc2+lFRCQCp8VzfiDJpqm8Hu2a0i+2OYsSU6mv/xk3xpjqUOODhmqTr3dncSI33/pv1lO9e/cu\nnpezOolIc+Aa4MdeZQK8DCSr6v9WexCm2Lj4OGYu2cx3+47SN7ZFsMMxxpg6wVo4y7AsKYOoiDCG\nXtgq2KGYWkpEEoDVQA8RSRORn4nINBHxnrprDPCJqp70KhsK/AQYISIb3McPazD0euumfh2IDA+z\nwUPGGFOFrIXTD1VlWfJBrrywNQ0bVN9gEVO3qeqkAPaZizN9knfZlzjzypoa1rxhBDf0acd7G/Yz\n80e9iYqwv39jjKksa+H0Izn9OPuOnOa63jYfnzH1zfj4OI7l5PPxlgPBDiXojhw5wt///vegxiAi\nA0TkZfd5TxGEFYpaAAAY6ElEQVRZLSK5IuJ3GWMR+cLr7sB+EVlS3vEi8oqIHBSRzSXKF3rVtUdE\nNlQw/lllxVrOsU+KyLXnc2wAda90BzVWtp4K/34i8qiI7BSRbSJyvVf5ngrWM1VE/uo+v0VEelfk\n+KogIi1E5P9VYX17RKTcW6si8qyIbHF/VuYaK/W+ich9IrLVrf+PJbZ1EpETRecTkQYi8rmIlNmI\naQmnH8vc1YVsAmhj6p/BF8QQ27IhixLTgh1K0AUz4fT6AvsN8Bf3eTYwHZhd1rGqepWq9lfV/jjd\nWooG3pV1/Fyc6clK1jXBq663veqqdqr6mKouq6nz1QQ3uZkIXIzzfv9dRKriVsItQI0nnEALoEIJ\nZ3nJWYDuBvqq6kOVrOec901EhgM3A/1U9WJK/638L/Bh0QtVzQM+BSZQBks4/fg0OYP+cS1o0zSw\n5RPriuHDh/Pxxx+fU/bcc89xzz33+D1m2LBh+JuK59ChQ0RERPDiiy9WaZzGVKewMGHcwDi++v4Q\nqdmngh1OUD3yyCN8//339O/fn4cecr7XROQhEVkrIptE5Am3rIuIJIvIP91WkU9EpKG7bbqIJLn7\nL3DLokVkiVu2RkT6uuWzROR1EfkKeN1daauvqm4EUNWDqroW8L2mbgki0gwYASwp7/jyFmpwB/ON\np8SMEn72nSEi20XkS6CHV3k3EflIRL51W2F7ikhzEdkrImHuPo1FJFVEIkRkrojc5pZfJiKrRGSj\niHwjIk1FxOO2cBV9Hv8VyPviygYK3LpHicg6t+5P3bJzWs1EZHNRi2gZv9/P3Vg2isjb4swxXNLN\nwAJVzVXV3cBOYJC7rdzJhEXkTvfc3+D0d0dEhgCjgWfdluhuIrLO65juRa/dFsQ/ish37vt4oVve\n2o15rfsYGtjbyDNAN/e8z4rjWff9+k6cae8QkWHuZ/4ekOR+drPd/TaJyH1edd7nfh7fiUjPkid0\n62iCswrdhBLb+rt/U5tEZLGItHTLS302vt434B7gGVXNBedvxqvuW4DdwJYSIS3h7DLNPlnC6UPG\nsRw2ph3luno42fukSZNYsGDBOWULFixg0qRyuyL6tGjRIgYPHkxCQrn/PldKZSagN8aXsQOdhZ3e\nXle/WzmfeeYZunXrxoYNG3j22WcBmgHdcRKE/sBAEbna3b078De3VeQIMNYtfwQYoKp9gaIBc08A\n692y33Du8q+9gWvdPtDxwDm3uCvoFuBTVT1WiTqKXAVkqOqOsnYSkYE4LXj9gR8Cl3ltfgm4T1UH\nAv8N/F1VjwIbcGarALgR+FhVz3jV2QBYCNyvqv2Aa4HTwM+Ao6p6mXuen4tIVzcZ3eDn0RtAVW9V\n1VQRaQ38Exjr1j2uEr/fO6p6mVtPshsfIjJaRJ509+kIeI/KS3PLcH+Pss7dHufaGQpcidsyp6qr\ngPeAh9zW6O+BoyLS3z30TuBVr6qOquolOEsPP+eWPQ/82Y1hLDDHPedwP+/jKve4R4Dv3fM+BNzq\nvjdFn9OzbtwAl+J8hhfhtFB2Afq7fwdnl7+DQ6p6KfACznVyDlUdDZx2z7mwxOZ5wK/dOr8DHnfL\nS302ft63i4CrRORrEflMRC5z34cmwK/d97+kzZx7HZRig4Z8+DTZSeaDPh3Sh4/Age+qts52l8AN\nz/jdfNtttzFz5kzy8vJo0KABe/bsYf/+/Vx11VXcc889rF27ltOnT3PbbbfxxBO+rrlzJSQk8Kc/\n/Ynbb7+dtLQ0YmNjAZg3bx6zZ89GROjbty+vv/46GRkZTJs2rXgqohdeeIEOHTpw4403snmz830z\ne/ZsTpw4waxZsxg2bBj9+/fnyy+/ZNKkSVx00UU89dRT5OXlERMTw/z582nbti0nTpzgvvvuIzEx\nERHh8ccf5+jRo2zatInnnnP+nfnnP/9JUlISf/7znyv7Dps6IrZlI4Z2a8WixDSmj+huc/Ge1Qz4\nAbDefd0EJ9FMAXaralH/xm9xvkwBNgHzxelHucQtuxI3IVXV5SISI05rJMB7qnrafd6eAFq9yjAJ\nN3GoAsXLz5bjKmCxqp6C4taooi/sIcAikeLrKdL9uRDnluQKnGSuZD+GHkC62zpLUQItIj8A+ha1\nggLNge5uy2F/AjMY+Nw9BlUtbzlen7+fq4+IPIVzm7kJ8LFb53s4iU1lXQ6sVNVM99wLcRIkX+YA\nd4rIL3He20Fe2xK8fhb9w38t0Nvrs2kmIk1UdQWBv5fgXNsJqloAZIjIZzjJ2DHgm6L32T3fi6qa\nD6Xe96JuG9/iJLABEWeavRaq+plb9BqwyH3u87PxIRyIxrkuLgPeFJELgFk4CfkJr/cIN/YCEckT\nkabucsw+KzUlLEvOIC66IRe1bRLsUGpcdHQ0gwYN4sMPP+Tmm29mwYIFjB8/HhHh6aefJjo6moKC\nAkaOHMmmTZvo27ev37pSU1NJT09n0KBBjB8/noULF/KrX/2KLVu28NRTT7Fq1SpatWpFdrbzNzZ9\n+nSuueYaFi9eTEFBASdOnODw4cNlxpuXl1d8O//w4cOsWbMGEWHOnDn88Y9/5E9/+hO/+93vaN68\nOd99913xfhERETz99NM8++yzRERE8Oqrr/KPf/yjit5FU1eMi4/l/gUbWL0ry6ZHO9f/qOo5fzDu\nrVbvNUELgIbu8x8BVwM3ATNE5JJy6veeIuw0cF59m8QZeDEIZ+qxShGnz92twMBKVBMGHHH7gpb0\nHvB7EYl2z7E80NBwWkzPSR7E6YrwhZ9jblfVpADqzufcO6GBfA5zgVtUdaOITAWG+dhnHxDn9TrW\nLatqb+O07i0HvlXVLK9t6uN5GDBYVXO8KxGnT6Ov1ohTqjqkgjGdLH8X4OzfUgFVl6vNpfzPBpwW\n53fUWf3iGxEpBFrhJPu3iTOIqAVQKCI5qvpX97hIIMdnjVjCWcqpvHy+3HmIyZd3omQGX+PKaIms\nTkW31YsSzpdffhmAN998k5deeon8/HzS09NJSkoqM+FcuHAh48ePB2DixIn89Kc/5Ve/+hXLly9n\n3LhxtGrlfIFHR0cDsHz5cubNc+6qeTwemjdvXm7COWHC2a4raWlpTJgwgfT0dPLy8uja1VmacNmy\nZed0E2jZsiUAI0aM4P3336dXr16cOXOGSy4p7zvQ1DfXX9yOZlHhvJmYWm8TzqZNm3L8+DkNFseA\nn4rIfLeloyNl9KcUp19inKquEKe/30Sc1pUvcPp8/U5EhuHcQjzm49/dZOBX5xn+bTjLyvr9EqyA\na4Gtqlrcx8L93eep6sgS+34OzBWR/8H5nr0J+If7++0WkXGqukicX7avqm5038u1OLd133dbx7xt\nA9qLyGWqutZNKE/jtFLdIyLLVfWMiFwE7HNbmQJtlVuDM3Cnq6ruFpFot7VtD87tfUTkUqBovVef\nv5+7rSmQLs5KaZPxnUi+B/xLRP4X6IDTQv5NyZ1EZKuqluy/+DXwvIjE4FyL44CN7rbj7vkBUNUc\nEfkY57b0z0rUMwGn7+UEnEFlAJ8A9wHPuufvr6obAmjhPOe8ONf2f4nIazgthVcDDwElf5el7n4r\nVDXf630/b6p6VEQOi8hVqvoFznzORa2d/j6bkvEvAYYDK9zrqQHO3+dVRTuIyCzgRFGy6X4eh7y7\ngZRkCWcJX+w4RF5+IdcF+3Z6EN188808+OCDrFu3jlOnTjFw4EB2797N7NmzWbt2LS1btmTq1Knk\n5JT9b3hCQgIHDhxg/nynW8r+/fvZsaPMrk+lhIeHU1hYWPy65DkbN25c/Py+++7jl7/8JaNHj2bl\nypXMmjWrzLrvuusufv/739OzZ0/uvPPOCsVl6oeoCA839+/IwsRU8uevI7pxA6IbNyCmSYOzzxtH\nEt24AS0bRRDuqXvd4mNiYhg6dCh9+vThhhtuAOdL/l/Aajc5PIGzSlbJBKmIB3jDvdUnwF9U9Yj7\nhfWKiGwCTgFTfB2sqlvFGVTTVFWPi0g7IBHn1n6hiDwA9HaTuQ+Au1R1v3v4RJykolg5xyfgtPq0\nEpE04HFVfdmrrpK309vjtAKWjHmde6t3I3AQWOu1eTLwgojMBCKABZxNmBbi3P4c5qPOPHEGh/yf\nOIOxTuMkwXNwui6scxPYTJx+qwFT1UwRuRt4x/0PwkHgOpwWwjtEZAtOorc9gN/vt+6+me7PpuD0\n4QTi3VH3W0TkTSAJ5/37RckE222dLvW/D1VNd6+d1Tj9hL2nqFoA/FNEpgO3uf0R5+MurlGiqpbu\ntZeL01UCnNkL/uaWh+Mk1tMoh6pmichX4kyn9SHwMHCF+/4o8LCqHpDSg3/m4HQH2CQiZ3D60f4V\nP0QkHpimqneVE9IU4EVxBmztwum/Cn4+G0q8b8ArOH+bm4E8YIrb2lmW4cB/ytpByq+jboqPj1df\nI6sfWrSRj7YcYN1vryMiCF8eycnJ9OrVq8bPW9KECRPYtm0bN998M0888QQbN27kjjvuYP369WRm\nZtK3b1/+8Ic/MHXqVIYNG8bs2bOJj48vPn779u3cdNNNbNu2rbjs8ccfx+PxMHbsWMaMGcPq1auJ\niYkhOzub6OhoJk6cyODBg3nggQeKb6k3atSI9u3bs23bNpo0acI111zDqFGjivtwep93wIABzJkz\nh4EDB3LnnXeye/duVq5cySOPPEJOTk5xf83Dhw8Xt3JeeumlZGZmsmnTpuKyivL1mYnIt6oa7+eQ\nauPvujbnb/ehk/zmne/IOJ5D9sk8jpzyPzi6RaMINwktSkgji597J6nNoiIICxM8IoQJiPvTEybn\nPA8TQQTCxNlX3H2DKRjXtog8CBxX1arqi1klROReIMXtn2iqkIjcCFygqn8pd+ey6/lvoLmq/tar\nbA9O8nuoclGaIiLyDvCIqm73t0+Nt3CKyCicWwYeYI6qlvzf51Sc5uyipt6/Fv0jIyJTgJlu+VOq\n+ppbPhCnb0JD4AOcEWAVzqQLCpXlWw8yrEeboCSboWTSpEmMGTOm+FZ0v379GDBgAD179iQuLo6h\nQ8ueLSIhIYExY87tNjV27FgmTJjAY489xowZM7jmmmvweDwMGDCAuXPn8vzzz3P33Xfz8ssv4/F4\neOGFF7jiiit47LHHGDRoEB07dqRnz1KzQxSbNWsW48aNo2XLlowYMYLdu51+2TNnzuQXv/gFffr0\nwePx8Pjjj3PrrU4f7PHjx7Nhw4bzTjZN3de1VWMS7h5c/Dq/oJDDp86QfTKPrJO5ZJ/Mc56fyDv7\n/GQuuw+d5Nu9h8k+mUdhFf6/vmQCGuYmqGEi4P4sKhecBNV5DcLZBNdJXs/u53383VddwPjL4soL\npSa9QDkjp4PBq++aqWKq+n5l6xCRxUA3nGmxTDURZwaFJWUlm1DDLZziTOy6HaepPg2nGX6Sd+dl\nN+GMV9V7SxwbjXMbJB6nifpbYKCqHhZnLq7pOE3EH+DcsvmQMvhqCTp6+gxP/juJ6y9uyw8ublep\n3/V8hUoLZ31x44038uCDDzJyZMkuWIGzFk5TlsJC5ejpM2SdLEpIczmWk4+qUqhQqEphoddzxX3t\nb7vvbeq+Budn0WvFWaq3+LXi7I/zvCgOdY9D4ZYBHf1OCxesa9sYU7vVdAvnIGCnqu4CEGcC4Jtx\n+nGU53pgaVGHWhFZCowSkZVAM1Vd45bPw+m/UmbC6UvzhhH8aXy/ih5maqEjR44waNAg+vXrV6lk\n05jyhIUJLRs3oGXjBsEOxRhjgqamE05fk71e7mO/seJMJLwdeFBVU/0c29F9pPkoL8XtFH03QKdO\nnc7zVzB1QYsWLdi+vczWf2OMMcZUkVDsqPhvoIs7Q/5SnElLq4SqvqSq8aoa37p166qqtsrV14Fc\ntZF9VsYYY0z5ajrhLHeyV1XNUnf9TpwpAwaWc+w+97nfOmuTqKgosrKyLJGpBVSVrKwsoqLOa05q\nY4wxpt6o6Vvqa4HuItIVJymcCNzuvYOItFfVdPflaJxJf8GZ3Pb34i5Cj7O02qOqmi0ix0RkMM6g\noTuA/6vm36PaxMbGkpaWRmZmZVZyMzUlKiqqeLlOY4wxxvhWowmnO5P+vTjJowd4xZ0A9kkg0Z3L\nbLo7QWw+kA1MdY/NFpHfcXaC2Se9ZuT/f5ydFulDzmPAUKiIiIgoXiHHGGOMMaYuqPF5OFX1A5yp\ni7zLHvN6/ijwqJ9jX8GZAb9keSLQp2ojNcYYY4wxVSEUBw0ZY4wxxpg6xBJOY4wxxhhTrertWuoi\nkgnsraHTtQJCdc3WUI4NQju+smLrrKo1PveWXdfnCOX4Qjk2CMFr2xhTu9XbhLMmiUhiqC4FF8qx\nQWjHF8qx1YRQ//1DOb5Qjg1CPz5jTO1jt9SNMcYYY0y1soTTGGOMMcZUK0s4a8ZLwQ6gDKEcG4R2\nfKEcW00I9d8/lOML5dgg9OMzxtQy1ofTGGOMMcZUK2vhNMYYY4wx1coSTmOMMcYYU60s4awmIhIn\nIitEJElEtojI/cGOqSQR8YjIehF5P9ixlCQiLUTkLRHZKiLJInJFsGPyJiIPup/rZhFJEJGoYMdU\nU+zarpxQvrbr83VtjKlelnBWn3zgV6raGxgM/EJEegc5ppLuB5KDHYQfzwMfqWpPoB8hFKeIdASm\nA/Gq2gfwABODG1WNsmu7ckLy2rbr2hhTnSzhrCaqmq6q69znx3G+VDoGN6qzRCQW+BEwJ9ixlCQi\nzYGrgZcBVDVPVY8EN6pSwoGGIhIONAL2BzmeGmPX9vmrBdd2vb2ujTHVyxLOGiAiXYABwNfBjeQc\nzwEPA4XBDsSHrkAm8Kp7W3SOiDQOdlBFVHUfMBtIAdKBo6r6SXCjCg67tissZK9tu66NMdXJEs5q\nJiJNgLeBB1T1WLDjARCRG4GDqvptsGPxIxy4FHhBVQcAJ4FHghvSWSLSErgZJ3noADQWkR8HN6qa\nZ9f2eQnZa9uua2NMdbKEsxqJSATOF/J8VX0n2PF4GQqMFpE9wAJghIi8EdyQzpEGpKlqUavZWzhf\n0qHiWmC3qmaq6hngHWBIkGOqUXZtn7dQvrbr/XVtjKk+lnBWExERnH5ayar6v8GOx5uqPqqqsara\nBWdQwHJVDZmWDFU9AKSKSA+3aCSQFMSQSkoBBotII/dzHkmIDPyoCXZtn78Qv7br9XVtjKle4cEO\noA4bCvwE+E5ENrhlv1HVD4IYU21yHzBfRBoAu4A7gxxPMVX9WkTeAtbhjNheT/1aCtCu7coJyWvb\nrmtjTHWypS2NMcYYY0y1slvqxhhjjDGmWlnCaYwxxhhjqpUlnMYYY4wxplpZwmmMMcYYY6qVJZzG\nGGOMMaZaWcJZi4nIVBFRP4+grc8sInNFJC1Y5ze1m13XxhhT99g8nHXDOJwVTLzlByMQY6qQXdfG\nGFNHWMJZN2xQ1Z3BDsKYKmbXtTHG1BF2S72O87o9ebWILBGREyKSJSJ/E5GGJfZtLyLzROSQiOSK\nyCYRKbUsoIh0FZHXReSAu98uEXnex34DROQLETklIjtEZFqJ7e1E5DUR2e/Wky4i74tIm6p/J0xd\nYte1McbULtbCWTd4RKTkZ1moqoVer98A3gT+DgwCHgMaA1MBRKQx8BnQEvgNkAr8GHhdRBqp6kvu\nfl2Bb4BTbh07gE7AD0qcvxnwL+A54Emc5fteEJFtqrrC3ed1oDPwkHu+tjjrNzc63zfC1Cl2XRtj\nTF2hqvaopQ+cL1X183i/xD4vljh2BlAAXOS+vtfdb1iJ/ZYBBwGP+3oecALoUEZcc926hnuVRQJZ\nwEteZSeA6cF+H+0RWg+7ru1hD3vYo+49rIWzbhhD6cEVJUfzvlni9QLgKZxWoe3A1cA+VV1ZYr83\ngFeB3sB3OC0+76vq/nJiOqVnW3xQ1VwR2Y7TalRkLfCQiAiwHNisqlpOvab+sOvaGGPqCEs464bN\nWv7gigw/rzu6P6OBdB/HHfDaDhBD6STAl8M+ynKBKK/XE4DHgYdxblGmi8iLwFN67m1TUz/ZdW2M\nMXWEDRqqP9r6eb3P/ZkNtPNxXDuv7QCHOPtlXimqelBVf6GqHYGeOLcsnwD+qyrqN/WCXdfGGFML\nWMJZf4wv8XoiUAh87b7+DIgVkaEl9rsdp69bkvv6E+BGEWlflcGp6jZV/Q1OC1Kfqqzb1Gl2XRtj\nTC1gt9Trhv4i0spHeaLX8x+KyLM4X6yDcG75zVPVHe72ucD9wDsiMgPn9uJk4Drgv1S1wN3vceCH\nwCoR+T2wE6dlaJSqlppqxh8RaY4zcGM+sBU4A9yMM5r4k0DrMXWaXdfGGFNHWMJZNyzyU97a6/mP\ngV8B9wB5wD+B/y7aqKonReQa4I/AM0BTYBvwE1V9w2u/PSIyGGdgxv8ATXBuX75bwZhzgHXAz3Gm\nkCl0zzdZVStal6mb7Lo2xpg6QmzwZN0mIlNxRuN2D2AAhjG1gl3XxhhTu1gfTmOMMcYYU60s4TTG\nGGOMMdXKbqkbY4wxxphqZS2cxhhjjDGmWlnCaYwxxhhjqpUlnMYYY4wxplpZwmmMMcYYY6qVJZzG\nGGOMMaZa/X9yvyJB7dfJTQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4wRSAvtABCT",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL_ENTAILMENT W/ BETTERMUSH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Kd6J8o4j6k",
        "colab_type": "text"
      },
      "source": [
        "runnin my textual entailent model :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no2oQo2CM3XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_b_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"snopes\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 10\n",
        "  mlp_one = 50\n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 11\n",
        "  inner_dropout = 0.3\n",
        "  outer_dropout = 0.6\n",
        "  C = 0.6\n",
        "  is_lstm=True\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00004\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 2\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.01\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq0ID4OwKBnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters_b_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uR6B4eAE7Ydh",
        "colab": {}
      },
      "source": [
        "class Hyperparameters_b_politi:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"politifact\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 8\n",
        "  mlp_one = 50  \n",
        "  mlp_two = 25\n",
        "  num_classes = 1\n",
        "  is_lstm=True\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout = 0.2\n",
        "  outer_dropout = 0.7\n",
        "  weights = [1, 1, 0.25, 1]\n",
        "  C = 0.6\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.00007\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 2\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.009\n",
        "  use_better=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0_fGUTfKLKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"politifact\"], Hyperparameters_b_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4JkXr8fcoee",
        "colab_type": "text"
      },
      "source": [
        "WOAH WERE DOIN SOME VALIDATION\n",
        "PLEASE VALIDATE ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgdGdgfwsOxa",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu() ,datasets[\"politifact\"].test_data, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Zfw_4Acupe",
        "colab_type": "text"
      },
      "source": [
        "JUST TESTIN HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViWwxJG5Oys",
        "colab_type": "text"
      },
      "source": [
        "##running sheena's model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ngDR0NMc26u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"snopes\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 9\n",
        "  inner_dropout=0.5\n",
        "  outer_dropout=0.5\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  is_lstm=True\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 2\n",
        "  lr=0.00007\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.009\n",
        "  use_better = False\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Sy7yz2yfOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"snopes\"], SheenaParameters_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqq85WyvO4vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_politi:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"politifact\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 11\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 1\n",
        "  lr=0.00005\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  use_better = False\n",
        "  early_threshold = -0.0005\n",
        "  is_lstm=True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOunnQsb5B7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sheena_predicted_ys, model = run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters_politi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLIae_QSsycn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yHnhc8pmszYg",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_challenge:\n",
        "  lstm_hidden_size = 100\n",
        "  dense_dimension = 200\n",
        "  attention_hops = 30\n",
        "  batch_size = datasets[\"challenge\"].batch_size\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 70\n",
        "  num_classes = 4\n",
        "  avg=False\n",
        "  weights = torch.tensor([2, 1, 0.2, 1], dtype=torch.double).cuda()\n",
        "  epochs = 12\n",
        "  inner_dropout = 0\n",
        "  outer_dropout = 0\n",
        "  C = 0\n",
        "  decay = 0\n",
        "  is_debug = False\n",
        "  lr=0.01\n",
        "  is_lstm = True\n",
        "  grad_clip = False\n",
        "  grad_clip_amount = 1\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.0005\n",
        "  use_better=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFF5cXaOs5cp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sheena_predicted_ys, model = run_model(models[\"sheena_model\"], datasets[\"challenge\"], SheenaParameters_challenge)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LavaeLb_wcPS",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_b_snopes:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"snopes\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  mlp_one = 25  \n",
        "  mlp_two = 10\n",
        "  avg=False\n",
        "  epochs = 14\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.6\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  grad_clip_amount = 1\n",
        "  lr=0.00005\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.00013\n",
        "  use_better = True\n",
        "  is_lstm = True\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1qVR4CrMGJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"snopes\"], SheenaParameters_b_snopes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Czr397iowaXX",
        "colab": {}
      },
      "source": [
        "class SheenaParameters_b_politi:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"politifact\"].batch_size\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=False\n",
        "  epochs = 8\n",
        "  inner_dropout=0.3\n",
        "  outer_dropout=0.5\n",
        "  C = 0.6\n",
        "  is_debug = False\n",
        "  grad_clip = True\n",
        "  grad_clip_amount=1\n",
        "  lr=0.0001\n",
        "  decay = 0\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  use_better = True\n",
        "  early_threshold = -0.013\n",
        "  is_lstm = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--XfnpT3wZ9c",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters_b_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"sheena model\",predicted_ys.cpu(), datasets[\"politifact\"].test_data, True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1DvOud6d0r",
        "colab_type": "text"
      },
      "source": [
        "##OK TESTING ON BROKE DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfFA1PNpzA8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeclareParameters_snopes:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"snopes\"].batch_size\n",
        "  max_length = 100\n",
        "  num_classes = 1\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0.5\n",
        "  epochs = 20\n",
        "  C = 0\n",
        "  is_debug = False\n",
        "  lr=0.0001\n",
        "  decay = 0.01\n",
        "  filters = [datasets[\"snopes\"].batch_size, 100, 8]\n",
        "  grad_clip = False\n",
        "  grad_clip_amount = 3\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.0004\n",
        "  is_lstm = True\n",
        "  big_gloves = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"real_declare\"], datasets[\"snopes\"], DeclareParameters_snopes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1c6Az3UST7bY",
        "colab": {}
      },
      "source": [
        "class DeclareParameters_politi:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"politifact\"].batch_size\n",
        "  max_length = 100\n",
        "  num_classes = 1\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0.5\n",
        "  epochs = 20\n",
        "  C = 0\n",
        "  is_debug = False\n",
        "  lr=0.0001\n",
        "  decay = 0.01\n",
        "  filters = [datasets[\"politifact\"].batch_size, 100, 8]\n",
        "  grad_clip = False\n",
        "  grad_clip_amount = 3\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.0004\n",
        "  is_lstm = True\n",
        "  big_gloves = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-BrIP06dkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_model(models[\"real_declare\"], datasets[\"politifact\"], DeclareParameters_politi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8ocKDLu25FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeclareParameters_challenge:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = datasets[\"challenge\"].batch_size\n",
        "  max_length = 100\n",
        "  num_classes = 4\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0.5\n",
        "  epochs = 20\n",
        "  C = 0\n",
        "  is_debug = False\n",
        "  lr=0.01\n",
        "  decay = 0.01\n",
        "  weights = torch.tensor([2, 1, 0.2, 1], dtype=torch.double).cuda()\n",
        "  filters = [datasets[\"politifact\"].batch_size, 100, 8]\n",
        "  grad_clip = False\n",
        "  grad_clip_amount = 3\n",
        "  early_stopping = 2\n",
        "  use_early_stopping = True\n",
        "  early_threshold = -0.0004\n",
        "  is_lstm = True\n",
        "  big_gloves = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skSB-tvD3IgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, _ = run_model(models[\"real_declare\"], datasets[\"challenge\"], DeclareParameters_challenge)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZsRrUK77HAU",
        "colab_type": "text"
      },
      "source": [
        "TESTING ON REAL DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCjS7Dfz7I8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"real declare model\", predicted_ys.cpu(), datasets[\"challenge\"].test_data, False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hECl8V-P8noH",
        "colab_type": "text"
      },
      "source": [
        "                  \"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDZugTi6AEHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_params = {\n",
        "    \"my_model\": {\"politifact\": Hyperparameters_politi, \"snopes\":Hyperparameters_snopes, \"challenge\":Hyperparameters_challenge},\n",
        "    #\"my_model_better\":{\"politifact\": Hyperparameters_b_politi, \"snopes\":Hyperparameters_b_snopes},\n",
        "    \"sheena_model\": {\"politifact\": SheenaParameters_politi, \"snopes\": SheenaParameters_snopes, \"challenge\": SheenaParameters_challenge},\n",
        "    #\"sheena_model_better\": {\"politifact\": SheenaParameters_b_politi, \"snopes\" : SheenaParameters_b_snopes},\n",
        "    \"real_declare\": {\"politifact\":DeclareParameters_politi, \"snopes\": DeclareParameters_snopes, \"challenge\": DeclareParameters_challenge}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWBCcIDk674v",
        "colab_type": "text"
      },
      "source": [
        "##VALIDATION LAND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGG5mT_uBEGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_amount = 5\n",
        "per_avg_amount = 10\n",
        "import csv\n",
        "\n",
        "full_results = []\n",
        "avg_results = []\n",
        "processed_results = []\n",
        "\n",
        "\n",
        "\n",
        "for data_name in datasets:\n",
        "  for model_name in models:\n",
        "    some_results = []\n",
        "  \n",
        "    for per_avg_i in range(per_avg_amount):\n",
        "      predicted_ys, model = run_model(models[model_name], datasets[data_name], all_params[model_name][data_name])\n",
        "      full_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      some_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      \n",
        "    processed_results.append(process_results(list_to_dict(some_results)))\n",
        "    print(processed_results)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUR-r4M717ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for result in full_results:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iImnSu2nFmgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}