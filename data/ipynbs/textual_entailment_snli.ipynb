{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s4NbGwIC9-z",
        "colab_type": "text"
      },
      "source": [
        "##HAHA ITS TIME TO SPEND 5 HOURS DOWNLOADING THINGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "38f3a23d-e4c5-47f5-a90d-5f32cc5f3ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 16:39:21--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  65.4MB/s    in 1.4s    \n",
            "\n",
            "2020-02-19 16:39:22 (65.4 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "a7cce00d-bf8c-4ae9-f822-464b6433cd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 16:39:31--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-02-19 16:39:31--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-02-19 16:39:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.89MB/s    in 6m 28s  \n",
            "\n",
            "2020-02-19 16:45:59 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "d33c5bd1-a5f1-438c-d20e-610db868da2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 16:46:28--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  3.85MB/s    in 1.2s    \n",
            "\n",
            "2020-02-19 16:46:30 (3.85 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "ffbae70b-95c4-45fa-fe4f-98bf3d35285c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "a6957be7-c04f-4a77-e419-ef77145e7ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 16:46:35--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  4.38MB/s    in 1.2s    \n",
            "\n",
            "2020-02-19 16:46:37 (4.38 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "outputId": "bbba218d-9b40-46c4-8d18-a12456fd03c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlJXKPPODFqp",
        "colab_type": "text"
      },
      "source": [
        "##LOOK AT ALL THIS CODE TO IMPORT DATA GOD THERE MUST BE SOMETHING WRONG WITH ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "24a85a55-fa2f-4431-fcfa-5499d1254fd8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "fd057479-6306-4eb5-8697-05ca066c10b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "38d4cb3a-8ffe-454f-9f94-990ab9a71874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "train_challenge, val_challenge = train_test_split(train_challenge, test_size=0.1, random_state=8)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()\n"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39952</th>\n",
              "      <td>2109</td>\n",
              "      <td>A SCHOOLBOY who was almost killed when he was ...</td>\n",
              "      <td>Islamic State claims it executed American phot...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20359</th>\n",
              "      <td>1212</td>\n",
              "      <td>Tiger Woods divorced Swedish model Elin Nordeg...</td>\n",
              "      <td>Sources: Guns N' Roses Frontman Axl Rose Found...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11075</th>\n",
              "      <td>682</td>\n",
              "      <td>There has been a shooting at the War Memorial ...</td>\n",
              "      <td>Wife and child of Islamic State leader Baghdad...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47329</th>\n",
              "      <td>2413</td>\n",
              "      <td>You may have a seen a story going around Faceb...</td>\n",
              "      <td>Armed U.S. drones spotted flying over Syria in...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15650</th>\n",
              "      <td>942</td>\n",
              "      <td>Ok, this is all still rumor, but there’s a cha...</td>\n",
              "      <td>UPDATE: BATMAN v SUPERMAN Batmobile Reportedly...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Body ID  ... Stance\n",
              "39952     2109  ...      2\n",
              "20359     1212  ...      2\n",
              "11075      682  ...      2\n",
              "47329     2413  ...      2\n",
              "15650      942  ...      1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "fake_news_challenge_mapping = {}\n",
        "\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None, is_folding=False):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_text\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  \n",
        "  if is_folding:\n",
        "    results = []\n",
        "    folded = KFold(n_splits=10, shuffle=True)\n",
        "    splitted_object = folded.split(unique)\n",
        "    for train_result, test_result in splitted_object:\n",
        "      train_ilocs = unique.iloc[train_result][\"claim_text\"]\n",
        "      test_ilocs = unique.iloc[test_result][\"claim_text\"]\n",
        "      results.append((facts[facts[\"claim_text\"].isin(train_ilocs)], facts[facts[\"claim_text\"].isin(test_ilocs)]))\n",
        "\n",
        "    return results\n",
        "\n",
        "  train_unique, big_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "  val_unique, test_unique = train_test_split(big_unique, test_size=0.5, random_state=8)\n",
        "  \n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_text\"].isin(test_unique[\"claim_text\"])]\n",
        "  val_facts = facts[facts[\"claim_text\"].isin(val_unique[\"claim_text\"])]\n",
        "  train_facts = facts[facts[\"claim_text\"].isin(train_unique[\"claim_text\"])]\n",
        "  return train_facts, test_facts, val_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts, val_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes, val_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "c2c725f6-ec9c-4a81-e88e-3079fc2866ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>vice news we dont have a timeline on the decis...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>a schedule i narcotic along with heroin and ec...</td>\n",
              "      <td>reason.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>now do you think you were maybe talking just a...</td>\n",
              "      <td>cnn.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_feb_04_barack-obama_barack-obama-says-its...</td>\n",
              "      <td>isnt schedule narcotic job congress</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>made to the new yorker that marijuana is no mo...</td>\n",
              "      <td>time.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jun_27_donald-trump_white-house-criticism...</td>\n",
              "      <td>obamacare signed law cbo estimated 23 million ...</td>\n",
              "      <td>donald trump</td>\n",
              "      <td>about the affordable health care act in its da...</td>\n",
              "      <td>eugeneweekly.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4849</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama to ban guns from 42 million social secur...</td>\n",
              "      <td>bearingarms.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4850</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>obama is looking to ban social security recipi...</td>\n",
              "      <td>rightwingnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4851</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>main navigation recent posts obama to ban 42 m...</td>\n",
              "      <td>downtrend.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4852</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>get news like this in your facebook news feed ...</td>\n",
              "      <td>thegatewaypundit.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4853</th>\n",
              "      <td>0</td>\n",
              "      <td>2015_jul_30_blog-posting_websites-say-obama-po...</td>\n",
              "      <td>obama makes huge move ban social security reci...</td>\n",
              "      <td>bloggers</td>\n",
              "      <td>to prove everyone wrong yet again this time it...</td>\n",
              "      <td>zerohedge.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...        article_source\n",
              "187            1  ...            reason.com\n",
              "188            1  ...            reason.com\n",
              "189            1  ...               cnn.com\n",
              "190            1  ...              time.com\n",
              "526            1  ...      eugeneweekly.com\n",
              "...          ...  ...                   ...\n",
              "4849           0  ...       bearingarms.com\n",
              "4850           0  ...     rightwingnews.com\n",
              "4851           0  ...         downtrend.com\n",
              "4852           0  ...  thegatewaypundit.com\n",
              "4853           0  ...         zerohedge.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Beq65oTgcBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:\n",
        "  def __init__(self, train_loader, test_loader, val_loader, test_data, val_data, tokeniser):\n",
        "    self.train_loader = train_loader\n",
        "    self.test_loader = test_loader\n",
        "    self.val_loader = val_loader\n",
        "    self.test_data = test_data\n",
        "    self.val_data = val_data\n",
        "    self.word_embeddings_small = load_glove_embeddings(\"glove.6B.50d.txt\", tokeniser.word_to_id, 50) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts4lYd83j-c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\"claim_text\", \"article\"]\n",
        "big_labels = [\"claim_text\", \"article\", \"article_source\"]\n",
        "challenge_labels = [\"articleBody\", \"Headline\"]\n",
        "\n",
        "def get_list(panda, labels):\n",
        "  label_to_data = {}\n",
        "  for label in labels:\n",
        "    label_to_data[label] = panda[label]\n",
        "  \n",
        "  x_list = convert_to_lists(label_to_data)\n",
        "  if labels[0] == \"claim_text\":\n",
        "    y_list = panda[\"cred_label\"].tolist()\n",
        "  else:\n",
        "    y_list = panda[\"Stance\"].tolist()\n",
        "  return x_list, y_list\n",
        "\n",
        "def get_loader(x, y, vocab_size, max_length, batch_size, name, training=True, drop_last=True):\n",
        "  stuff = []\n",
        "  for key in x:\n",
        "    stuff.append(torch.from_numpy(x[key]).type(torch.LongTensor))\n",
        "  stuff.append(torch.from_numpy(y).type(torch.DoubleTensor))\n",
        "\n",
        "  tensorset = data_utils.TensorDataset(*stuff)\n",
        "  loader = data_utils.DataLoader(tensorset, batch_size=batch_size, drop_last=drop_last, shuffle=training)\n",
        "  loader.name = name\n",
        "  return loader\n",
        "\n",
        "  \n",
        "def get_dataset(train, test, val, vocab_size, max_length, batch_size, labels, name):\n",
        "  is_challenge = labels[0] == \"articleBody\"\n",
        "  train_list_x, train_list_y = get_list(train, labels)\n",
        "  if not is_challenge:\n",
        "    test_list_x, test_list_y = get_list(test, labels)\n",
        "  val_list_x, val_list_y = get_list(val, labels)\n",
        "\n",
        "\n",
        "\n",
        "  #tokenising various stuff, setting up numpy dictionaries :)\n",
        "  tokeniser = Tokeniser(train_list_x, vocab_size, max_length)\n",
        "  x_train = tokeniser.do_everything(train_list_x)\n",
        "  x_test = tokeniser.do_everything(test_list_x)\n",
        "  x_val = tokeniser.do_everything(val_list_x)\n",
        "  y_train = np.array(train_list_y, dtype=np.float32)\n",
        "  y_test = np.array(test_list_y, dtype=np.float32)\n",
        "  y_val = np.array(val_list_y, dtype=np.float32)\n",
        "  \n",
        "  #datasets/loaders\n",
        "  train_loader = get_loader(x_train, y_train, vocab_size, max_length, batch_size, name, True)\n",
        "  test_loader = get_loader(x_test, y_test, vocab_size, max_length, batch_size, name, False, drop_last=False)\n",
        "  val_loader = get_loader(x_val, y_val, vocab_size, max_length, batch_size, name, False)\n",
        "  return Dataset(train_loader, test_loader, val_loader,  y_test, y_val, tokeniser)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0MMrKlu6_jX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "outputId": "29dde96e-c087-4481-a897-c42be59fc78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 100\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "\n",
        "snopes_dataset = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "fact_dataset = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, labels, \"fact_data\")\n",
        "big_snopes = get_dataset(train_snopes, test_snopes, val_snopes, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "big_fact = get_dataset(train_facts, test_facts, val_facts, VOCAB_SIZE, MAX_LENGTH, BATCH_SIZE, big_labels, \"fact_data\")\n",
        "\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39093\n",
            "33766\n",
            "44623\n",
            "37174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smeSRlk30Ccq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTdDpyN44DQa",
        "colab_type": "text"
      },
      "source": [
        "##TEXTUAL ENTAILMENT MODEL CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    \n",
        "    self.embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.normaliser = torch.nn.BatchNorm1d(self.embedding_size)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x[:, 0:self.hp.max_length])\n",
        "    #embedding = self.normaliser(embedding.transpose(1,2))\n",
        "    embedding = self.dropout(embedding)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    tanh_W_H = self.dropout(tanh_W_H)\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.premise_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_dropout = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    premise_factor = self.premise_dropout(premise_factor)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    hypothesis_factor = self.hypothesis_dropout(hypothesis_factor)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=50)\n",
        "    self.linear2 = torch.nn.Linear(50, 20)\n",
        "    self.dropout1 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    self.dropout2 = torch.nn.Dropout(p=hp.inner_dropout)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "      x = self.dropout1(x)\n",
        "    else:\n",
        "      x = torch.relu(self.linear1(x.reshape(self.hp.batch_size, -1)))\n",
        "      x = self.dropout1(x)\n",
        "      x = torch.relu(self.linear2(x))\n",
        "      x = self.dropout2(x)\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    print(word_embeddings.shape)\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout),\n",
        "                     torch.nn.Dropout(p=hp.outer_dropout)]\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    self.dropouts[1](premise_embedding)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    self.dropouts[3](hypothesis_embedding)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    self.dropouts[4](factorised_mush)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention*premise_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpWRHhOxCjFl",
        "colab_type": "text"
      },
      "source": [
        "##EVAL SUMMARY :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUhazL34GWZ",
        "colab_type": "text"
      },
      "source": [
        "##SHEENABASELINE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_UvQQWx4IcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "    self.dropouts = [torch.nn.Dropout(p=hp.outer_dropout)]*5\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    processed_premise = self.dropouts[0](processed_premise)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    premise_embedding = self.dropouts[1](premise_embedding)\n",
        "    \n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    processed_hypothesis = self.dropouts[2](processed_hypothesis)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    hypothesis_embedding = self.dropouts[3](hypothesis_embedding)\n",
        "    combined = premise_embedding * hypothesis_embedding\n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    avg = self.dropouts[4](avg)\n",
        "    output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWRCDtWR4Lcq",
        "colab_type": "text"
      },
      "source": [
        "##BAD DECLARE CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db8ikkk64Kx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def load_embeddings(self, word_embeddings):\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, self.hp)\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(101, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    mean_embeddings = torch.unsqueeze(torch.sum(embeddings, 1) / self.hp.max_length, 1) #change to accurate size of lenfgth\n",
        "  \n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    #TODO: use repeat function to get 100*100\n",
        "    main_embeddings = torch.cat((mean_embeddings, added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    attention_weights = softmax(self.premise_linear(processed_premise))#TODO: turn into row vector\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis,attention_weights.transpose(1,2))\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    avg = torch.sum(combined, 1)/self.hp.max_length #todo: fix padding\n",
        "\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    output = torch.sigmoid(self.linear_final(smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMmJP6kC4Th3",
        "colab_type": "text"
      },
      "source": [
        "## GOOD DECLARE CODE???\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrRhCjK84VeR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RealDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(RealDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(hp.max_length, word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(10000, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(100, 8)\n",
        "    self.linear_almost_there = torch.nn.Linear(8, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.dropout = torch.nn.Dropout(p=0.2)\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    lengths = self.hp.max_length - (premise == 0).sum(dim=1)\n",
        "    lengths = lengths.repeat(50, 1).transpose(0,1)\n",
        "    summed_embeddings = torch.sum(embeddings, 1)\n",
        "    mean_embeddings = torch.unsqueeze(summed_embeddings / lengths, 1) #change to accurate size of lenfgth\n",
        "    flattened_embeddings = mean_embeddings.reshape(self.hp.batch_size, -1)\n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100]).reshape(self.hp.batch_size, -1)\n",
        "    #TODO: use repeat function to get 100*100 #DONE!\n",
        "    main_embeddings = torch.cat((flattened_embeddings.repeat(1, 100), added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    attention_weights = softmax(torch.tanh(self.premise_linear(main_embeddings)))#TODO: turn into row vector\n",
        "\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis, attention_weights.unsqueeze(2))\n",
        "    \n",
        "\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    new_lengths = lengths.repeat(1, 2)\n",
        "\n",
        "    avg = torch.sum(combined, 1)/new_lengths #todo: fix padding\n",
        "\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    smaller = self.dropout(smaller)\n",
        "    even_smaller = F.relu(self.linear_almost_there(smaller))\n",
        "    output = torch.sigmoid(self.linear_final(even_smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "##TRAIN/TEST/HELPERS\n",
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def should_stop(losses, limit):\n",
        "  shouldnt_stop = False \n",
        "  if len(losses) < limit:\n",
        "    return False\n",
        "  last = losses[-1]\n",
        "  if limit == 2:\n",
        "    return last >= losses[-2]\n",
        "  \n",
        "  for i in range(len(losses)-2, len(losses) - limit):\n",
        "    shouldnt_stop = shouldnt_stop or last < losses[i]\n",
        "    last = losses[i]\n",
        "  return not shouldnt_stop\n",
        "\n",
        "\n",
        "def train(model=None, \n",
        "          dataset = None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  val_losses = []\n",
        "  val_accuracies = []\n",
        "\n",
        "  is_binary = hp.num_classes == 1\n",
        "  is_validating = False\n",
        "  has_stopped = False\n",
        "  \n",
        "  if dataset.train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif dataset.train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  \n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "\n",
        "    for i in range(2):\n",
        "      \n",
        "      total_loss = 0\n",
        "      batch_count = 0\n",
        "      correct = 0\n",
        "      penal = 0\n",
        "\n",
        "      if is_validating:\n",
        "        model.train(False)\n",
        "        model.eval()\n",
        "        loader = dataset.val_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 1\n",
        "      elif has_stopped:\n",
        "        model.train(False)\n",
        "        loader = dataset.train_loader\n",
        "        torch.no_grad()\n",
        "        debug_amount = 10\n",
        "      else:\n",
        "        model.train(True)\n",
        "        loader = dataset.train_loader\n",
        "        torch.enable_grad()\n",
        "        debug_amount = 10\n",
        "      \n",
        "      for batch_index, train_data in enumerate(loader):\n",
        "      #setting everything up\n",
        "        model.hidden_state = model.reset_for_testing(train_data[0].shape[0])\n",
        "        train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "        predicted_y, attention = model(*train_data[:-1])\n",
        "        actual_y = train_data[-1]\n",
        "        squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "        if hp.C > 0:\n",
        "          attentionT = attention.transpose(1,2)\n",
        "          identity = torch.eye(attention.size(1))\n",
        "          identity = Variable(identity.unsqueeze(0).expand(loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "          penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "        if is_binary:\n",
        "          loss = loss_function(squeezed_y, actual_y.double())\n",
        "          loss += hp.C * penal/loader.batch_size\n",
        "          correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "        else:\n",
        "          loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/loader.batch_size)\n",
        "          correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "        total_loss += loss.data\n",
        "\n",
        "        if using_gradient_clipping:\n",
        "          torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      \n",
        "      #cleaning up regularisation\n",
        "        if hp.C > 0:\n",
        "          del(penal)\n",
        "          del(identity)\n",
        "          del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "        optimiser.zero_grad()\n",
        "        if not is_validating and not has_stopped:\n",
        "          loss.backward()\n",
        "          optimiser.step()\n",
        "        if hp.is_debug and batch_index % debug_amount == 0:\n",
        "          print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, ISvAL: {}, HasStopped: {}\".format(\n",
        "              epoch, batch_index * len(train_data[0]), len(loader.dataset),\n",
        "              100. * batch_index / len(loader), loss.item(), is_validating, has_stopped\n",
        "          ))\n",
        "\n",
        "      \n",
        "        batch_count += 1\n",
        "      \n",
        "        free_data(train_data)\n",
        "\n",
        "      print(\"Average loss is:\",total_loss/batch_count, \"while validation_status:\", is_validating, \"and stopping_status\", has_stopped)\n",
        "      correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "      accuracy = correct_but_numpy / float(batch_count * loader.batch_size)\n",
        "      print(\"Accuracy of the model\", accuracy)\n",
        "      if (not is_validating):\n",
        "        losses.append(total_loss/batch_count)\n",
        "        accuracies.append(accuracy)\n",
        "      else:\n",
        "        val_losses.append(total_loss/batch_count)\n",
        "        val_accuracies.append(accuracy)\n",
        "      if hp.use_early_stopping:\n",
        "        has_stopped = should_stop(val_losses, hp.early_stopping)\n",
        "\n",
        "      is_validating = not is_validating\n",
        "  return losses, val_losses, accuracies, val_accuracies "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, val_losses, accuracies, val_accuracies, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  \n",
        "  plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Train Accuracy\")\n",
        "  plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.plot(range(1, epochs+1), val_accuracies, scalex=True, scaley=True, label=\"Val Accuracy\")\n",
        "  plt.annotate(str(val_accuracies[-1]), xy=(epochs,val_accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Train Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.plot(range(1, epochs+1), val_losses,scalex=True, scaley=True, label=\"Val Loss\")\n",
        "  plt.annotate(str(val_losses[-1]), xy=(epochs,val_losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYfImtudskLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwADakVSwJat",
        "colab_type": "text"
      },
      "source": [
        "NEW FUNCTIONS TO AUTOMATE THE RUNNING OF LOTS OF DATASETS/MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFmSdvMewHrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(model, dataset, hp, is_plot=True):\n",
        "  runnable_model = model(hp, dataset.word_embeddings_small).cuda()\n",
        "  bce_loss = torch.nn.BCELoss()\n",
        "  cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "  optimiser = torch.optim.Adam(runnable_model.parameters(), lr=hp.lr, weight_decay=hp.decay)\n",
        "  losses, val_losses, accuracies, val_accuracies = train(model=runnable_model,\n",
        "                       dataset = dataset,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = optimiser,\n",
        "                       hp = hp,\n",
        "                       using_gradient_clipping=hp.grad_clip)\n",
        "  if is_plot:\n",
        "    plot_stuff(hp.epochs, losses,val_losses, accuracies, val_accuracies)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  check_loader = dataset.test_loader\n",
        "  predicted_ys = batch_wise_evaluate(runnable_model, \n",
        "         check_loader,\n",
        "         hp)\n",
        "  return predicted_ys, runnable_model\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "def get_results(model_name, dataset_name, predictions, true_labels):\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(predictions.shape) == 1):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  return {\"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc_full}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2DLo4OoUO4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(predictions.shape) == 1):\n",
        "    fpr, tpr, thresholds = roc_curve(true_labels, predictions)\n",
        "    auc_full = auc(fpr, tpr)\n",
        "  else:\n",
        "    auc_full = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc_full))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2oMDNooNrMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_to_dict(results):\n",
        "  big_results = {\"model_name\": [],\n",
        "                 \"dataset_name\": [],\n",
        "                \"precision\": [],\n",
        "                 \"recall\": [],\n",
        "                 \"accuracy\": [],\n",
        "                 \"f1\": [],\n",
        "                 \"auc\": []}\n",
        "  for result in results:\n",
        "    for key in result:\n",
        "      big_results[key].append(result[key])\n",
        "\n",
        "  return pd.DataFrame.from_dict(big_results)\n",
        "\n",
        "def process_results(big_results):\n",
        "  return (big_results[\"model_name\"][0], big_results[\"dataset_name\"][0], big_results.mean(), big_results.std())\n",
        "  \n",
        "  \n",
        "def get_avgs(some_results):\n",
        "  avg_results = {\"model_name\": some_results[0][\"model_name\"],\n",
        "                 \"dataset_name\": some_results[0][\"dataset_name\"],\n",
        "                \"precision\": 0.0,\n",
        "                 \"recall\": 0.0,\n",
        "                 \"accuracy\": 0.0,\n",
        "                 \"f1\": 0.0,\n",
        "                 \"auc\": 0.0}\n",
        "  for result in some_results:\n",
        "    for key in result:\n",
        "      if type(result[key]) is float:\n",
        "        avg_results[key] += result[key]\n",
        "  \n",
        "  for key in avg_results:\n",
        "    if(type(avg_results[key] is float)):\n",
        "      avg_results[key] /= len(some_results)\n",
        "  \n",
        "  return avg_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "##RUNNING THE MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "datasets = {\n",
        "    \"politifact\": fact_dataset,\n",
        "    \"snopes\": snopes_dataset\n",
        "}\n",
        "models = {\n",
        "    \"my_model\": TextualEntailmentModel,\n",
        "    \"sheena_model\": BaselineSentenceEntailment,\n",
        "    \"real_declare\": RealDeclare\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 40\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 20\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 10\n",
        "  inner_dropout = 0.5\n",
        "  outer_dropout = 0.5\n",
        "  C = 0.3\n",
        "  decay = 0\n",
        "  is_debug = True\n",
        "  lr=0.00008\n",
        "  grad_clip = True\n",
        "  early_stopping = 5\n",
        "  use_early_stopping = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4wRSAvtABCT",
        "colab_type": "text"
      },
      "source": [
        "##CROSS VALIDATION ZONE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Kd6J8o4j6k",
        "colab_type": "text"
      },
      "source": [
        "runnin my textual entailent model :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "be5a07fb-f1e8-49aa-b0d9-3c9d9c91d032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "NUM_OF_AVGS = 5\n",
        "avgs = []\n",
        "\"\"\"\n",
        "for i in range(NUM_OF_AVGS):\n",
        "  \n",
        "  \n",
        "  \n",
        "  avgs.append(results)\n",
        "\n",
        "print(process_results(list_to_dict(avgs)))\n",
        "\"\"\"\n",
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"snopes\"], Hyperparameters)\n",
        "results = get_results(\"my_model\", \"snopes\", predicted_ys.cpu(), datasets[\"snopes\"].test_data)\n",
        "print(results)\n",
        "  #textual_entailment_model.to(device)\n",
        "predicted_ys, text_model= run_model(models[\"my_model\"], datasets[\"politifact\"], Hyperparameters)\n",
        "results = get_results(\"my_model\", \"politifact\", predicted_ys.cpu(), datasets[\"politifact\"].test_data)\n",
        "print(results)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([39093, 50])\n",
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/12119 (0%)]\tLoss: 1.642203, ISvAL: False, HasStopped: False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [1000/12119 (8%)]\tLoss: 1.647539, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [2000/12119 (17%)]\tLoss: 1.644302, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [3000/12119 (25%)]\tLoss: 1.638998, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [4000/12119 (33%)]\tLoss: 1.637949, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [5000/12119 (41%)]\tLoss: 1.642163, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [6000/12119 (50%)]\tLoss: 1.635891, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [7000/12119 (58%)]\tLoss: 1.642113, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [8000/12119 (66%)]\tLoss: 1.641102, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [9000/12119 (74%)]\tLoss: 1.628733, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [10000/12119 (83%)]\tLoss: 1.644156, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [11000/12119 (91%)]\tLoss: 1.633921, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [12000/12119 (99%)]\tLoss: 1.638006, ISvAL: False, HasStopped: False\n",
            "Average loss is: tensor(1.6431, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5007438016528926\n",
            "Train Epoch: 0 [0/1507 (0%)]\tLoss: 1.677756, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [100/1507 (7%)]\tLoss: 1.672656, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [200/1507 (13%)]\tLoss: 1.658408, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [300/1507 (20%)]\tLoss: 1.655354, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [400/1507 (27%)]\tLoss: 1.687963, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [500/1507 (33%)]\tLoss: 1.658386, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [600/1507 (40%)]\tLoss: 1.657389, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [700/1507 (47%)]\tLoss: 1.667579, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [800/1507 (53%)]\tLoss: 1.680827, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [900/1507 (60%)]\tLoss: 1.649229, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [1000/1507 (67%)]\tLoss: 1.605424, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [1100/1507 (73%)]\tLoss: 1.604406, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [1200/1507 (80%)]\tLoss: 1.630876, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [1300/1507 (87%)]\tLoss: 1.625783, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 0 [1400/1507 (93%)]\tLoss: 1.603374, ISvAL: True, HasStopped: False\n",
            "Average loss is: tensor(1.6490, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/12119 (0%)]\tLoss: 1.651316, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [1000/12119 (8%)]\tLoss: 1.644096, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [2000/12119 (17%)]\tLoss: 1.641107, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [3000/12119 (25%)]\tLoss: 1.646086, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [4000/12119 (33%)]\tLoss: 1.644076, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [5000/12119 (41%)]\tLoss: 1.636121, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [6000/12119 (50%)]\tLoss: 1.647788, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [7000/12119 (58%)]\tLoss: 1.643040, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [8000/12119 (66%)]\tLoss: 1.636282, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [9000/12119 (74%)]\tLoss: 1.639205, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [10000/12119 (83%)]\tLoss: 1.642769, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [11000/12119 (91%)]\tLoss: 1.642140, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 1 [12000/12119 (99%)]\tLoss: 1.634670, ISvAL: False, HasStopped: False\n",
            "Average loss is: tensor(1.6429, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5008264462809917\n",
            "Train Epoch: 1 [0/1507 (0%)]\tLoss: 1.672971, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [100/1507 (7%)]\tLoss: 1.668442, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [200/1507 (13%)]\tLoss: 1.656178, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [300/1507 (20%)]\tLoss: 1.653503, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [400/1507 (27%)]\tLoss: 1.682119, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [500/1507 (33%)]\tLoss: 1.655870, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [600/1507 (40%)]\tLoss: 1.655272, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [700/1507 (47%)]\tLoss: 1.664152, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [800/1507 (53%)]\tLoss: 1.675791, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [900/1507 (60%)]\tLoss: 1.648060, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [1000/1507 (67%)]\tLoss: 1.609794, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [1100/1507 (73%)]\tLoss: 1.608916, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [1200/1507 (80%)]\tLoss: 1.631827, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [1300/1507 (87%)]\tLoss: 1.627401, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 1 [1400/1507 (93%)]\tLoss: 1.607905, ISvAL: True, HasStopped: False\n",
            "Average loss is: tensor(1.6479, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.442\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/12119 (0%)]\tLoss: 1.644749, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [1000/12119 (8%)]\tLoss: 1.638438, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [2000/12119 (17%)]\tLoss: 1.642069, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [3000/12119 (25%)]\tLoss: 1.650137, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [4000/12119 (33%)]\tLoss: 1.637115, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [5000/12119 (41%)]\tLoss: 1.640772, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [6000/12119 (50%)]\tLoss: 1.641256, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [7000/12119 (58%)]\tLoss: 1.641908, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [8000/12119 (66%)]\tLoss: 1.642396, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [9000/12119 (74%)]\tLoss: 1.641053, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [10000/12119 (83%)]\tLoss: 1.645090, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [11000/12119 (91%)]\tLoss: 1.644569, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 2 [12000/12119 (99%)]\tLoss: 1.642212, ISvAL: False, HasStopped: False\n",
            "Average loss is: tensor(1.6419, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5054545454545455\n",
            "Train Epoch: 2 [0/1507 (0%)]\tLoss: 1.628130, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [100/1507 (7%)]\tLoss: 1.628825, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [200/1507 (13%)]\tLoss: 1.637174, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [300/1507 (20%)]\tLoss: 1.637884, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [400/1507 (27%)]\tLoss: 1.629339, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [500/1507 (33%)]\tLoss: 1.631236, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [600/1507 (40%)]\tLoss: 1.637035, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [700/1507 (47%)]\tLoss: 1.632725, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [800/1507 (53%)]\tLoss: 1.629768, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [900/1507 (60%)]\tLoss: 1.638441, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [1000/1507 (67%)]\tLoss: 1.652992, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [1100/1507 (73%)]\tLoss: 1.653904, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [1200/1507 (80%)]\tLoss: 1.640475, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [1300/1507 (87%)]\tLoss: 1.642802, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 2 [1400/1507 (93%)]\tLoss: 1.652263, ISvAL: True, HasStopped: False\n",
            "Average loss is: tensor(1.6382, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5633333333333334\n",
            "Running EPOCH: 4\n",
            "Train Epoch: 3 [0/12119 (0%)]\tLoss: 1.642116, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [1000/12119 (8%)]\tLoss: 1.637214, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [2000/12119 (17%)]\tLoss: 1.637040, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [3000/12119 (25%)]\tLoss: 1.634865, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [4000/12119 (33%)]\tLoss: 1.633300, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [5000/12119 (41%)]\tLoss: 1.638077, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [6000/12119 (50%)]\tLoss: 1.638811, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [7000/12119 (58%)]\tLoss: 1.641946, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [8000/12119 (66%)]\tLoss: 1.648419, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [9000/12119 (74%)]\tLoss: 1.640895, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [10000/12119 (83%)]\tLoss: 1.629751, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [11000/12119 (91%)]\tLoss: 1.640842, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 3 [12000/12119 (99%)]\tLoss: 1.638146, ISvAL: False, HasStopped: False\n",
            "Average loss is: tensor(1.6392, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5292561983471075\n",
            "Train Epoch: 3 [0/1507 (0%)]\tLoss: 1.613863, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [100/1507 (7%)]\tLoss: 1.612637, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [200/1507 (13%)]\tLoss: 1.636834, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [300/1507 (20%)]\tLoss: 1.631610, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [400/1507 (27%)]\tLoss: 1.619972, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [500/1507 (33%)]\tLoss: 1.615754, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [600/1507 (40%)]\tLoss: 1.631723, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [700/1507 (47%)]\tLoss: 1.622728, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [800/1507 (53%)]\tLoss: 1.615867, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [900/1507 (60%)]\tLoss: 1.630827, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [1000/1507 (67%)]\tLoss: 1.659492, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [1100/1507 (73%)]\tLoss: 1.659043, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [1200/1507 (80%)]\tLoss: 1.632225, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [1300/1507 (87%)]\tLoss: 1.637645, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 3 [1400/1507 (93%)]\tLoss: 1.657292, ISvAL: True, HasStopped: False\n",
            "Average loss is: tensor(1.6318, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.5973333333333334\n",
            "Running EPOCH: 5\n",
            "Train Epoch: 4 [0/12119 (0%)]\tLoss: 1.639064, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [1000/12119 (8%)]\tLoss: 1.640265, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [2000/12119 (17%)]\tLoss: 1.632467, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [3000/12119 (25%)]\tLoss: 1.641554, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [4000/12119 (33%)]\tLoss: 1.638962, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [5000/12119 (41%)]\tLoss: 1.635631, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [6000/12119 (50%)]\tLoss: 1.644496, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [7000/12119 (58%)]\tLoss: 1.639994, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [8000/12119 (66%)]\tLoss: 1.629567, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [9000/12119 (74%)]\tLoss: 1.631207, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [10000/12119 (83%)]\tLoss: 1.624765, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [11000/12119 (91%)]\tLoss: 1.621355, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 4 [12000/12119 (99%)]\tLoss: 1.629589, ISvAL: False, HasStopped: False\n",
            "Average loss is: tensor(1.6322, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status False\n",
            "Accuracy of the model 0.5594214876033058\n",
            "Train Epoch: 4 [0/1507 (0%)]\tLoss: 1.516687, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [100/1507 (7%)]\tLoss: 1.509834, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [200/1507 (13%)]\tLoss: 1.638964, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [300/1507 (20%)]\tLoss: 1.609298, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [400/1507 (27%)]\tLoss: 1.535719, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [500/1507 (33%)]\tLoss: 1.525638, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [600/1507 (40%)]\tLoss: 1.596370, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [700/1507 (47%)]\tLoss: 1.557963, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [800/1507 (53%)]\tLoss: 1.513172, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [900/1507 (60%)]\tLoss: 1.581171, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [1000/1507 (67%)]\tLoss: 1.741745, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [1100/1507 (73%)]\tLoss: 1.729818, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [1200/1507 (80%)]\tLoss: 1.612945, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [1300/1507 (87%)]\tLoss: 1.633241, ISvAL: True, HasStopped: False\n",
            "Train Epoch: 4 [1400/1507 (93%)]\tLoss: 1.726212, ISvAL: True, HasStopped: False\n",
            "Average loss is: tensor(1.6019, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status False\n",
            "Accuracy of the model 0.6106666666666667\n",
            "Running EPOCH: 6\n",
            "Train Epoch: 5 [0/12119 (0%)]\tLoss: 1.615762, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [1000/12119 (8%)]\tLoss: 1.640882, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [2000/12119 (17%)]\tLoss: 1.595443, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [3000/12119 (25%)]\tLoss: 1.647541, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [4000/12119 (33%)]\tLoss: 1.589763, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [5000/12119 (41%)]\tLoss: 1.625171, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [6000/12119 (50%)]\tLoss: 1.622144, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [7000/12119 (58%)]\tLoss: 1.654835, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [8000/12119 (66%)]\tLoss: 1.627231, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [9000/12119 (74%)]\tLoss: 1.629940, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [10000/12119 (83%)]\tLoss: 1.587689, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [11000/12119 (91%)]\tLoss: 1.613284, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 5 [12000/12119 (99%)]\tLoss: 1.618095, ISvAL: False, HasStopped: True\n",
            "Average loss is: tensor(1.6165, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.5714876033057851\n",
            "Train Epoch: 5 [0/1507 (0%)]\tLoss: 1.516687, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [100/1507 (7%)]\tLoss: 1.509834, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [200/1507 (13%)]\tLoss: 1.638964, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [300/1507 (20%)]\tLoss: 1.609298, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [400/1507 (27%)]\tLoss: 1.535719, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [500/1507 (33%)]\tLoss: 1.525638, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [600/1507 (40%)]\tLoss: 1.596370, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [700/1507 (47%)]\tLoss: 1.557963, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [800/1507 (53%)]\tLoss: 1.513172, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [900/1507 (60%)]\tLoss: 1.581171, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [1000/1507 (67%)]\tLoss: 1.741745, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [1100/1507 (73%)]\tLoss: 1.729818, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [1200/1507 (80%)]\tLoss: 1.612945, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [1300/1507 (87%)]\tLoss: 1.633241, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 5 [1400/1507 (93%)]\tLoss: 1.726212, ISvAL: True, HasStopped: True\n",
            "Average loss is: tensor(1.6019, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6106666666666667\n",
            "Running EPOCH: 7\n",
            "Train Epoch: 6 [0/12119 (0%)]\tLoss: 1.598623, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [1000/12119 (8%)]\tLoss: 1.634767, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [2000/12119 (17%)]\tLoss: 1.603658, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [3000/12119 (25%)]\tLoss: 1.602294, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [4000/12119 (33%)]\tLoss: 1.641202, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [5000/12119 (41%)]\tLoss: 1.601619, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [6000/12119 (50%)]\tLoss: 1.605624, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [7000/12119 (58%)]\tLoss: 1.603453, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [8000/12119 (66%)]\tLoss: 1.634625, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [9000/12119 (74%)]\tLoss: 1.632526, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [10000/12119 (83%)]\tLoss: 1.630078, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [11000/12119 (91%)]\tLoss: 1.606621, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 6 [12000/12119 (99%)]\tLoss: 1.632023, ISvAL: False, HasStopped: True\n",
            "Average loss is: tensor(1.6165, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.5715702479338843\n",
            "Train Epoch: 6 [0/1507 (0%)]\tLoss: 1.516687, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [100/1507 (7%)]\tLoss: 1.509834, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [200/1507 (13%)]\tLoss: 1.638964, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [300/1507 (20%)]\tLoss: 1.609298, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [400/1507 (27%)]\tLoss: 1.535719, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [500/1507 (33%)]\tLoss: 1.525638, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [600/1507 (40%)]\tLoss: 1.596370, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [700/1507 (47%)]\tLoss: 1.557963, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [800/1507 (53%)]\tLoss: 1.513172, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [900/1507 (60%)]\tLoss: 1.581171, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [1000/1507 (67%)]\tLoss: 1.741745, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [1100/1507 (73%)]\tLoss: 1.729818, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [1200/1507 (80%)]\tLoss: 1.612945, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [1300/1507 (87%)]\tLoss: 1.633241, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 6 [1400/1507 (93%)]\tLoss: 1.726212, ISvAL: True, HasStopped: True\n",
            "Average loss is: tensor(1.6019, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6106666666666667\n",
            "Running EPOCH: 8\n",
            "Train Epoch: 7 [0/12119 (0%)]\tLoss: 1.620667, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [1000/12119 (8%)]\tLoss: 1.585670, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [2000/12119 (17%)]\tLoss: 1.653807, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [3000/12119 (25%)]\tLoss: 1.620672, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [4000/12119 (33%)]\tLoss: 1.634207, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [5000/12119 (41%)]\tLoss: 1.617117, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [6000/12119 (50%)]\tLoss: 1.628900, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [7000/12119 (58%)]\tLoss: 1.613807, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [8000/12119 (66%)]\tLoss: 1.609595, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [9000/12119 (74%)]\tLoss: 1.629024, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [10000/12119 (83%)]\tLoss: 1.595465, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [11000/12119 (91%)]\tLoss: 1.590550, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 7 [12000/12119 (99%)]\tLoss: 1.595710, ISvAL: False, HasStopped: True\n",
            "Average loss is: tensor(1.6163, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.571900826446281\n",
            "Train Epoch: 7 [0/1507 (0%)]\tLoss: 1.516687, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [100/1507 (7%)]\tLoss: 1.509834, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [200/1507 (13%)]\tLoss: 1.638964, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [300/1507 (20%)]\tLoss: 1.609298, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [400/1507 (27%)]\tLoss: 1.535719, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [500/1507 (33%)]\tLoss: 1.525638, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [600/1507 (40%)]\tLoss: 1.596370, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [700/1507 (47%)]\tLoss: 1.557963, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [800/1507 (53%)]\tLoss: 1.513172, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [900/1507 (60%)]\tLoss: 1.581171, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [1000/1507 (67%)]\tLoss: 1.741745, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [1100/1507 (73%)]\tLoss: 1.729818, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [1200/1507 (80%)]\tLoss: 1.612945, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [1300/1507 (87%)]\tLoss: 1.633241, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 7 [1400/1507 (93%)]\tLoss: 1.726212, ISvAL: True, HasStopped: True\n",
            "Average loss is: tensor(1.6019, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6106666666666667\n",
            "Running EPOCH: 9\n",
            "Train Epoch: 8 [0/12119 (0%)]\tLoss: 1.593170, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [1000/12119 (8%)]\tLoss: 1.628282, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [2000/12119 (17%)]\tLoss: 1.603898, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [3000/12119 (25%)]\tLoss: 1.635373, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [4000/12119 (33%)]\tLoss: 1.619274, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [5000/12119 (41%)]\tLoss: 1.589044, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [6000/12119 (50%)]\tLoss: 1.632382, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [7000/12119 (58%)]\tLoss: 1.622952, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [8000/12119 (66%)]\tLoss: 1.611210, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [9000/12119 (74%)]\tLoss: 1.600555, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [10000/12119 (83%)]\tLoss: 1.602933, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [11000/12119 (91%)]\tLoss: 1.602971, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 8 [12000/12119 (99%)]\tLoss: 1.594705, ISvAL: False, HasStopped: True\n",
            "Average loss is: tensor(1.6164, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.5716528925619835\n",
            "Train Epoch: 8 [0/1507 (0%)]\tLoss: 1.516687, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [100/1507 (7%)]\tLoss: 1.509834, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [200/1507 (13%)]\tLoss: 1.638964, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [300/1507 (20%)]\tLoss: 1.609298, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [400/1507 (27%)]\tLoss: 1.535719, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [500/1507 (33%)]\tLoss: 1.525638, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [600/1507 (40%)]\tLoss: 1.596370, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [700/1507 (47%)]\tLoss: 1.557963, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [800/1507 (53%)]\tLoss: 1.513172, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [900/1507 (60%)]\tLoss: 1.581171, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [1000/1507 (67%)]\tLoss: 1.741745, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [1100/1507 (73%)]\tLoss: 1.729818, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [1200/1507 (80%)]\tLoss: 1.612945, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [1300/1507 (87%)]\tLoss: 1.633241, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 8 [1400/1507 (93%)]\tLoss: 1.726212, ISvAL: True, HasStopped: True\n",
            "Average loss is: tensor(1.6019, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6106666666666667\n",
            "Running EPOCH: 10\n",
            "Train Epoch: 9 [0/12119 (0%)]\tLoss: 1.627725, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [1000/12119 (8%)]\tLoss: 1.595329, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [2000/12119 (17%)]\tLoss: 1.619468, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [3000/12119 (25%)]\tLoss: 1.628546, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [4000/12119 (33%)]\tLoss: 1.645486, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [5000/12119 (41%)]\tLoss: 1.624440, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [6000/12119 (50%)]\tLoss: 1.600928, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [7000/12119 (58%)]\tLoss: 1.612155, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [8000/12119 (66%)]\tLoss: 1.610051, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [9000/12119 (74%)]\tLoss: 1.636320, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [10000/12119 (83%)]\tLoss: 1.606433, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [11000/12119 (91%)]\tLoss: 1.588835, ISvAL: False, HasStopped: True\n",
            "Train Epoch: 9 [12000/12119 (99%)]\tLoss: 1.596815, ISvAL: False, HasStopped: True\n",
            "Average loss is: tensor(1.6163, device='cuda:0', dtype=torch.float64) while validation_status: False and stopping_status True\n",
            "Accuracy of the model 0.5717355371900826\n",
            "Train Epoch: 9 [0/1507 (0%)]\tLoss: 1.516687, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [100/1507 (7%)]\tLoss: 1.509834, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [200/1507 (13%)]\tLoss: 1.638964, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [300/1507 (20%)]\tLoss: 1.609298, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [400/1507 (27%)]\tLoss: 1.535719, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [500/1507 (33%)]\tLoss: 1.525638, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [600/1507 (40%)]\tLoss: 1.596370, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [700/1507 (47%)]\tLoss: 1.557963, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [800/1507 (53%)]\tLoss: 1.513172, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [900/1507 (60%)]\tLoss: 1.581171, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [1000/1507 (67%)]\tLoss: 1.741745, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [1100/1507 (73%)]\tLoss: 1.729818, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [1200/1507 (80%)]\tLoss: 1.612945, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [1300/1507 (87%)]\tLoss: 1.633241, ISvAL: True, HasStopped: True\n",
            "Train Epoch: 9 [1400/1507 (93%)]\tLoss: 1.726212, ISvAL: True, HasStopped: True\n",
            "Average loss is: tensor(1.6019, device='cuda:0', dtype=torch.float64) while validation_status: True and stopping_status True\n",
            "Accuracy of the model 0.6106666666666667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'model_name': 'my_model', 'dataset_name': 'snopes', 'precision': 0.5468833507511208, 'recall': 0.6051127257185597, 'accuracy': 0.5466405740378343, 'f1': 0.47390836114555235, 'auc': 0.5468833507511207}\n",
            "torch.Size([33766, 50])\n",
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/23817 (0%)]\tLoss: 1.643925, ISvAL: False, HasStopped: False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [1000/23817 (4%)]\tLoss: 1.643916, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [2000/23817 (8%)]\tLoss: 1.642962, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [3000/23817 (13%)]\tLoss: 1.642944, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [4000/23817 (17%)]\tLoss: 1.644819, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [5000/23817 (21%)]\tLoss: 1.641049, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [6000/23817 (25%)]\tLoss: 1.642918, ISvAL: False, HasStopped: False\n",
            "Train Epoch: 0 [7000/23817 (29%)]\tLoss: 1.643811, ISvAL: False, HasStopped: False\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-f742890b7ec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m#textual_entailment_model.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpredicted_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"politifact\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"politifact\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_ys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"politifact\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-147-1a3c21a92b33>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, dataset, hp, is_plot)\u001b[0m\n\u001b[1;32m      9\u001b[0m                        \u001b[0moptimiser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                        \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                        using_gradient_clipping=hp.grad_clip)\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_plot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplot_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-144-e0221d201cd8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, loss_function, optimiser, hp, using_gradient_clipping)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_validating\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m           \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_debug\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdebug_amount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiKSouRQRERERFKUHIqIiIhIyv8DJnCdXoV2w4cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4JkXr8fcoee",
        "colab_type": "text"
      },
      "source": [
        "WOAH WERE DOIN SOME VALIDATION\n",
        "PLEASE VALIDATE ME"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b1b85456-7f1d-4ada-9cdc-e216ccb61709"
      },
      "source": [
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu() ,datasets[\"politifact\"].test_data)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.631 P=0.614 R=0.636 F1=0.606 AUC=0.614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.417     0.648     0.507       836\n",
            "         1.0      0.811     0.624     0.705      2019\n",
            "\n",
            "    accuracy                          0.631      2855\n",
            "   macro avg      0.614     0.636     0.606      2855\n",
            "weighted avg      0.695     0.631     0.647      2855\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 542  759]\n",
            " [ 294 1260]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6137067120925691,\n",
              " 0.6361983406442623,\n",
              " 0.6311733800350263,\n",
              " 0.6062714155888395)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Zfw_4Acupe",
        "colab_type": "text"
      },
      "source": [
        "JUST TESTIN HERE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsngYK8wcvc8",
        "colab_type": "code",
        "outputId": "b6de5f47-bdb6-4a75-d8ae-a318e55cc82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "test_results= batch_wise_evaluate(text_model, datasets[\"politifact\"].test_loader, Hyperparameters)\n",
        "evaluation_summary(\"textual entailment test model\", test_results.cpu(), datasets[\"politifact\"].test_data)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: textual entailment test model\n",
            "Classifier 'textual entailment test model' has Acc=0.631 P=0.614 R=0.636 F1=0.606 AUC=0.614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.417     0.648     0.507       836\n",
            "         1.0      0.811     0.624     0.705      2019\n",
            "\n",
            "    accuracy                          0.631      2855\n",
            "   macro avg      0.614     0.636     0.606      2855\n",
            "weighted avg      0.695     0.631     0.647      2855\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 542  759]\n",
            " [ 294 1260]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6137067120925691,\n",
              " 0.6361983406442623,\n",
              " 0.6311733800350263,\n",
              " 0.6062714155888395)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qViWwxJG5Oys",
        "colab_type": "text"
      },
      "source": [
        "##running sheena's model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ngDR0NMc26u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SheenaParameters:\n",
        "  lstm_hidden_size = 40\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 150\n",
        "  gravity = 70\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  inner_dropout=0.5\n",
        "  outer_dropout=0.5\n",
        "  C = 0.3\n",
        "  is_debug = True\n",
        "  grad_clip = True\n",
        "  lr=0.0005\n",
        "  decay = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOunnQsb5B7a",
        "colab_type": "code",
        "outputId": "874a4d76-8a29-4641-a2bb-8ba1a1fa4209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sheena_predicted_ys, model = run_model(models[\"sheena_model\"], datasets[\"politifact\"], SheenaParameters)\n",
        "results = get_results(\"sheena_model\", \"politifact\", sheena_predicted_ys.cpu(), datasets[\"politifact\"].test_data)\n",
        "print(results)\n",
        "sheena_predicted_ys, model = run_model(models[\"sheena_model\"], datasets[\"snopes\"], SheenaParameters)\n",
        "results = get_results(\"sheena_model\", \"snopes\", sheena_predicted_ys.cpu(), datasets[\"snopes\"].test_data)\n",
        "print(results)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23817 (0%)]\tLoss: 1.632923, ISvAL: False\n",
            "Train Epoch: 0 [1000/23817 (4%)]\tLoss: 1.636421, ISvAL: False\n",
            "Train Epoch: 0 [2000/23817 (8%)]\tLoss: 1.635293, ISvAL: False\n",
            "Train Epoch: 0 [3000/23817 (13%)]\tLoss: 1.635388, ISvAL: False\n",
            "Train Epoch: 0 [4000/23817 (17%)]\tLoss: 1.635880, ISvAL: False\n",
            "Train Epoch: 0 [5000/23817 (21%)]\tLoss: 1.635460, ISvAL: False\n",
            "Train Epoch: 0 [6000/23817 (25%)]\tLoss: 1.633643, ISvAL: False\n",
            "Train Epoch: 0 [7000/23817 (29%)]\tLoss: 1.633273, ISvAL: False\n",
            "Train Epoch: 0 [8000/23817 (34%)]\tLoss: 1.633423, ISvAL: False\n",
            "Train Epoch: 0 [9000/23817 (38%)]\tLoss: 1.629028, ISvAL: False\n",
            "Train Epoch: 0 [10000/23817 (42%)]\tLoss: 1.622762, ISvAL: False\n",
            "Train Epoch: 0 [11000/23817 (46%)]\tLoss: 1.628427, ISvAL: False\n",
            "Train Epoch: 0 [12000/23817 (50%)]\tLoss: 1.607216, ISvAL: False\n",
            "Train Epoch: 0 [13000/23817 (55%)]\tLoss: 1.643706, ISvAL: False\n",
            "Train Epoch: 0 [14000/23817 (59%)]\tLoss: 1.598359, ISvAL: False\n",
            "Train Epoch: 0 [15000/23817 (63%)]\tLoss: 1.585997, ISvAL: False\n",
            "Train Epoch: 0 [16000/23817 (67%)]\tLoss: 1.566020, ISvAL: False\n",
            "Train Epoch: 0 [17000/23817 (71%)]\tLoss: 1.632932, ISvAL: False\n",
            "Train Epoch: 0 [18000/23817 (76%)]\tLoss: 1.567641, ISvAL: False\n",
            "Train Epoch: 0 [19000/23817 (80%)]\tLoss: 1.609590, ISvAL: False\n",
            "Train Epoch: 0 [20000/23817 (84%)]\tLoss: 1.592317, ISvAL: False\n",
            "Train Epoch: 0 [21000/23817 (88%)]\tLoss: 1.607314, ISvAL: False\n",
            "Train Epoch: 0 [22000/23817 (92%)]\tLoss: 1.579295, ISvAL: False\n",
            "Train Epoch: 0 [23000/23817 (97%)]\tLoss: 1.553230, ISvAL: False\n",
            "Average loss is: tensor(1.6086, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.5664285714285714\n",
            "Train Epoch: 0 [0/2884 (0%)]\tLoss: 1.536414, ISvAL: True\n",
            "Train Epoch: 0 [100/2884 (4%)]\tLoss: 1.533699, ISvAL: True\n",
            "Train Epoch: 0 [200/2884 (7%)]\tLoss: 1.615807, ISvAL: True\n",
            "Train Epoch: 0 [300/2884 (11%)]\tLoss: 1.528715, ISvAL: True\n",
            "Train Epoch: 0 [400/2884 (14%)]\tLoss: 1.685530, ISvAL: True\n",
            "Train Epoch: 0 [500/2884 (18%)]\tLoss: 1.507028, ISvAL: True\n",
            "Train Epoch: 0 [600/2884 (21%)]\tLoss: 1.525116, ISvAL: True\n",
            "Train Epoch: 0 [700/2884 (25%)]\tLoss: 1.512875, ISvAL: True\n",
            "Train Epoch: 0 [800/2884 (29%)]\tLoss: 1.821079, ISvAL: True\n",
            "Train Epoch: 0 [900/2884 (32%)]\tLoss: 1.626006, ISvAL: True\n",
            "Train Epoch: 0 [1000/2884 (36%)]\tLoss: 1.574812, ISvAL: True\n",
            "Train Epoch: 0 [1100/2884 (39%)]\tLoss: 1.719985, ISvAL: True\n",
            "Train Epoch: 0 [1200/2884 (43%)]\tLoss: 1.702533, ISvAL: True\n",
            "Train Epoch: 0 [1300/2884 (46%)]\tLoss: 1.466340, ISvAL: True\n",
            "Train Epoch: 0 [1400/2884 (50%)]\tLoss: 1.548208, ISvAL: True\n",
            "Train Epoch: 0 [1500/2884 (54%)]\tLoss: 1.599146, ISvAL: True\n",
            "Train Epoch: 0 [1600/2884 (57%)]\tLoss: 1.673964, ISvAL: True\n",
            "Train Epoch: 0 [1700/2884 (61%)]\tLoss: 1.499868, ISvAL: True\n",
            "Train Epoch: 0 [1800/2884 (64%)]\tLoss: 1.576832, ISvAL: True\n",
            "Train Epoch: 0 [1900/2884 (68%)]\tLoss: 1.645861, ISvAL: True\n",
            "Train Epoch: 0 [2000/2884 (71%)]\tLoss: 1.711205, ISvAL: True\n",
            "Train Epoch: 0 [2100/2884 (75%)]\tLoss: 1.686570, ISvAL: True\n",
            "Train Epoch: 0 [2200/2884 (79%)]\tLoss: 1.561495, ISvAL: True\n",
            "Train Epoch: 0 [2300/2884 (82%)]\tLoss: 1.611582, ISvAL: True\n",
            "Train Epoch: 0 [2400/2884 (86%)]\tLoss: 1.768950, ISvAL: True\n",
            "Train Epoch: 0 [2500/2884 (89%)]\tLoss: 1.508855, ISvAL: True\n",
            "Train Epoch: 0 [2600/2884 (93%)]\tLoss: 1.615509, ISvAL: True\n",
            "Train Epoch: 0 [2700/2884 (96%)]\tLoss: 1.750681, ISvAL: True\n",
            "Average loss is: tensor(1.6112, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.5903571428571428\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23817 (0%)]\tLoss: 1.480175, ISvAL: False\n",
            "Train Epoch: 1 [1000/23817 (4%)]\tLoss: 1.577185, ISvAL: False\n",
            "Train Epoch: 1 [2000/23817 (8%)]\tLoss: 1.533805, ISvAL: False\n",
            "Train Epoch: 1 [3000/23817 (13%)]\tLoss: 1.514360, ISvAL: False\n",
            "Train Epoch: 1 [4000/23817 (17%)]\tLoss: 1.536653, ISvAL: False\n",
            "Train Epoch: 1 [5000/23817 (21%)]\tLoss: 1.590565, ISvAL: False\n",
            "Train Epoch: 1 [6000/23817 (25%)]\tLoss: 1.546509, ISvAL: False\n",
            "Train Epoch: 1 [7000/23817 (29%)]\tLoss: 1.545004, ISvAL: False\n",
            "Train Epoch: 1 [8000/23817 (34%)]\tLoss: 1.436001, ISvAL: False\n",
            "Train Epoch: 1 [9000/23817 (38%)]\tLoss: 1.498044, ISvAL: False\n",
            "Train Epoch: 1 [10000/23817 (42%)]\tLoss: 1.526635, ISvAL: False\n",
            "Train Epoch: 1 [11000/23817 (46%)]\tLoss: 1.489178, ISvAL: False\n",
            "Train Epoch: 1 [12000/23817 (50%)]\tLoss: 1.462481, ISvAL: False\n",
            "Train Epoch: 1 [13000/23817 (55%)]\tLoss: 1.487565, ISvAL: False\n",
            "Train Epoch: 1 [14000/23817 (59%)]\tLoss: 1.493597, ISvAL: False\n",
            "Train Epoch: 1 [15000/23817 (63%)]\tLoss: 1.508525, ISvAL: False\n",
            "Train Epoch: 1 [16000/23817 (67%)]\tLoss: 1.491107, ISvAL: False\n",
            "Train Epoch: 1 [17000/23817 (71%)]\tLoss: 1.460077, ISvAL: False\n",
            "Train Epoch: 1 [18000/23817 (76%)]\tLoss: 1.401370, ISvAL: False\n",
            "Train Epoch: 1 [19000/23817 (80%)]\tLoss: 1.420865, ISvAL: False\n",
            "Train Epoch: 1 [20000/23817 (84%)]\tLoss: 1.431821, ISvAL: False\n",
            "Train Epoch: 1 [21000/23817 (88%)]\tLoss: 1.428776, ISvAL: False\n",
            "Train Epoch: 1 [22000/23817 (92%)]\tLoss: 1.430917, ISvAL: False\n",
            "Train Epoch: 1 [23000/23817 (97%)]\tLoss: 1.423227, ISvAL: False\n",
            "Average loss is: tensor(1.4839, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.6728151260504202\n",
            "Train Epoch: 1 [0/2884 (0%)]\tLoss: 1.465539, ISvAL: True\n",
            "Train Epoch: 1 [100/2884 (4%)]\tLoss: 1.402943, ISvAL: True\n",
            "Train Epoch: 1 [200/2884 (7%)]\tLoss: 1.547335, ISvAL: True\n",
            "Train Epoch: 1 [300/2884 (11%)]\tLoss: 1.485754, ISvAL: True\n",
            "Train Epoch: 1 [400/2884 (14%)]\tLoss: 1.563480, ISvAL: True\n",
            "Train Epoch: 1 [500/2884 (18%)]\tLoss: 1.545738, ISvAL: True\n",
            "Train Epoch: 1 [600/2884 (21%)]\tLoss: 1.354734, ISvAL: True\n",
            "Train Epoch: 1 [700/2884 (25%)]\tLoss: 1.521353, ISvAL: True\n",
            "Train Epoch: 1 [800/2884 (29%)]\tLoss: 1.815028, ISvAL: True\n",
            "Train Epoch: 1 [900/2884 (32%)]\tLoss: 1.631944, ISvAL: True\n",
            "Train Epoch: 1 [1000/2884 (36%)]\tLoss: 1.508941, ISvAL: True\n",
            "Train Epoch: 1 [1100/2884 (39%)]\tLoss: 1.813845, ISvAL: True\n",
            "Train Epoch: 1 [1200/2884 (43%)]\tLoss: 1.700369, ISvAL: True\n",
            "Train Epoch: 1 [1300/2884 (46%)]\tLoss: 1.385583, ISvAL: True\n",
            "Train Epoch: 1 [1400/2884 (50%)]\tLoss: 1.415015, ISvAL: True\n",
            "Train Epoch: 1 [1500/2884 (54%)]\tLoss: 1.589940, ISvAL: True\n",
            "Train Epoch: 1 [1600/2884 (57%)]\tLoss: 1.612439, ISvAL: True\n",
            "Train Epoch: 1 [1700/2884 (61%)]\tLoss: 1.445641, ISvAL: True\n",
            "Train Epoch: 1 [1800/2884 (64%)]\tLoss: 1.547635, ISvAL: True\n",
            "Train Epoch: 1 [1900/2884 (68%)]\tLoss: 1.565303, ISvAL: True\n",
            "Train Epoch: 1 [2000/2884 (71%)]\tLoss: 1.619826, ISvAL: True\n",
            "Train Epoch: 1 [2100/2884 (75%)]\tLoss: 1.735279, ISvAL: True\n",
            "Train Epoch: 1 [2200/2884 (79%)]\tLoss: 1.625298, ISvAL: True\n",
            "Train Epoch: 1 [2300/2884 (82%)]\tLoss: 1.620596, ISvAL: True\n",
            "Train Epoch: 1 [2400/2884 (86%)]\tLoss: 1.813780, ISvAL: True\n",
            "Train Epoch: 1 [2500/2884 (89%)]\tLoss: 1.438873, ISvAL: True\n",
            "Train Epoch: 1 [2600/2884 (93%)]\tLoss: 1.614083, ISvAL: True\n",
            "Train Epoch: 1 [2700/2884 (96%)]\tLoss: 1.536247, ISvAL: True\n",
            "Average loss is: tensor(1.5687, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.6225\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23817 (0%)]\tLoss: 1.405566, ISvAL: False\n",
            "Train Epoch: 2 [1000/23817 (4%)]\tLoss: 1.372799, ISvAL: False\n",
            "Train Epoch: 2 [2000/23817 (8%)]\tLoss: 1.352735, ISvAL: False\n",
            "Train Epoch: 2 [3000/23817 (13%)]\tLoss: 1.454825, ISvAL: False\n",
            "Train Epoch: 2 [4000/23817 (17%)]\tLoss: 1.354611, ISvAL: False\n",
            "Train Epoch: 2 [5000/23817 (21%)]\tLoss: 1.384323, ISvAL: False\n",
            "Train Epoch: 2 [6000/23817 (25%)]\tLoss: 1.368258, ISvAL: False\n",
            "Train Epoch: 2 [7000/23817 (29%)]\tLoss: 1.275169, ISvAL: False\n",
            "Train Epoch: 2 [8000/23817 (34%)]\tLoss: 1.300605, ISvAL: False\n",
            "Train Epoch: 2 [9000/23817 (38%)]\tLoss: 1.316036, ISvAL: False\n",
            "Train Epoch: 2 [10000/23817 (42%)]\tLoss: 1.279415, ISvAL: False\n",
            "Train Epoch: 2 [11000/23817 (46%)]\tLoss: 1.289426, ISvAL: False\n",
            "Train Epoch: 2 [12000/23817 (50%)]\tLoss: 1.223414, ISvAL: False\n",
            "Train Epoch: 2 [13000/23817 (55%)]\tLoss: 1.336866, ISvAL: False\n",
            "Train Epoch: 2 [14000/23817 (59%)]\tLoss: 1.301518, ISvAL: False\n",
            "Train Epoch: 2 [15000/23817 (63%)]\tLoss: 1.187965, ISvAL: False\n",
            "Train Epoch: 2 [16000/23817 (67%)]\tLoss: 1.222390, ISvAL: False\n",
            "Train Epoch: 2 [17000/23817 (71%)]\tLoss: 1.169182, ISvAL: False\n",
            "Train Epoch: 2 [18000/23817 (76%)]\tLoss: 1.254772, ISvAL: False\n",
            "Train Epoch: 2 [19000/23817 (80%)]\tLoss: 1.180494, ISvAL: False\n",
            "Train Epoch: 2 [20000/23817 (84%)]\tLoss: 1.209797, ISvAL: False\n",
            "Train Epoch: 2 [21000/23817 (88%)]\tLoss: 1.152007, ISvAL: False\n",
            "Train Epoch: 2 [22000/23817 (92%)]\tLoss: 1.165517, ISvAL: False\n",
            "Train Epoch: 2 [23000/23817 (97%)]\tLoss: 1.151911, ISvAL: False\n",
            "Average loss is: tensor(1.2884, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.7496218487394958\n",
            "Train Epoch: 2 [0/2884 (0%)]\tLoss: 1.461082, ISvAL: True\n",
            "Train Epoch: 2 [100/2884 (4%)]\tLoss: 1.322957, ISvAL: True\n",
            "Train Epoch: 2 [200/2884 (7%)]\tLoss: 1.550648, ISvAL: True\n",
            "Train Epoch: 2 [300/2884 (11%)]\tLoss: 1.476552, ISvAL: True\n",
            "Train Epoch: 2 [400/2884 (14%)]\tLoss: 1.532340, ISvAL: True\n",
            "Train Epoch: 2 [500/2884 (18%)]\tLoss: 1.639587, ISvAL: True\n",
            "Train Epoch: 2 [600/2884 (21%)]\tLoss: 1.351754, ISvAL: True\n",
            "Train Epoch: 2 [700/2884 (25%)]\tLoss: 1.488165, ISvAL: True\n",
            "Train Epoch: 2 [800/2884 (29%)]\tLoss: 1.842047, ISvAL: True\n",
            "Train Epoch: 2 [900/2884 (32%)]\tLoss: 1.632185, ISvAL: True\n",
            "Train Epoch: 2 [1000/2884 (36%)]\tLoss: 1.528254, ISvAL: True\n",
            "Train Epoch: 2 [1100/2884 (39%)]\tLoss: 2.126699, ISvAL: True\n",
            "Train Epoch: 2 [1200/2884 (43%)]\tLoss: 1.698836, ISvAL: True\n",
            "Train Epoch: 2 [1300/2884 (46%)]\tLoss: 1.426184, ISvAL: True\n",
            "Train Epoch: 2 [1400/2884 (50%)]\tLoss: 1.435132, ISvAL: True\n",
            "Train Epoch: 2 [1500/2884 (54%)]\tLoss: 1.681985, ISvAL: True\n",
            "Train Epoch: 2 [1600/2884 (57%)]\tLoss: 1.734100, ISvAL: True\n",
            "Train Epoch: 2 [1700/2884 (61%)]\tLoss: 1.438166, ISvAL: True\n",
            "Train Epoch: 2 [1800/2884 (64%)]\tLoss: 1.556663, ISvAL: True\n",
            "Train Epoch: 2 [1900/2884 (68%)]\tLoss: 1.505271, ISvAL: True\n",
            "Train Epoch: 2 [2000/2884 (71%)]\tLoss: 1.642706, ISvAL: True\n",
            "Train Epoch: 2 [2100/2884 (75%)]\tLoss: 1.832455, ISvAL: True\n",
            "Train Epoch: 2 [2200/2884 (79%)]\tLoss: 1.752096, ISvAL: True\n",
            "Train Epoch: 2 [2300/2884 (82%)]\tLoss: 1.663505, ISvAL: True\n",
            "Train Epoch: 2 [2400/2884 (86%)]\tLoss: 1.978391, ISvAL: True\n",
            "Train Epoch: 2 [2500/2884 (89%)]\tLoss: 1.424524, ISvAL: True\n",
            "Train Epoch: 2 [2600/2884 (93%)]\tLoss: 1.628690, ISvAL: True\n",
            "Train Epoch: 2 [2700/2884 (96%)]\tLoss: 1.544080, ISvAL: True\n",
            "Average loss is: tensor(1.6034, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.6346428571428572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'model_name': 'sheena_model', 'dataset_name': 'politifact', 'precision': 0.644042252420423, 'recall': 0.6448108028546651, 'accuracy': 0.647985989492119, 'f1': 0.6443161427681551, 'auc': 0.644042252420423}\n",
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:76: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/12119 (0%)]\tLoss: 1.635951, ISvAL: False\n",
            "Train Epoch: 0 [1000/12119 (8%)]\tLoss: 1.640356, ISvAL: False\n",
            "Train Epoch: 0 [2000/12119 (17%)]\tLoss: 1.632332, ISvAL: False\n",
            "Train Epoch: 0 [3000/12119 (25%)]\tLoss: 1.633542, ISvAL: False\n",
            "Train Epoch: 0 [4000/12119 (33%)]\tLoss: 1.636716, ISvAL: False\n",
            "Train Epoch: 0 [5000/12119 (41%)]\tLoss: 1.634425, ISvAL: False\n",
            "Train Epoch: 0 [6000/12119 (50%)]\tLoss: 1.634336, ISvAL: False\n",
            "Train Epoch: 0 [7000/12119 (58%)]\tLoss: 1.634029, ISvAL: False\n",
            "Train Epoch: 0 [8000/12119 (66%)]\tLoss: 1.630527, ISvAL: False\n",
            "Train Epoch: 0 [9000/12119 (74%)]\tLoss: 1.628224, ISvAL: False\n",
            "Train Epoch: 0 [10000/12119 (83%)]\tLoss: 1.624626, ISvAL: False\n",
            "Train Epoch: 0 [11000/12119 (91%)]\tLoss: 1.614710, ISvAL: False\n",
            "Train Epoch: 0 [12000/12119 (99%)]\tLoss: 1.607607, ISvAL: False\n",
            "Average loss is: tensor(1.6309, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.512396694214876\n",
            "Train Epoch: 0 [0/1507 (0%)]\tLoss: 1.617689, ISvAL: True\n",
            "Train Epoch: 0 [100/1507 (7%)]\tLoss: 1.616028, ISvAL: True\n",
            "Train Epoch: 0 [200/1507 (13%)]\tLoss: 1.623784, ISvAL: True\n",
            "Train Epoch: 0 [300/1507 (20%)]\tLoss: 1.620710, ISvAL: True\n",
            "Train Epoch: 0 [400/1507 (27%)]\tLoss: 1.617632, ISvAL: True\n",
            "Train Epoch: 0 [500/1507 (33%)]\tLoss: 1.614359, ISvAL: True\n",
            "Train Epoch: 0 [600/1507 (40%)]\tLoss: 1.622705, ISvAL: True\n",
            "Train Epoch: 0 [700/1507 (47%)]\tLoss: 1.617612, ISvAL: True\n",
            "Train Epoch: 0 [800/1507 (53%)]\tLoss: 1.617469, ISvAL: True\n",
            "Train Epoch: 0 [900/1507 (60%)]\tLoss: 1.620716, ISvAL: True\n",
            "Train Epoch: 0 [1000/1507 (67%)]\tLoss: 1.626248, ISvAL: True\n",
            "Train Epoch: 0 [1100/1507 (73%)]\tLoss: 1.627955, ISvAL: True\n",
            "Train Epoch: 0 [1200/1507 (80%)]\tLoss: 1.619374, ISvAL: True\n",
            "Train Epoch: 0 [1300/1507 (87%)]\tLoss: 1.622725, ISvAL: True\n",
            "Train Epoch: 0 [1400/1507 (93%)]\tLoss: 1.627169, ISvAL: True\n",
            "Average loss is: tensor(1.6208, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.5553333333333333\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/12119 (0%)]\tLoss: 1.609217, ISvAL: False\n",
            "Train Epoch: 1 [1000/12119 (8%)]\tLoss: 1.599726, ISvAL: False\n",
            "Train Epoch: 1 [2000/12119 (17%)]\tLoss: 1.592207, ISvAL: False\n",
            "Train Epoch: 1 [3000/12119 (25%)]\tLoss: 1.580111, ISvAL: False\n",
            "Train Epoch: 1 [4000/12119 (33%)]\tLoss: 1.589071, ISvAL: False\n",
            "Train Epoch: 1 [5000/12119 (41%)]\tLoss: 1.588147, ISvAL: False\n",
            "Train Epoch: 1 [6000/12119 (50%)]\tLoss: 1.571181, ISvAL: False\n",
            "Train Epoch: 1 [7000/12119 (58%)]\tLoss: 1.567172, ISvAL: False\n",
            "Train Epoch: 1 [8000/12119 (66%)]\tLoss: 1.528862, ISvAL: False\n",
            "Train Epoch: 1 [9000/12119 (74%)]\tLoss: 1.551645, ISvAL: False\n",
            "Train Epoch: 1 [10000/12119 (83%)]\tLoss: 1.502159, ISvAL: False\n",
            "Train Epoch: 1 [11000/12119 (91%)]\tLoss: 1.498573, ISvAL: False\n",
            "Train Epoch: 1 [12000/12119 (99%)]\tLoss: 1.446528, ISvAL: False\n",
            "Average loss is: tensor(1.5589, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.5961157024793389\n",
            "Train Epoch: 1 [0/1507 (0%)]\tLoss: 1.491081, ISvAL: True\n",
            "Train Epoch: 1 [100/1507 (7%)]\tLoss: 1.481475, ISvAL: True\n",
            "Train Epoch: 1 [200/1507 (13%)]\tLoss: 1.677951, ISvAL: True\n",
            "Train Epoch: 1 [300/1507 (20%)]\tLoss: 1.582353, ISvAL: True\n",
            "Train Epoch: 1 [400/1507 (27%)]\tLoss: 1.619144, ISvAL: True\n",
            "Train Epoch: 1 [500/1507 (33%)]\tLoss: 1.442007, ISvAL: True\n",
            "Train Epoch: 1 [600/1507 (40%)]\tLoss: 1.601126, ISvAL: True\n",
            "Train Epoch: 1 [700/1507 (47%)]\tLoss: 1.554223, ISvAL: True\n",
            "Train Epoch: 1 [800/1507 (53%)]\tLoss: 1.504083, ISvAL: True\n",
            "Train Epoch: 1 [900/1507 (60%)]\tLoss: 1.545707, ISvAL: True\n",
            "Train Epoch: 1 [1000/1507 (67%)]\tLoss: 1.608154, ISvAL: True\n",
            "Train Epoch: 1 [1100/1507 (73%)]\tLoss: 1.632392, ISvAL: True\n",
            "Train Epoch: 1 [1200/1507 (80%)]\tLoss: 1.510193, ISvAL: True\n",
            "Train Epoch: 1 [1300/1507 (87%)]\tLoss: 1.502679, ISvAL: True\n",
            "Train Epoch: 1 [1400/1507 (93%)]\tLoss: 1.559837, ISvAL: True\n",
            "Average loss is: tensor(1.5542, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.6193333333333333\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/12119 (0%)]\tLoss: 1.515022, ISvAL: False\n",
            "Train Epoch: 2 [1000/12119 (8%)]\tLoss: 1.477866, ISvAL: False\n",
            "Train Epoch: 2 [2000/12119 (17%)]\tLoss: 1.467394, ISvAL: False\n",
            "Train Epoch: 2 [3000/12119 (25%)]\tLoss: 1.446160, ISvAL: False\n",
            "Train Epoch: 2 [4000/12119 (33%)]\tLoss: 1.417713, ISvAL: False\n",
            "Train Epoch: 2 [5000/12119 (41%)]\tLoss: 1.422268, ISvAL: False\n",
            "Train Epoch: 2 [6000/12119 (50%)]\tLoss: 1.414926, ISvAL: False\n",
            "Train Epoch: 2 [7000/12119 (58%)]\tLoss: 1.421741, ISvAL: False\n",
            "Train Epoch: 2 [8000/12119 (66%)]\tLoss: 1.421091, ISvAL: False\n",
            "Train Epoch: 2 [9000/12119 (74%)]\tLoss: 1.351592, ISvAL: False\n",
            "Train Epoch: 2 [10000/12119 (83%)]\tLoss: 1.369029, ISvAL: False\n",
            "Train Epoch: 2 [11000/12119 (91%)]\tLoss: 1.346022, ISvAL: False\n",
            "Train Epoch: 2 [12000/12119 (99%)]\tLoss: 1.319515, ISvAL: False\n",
            "Average loss is: tensor(1.4068, device='cuda:0', dtype=torch.float64) while validation_status: False\n",
            "Accuracy of the model 0.7269421487603306\n",
            "Train Epoch: 2 [0/1507 (0%)]\tLoss: 1.458842, ISvAL: True\n",
            "Train Epoch: 2 [100/1507 (7%)]\tLoss: 1.536966, ISvAL: True\n",
            "Train Epoch: 2 [200/1507 (13%)]\tLoss: 1.736814, ISvAL: True\n",
            "Train Epoch: 2 [300/1507 (20%)]\tLoss: 1.566648, ISvAL: True\n",
            "Train Epoch: 2 [400/1507 (27%)]\tLoss: 1.743246, ISvAL: True\n",
            "Train Epoch: 2 [500/1507 (33%)]\tLoss: 1.435168, ISvAL: True\n",
            "Train Epoch: 2 [600/1507 (40%)]\tLoss: 1.627253, ISvAL: True\n",
            "Train Epoch: 2 [700/1507 (47%)]\tLoss: 1.563305, ISvAL: True\n",
            "Train Epoch: 2 [800/1507 (53%)]\tLoss: 1.534833, ISvAL: True\n",
            "Train Epoch: 2 [900/1507 (60%)]\tLoss: 1.524481, ISvAL: True\n",
            "Train Epoch: 2 [1000/1507 (67%)]\tLoss: 1.437689, ISvAL: True\n",
            "Train Epoch: 2 [1100/1507 (73%)]\tLoss: 1.481303, ISvAL: True\n",
            "Train Epoch: 2 [1200/1507 (80%)]\tLoss: 1.350891, ISvAL: True\n",
            "Train Epoch: 2 [1300/1507 (87%)]\tLoss: 1.495453, ISvAL: True\n",
            "Train Epoch: 2 [1400/1507 (93%)]\tLoss: 1.401849, ISvAL: True\n",
            "Average loss is: tensor(1.5263, device='cuda:0', dtype=torch.float64) while validation_status: True\n",
            "Accuracy of the model 0.644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'model_name': 'sheena_model', 'dataset_name': 'snopes', 'precision': 0.6045969342424624, 'recall': 0.6153977601346022, 'accuracy': 0.6046966731898239, 'f1': 0.5951838540323087, 'auc': 0.6045969342424624}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5NDMzMzMiv4bQF+MgiQtKrIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noYiIiIhkKDkUERERkQwlhyIiIiKS8f8BlSYLUy9/Pr0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"sheena model\", sheena_predicted_ys.cpu(), datasets[\"politifact\"].val_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1DvOud6d0r",
        "colab_type": "text"
      },
      "source": [
        "##OK TESTING ON BROKE DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfFA1PNpzA8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeclareParameters:\n",
        "  lstm_hidden_size = 64\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = 100\n",
        "  num_classes = 1\n",
        "  inner_dropout=0\n",
        "  outer_dropout=0\n",
        "  epochs = 30\n",
        "  C = 0\n",
        "  is_debug = True\n",
        "  lr=0.0002\n",
        "  decay = 0\n",
        "  grad_clip = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_ys, text_model= run_model(models[\"real_declare\"], datasets[\"snopes\"], DeclareParameters)\n",
        "results = get_results(\"real_declare\", \"snopes\", predicted_ys.cpu(), datasets[\"snopes\"].test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-BrIP06dkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZsRrUK77HAU",
        "colab_type": "text"
      },
      "source": [
        "TESTING ON REAL DECLARE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1JetqyT7Imn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "declare_real_results, declare_predicted_ys =  run_model(models[\"real_declare\"], datasets[\"politifact\"], Hyperparameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCjS7Dfz7I8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation_summary(\"real declare model\", declare_predicted_ys.cpu(), declare_real_results.cpu(), datasets[\"politifact\"].test_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hECl8V-P8noH",
        "colab_type": "text"
      },
      "source": [
        "                  \"model_name\":model_name,\n",
        "                  \"dataset_name\": dataset_name,\n",
        "                  \"precision\":precision,\n",
        "                  \"recall\": recall,\n",
        "                  \"accuracy\": accuracy,\n",
        "                  \"f1\": f1,\n",
        "                  \"auc\": auc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDZugTi6AEHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_params = {\n",
        "    \"my_model\": Hyperparameters,\n",
        "    \"sheena_model\": SheenaParameters,\n",
        "    \"broke_declare\": DeclareParameters,\n",
        "    \"real_declare\": DeclareParameters\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWBCcIDk674v",
        "colab_type": "text"
      },
      "source": [
        "##VALIDATION LAND"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGG5mT_uBEGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "avg_amount = 5\n",
        "per_avg_amount = 10\n",
        "import csv\n",
        "\n",
        "full_results = []\n",
        "avg_results = []\n",
        "processed_results = []\n",
        "\n",
        "\n",
        "\n",
        "for data_name in datasets:\n",
        "  for model_name in models:\n",
        "    some_results = []\n",
        "  \n",
        "    for per_avg_i in range(per_avg_amount):\n",
        "      predicted_ys, model = run_model(models[model_name], datasets[data_name], all_params[model_name])\n",
        "      full_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      some_results.append(get_results(model_name, data_name, predicted_ys.cpu(), datasets[data_name].test_data))\n",
        "      \n",
        "    processed_results.append(process_results(list_to_dict(some_results)))\n",
        "    print(processed_results)\n",
        "      #avg_results.append(get_avgs(some_results))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUR-r4M717ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for result in full_results:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWgiTDHE2tP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}