{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/textual_entailment_snli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "474676f0-b945-452c-9407-50d7cd2c0977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-20 14:12:23--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  70.3MB/s    in 1.3s    \n",
            "\n",
            "2020-01-20 14:12:25 (70.3 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "97a47d10-72ef-48fa-cbc0-9a33b95f5f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-20 14:12:33--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-01-20 14:12:33--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-01-20 14:12:33--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.07MB/s    in 6m 27s  \n",
            "\n",
            "2020-01-20 14:19:00 (2.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "ede7bcf9-1e5c-41f5-8f67-35dfba39f1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-20 14:19:25--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  3.99MB/s    in 1.2s    \n",
            "\n",
            "2020-01-20 14:19:27 (3.99 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "fd953edd-f8ed-4f62-a699-4100657a2c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcNEOBx94jF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "2fed3523-3b7a-45fb-b299-351efe22ce5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-20 14:19:35--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  4.43MB/s    in 1.2s    \n",
            "\n",
            "2020-01-20 14:19:36 (4.43 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRc7BNxcOlee",
        "colab_type": "text"
      },
      "source": [
        "Some imports lol :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9P3r8j78KeG",
        "colab_type": "code",
        "outputId": "b9a207fa-2084-4020-99e2-95a9900e129b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "outputId": "82abb721-57e7-4a29-dee1-20767c793bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import math\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "2da5804d-286a-4841-f550-a73e07a2854a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "ddb4dfe2-e3b9-4fd2-fedb-17730f5c68d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "outputId": "9a39ded7-409e-4966-da62-ec3762af9763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "politi_mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "snopes_mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"false\": 0, \"pants on fire!\": 0}\n",
        "\n",
        "def slice_snopes(unique):\n",
        "  true_claims = unique[unique[\"cred_label\"] == 1]\n",
        "  false_claims = unique[unique[\"cred_label\"] == 0]\n",
        "  false_claims = false_claims.head(int(len(false_claims)/3))\n",
        "  return pd.concat([true_claims, false_claims]).sample(frac=1)\n",
        "\n",
        "\n",
        "def preprocess_fact_data(facts, mapping, slice_function=None):\n",
        "  \n",
        "  facts = facts.replace({\"cred_label\": mapping})\n",
        "  unique = facts.drop_duplicates(\"claim_id\")\n",
        "  if (slice_function):\n",
        "    unique = slice_function(unique)\n",
        "  \n",
        "#splitting the claims\n",
        "  train_unique, test_unique = train_test_split(unique, test_size=0.2, random_state=8)\n",
        "\n",
        "  \n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_unique[\"claim_id\"])]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_unique[\"claim_id\"])]\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts, politi_mapping)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes, snopes_mapping, slice_snopes)\n",
        "\n",
        "train_facts.head(500)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>for firms moving overseas in order to create a...</td>\n",
              "      <td>foxnews.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>get a tax break specifically by outsourcing jo...</td>\n",
              "      <td>newslines.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>confusing clashes over taxes in wednesday s pr...</td>\n",
              "      <td>wsj.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>support on this bill in a time of tight budget...</td>\n",
              "      <td>senate.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2012_oct_08_barack-obama_obama-says-tax-code-r...</td>\n",
              "      <td>federal tax code loopholes giving incentives c...</td>\n",
              "      <td>barack obama</td>\n",
              "      <td>tax a lower rate for american manufacturing an...</td>\n",
              "      <td>archives.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>to have a different standard the senate will h...</td>\n",
              "      <td>thedailybeast.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>double standard for mcconnell to be less conce...</td>\n",
              "      <td>weaselzippers.us</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_jan_08_cory-booker_booker-mcconnell-full-...</td>\n",
              "      <td>2009 mitch mcconnell person thats saying hey g...</td>\n",
              "      <td>cory booker</td>\n",
              "      <td>cory booker on government reform even billiona...</td>\n",
              "      <td>ontheissues.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>think are deeply committed to do and we are ob...</td>\n",
              "      <td>whitehouse.gov</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>1</td>\n",
              "      <td>2017_feb_15_benjamin-netanyahu_benjamin-netany...</td>\n",
              "      <td>past weeks president donald trump pointed iran...</td>\n",
              "      <td>benjamin netanyahu</td>\n",
              "      <td>are deeply committed to do and we are obviousl...</td>\n",
              "      <td>haaretz.com</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cred_label  ...     article_source\n",
              "0             1  ...        foxnews.com\n",
              "1             1  ...      newslines.org\n",
              "2             1  ...            wsj.com\n",
              "3             1  ...         senate.gov\n",
              "4             1  ...       archives.gov\n",
              "..          ...  ...                ...\n",
              "554           1  ...  thedailybeast.com\n",
              "555           1  ...   weaselzippers.us\n",
              "556           1  ...    ontheissues.org\n",
              "557           1  ...     whitehouse.gov\n",
              "558           1  ...        haaretz.com\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk-sQJe0Y-Bj",
        "colab_type": "code",
        "outputId": "af3b3cc0-7cf8-43b3-bb43-1ba138e262dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "test_facts.head(500)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cred_label</th>\n",
              "      <th>claim_id</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_source</th>\n",
              "      <th>article</th>\n",
              "      <th>article_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>morning new tv advertisement argues that posit...</td>\n",
              "      <td>desmoinesregister.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>iowans could not support household on current ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>not budged in five years leaving many falling ...</td>\n",
              "      <td>americanprogressaction.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>are working to support themselves or their fam...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1</td>\n",
              "      <td>2014_aug_01_bruce-braley_iowa-senate-candidate...</td>\n",
              "      <td>says us senate candidate joni ernst not suppor...</td>\n",
              "      <td>bruce braley</td>\n",
              "      <td>prove that i had those good hardworking skills...</td>\n",
              "      <td>iowademocrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2766</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>cap is melting palin im not one to attribute e...</td>\n",
              "      <td>mysinchew.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2767</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>control the weapons the theocracy does secreta...</td>\n",
              "      <td>blastmagazine.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>0</td>\n",
              "      <td>2008_oct_02_joe-biden_mccain-refused-to-commit...</td>\n",
              "      <td>john mccain said wouldnt even sit government s...</td>\n",
              "      <td>joe biden</td>\n",
              "      <td>be left with only one conclusion mccain was co...</td>\n",
              "      <td>chrisweigant.com</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2850</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>speech politifact called claim false that demo...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2851</th>\n",
              "      <td>0</td>\n",
              "      <td>2009_may_19_mike-pence_120-million-deprived-he...</td>\n",
              "      <td>democrats propose health care plan deprive rou...</td>\n",
              "      <td>mike pence</td>\n",
              "      <td>covering conduct going back as far as 1994 was...</td>\n",
              "      <td>democrats.org</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      cred_label  ...              article_source\n",
              "85             1  ...       desmoinesregister.com\n",
              "86             1  ...  americanprogressaction.org\n",
              "87             1  ...  americanprogressaction.org\n",
              "88             1  ...           iowademocrats.org\n",
              "89             1  ...           iowademocrats.org\n",
              "...          ...  ...                         ...\n",
              "2766           0  ...               mysinchew.com\n",
              "2767           0  ...           blastmagazine.com\n",
              "2768           0  ...            chrisweigant.com\n",
              "2850           0  ...               democrats.org\n",
              "2851           0  ...               democrats.org\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 500\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "snopes_tokeniser = Tokeniser(x_train_snopes_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "\n",
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n",
        "x_snopes_train = snopes_tokeniser.do_everything(x_train_snopes_list)\n",
        "x_snopes_test = snopes_tokeniser.do_everything(x_test_snopes_list)\n",
        "y_snopes_train = np.array(y_train_snopes_list, dtype=np.float32)\n",
        "y_snopes_test = np.array(y_test_snopes_list, dtype=np.float32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "we_shufflin = True\n",
        "shufflin_test = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "train_fact_source_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_source_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_fact_source_loader.name = \"fact_data\"\n",
        "\n",
        "#POLITIFACT/SNOPES W/ SOURCES\n",
        "train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_train).type(torch.LongTensor))\n",
        "test_snopes_data= data_utils.TensorDataset(torch.from_numpy(x_snopes_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_test).type(torch.LongTensor))\n",
        "train_snopes_loader = data_utils.DataLoader(train_snopes_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "test_snopes_loader = data_utils.DataLoader(test_snopes_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test)\n",
        "test_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True, shuffle=we_shufflin)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False, shuffle=shufflin_test )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "Helper function. I don't know why we have such a helper function but it's here.\n",
        "Does a softmax after transposing and reshaping things ??\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNWEGDqGSHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(input, axis=1):\n",
        "    \"\"\"\n",
        "        Softmax applied to axis=n\n",
        " \n",
        "        Args:\n",
        "           input: {Tensor,Variable} input on which softmax is to be applied\n",
        "           axis : {int} axis on which softmax is to be applied\n",
        " \n",
        "        Returns:\n",
        "            softmaxed tensors\n",
        " \n",
        "       \n",
        "    \"\"\"\n",
        "    input_size = input.size()\n",
        "    trans_input = input.transpose(axis, len(input_size)-1)\n",
        "    trans_size = trans_input.size()\n",
        "    input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
        "    soft_max_2d = F.softmax(input_2d)\n",
        "    soft_max_nd = soft_max_2d.view(*trans_size)  \n",
        "    return soft_max_nd.transpose(axis, len(input_size)-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNn8GSuge4zO",
        "colab_type": "text"
      },
      "source": [
        "First part of the model (split out so to test alone)\n",
        "Basically, a wrapper for an lstm\n",
        "Takes in a sequence, spits out a sequence of matrices demonstrating ~an understanding~ of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ0p9OyYubDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceProcessor(torch.nn.Module):  \n",
        "  def __init__(self, word_embeddings, hp):\n",
        "    super(SequenceProcessor, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.embedding_size = word_embeddings.size(1)\n",
        "    self.cool_lstm = torch.nn.LSTM(\n",
        "        input_size = self.embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "\n",
        "    \n",
        "  def forward(self, x, hidden_layer):\n",
        "    embedding = self.embeddings(x)\n",
        "    return self.cool_lstm(embedding,\n",
        "                          hidden_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns8HjHO-fLmw",
        "colab_type": "text"
      },
      "source": [
        "Next bit of model. Given a processed set of "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwa-C0g5RapM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AttentionModel(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(AttentionModel, self).__init__()\n",
        "    self.first_linear = torch.nn.Linear(\n",
        "        in_features= 2*hp.lstm_hidden_size,\n",
        "        out_features = hp.dense_dimension,\n",
        "        bias = False\n",
        "    )\n",
        "    self.second_linear = torch.nn.Linear(\n",
        "        in_features = hp.dense_dimension,\n",
        "        out_features = hp.attention_hops,\n",
        "        bias = False\n",
        "    )\n",
        "    self.dropout = torch.nn.Dropout(p=hp.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(x)\n",
        "    tanh_W_H = torch.tanh(self.first_linear(x))\n",
        "    #[512 rows, 150 numerical words, of size 100] (512, 150, 100) <bmm> (1, 100, 100) = (512, 150, 100)\n",
        "    #another batch matrix multiply, wow!\n",
        "    weight_by_attention_hops = self.second_linear(tanh_W_H) # (100, 10) by (512, 10, 100)\n",
        "    #[512 rows, 10 attention hops of size 100] (512, 150, 100) <bmm> (1, 10, 100) = (512, 10, 150)\n",
        "    \n",
        "    attention = softmax(weight_by_attention_hops).transpose(2,1)\n",
        "    sentence_embeddings = torch.bmm(attention,x)\n",
        "    return sentence_embeddings, attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3oc5NYaftFW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLcy-vvnSts-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def better_mush(premise, hypothesis):\n",
        "    pooled_premise1 = premise[:,:,::2]\n",
        "    pooled_premise2 = premise[:,:,1::2]\n",
        "    pooled_hypothesis1 = hypothesis[:,:,::2]\n",
        "    pooled_hypothesis2 = hypothesis[:,:,1::2]\n",
        "\n",
        "    better_mush = torch.cat((pooled_premise1 * pooled_hypothesis1 + pooled_premise2 * pooled_hypothesis2,\n",
        "                               pooled_premise1 * pooled_hypothesis2 - pooled_premise2 * pooled_hypothesis1),2)\n",
        "    return better_mush\n",
        "\n",
        "class Factoriser(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(Factoriser, self).__init__()\n",
        "    self.premise_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    self.hypothesis_weight = Parameter(torch.Tensor(\n",
        "        hp.attention_hops, \n",
        "        hp.lstm_hidden_size*2,\n",
        "        hp.gravity\n",
        "        ))\n",
        "    init.kaiming_uniform_(self.premise_weight, a=math.sqrt(5))\n",
        "    init.kaiming_uniform_(self.hypothesis_weight, a=math.sqrt(5))\n",
        "\n",
        "  def batcheddot(self, a, b):\n",
        "    better_a = a.transpose(0,1)\n",
        "    bmmd = torch.bmm(better_a, b)\n",
        "    return bmmd.transpose(0,1)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "\n",
        "    premise_factor = self.batcheddot(premise, self.premise_weight)\n",
        "    hypothesis_factor = self.batcheddot(hypothesis, self.hypothesis_weight)\n",
        "    return better_mush(premise_factor,hypothesis_factor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzkD8l2eTlNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hp):\n",
        "    super(MLP, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(\n",
        "        in_features=hp.attention_hops*hp.gravity, \n",
        "        out_features=20)\n",
        "    if hp.avg:\n",
        "      self.final_linear = torch.nn.Linear(hp.gravity, hp.num_classes)\n",
        "    else:\n",
        "      self.final_linear = torch.nn.Linear(20, hp.num_classes)\n",
        "    self.hp = hp\n",
        "  def forward(self, x):\n",
        "    if self.hp.avg:\n",
        "      x = torch.sum(x, 1)/self.hp.attention_hops\n",
        "    else:\n",
        "      x = self.linear1(x.reshape(self.hp.batch_size, -1))\n",
        "    if (self.hp.num_classes > 1):\n",
        "      x = softmax(self.final_linear(x))\n",
        "    else:\n",
        "      x = torch.sigmoid(self.final_linear(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J9bayMWZAG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextualEntailmentModel(torch.nn.Module):\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden_state = torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size).cuda()\n",
        "    cell_state = torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "\n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(TextualEntailmentModel, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.factoriser = Factoriser(hp)\n",
        "    self.MLP = MLP(hp)\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def forward(self, premise, hypothesis):\n",
        "    processed_premise, self.hidden_state = self.premise_processor(premise, self.hidden_state)\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, self.hidden_state = self.hypothesis_processor(hypothesis, self.hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    factorised_mush = self.factoriser(premise_embedding, hypothesis_embedding)\n",
        "    return self.MLP(factorised_mush), hypothesis_attention\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, unnormalised_predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  if (len(unnormalised_predictions.shape) == 1):\n",
        "    auc = roc_auc_score(true_labels, unnormalised_predictions)\n",
        "  else:\n",
        "    auc = 0\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f AUC=%0.3f\" % (description,accuracy,precision,recall,f1, auc))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhoKGK_wdLb",
        "colab_type": "text"
      },
      "source": [
        "HELPER FUNCTIONS FOR DOIN SOME TRAININ AND TESTIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuFLnRT7wgBf",
        "colab_type": "text"
      },
      "source": [
        "TRAIN FUNCT, ITS BIG CAUSE IT DOES PRETTY MUCH EVERYTHING\n",
        "\n",
        "INCLUDING NORMALISATION IN THE WEIRD WAY THE SELF ATTENTIVE MODEL REQUIRES\n",
        "\n",
        "ALSO A SWITCH TO ENSURE IT DOES THE BEST AT GETTING BOTH BINARY AND NON BINARY LOSS :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ3p3VOkwXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "  torch.enable_grad()\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh8DUbUcwxP4",
        "colab_type": "text"
      },
      "source": [
        "TEST FUNCTION\n",
        "\n",
        "THIS STRONG BOY GOES THROUGHH AND ADDS RESULTS ALL OVER THE SHOP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79SQs1C2wG7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  real_results = []\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "      real_results.append(y_squeezed)\n",
        "  return torch.cat(real_results, 0), torch.cat(all_results, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrzwqgMswGo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "f26b6ce5-66ac-474e-f44d-727ea81dc590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",fact_tokeniser.word_to_id,300)\n",
        "small_gloves = load_glove_embeddings(\"glove.6B.50d.txt\", fact_tokeniser.word_to_id, 50)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36905\n",
            "36905\n",
            "torch.Size([36905, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThUmtTpe81Mc",
        "colab_type": "text"
      },
      "source": [
        "##TextualEntailment Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 20\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 20\n",
        "  num_classes = 1\n",
        "  avg=True\n",
        "  epochs = 3\n",
        "  dropout=0.3\n",
        "  C = 0.3\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "16fb3930-1900-4cf2-f724-f1119bba00ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "pass\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, small_gloves).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.636918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.644763\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.639692\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.629773\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.459514\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.370941\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.259479\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.054737\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.107895\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.024971\n",
            "Average loss is: tensor(1.3883, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.7364783653846154\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 0.976385\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 0.981190\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 0.979711\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 1.012315\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 0.927052\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 0.927304\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 0.890158\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 0.929335\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 0.933962\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 0.872006\n",
            "Average loss is: tensor(0.9405, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9823574862637363\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 0.842396\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 0.827416\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 0.802088\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 0.796762\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 0.800322\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 0.806409\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 0.790203\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 0.777760\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 0.754256\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 0.737679\n",
            "Average loss is: tensor(0.7951, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9964800824175825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "29ddfa88-842e-47dd-ce60-9a143ca08e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0MzMzMxy/h/4DKEzBO1cOwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "ce7c1ea0-16bd-4805-ab83-07b7295552d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "real_results, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "33fb4435-8010-4696-ebe8-6b0f8176d843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "print(predicted_ys.cpu().shape)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6102])\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.639 P=0.640 R=0.640 F1=0.639 AUC=0.666\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.658     0.615     0.636      3124\n",
            "         1.0      0.622     0.664     0.642      2978\n",
            "\n",
            "    accuracy                          0.639      6102\n",
            "   macro avg      0.640     0.640     0.639      6102\n",
            "weighted avg      0.640     0.639     0.639      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1921 1000]\n",
            " [1203 1978]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6397342639415539, 0.6395604686179228, 0.638970829236316, 0.6389393238001884)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUa9XwZ-4Xny",
        "colab_type": "text"
      },
      "source": [
        "##Baseline Sentence Entailment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineSentenceEntailment(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineSentenceEntailment, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_embedder = AttentionModel(hp)\n",
        "    self.hypothesis_embedder = AttentionModel(hp)\n",
        "    self.linear_final = torch.nn.Linear(hp.lstm_hidden_size*2, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #premise/hypothesis embeddinbgs\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    main_embeddings = torch.cat((embeddings, added_embeddings), 1)\n",
        "    reshaped_embeddings = main_embeddings.view(self.hp.batch_size, self.hp.max_length, -1)\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "\n",
        "    premise_embedding, premise_attention = self.premise_embedder(processed_premise)\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    hypothesis_embedding, hypothesis_attention = self.hypothesis_embedder(processed_hypothesis)\n",
        "    combined = premise_embedding * hypothesis_embedding\n",
        "    avg = torch.sum(combined, 1)/self.hp.attention_hops\n",
        "    output = torch.sigmoid(self.linear_final(avg))\n",
        "    return output, hypothesis_attention\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8fbaSIM4jhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineHyperparameters:\n",
        "  lstm_hidden_size = 50\n",
        "  dense_dimension = 30\n",
        "  attention_hops = 10\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  num_classes = 1\n",
        "  epochs = 4\n",
        "  C = 0.3\n",
        "  is_debug = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKfpJ-Hk4ePj",
        "colab_type": "code",
        "outputId": "01d4bdd1-d21b-4459-e291-c4ca2950714b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "baseline_model = BaselineSentenceEntailment(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(baseline_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "base_loss, base_accuracy = train(model=baseline_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.638679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.637006\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.605715\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.542091\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.548132\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.374001\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.284938\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.134314\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.182213\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.063143\n",
            "Average loss is: tensor(1.3891, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.738538804945055\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.011575\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 0.933246\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 0.929518\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 0.951415\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 0.944368\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 0.926378\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 0.870224\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 0.898298\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 0.906823\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 0.874102\n",
            "Average loss is: tensor(0.9199, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9738152472527473\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 0.852999\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 0.837161\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 0.833532\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 0.812001\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 0.836376\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 0.850160\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 0.835628\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 0.788899\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 0.768337\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 0.740902\n",
            "Average loss is: tensor(0.8186, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9933464972527473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXQ16nQW6Xb7",
        "colab_type": "code",
        "outputId": "3902abfc-159b-4c94-8903-ccad2b41554c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, base_loss, base_accuracy)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMzM8txcmhmZmZmOf8P5MkkpA0avtEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY6ih2k9hGy",
        "colab_type": "code",
        "outputId": "831aa401-a271-4f08-a6f3-ae18ebf22def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "base_real_results, baseline_predicted_ys = batch_wise_evaluate(baseline_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlPE-kpx9riu",
        "colab_type": "code",
        "outputId": "122f233a-e713-45d5-f202-40d0edf3284c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "evaluation_summary(\"baseline model\", baseline_predicted_ys.cpu(), base_real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: baseline model\n",
            "Classifier 'baseline model' has Acc=0.627 P=0.630 R=0.631 F1=0.627 AUC=0.684\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.690     0.596     0.639      3383\n",
            "         1.0      0.570     0.667     0.615      2719\n",
            "\n",
            "    accuracy                          0.627      6102\n",
            "   macro avg      0.630     0.631     0.627      6102\n",
            "weighted avg      0.636     0.627     0.628      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[2015  906]\n",
            " [1368 1813]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.629889403457989, 0.6312072227524486, 0.6273352999016716, 0.6269264604663168)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gmzMChW2xxT",
        "colab_type": "text"
      },
      "source": [
        "##DECLARE BASELINE :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qhGP9Y-Cj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaselineDeclare(torch.nn.Module):\n",
        "  def init_hidden(self):\n",
        "    hidden_state = Variable(torch.zeros(2,self.hp.batch_size,self.hp.lstm_hidden_size)).cuda()\n",
        "    cell_state = Variable(torch.zeros(2,self.hp.batch_size, self.hp.lstm_hidden_size)).cuda()\n",
        "    return (hidden_state, cell_state)\n",
        "  def reset_for_testing(self, new_batch):\n",
        "    self.hp.batch_size = new_batch\n",
        "    self.hidden_state = self.init_hidden()\n",
        "  \n",
        "  def __init__(self, hp, word_embeddings):\n",
        "    super(BaselineDeclare, self).__init__()\n",
        "    self.hp = hp\n",
        "    self.embeddings_size = word_embeddings.size(1)\n",
        "    self.premise_embeddings = torch.nn.Embedding(word_embeddings.size(0), word_embeddings.size(1))\n",
        "    self.premise_embeddings.weight = torch.nn.Parameter(word_embeddings)\n",
        "    self.premise_embedding_size = word_embeddings.size(1)\n",
        "    self.premise_lstm = torch.nn.LSTM(\n",
        "        input_size = self.premise_embedding_size,\n",
        "        hidden_size = hp.lstm_hidden_size,\n",
        "        num_layers=1,\n",
        "        batch_first=True,\n",
        "        bidirectional=True\n",
        "      )\n",
        "    self.hypothesis_processor = SequenceProcessor(word_embeddings, hp)\n",
        "    self.premise_linear = torch.nn.Linear(2*hp.lstm_hidden_size, 2*hp.lstm_hidden_size)\n",
        "\n",
        "    self.linear_penultimate = torch.nn.Linear(101, 8)\n",
        "    #TODO: add third dense layer with relu\n",
        "    self.linear_final = torch.nn.Linear(8, hp.num_classes)\n",
        "\n",
        "  def forward(self, premise, hypothesis):\n",
        "    #get word embeddings for claim, take a mean over the length\n",
        "    embeddings = self.premise_embeddings(premise)\n",
        "    mean_embeddings = torch.unsqueeze(torch.sum(embeddings, 1) / self.hp.max_length, 1) #change to accurate size of lenfgth\n",
        "  \n",
        "\n",
        "    #get word embeddings for article, slap that onto the much smaller claim\n",
        "    added_embeddings = self.premise_embeddings(hypothesis[:, :100])\n",
        "    #TODO: use repeat function to get 100*100\n",
        "    main_embeddings = torch.cat((mean_embeddings, added_embeddings), 1)\n",
        "    #shape is 101 * 50\n",
        "\n",
        "    #attention processing on claim+article combination\n",
        "    processed_premise, hidden_state = self.premise_lstm(main_embeddings, self.hidden_state)\n",
        "    attention_weights = softmax(self.premise_linear(processed_premise))#TODO: turn into row vector\n",
        "    #simple embedding of article alone\n",
        "    processed_hypothesis, hidden_state = self.hypothesis_processor(hypothesis, hidden_state)\n",
        "    #matrix multiply of the two\n",
        "    combined = torch.bmm(processed_hypothesis,attention_weights.transpose(1,2))\n",
        "    #final processing - another average, and then a relu + sigmoid\n",
        "    avg = torch.sum(combined, 1)/self.hp.max_length #todo: fix padding\n",
        "\n",
        "    smaller = F.relu(self.linear_penultimate(avg))\n",
        "    output = torch.sigmoid(self.linear_final(smaller))\n",
        "    return output, torch.zeros(self.hp.batch_size, self.hp.attention_hops, self.hp.lstm_hidden_size*2).cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2AvWEFOBYMQ",
        "colab_type": "code",
        "outputId": "7f04d37f-3493-4c6f-8dde-ebdd43bc471a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "declare_model = BaselineDeclare(Hyperparameters, small_gloves).cuda()\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adam(declare_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "declare_loss, declare_accuracy = train(model=declare_model,\n",
        "                       train_loader=train_fact_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/23454 (0%)]\tLoss: 1.644697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/23454 (11%)]\tLoss: 1.642925\n",
            "Train Epoch: 0 [5120/23454 (22%)]\tLoss: 1.611125\n",
            "Train Epoch: 0 [7680/23454 (33%)]\tLoss: 1.590836\n",
            "Train Epoch: 0 [10240/23454 (44%)]\tLoss: 1.575893\n",
            "Train Epoch: 0 [12800/23454 (55%)]\tLoss: 1.463525\n",
            "Train Epoch: 0 [15360/23454 (66%)]\tLoss: 1.502222\n",
            "Train Epoch: 0 [17920/23454 (77%)]\tLoss: 1.429139\n",
            "Train Epoch: 0 [20480/23454 (88%)]\tLoss: 1.323183\n",
            "Train Epoch: 0 [23040/23454 (99%)]\tLoss: 1.297609\n",
            "Average loss is: tensor(1.5060, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.693595467032967\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/23454 (0%)]\tLoss: 1.204724\n",
            "Train Epoch: 1 [2560/23454 (11%)]\tLoss: 1.212145\n",
            "Train Epoch: 1 [5120/23454 (22%)]\tLoss: 1.172106\n",
            "Train Epoch: 1 [7680/23454 (33%)]\tLoss: 1.126093\n",
            "Train Epoch: 1 [10240/23454 (44%)]\tLoss: 1.154160\n",
            "Train Epoch: 1 [12800/23454 (55%)]\tLoss: 1.163131\n",
            "Train Epoch: 1 [15360/23454 (66%)]\tLoss: 1.199497\n",
            "Train Epoch: 1 [17920/23454 (77%)]\tLoss: 1.161656\n",
            "Train Epoch: 1 [20480/23454 (88%)]\tLoss: 1.238054\n",
            "Train Epoch: 1 [23040/23454 (99%)]\tLoss: 1.219918\n",
            "Average loss is: tensor(1.1710, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9095123626373627\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/23454 (0%)]\tLoss: 1.034290\n",
            "Train Epoch: 2 [2560/23454 (11%)]\tLoss: 1.013505\n",
            "Train Epoch: 2 [5120/23454 (22%)]\tLoss: 1.020903\n",
            "Train Epoch: 2 [7680/23454 (33%)]\tLoss: 1.033008\n",
            "Train Epoch: 2 [10240/23454 (44%)]\tLoss: 1.030357\n",
            "Train Epoch: 2 [12800/23454 (55%)]\tLoss: 1.062770\n",
            "Train Epoch: 2 [15360/23454 (66%)]\tLoss: 1.039564\n",
            "Train Epoch: 2 [17920/23454 (77%)]\tLoss: 1.031820\n",
            "Train Epoch: 2 [20480/23454 (88%)]\tLoss: 1.056286\n",
            "Train Epoch: 2 [23040/23454 (99%)]\tLoss: 1.018870\n",
            "Average loss is: tensor(1.0271, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.9723128434065934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZweMG4WBnoY",
        "colab_type": "code",
        "outputId": "80c848b9-89f3-4c89-bdbf-8731e119976f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, declare_loss, declare_accuracy)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAEbCAYAAACoWC5HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6sN7kk2TqdE",
        "colab_type": "code",
        "outputId": "0ee30f53-188f-49d9-ae99-21d1d69b7cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "declare_real_results, declare_predicted_ys = batch_wise_evaluate(declare_model, \n",
        "         test_fact_loader,\n",
        "         Hyperparameters)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeJHn9s8T1bk",
        "colab_type": "code",
        "outputId": "fdf85c78-5b47-4ec6-f122-04cc38632295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "evaluation_summary(\"declare model\", declare_predicted_ys.cpu(), declare_real_results.cpu(), y_fact_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation for: declare model\n",
            "Classifier 'declare model' has Acc=0.630 P=0.631 R=0.631 F1=0.630 AUC=0.675\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.659     0.604     0.630      3184\n",
            "         1.0      0.604     0.658     0.630      2918\n",
            "\n",
            "    accuracy                          0.630      6102\n",
            "   macro avg      0.631     0.631     0.630      6102\n",
            "weighted avg      0.632     0.630     0.630      6102\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1924  997]\n",
            " [1260 1921]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6312883399928603, 0.631299489221295, 0.6301212717141921, 0.6301211823100656)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0JKeQxFT5kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}