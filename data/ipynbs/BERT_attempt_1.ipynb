{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textual entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiotrusWatson/level4project/blob/master/data/ipynbs/BERT_attempt_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3NYKgSzNCZO",
        "colab_type": "text"
      },
      "source": [
        "lets get the snli dataset baybee"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oddcFXt8M-gL",
        "colab_type": "code",
        "outputId": "5799f469-1ee1-419c-9cff-cb88b7e7e59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
        "!unzip snli_1.0.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 15:13:07--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  21.0MB/s    in 7.2s    \n",
            "\n",
            "2019-12-19 15:13:16 (12.6 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n",
            "Archive:  snli_1.0.zip\n",
            "   creating: snli_1.0/\n",
            "  inflating: snli_1.0/.DS_Store      \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/snli_1.0/\n",
            "  inflating: __MACOSX/snli_1.0/._.DS_Store  \n",
            " extracting: snli_1.0/Icon           \n",
            "  inflating: __MACOSX/snli_1.0/._Icon  \n",
            "  inflating: snli_1.0/README.txt     \n",
            "  inflating: __MACOSX/snli_1.0/._README.txt  \n",
            "  inflating: snli_1.0/snli_1.0_dev.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_dev.txt  \n",
            "  inflating: snli_1.0/snli_1.0_test.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_test.txt  \n",
            "  inflating: snli_1.0/snli_1.0_train.jsonl  \n",
            "  inflating: snli_1.0/snli_1.0_train.txt  \n",
            "  inflating: __MACOSX/._snli_1.0     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w4-cOWalFcJ",
        "colab_type": "code",
        "outputId": "d5872db1-1d65-4882-fcdd-bcff6dcaa871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Download the Glove.zip file and expand it.\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 15:13:24--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-12-19 15:13:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-12-19 15:13:25--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.90MB/s    in 6m 30s  \n",
            "\n",
            "2019-12-19 15:19:56 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIQox57_oPpU",
        "colab_type": "code",
        "outputId": "fc8e8e93-2f16-48f4-f475-c10d5a7becea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the PolitiFact Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
        "!unzip PolitiFact.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 15:20:20--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/PolitiFact.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4976217 (4.7M) [application/zip]\n",
            "Saving to: ‘PolitiFact.zip’\n",
            "\n",
            "PolitiFact.zip      100%[===================>]   4.75M  2.21MB/s    in 2.1s    \n",
            "\n",
            "2019-12-19 15:20:23 (2.21 MB/s) - ‘PolitiFact.zip’ saved [4976217/4976217]\n",
            "\n",
            "Archive:  PolitiFact.zip\n",
            "   creating: PolitiFact/\n",
            "  inflating: PolitiFact/README       \n",
            "  inflating: PolitiFact/politifact.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxjuOCbTuMC9",
        "colab_type": "code",
        "outputId": "8672806f-b1fe-44e4-cd0d-551c2a93bcde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/FakeNewsChallenge/fnc-1.git\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fnc-1'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0NsutKljq6J",
        "colab_type": "code",
        "outputId": "e810cae6-60da-4962-d4a9-a8b8f993c08b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# Get the Snopes Dataset from the location provided in the DeClarE paper.\n",
        "!wget http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
        "!unzip Snopes.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 15:20:33--  http://resources.mpi-inf.mpg.de/impact/dl_cred_analysis/Snopes.zip\n",
            "Resolving resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)... 139.19.206.46\n",
            "Connecting to resources.mpi-inf.mpg.de (resources.mpi-inf.mpg.de)|139.19.206.46|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5559754 (5.3M) [application/zip]\n",
            "Saving to: ‘Snopes.zip’\n",
            "\n",
            "Snopes.zip          100%[===================>]   5.30M  2.40MB/s    in 2.2s    \n",
            "\n",
            "2019-12-19 15:20:36 (2.40 MB/s) - ‘Snopes.zip’ saved [5559754/5559754]\n",
            "\n",
            "Archive:  Snopes.zip\n",
            "   creating: Snopes/\n",
            "  inflating: Snopes/README           \n",
            "  inflating: Snopes/snopes.tsv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPUlCQyAOUxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch,keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn import init\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data_utils\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr0NUjsQ7Vt",
        "colab_type": "text"
      },
      "source": [
        "lets load this shit :^)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr_88NFOoTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe = pd.read_json('./snli_1.0/snli_1.0_train.jsonl', lines=True)\n",
        "test_dataframe = pd.read_json('./snli_1.0/snli_1.0_test.jsonl', lines=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaA9gj9kPLcu",
        "colab_type": "code",
        "outputId": "27861e30-d08b-487e-b325-4e33f77ff787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_dataframe.head(50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>annotator_labels</th>\n",
              "      <th>captionID</th>\n",
              "      <th>gold_label</th>\n",
              "      <th>pairID</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence1_binary_parse</th>\n",
              "      <th>sentence1_parse</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence2_binary_parse</th>\n",
              "      <th>sentence2_parse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3416050480.jpg#4r1n</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3416050480.jpg#4r1c</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3416050480.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3416050480.jpg#4r1e</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2267923837.jpg#2r1n</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
              "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2267923837.jpg#2r1e</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>There are children present</td>\n",
              "      <td>( There ( ( are children ) present ) )</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2267923837.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2267923837.jpg#2r1c</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
              "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
              "      <td>The kids are frowning</td>\n",
              "      <td>( ( The kids ) ( are frowning ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3691670743.jpg#0r1c</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "      <td>( ( The boy ) ( ( ( skates down ) ( the sidewa...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3691670743.jpg#0r1e</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy does a skateboarding trick.</td>\n",
              "      <td>( ( The boy ) ( ( does ( a ( skateboarding tri...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3691670743.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3691670743.jpg#0r1n</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>( ( A boy ) ( ( is ( ( jumping ( on skateboard...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ is) (VP...</td>\n",
              "      <td>The boy is wearing safety equipment.</td>\n",
              "      <td>( ( The boy ) ( ( is ( wearing ( safety equipm...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1n</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An older man drinks his juice as he waits for ...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( drinks ( his juic...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#0r1c</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A boy flips a burger.</td>\n",
              "      <td>( ( A boy ) ( ( flips ( a burger ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[entailment, neutral, entailment, neutral, neu...</td>\n",
              "      <td>4804607632.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#0r1e</td>\n",
              "      <td>An older man sits with his orange juice at a s...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( ( sits ( with ( ( h...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>An elderly man sits in a small shop.</td>\n",
              "      <td>( ( An ( elderly man ) ) ( ( sits ( in ( a ( s...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#4r1n</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>Some women are hugging on vacation.</td>\n",
              "      <td>( ( Some women ) ( ( are ( hugging ( on vacati...</td>\n",
              "      <td>(ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#4r1c</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>The women are sleeping.</td>\n",
              "      <td>( ( The women ) ( ( are sleeping ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#4r1e</td>\n",
              "      <td>Two blond women are hugging one another.</td>\n",
              "      <td>( ( Two ( blond women ) ) ( ( are ( hugging ( ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (JJ blond) (NNS women)) ...</td>\n",
              "      <td>There are women showing affection.</td>\n",
              "      <td>( There ( ( are ( women ( showing affection ) ...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#2r1n</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are eating omelettes.</td>\n",
              "      <td>( ( The people ) ( ( are ( eating omelettes ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#2r1c</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The people are sitting at desks in school.</td>\n",
              "      <td>( ( The people ) ( ( are ( sitting ( at ( desk...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#2r1e</td>\n",
              "      <td>A few people in a restaurant setting, one of t...</td>\n",
              "      <td>( ( ( A ( few people ) ) ( in ( ( ( a ( restau...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ few) (NNS people))...</td>\n",
              "      <td>The diners are at a restaurant.</td>\n",
              "      <td>( ( The diners ) ( ( are ( at ( a restaurant )...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4804607632.jpg#3r1e</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man is drinking juice.</td>\n",
              "      <td>( ( A man ) ( ( is ( drinking juice ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4804607632.jpg#3r1c</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>Two women are at a restaurant drinking wine.</td>\n",
              "      <td>( ( Two women ) ( ( are ( at ( a ( restaurant ...</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4804607632.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4804607632.jpg#3r1n</td>\n",
              "      <td>An older man is drinking orange juice at a res...</td>\n",
              "      <td>( ( An ( older man ) ) ( ( is ( ( drinking ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...</td>\n",
              "      <td>A man in a restaurant is waiting for his meal ...</td>\n",
              "      <td>( ( ( A man ) ( in ( a restaurant ) ) ) ( ( is...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4850814517.jpg#1r1n</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man getting a drink of water from a fo...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( getting ( ( a drin...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4850814517.jpg#1r1c</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man wearing a brown shirt is reading a...</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( wearing ( a ( brown ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4850814517.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4850814517.jpg#1r1e</td>\n",
              "      <td>A man with blond-hair, and a brown shirt drink...</td>\n",
              "      <td>( ( ( ( ( ( A man ) ( with blond-hair ) ) , ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man)) (PP (IN with) (...</td>\n",
              "      <td>A blond man drinking water from a fountain.</td>\n",
              "      <td>( ( ( A ( blond man ) ) ( ( drinking water ) (...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#0r1c</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends scowl at each other over a full di...</td>\n",
              "      <td>( ( The friends ) ( ( scowl ( at ( ( each othe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#0r1e</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>There are two woman in this picture.</td>\n",
              "      <td>( There ( ( are ( ( two woman ) ( in ( this pi...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
              "      <td>4705552913.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#0r1n</td>\n",
              "      <td>Two women who just had lunch hugging and sayin...</td>\n",
              "      <td>( ( ( Two women ) ( who ( just ( had ( lunch (...</td>\n",
              "      <td>(ROOT (NP (NP (CD Two) (NNS women)) (SBAR (WHN...</td>\n",
              "      <td>The friends have just met for the first time i...</td>\n",
              "      <td>( ( The friends ) ( ( ( ( ( ( have just ) ( me...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4705552913.jpg#3r1n</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>The two sisters saw each other across the crow...</td>\n",
              "      <td>( ( The ( two sisters ) ) ( ( ( ( ( saw ( each...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4705552913.jpg#3r1c</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two groups of rival gang members flipped each ...</td>\n",
              "      <td>( ( ( Two groups ) ( of ( rival ( gang members...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[entailment, entailment, entailment, entailmen...</td>\n",
              "      <td>4705552913.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4705552913.jpg#3r1e</td>\n",
              "      <td>Two women, holding food carryout containers, hug.</td>\n",
              "      <td>( ( ( ( ( Two women ) , ) ( holding ( food ( c...</td>\n",
              "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (, ,) (...</td>\n",
              "      <td>Two women hug each other.</td>\n",
              "      <td>( ( Two women ) ( ( hug ( each other ) ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3637966641.jpg#1r1n</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to score the games winning out.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( ( trying ( to score ) ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3637966641.jpg#1r1e</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is trying to tag a runner out.</td>\n",
              "      <td>( ( A team ) ( ( is ( trying ( to ( ( tag ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3637966641.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3637966641.jpg#1r1c</td>\n",
              "      <td>A Little League team tries to catch a runner s...</td>\n",
              "      <td>( ( A ( Little ( League team ) ) ) ( ( tries (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NNP Little) (NNP League) ...</td>\n",
              "      <td>A team is playing baseball on Saturn.</td>\n",
              "      <td>( ( A team ) ( ( is ( ( playing baseball ) ( o...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>3636329461.jpg#0r1c</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school hosts a basketball game.</td>\n",
              "      <td>( ( A school ) ( ( hosts ( a ( basketball game...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>[neutral, neutral, neutral, neutral, entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>3636329461.jpg#0r1n</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A high school is hosting an event.</td>\n",
              "      <td>( ( A ( high school ) ) ( ( is ( hosting ( an ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>3636329461.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3636329461.jpg#0r1e</td>\n",
              "      <td>The school is having a special event in order ...</td>\n",
              "      <td>( ( The school ) ( ( is ( ( having ( ( a ( spe...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN school)) (VP (VBZ is...</td>\n",
              "      <td>A school is hosting an event.</td>\n",
              "      <td>( ( A school ) ( ( is ( hosting ( an event ) )...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>4934873039.jpg#0r1c</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women do not care what clothes they wear.</td>\n",
              "      <td>( ( The women ) ( ( ( do not ) ( care ( ( what...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#0r1e</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>Women are waiting by a tram.</td>\n",
              "      <td>( Women ( ( are ( waiting ( by ( a tram ) ) ) ...</td>\n",
              "      <td>(ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>[neutral, contradiction, neutral, neutral, ent...</td>\n",
              "      <td>4934873039.jpg#0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#0r1n</td>\n",
              "      <td>High fashion ladies wait outside a tram beside...</td>\n",
              "      <td>( ( High ( fashion ladies ) ) ( ( ( wait ( out...</td>\n",
              "      <td>(ROOT (S (NP (JJ High) (NN fashion) (NNS ladie...</td>\n",
              "      <td>The women enjoy having a good fashion sense.</td>\n",
              "      <td>( ( The women ) ( ( enjoy ( having ( a ( good ...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#1r1n</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A child with mom and dad, on summer vacation a...</td>\n",
              "      <td>( ( ( A child ) ( with ( ( mom and ) dad ) ) )...</td>\n",
              "      <td>(ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#1r1e</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the beach.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#1</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#1r1c</td>\n",
              "      <td>A man, woman, and child enjoying themselves on...</td>\n",
              "      <td>( ( ( A ( man ( , ( woman ( , ( and child ) ) ...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN man) (, ,) (NN woman)...</td>\n",
              "      <td>A family of three is at the mall shopping.</td>\n",
              "      <td>( ( ( A family ) ( of three ) ) ( ( is ( at ( ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>neutral</td>\n",
              "      <td>4934873039.jpg#2r1n</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>The people waiting on the train are sitting.</td>\n",
              "      <td>( ( ( The people ) ( waiting ( on ( the train ...</td>\n",
              "      <td>(ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>[contradiction, entailment, contradiction, ent...</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1c</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people just getting on a train</td>\n",
              "      <td>( There ( are ( people ( just ( getting ( on (...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>4934873039.jpg#2</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4934873039.jpg#2r1e</td>\n",
              "      <td>People waiting to get on a train or just getti...</td>\n",
              "      <td>( ( People ( ( ( waiting ( to ( get ( on ( a t...</td>\n",
              "      <td>(ROOT (NP (NP (NNS People)) (VP (VP (VBG waiti...</td>\n",
              "      <td>There are people waiting on a train.</td>\n",
              "      <td>( There ( ( are ( people ( waiting ( on ( a tr...</td>\n",
              "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#3r1e</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing with a young child outside.</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing ( with ( a ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>[neutral]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>2946464027.jpg#3r1n</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple are playing frisbee with a young chil...</td>\n",
              "      <td>( ( A couple ) ( ( are ( ( playing frisbee ) (...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#3</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#3r1c</td>\n",
              "      <td>A couple playing with a little boy on the beach.</td>\n",
              "      <td>( ( ( A couple ) ( playing ( with ( ( a ( litt...</td>\n",
              "      <td>(ROOT (NP (NP (DT A) (NN couple)) (VP (VBG pla...</td>\n",
              "      <td>A couple watch a little girl play by herself o...</td>\n",
              "      <td>( ( A couple ) ( ( ( ( watch ( a ( little ( gi...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>[contradiction]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2946464027.jpg#4r1c</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is sitting down for dinner.</td>\n",
              "      <td>( ( The family ) ( ( is ( ( sitting down ) ( f...</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>[entailment]</td>\n",
              "      <td>2946464027.jpg#4</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2946464027.jpg#4r1e</td>\n",
              "      <td>A couple play in the tide with their young son.</td>\n",
              "      <td>( ( A couple ) ( ( play ( in ( ( the tide ) ( ...</td>\n",
              "      <td>(ROOT (S (NP (DT A) (NN couple)) (VP (VBP play...</td>\n",
              "      <td>The family is outside.</td>\n",
              "      <td>( ( The family ) ( ( is outside ) . ) )</td>\n",
              "      <td>(ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     annotator_labels  ...                                    sentence2_parse\n",
              "0                                           [neutral]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "1                                     [contradiction]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "2                                        [entailment]  ...  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...\n",
              "3                                           [neutral]  ...  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...\n",
              "4                                        [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...\n",
              "5                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NNS kids)) (VP (VBP are...\n",
              "6                                     [contradiction]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ skate...\n",
              "7                                        [entailment]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ does)...\n",
              "8                                           [neutral]  ...  (ROOT (S (NP (DT The) (NN boy)) (VP (VBZ is) (...\n",
              "9                                           [neutral]  ...  (ROOT (S (NP (DT An) (JJR older) (NN man)) (VP...\n",
              "10                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN boy)) (VP (VBZ flips) ...\n",
              "11  [entailment, neutral, entailment, neutral, neu...  ...  (ROOT (S (NP (DT An) (JJ elderly) (NN man)) (V...\n",
              "12                                          [neutral]  ...  (ROOT (S (NP (DT Some) (NNS women)) (VP (VBP a...\n",
              "13                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP ar...\n",
              "14                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "15                                          [neutral]  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "16  [contradiction, contradiction, contradiction, ...  ...  (ROOT (S (NP (DT The) (NNS people)) (VP (VBP a...\n",
              "17                                       [entailment]  ...  (ROOT (S (NP (DT The) (NNS diners)) (VP (VBP a...\n",
              "18                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...\n",
              "19                                    [contradiction]  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...\n",
              "20                                          [neutral]  ...  (ROOT (S (NP (NP (DT A) (NN man)) (PP (IN in) ...\n",
              "21                                          [neutral]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "22                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (JJ blond) (NN man)) (...\n",
              "23                                       [entailment]  ...  (ROOT (NP (NP (DT A) (JJ blond) (NN man)) (VP ...\n",
              "24                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VBP ...\n",
              "25                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "26      [neutral, neutral, neutral, neutral, neutral]  ...  (ROOT (S (NP (DT The) (NNS friends)) (VP (VP (...\n",
              "27                                          [neutral]  ...  (ROOT (S (NP (DT The) (CD two) (NNS sisters)) ...\n",
              "28                                    [contradiction]  ...  (ROOT (S (NP (NP (CD Two) (NNS groups)) (PP (I...\n",
              "29  [entailment, entailment, entailment, entailmen...  ...  (ROOT (S (NP (CD Two) (NNS women)) (VP (VB hug...\n",
              "30                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "31                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "32                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN team)) (VP (VBZ is) (V...\n",
              "33                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ host...\n",
              "34   [neutral, neutral, neutral, neutral, entailment]  ...  (ROOT (S (NP (DT A) (JJ high) (NN school)) (VP...\n",
              "35                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN school)) (VP (VBZ is) ...\n",
              "36                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP do...\n",
              "37                                       [entailment]  ...  (ROOT (S (NP (NNP Women)) (VP (VBP are) (VP (V...\n",
              "38  [neutral, contradiction, neutral, neutral, ent...  ...  (ROOT (S (NP (DT The) (NNS women)) (VP (VBP en...\n",
              "39                                          [neutral]  ...  (ROOT (FRAG (NP (NP (DT A) (NN child)) (PP (IN...\n",
              "40                                       [entailment]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "41                                    [contradiction]  ...  (ROOT (S (NP (NP (DT A) (NN family)) (PP (IN o...\n",
              "42                                          [neutral]  ...  (ROOT (S (NP (NP (DT The) (NNS people)) (VP (V...\n",
              "43  [contradiction, entailment, contradiction, ent...  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "44                                       [entailment]  ...  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP...\n",
              "45                                       [entailment]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "46                                          [neutral]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP are)...\n",
              "47                                    [contradiction]  ...  (ROOT (S (NP (DT A) (NN couple)) (VP (VBP watc...\n",
              "48                                    [contradiction]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "49                                       [entailment]  ...  (ROOT (S (NP (DT The) (NN family)) (VP (VBZ is...\n",
              "\n",
              "[50 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CIt0hMDmPQN",
        "colab_type": "text"
      },
      "source": [
        "Helper functions: something that bulk converts things into lists, and a tokeniser that also pads and numpies things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "106ajZAIuYuc",
        "colab_type": "code",
        "outputId": "bbd4db3c-cdd0-4e0c-becd-61a2c8344886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def merge_bodies(articles, claims):\n",
        "  merged = pd.merge(articles, claims, on=\"Body ID\")\n",
        "  mapping = {\"disagree\": 0, \"discuss\": 1, \"unrelated\": 2, \"agree\": 3}\n",
        "  return merged.replace({\"Stance\": mapping})\n",
        "  \n",
        "  \n",
        "train_articles = pd.read_csv(\"./fnc-1/train_bodies.csv\")\n",
        "train_claims = pd.read_csv(\"./fnc-1/train_stances.csv\")\n",
        "test_articles = pd.read_csv(\"./fnc-1/test_bodies.csv\")\n",
        "test_claims = pd.read_csv(\"./fnc-1/test_stances_unlabeled.csv\")\n",
        "\n",
        "\n",
        "train_challenge = merge_bodies(train_articles, train_claims)\n",
        "\n",
        "test_challenge = merge_bodies(test_articles, test_claims)\n",
        "train_challenge.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Soldier shot, Parliament locked down after gun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID  ... Stance\n",
              "0        0  ...      2\n",
              "1        0  ...      2\n",
              "2        0  ...      2\n",
              "3        0  ...      2\n",
              "4        0  ...      2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGTfl70eyBuk",
        "colab_type": "text"
      },
      "source": [
        "also: lets load politifact :^^)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URzg1ioi2XmS",
        "colab_type": "text"
      },
      "source": [
        "thing to divide true and false"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUtFzYD42UR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As can be seen from the statistics above, class 0 has 3 times more data than class 1\n",
        "# Method to divide input data into true and false dataframes and return them\n",
        "def divide_truefalse(fact):\n",
        "  col = ['cred_label','claim_id','claim_text','article','article_source','bin_cred_label']\n",
        "  true_data= list()\n",
        "  false_data=list()\n",
        "  for index, row in fact.iterrows():\n",
        "    if row['cred_label'] == 'true' or row['cred_label'] == 'mostly true':\n",
        "      true_data.append(row)\n",
        "    else:\n",
        "      false_data.append(row)\n",
        "\n",
        "  data_frame_true = pd.DataFrame(true_data,columns=col)\n",
        "  data_frame_false = pd.DataFrame(false_data,columns=col)\n",
        "  return data_frame_true,data_frame_false"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ElyllO280i",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing snopes data so that it has equal amounts of true and false"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhtxlEnY22l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "snopes = pd.read_csv(\"./Snopes/snopes.tsv\", delimiter= \"\\t\", names=['cred_label','claim_id','claim_text','article','article_source'])\n",
        "mapping = {\"true\": 1, \"half-true\": 1, \"mostly true\": 1, \"mostly false\": 0, \"pants on fire\":0, \"false\":0}\n",
        "snopes = snopes.replace({\"cred_label\": mapping})\n",
        "snopes_true, snopes_false = divide_truefalse(snopes)\n",
        "top = snopes_false.head(8000)\n",
        "frame = [snopes_true, top]\n",
        "snopes = pd.concat(frame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz3T51bxyBDP",
        "colab_type": "code",
        "outputId": "bb9e439b-e2d0-4951-84d9-ebf024a2d312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "facts = pd.read_csv('./PolitiFact/politifact.tsv', delimiter = '\\t', names = ['cred_label','claim_id','claim_text','claim_source','article','article_source'])\n",
        "facts.head(50)\n",
        "\n",
        "mapping = {\"True\": 1, \"Half-True\": 1, \"Mostly True\": 1, \"Mostly False\": 0, \"False\": 0, \"Pants on Fire!\": 0}\n",
        "facts = facts.replace({\"cred_label\": mapping})\n",
        "\n",
        "\n",
        "def preprocess_fact_data(facts):\n",
        "  unique_claims = facts[\"claim_id\"].unique()\n",
        "\n",
        "#splitting the claims\n",
        "  train_claims, test_claims = train_test_split(unique_claims, test_size=0.2, random_state=8)\n",
        "\n",
        "#recreating dataset\n",
        "  test_facts = facts[facts[\"claim_id\"].isin(test_claims)]\n",
        "  train_facts = facts[facts[\"claim_id\"].isin(train_claims)]\n",
        "  return train_facts, test_facts\n",
        "#get unique claims to divide dataset cleanly\n",
        "train_facts, test_facts = preprocess_fact_data(facts)\n",
        "train_snopes, test_snopes = preprocess_fact_data(snopes)\n",
        "\n",
        "print(snopes.groupby(\"cred_label\").count())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            claim_id  claim_text  article  article_source  bin_cred_label\n",
            "cred_label                                                               \n",
            "0               6127        6127     6127            6127               0\n",
            "1               1873        1873     1873            1873               0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEgm0N3nRAbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_lists(names_to_lists):\n",
        "  for key in names_to_lists:\n",
        "    names_to_lists[key] = names_to_lists[key].tolist()\n",
        "  return names_to_lists\n",
        "\n",
        "class Tokeniser:\n",
        "  def __init__(self, texts, vocab_size, max_len):\n",
        "    self.t = Tokenizer()\n",
        "    self.max_len = max_len\n",
        "    self.t.num_words = vocab_size\n",
        "    \n",
        "    full_corpus = []\n",
        "\n",
        "    for index in texts:\n",
        "      for text in texts[index]:\n",
        "        full_corpus.append(text)\n",
        "    \n",
        "    self.t.fit_on_texts(full_corpus)\n",
        "\n",
        "  def full_process(self, text):\n",
        "    \"\"\"OK SO: converts a list of strings into a list of numerical sequences\n",
        "then pads them out so they're all a consistent size\n",
        "then returns a numpy array of that :) \"\"\"\n",
        "    new_sequence = self.t.texts_to_sequences(text)\n",
        "    #todo: modify to make it spit out a summarised version ABOUT HERE\n",
        "    padded_sequence = pad_sequences(new_sequence, maxlen=self.max_len, padding =\"post\")\n",
        "    return np.array(padded_sequence, dtype=np.float32)\n",
        "\n",
        "  def do_everything(self, texts):\n",
        "    for index in texts:\n",
        "      texts[index] = self.full_process(texts[index])\n",
        "    self.word_to_id = self.t.word_index\n",
        "    return texts\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "# Get the embedding matrix using Glove. \n",
        "vocab,word2idx = None,{}\n",
        "\n",
        "def load_glove_embeddings(path, word2idx, embedding_dim):\n",
        "    \"\"\"Loading the glove embeddings\"\"\"\n",
        "    vocab_size = len(word2idx) + 1\n",
        "    print(vocab_size)\n",
        "    with open(path) as f:\n",
        "        embeddings = np.zeros((vocab_size, embedding_dim))\n",
        "        for line in f.readlines():\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            index = word2idx.get(word)\n",
        "            if index:\n",
        "                vector = np.array(values[1:], dtype='float32')\n",
        "                if vector.shape[-1] != embedding_dim:\n",
        "                    raise Exception('Dimension not matching.')\n",
        "                embeddings[index] = vector\n",
        "        return torch.from_numpy(embeddings).float()\n",
        "\n",
        "#assumption: we're going to only care about classification per text\n",
        "def generate_indexes(labels):\n",
        "  return [1 if label == \"neutral\" else 2 if label == \"entailment\" else 0 for label in labels]\n",
        "\n",
        "index_to_label = [\"contradiction\",\"neutral\",\"entailment\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-JRbJ3txE02",
        "colab_type": "text"
      },
      "source": [
        "here i set up the tokeniser, and turn everything into a list its a fun cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEFVhCmRUM2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LENGTH = 150\n",
        "VOCAB_SIZE = 20000\n",
        "BATCH_SIZE = 256\n",
        "SAMPLE_SAMPLE_SIZE = 1\n",
        "\n",
        "chopped_train_dataframe = train_dataframe.sample(n=int(len(train_dataframe[\"sentence1\"])/SAMPLE_SAMPLE_SIZE))\n",
        "x_train_lists = convert_to_lists({\"premise\": chopped_train_dataframe[\"sentence1\"], \"hypothesis\": chopped_train_dataframe[\"sentence2\"]})\n",
        "y_train_list = chopped_train_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_train_fact_list = convert_to_lists({\"claim_text\": train_facts[\"claim_text\"], \n",
        "                   \"claim_source\": train_facts[\"claim_source\"],\n",
        "                   \"article\": train_facts[\"article\"],\n",
        "                   \"article_source\": train_facts[\"article_source\"]})\n",
        "y_train_fact_list = train_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_test_lists = convert_to_lists({\"premise\": test_dataframe[\"sentence1\"], \"hypothesis\": test_dataframe[\"sentence2\"]})\n",
        "y_test_list = test_dataframe[\"gold_label\"].tolist()\n",
        "\n",
        "x_test_fact_list = convert_to_lists({\"claim_text\": test_facts[\"claim_text\"], \n",
        "                   \"claim_source\": test_facts[\"claim_source\"],\n",
        "                   \"article\": test_facts[\"article\"],\n",
        "                   \"article_source\": test_facts[\"article_source\"]})\n",
        "y_test_fact_list = test_facts[\"cred_label\"].tolist()\n",
        "\n",
        "x_train_challenge_list = convert_to_lists({\"claim_text\": train_challenge[\"Headline\"], \"article\": train_challenge[\"articleBody\"]})\n",
        "y_train_challenge_list = train_challenge[\"Stance\"].tolist()\n",
        "\n",
        "x_test_challenge_list = convert_to_lists({\"claim_text\": test_challenge[\"Headline\"], \"article\": test_challenge[\"articleBody\"]})\n",
        "\n",
        "x_train_snopes_list = convert_to_lists({\"claim_text\": train_snopes[\"claim_text\"],\n",
        "                   \"article\": train_snopes[\"article\"],\n",
        "                   \"article_source\": train_snopes[\"article_source\"]})\n",
        "x_test_snopes_list = convert_to_lists({\"claim_text\": test_snopes[\"claim_text\"],\n",
        "                   \"article\": test_snopes[\"article\"],\n",
        "                   \"article_source\": test_snopes[\"article_source\"]})\n",
        "y_train_snopes_list = train_snopes[\"cred_label\"].tolist()\n",
        "y_test_snopes_list = test_snopes[\"cred_label\"].tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_tokeniser = Tokeniser(x_train_lists, VOCAB_SIZE, MAX_LENGTH)\n",
        "fact_tokeniser = Tokeniser(x_train_fact_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "challenge_tokeniser = Tokeniser(x_train_challenge_list, VOCAB_SIZE, MAX_LENGTH)\n",
        "snopes_tokeniser = Tokeniser(x_train_snopes_list, VOCAB_SIZE, MAX_LENGTH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1TbAK2zxN09",
        "colab_type": "text"
      },
      "source": [
        "this cell uses the setup tokeniser to SLAP THAT SHIT INTO NUMPY ARRAYS WITH PADDING YEAH BABY\n",
        "(also tokenises it thats p important)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mbOCXki_Mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_tokeniser.do_everything(x_train_lists)\n",
        "x_test = x_tokeniser.do_everything(x_test_lists)\n",
        "y_train = np.array(generate_indexes(y_train_list), dtype=np.float32)\n",
        "y_test = np.array(generate_indexes(y_test_list), dtype=np.float32)\n",
        "\n",
        "x_fact_train = fact_tokeniser.do_everything(x_train_fact_list)\n",
        "x_fact_test = fact_tokeniser.do_everything(x_test_fact_list)\n",
        "y_fact_train = np.array(y_train_fact_list, dtype=np.float32)\n",
        "y_fact_test = np.array(y_test_fact_list, dtype=np.float32)\n",
        "\n",
        "x_challenge_train = challenge_tokeniser.do_everything(x_train_challenge_list)\n",
        "x_challenge_test = challenge_tokeniser.do_everything(x_test_challenge_list)\n",
        "y_challenge_train = np.array(y_train_challenge_list, dtype=np.float32)\n",
        "\n",
        "x_snopes_train = snopes_tokeniser.do_everything(x_train_snopes_list)\n",
        "x_snopes_test = snopes_tokeniser.do_everything(x_test_snopes_list)\n",
        "y_snopes_train = np.array(y_train_snopes_list, dtype=np.float32)\n",
        "y_snopes_test = np.array(y_test_snopes_list, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRR_2Nr-mLmn",
        "colab_type": "text"
      },
      "source": [
        "and here we slap the loaded stuff into a neat tensordataset. this is good because ???"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L53RKo-fjxQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with_sources = False\n",
        "#alright lets tensordataset textual entailment stuff\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_train[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_train[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_train).type(torch.DoubleTensor))\n",
        "train_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_loader.name = \"entailment_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_test[\"premise\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_test[\"hypothesis\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_test).type(torch.DoubleTensor))\n",
        "test_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False )\n",
        "test_loader.name = \"entailment_data\"\n",
        "\n",
        "if (with_sources):\n",
        "#AND THE SAME FOR FACT CHECKING (CURRENTLY SET UP KINDA RIGIDLY FOR FIRST TEST :())\n",
        "  train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"claim_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "  train_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_train).type(torch.LongTensor))\n",
        "  test_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article_source\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_test).type(torch.LongTensor))\n",
        "  \n",
        "\n",
        "else:\n",
        "  train_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_train).type(torch.LongTensor))\n",
        "  test_fact_data = data_utils.TensorDataset(torch.from_numpy(x_fact_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_fact_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_fact_test).type(torch.LongTensor))\n",
        "  train_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_train).type(torch.LongTensor))\n",
        "  test_snopes_data = data_utils.TensorDataset(torch.from_numpy(x_snopes_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_snopes_test[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_snopes_test).type(torch.LongTensor))\n",
        "\n",
        "train_fact_loader = data_utils.DataLoader(train_fact_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_fact_loader.name = \"fact_data\"\n",
        "test_fact_loader = data_utils.DataLoader(test_fact_data, batch_size=BATCH_SIZE, drop_last=False)\n",
        "test_fact_loader.name = \"fact_data\"\n",
        "\n",
        "train_snopes_loader = data_utils.DataLoader(train_snopes_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_snopes_loader.name = \"fact_data\"\n",
        "test_snopes_loader = data_utils.DataLoader(test_snopes_data, batch_size=BATCH_SIZE, drop_last=False)\n",
        "test_snopes_loader.name = \"fact_data\"\n",
        "\n",
        "\n",
        "train_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_train[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_train[\"article\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(y_challenge_train).type(torch.DoubleTensor))\n",
        "train_challenge_loader = data_utils.DataLoader(train_data, batch_size=BATCH_SIZE, drop_last=True)\n",
        "train_challenge_loader.name = \"challenge_data\"\n",
        "\n",
        "test_data = data_utils.TensorDataset(torch.from_numpy(x_challenge_test[\"claim_text\"]).type(torch.LongTensor),\n",
        "                                      torch.from_numpy(x_challenge_test[\"article\"]).type(torch.LongTensor))\n",
        "test_challenge_loader = data_utils.DataLoader(test_data, batch_size=BATCH_SIZE, drop_last=False )\n",
        "test_loader.name = \"challenge_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_8XDxIO8huI",
        "colab_type": "text"
      },
      "source": [
        "CONSTANT DEFINITIONS:\n",
        "  * COLLECTION OF DOWNLOADED MODELS\n",
        "  * WEIGHT NAME\n",
        "  * IMPLEMENTATION OF GELU\n",
        "  * WAY OF CHOOSING ACTIVATION FUNCTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kagidhx8iZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_ARCHIVE_MAP = {\n",
        "    'bert-base-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz\",\n",
        "    'bert-large-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz\",\n",
        "    'bert-base-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz\",\n",
        "    'bert-large-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz\",\n",
        "    'bert-base-multilingual-uncased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased.tar.gz\",\n",
        "    'bert-base-multilingual-cased': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased.tar.gz\",\n",
        "    'bert-base-chinese': \"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese.tar.gz\",\n",
        "}\n",
        "WEIGHTS_NAME = 'pytorch_model.bin'\n",
        "\n",
        "def gelu(x):\n",
        "    \"\"\"Implementation of the gelu activation function.\n",
        "        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n",
        "        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "    \"\"\"\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
        "\n",
        "\n",
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"swish\": swish}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jifZntROetvo",
        "colab_type": "text"
      },
      "source": [
        "HERES AN OBJECT TO GIVE BERT SOME NICE HYPERPARAMS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuUKfFfO8Vb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertConfig(object):\n",
        "    \"\"\"Configuration class to store the configuration of a `BertModel`.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 vocab_size_or_config_json_file,\n",
        "                 hidden_size=768,\n",
        "                 num_hidden_layers=12,\n",
        "                 num_attention_heads=12,\n",
        "                 intermediate_size=3072,\n",
        "                 hidden_act=\"gelu\",\n",
        "                 hidden_dropout_prob=0.1,\n",
        "                 attention_probs_dropout_prob=0.1,\n",
        "                 max_position_embeddings=512,\n",
        "                 type_vocab_size=2,\n",
        "                 initializer_range=0.02):\n",
        "        \"\"\"Constructs BertConfig.\n",
        "        Args:\n",
        "            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n",
        "            hidden_size: Size of the encoder layers and the pooler layer.\n",
        "            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n",
        "            num_attention_heads: Number of attention heads for each attention layer in\n",
        "                the Transformer encoder.\n",
        "            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n",
        "                layer in the Transformer encoder.\n",
        "            hidden_act: The non-linear activation function (function or string) in the\n",
        "                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n",
        "            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n",
        "                layers in the embeddings, encoder, and pooler.\n",
        "            attention_probs_dropout_prob: The dropout ratio for the attention\n",
        "                probabilities.\n",
        "            max_position_embeddings: The maximum sequence length that this model might\n",
        "                ever be used with. Typically set this to something large just in case\n",
        "                (e.g., 512 or 1024 or 2048).\n",
        "            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n",
        "                `BertModel`.\n",
        "            initializer_range: The sttdev of the truncated_normal_initializer for\n",
        "                initializing all weight matrices.\n",
        "        \"\"\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.hidden_act = hidden_act\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_dropout_prob = hidden_dropout_prob\n",
        "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.type_vocab_size = type_vocab_size\n",
        "        self.initializer_range = initializer_range\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7k2Rj3K8zDO",
        "colab_type": "text"
      },
      "source": [
        "This provides layer normalisation. this is important in order to ensure that training time is a bit faster on these fat GPUs, by making sure we get the mean + variance and usin those to normalise each value\n",
        "its wild"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn6JKIm18vP8",
        "colab_type": "code",
        "outputId": "590a5975-5bec-467f-d27d-0609d28fa308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "class BertLayerNorm(nn.Module):\n",
        "  def __init__(self, hidden_size, epsilon=1e-12):\n",
        "    super(BertLayerNorm, self).__init__()\n",
        "    self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "    #adding a bias that slowly learns where its place is :)\n",
        "    self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "    self.variance_epsilon = epsilon\n",
        "\n",
        "  def forward(self, x): \n",
        "    mean_of_x = x.mean(-1, keepdim=True) #gets the mean of last axis\n",
        "    power_mean = (x - mean_of_x).pow(2).mean(-1, keepdim=True) # gets difference, raises to ^2 then means\n",
        "    x = (x - mean_of_x) / torch.sqrt(power_mean + self.variance_epsilon)\n",
        "    return self.weight * x + self.bias\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8d5ccbdaf484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBertLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBertLayerNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance_epsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH8FosjLy4vh",
        "colab_type": "text"
      },
      "source": [
        "Encodes embeddings repeatedly, in such a way that they contain where the word is in a sentence AND also the token type\n",
        "wild"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52m5fT0t62xF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(BertEmbeddings, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size)\n",
        "        self.position_embeddings = nn.Embedding(config.max_position_embeddings, config.hidden_size)\n",
        "        self.token_type_embeddings = nn.Embedding(config.type_vocab_size, config.hidden_size)\n",
        "\n",
        "        # self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load\n",
        "        # any TensorFlow checkpoint file\n",
        "        self.LayerNorm = BertLayerNorm(config.hidden_size, eps=1e-12)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None):\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros_like(input_ids)\n",
        "\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "        position_embeddings = self.position_embeddings(position_ids)\n",
        "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
        "\n",
        "        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n",
        "        embeddings = self.LayerNorm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOKe7YTVzKUB",
        "colab_type": "text"
      },
      "source": [
        "This is where the magic happens baybeeee\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md_H2-4y7aBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertSelfAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertSelfAttention, self).__init__()\n",
        "    hidden_size = config.hidden_size\n",
        "    self.number_of_heads = config.num_attention_heads\n",
        "\n",
        "    if hidden_size % number_of_heads != 0:\n",
        "      raise ValueError(\"The hidden size {} is not a multiple of the number of attention heads {}\".format(\n",
        "          hidden_size, self.number_of_heads\n",
        "      ))\n",
        "    self.size_of_heads = int(hidden_size / number_of_heads)\n",
        "    self.full_head_amount = self.number_of_heads * self.size_of_heads\n",
        "\n",
        "    #attention model - heres the query key and value!!\n",
        "    self.query = nn.Linear(hidden_size, self.full_head_amount)\n",
        "    self.key = nn.Linear(hidden_size, self.full_head_amount)\n",
        "    self.value = nn.Linear(hidden_size, self.full_head_amount)\n",
        "\n",
        "    self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
        "\n",
        "  #transpose for scores TODO\n",
        "  def prepare_for_processing(self, x):\n",
        "    new_shape = x.size()[:-1] + (self.number_of_heads, self.size_of_heads) #concatenatin 2 new dimensions\n",
        "    x = x.view(*new_shape)\n",
        "    return x.permute(0, 2, 1, 3) #reshapin so we can do maths nicely\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask):\n",
        "    #procesisng the query etc, then reshaping so we can not be fiddlin w/ the number of heads\n",
        "    query_layer = self.prepare_for_processing(self.query(hidden_states))\n",
        "    key_layer = self.prepare_for_processing(self.key(hidden_states))\n",
        "    value_layer = self.prepare_for_processing(self.value(hidden_states))\n",
        "\n",
        "    #dottin those queries + those keys together\n",
        "    raw_attention = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "    raw_attention = raw_attention / math.sqrt(self.size_of_heads)\n",
        "    #slap that mask on that we got from earlier\n",
        "    raw_attention = raw_attention + attention_mask\n",
        "\n",
        "    #normalise attention so we get probabilities :)\n",
        "    normal_attention = nn.Softmax(dim=-1)(raw_attention)\n",
        "    \n",
        "    #add dropout cause google did it\n",
        "    normal_attention = self.dropout(normal_attention)\n",
        "\n",
        "    #reversing what we did with query etc to make score calculation work\n",
        "    context_layer = torch.matmul(normal_attention, value_layer)\n",
        "    context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "    new_shape = context_layer.size()[:-2] + (self.full_head_amount,)\n",
        "\n",
        "    context_layer = context_layer.view(*new_shape)\n",
        "    return context_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBNRODkR480j",
        "colab_type": "text"
      },
      "source": [
        "This preprocesses Bert weights ready for output. It's what the base Bert model should be trained on most likley"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQG8yQWC4-8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertAttentionOutput(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertAttentionOutput, self).__init__()\n",
        "    self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.LayerNorm = BertLayerNorm(config.hidden_size, epsilon = 1e-12)\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "  def forward(self, hidden_states, input_tensor):\n",
        "    #quick linear mult into a dropout and a final normalisation\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.dropout(hidden_states)\n",
        "    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "    return hidden_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQWW-cSM6amk",
        "colab_type": "text"
      },
      "source": [
        "Simply takes an input and passes it through a multiheaded attention and into the output processor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnwaUW9B7jSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BertAttention, self).__init__()\n",
        "        self.attention = BertSelfAttention(config)\n",
        "        self.output = BertAttentionOutput(config)\n",
        "\n",
        "    def forward(self, input_tensor, attention_mask):\n",
        "        self_output = self.attention(input_tensor, attention_mask)\n",
        "        attention_output = self.output(self_output, input_tensor)\n",
        "        return attention_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3qg-4Rs6y2W",
        "colab_type": "text"
      },
      "source": [
        "Shrinks size while applying an activation function to things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl3ZM7Y68CPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertIntermediate(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertIntermediate, self).__init__()\n",
        "    self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
        "    self.activation_function = ACT2FN[config.hidden_act]\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.activation_function(hidden_states)\n",
        "    return hidden_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpACEfBW9jd8",
        "colab_type": "text"
      },
      "source": [
        "Applies final layer of normalisation etc just to make sure "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dFgHD6Q9dot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertOutput(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertOutput, self).__init__()\n",
        "    self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
        "    self.LayerNorm = BertLayerNorm(config.hidden_size, epsilon=1e-12)\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "  \n",
        "  def forward(self, hidden_states, input_tensor):\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.dropout(hidden_states)\n",
        "    hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
        "\n",
        "    return hidden_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVmioYI__9Ke",
        "colab_type": "text"
      },
      "source": [
        "Pipeline - at every given layer, feeds input to an attention model, through an intermediary reshape, and then an output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yWW9tUG_9vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLayer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertLayer, self).__init__()\n",
        "    self.attention = BertAttention(config)\n",
        "    self.intermediate = BertIntermediate(config)\n",
        "    self.output = BertOutput(config)\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask):\n",
        "    attention_output = self.attention(hidden_states, attention_mask)\n",
        "    intermediate_output = self.intermediate(attention_output)\n",
        "    final_output = self.output(intermediate_output, attention_output)\n",
        "    return final_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lHrphW2D1Ei",
        "colab_type": "text"
      },
      "source": [
        "Here's a collection of layers! very exciting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4zUJ9oCD47i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertEncoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertEncoder, self).__init__()\n",
        "    layer = BertLayer(config)\n",
        "    #we copy all the layers for as many as we've decided its great\n",
        "    self.layer = nn.ModuleList([copy.deepcopy(layer) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "  def forward(self, hidden_states, attention_mask, output_all_encoded_layers=True):\n",
        "    all_encoder_layers = []\n",
        "    for layer_module in self.layer:\n",
        "      hidden_states = layer_module(hidden_states, attention_mask)\n",
        "      #either get all encoded layers or just the last one :)\n",
        "      if output_all_encoded_layers:\n",
        "        all_encoder_layers.append(hidden_states)\n",
        "    if not output_all_encoded_layers:\n",
        "      all_encoder_layers.append(hidden_states)\n",
        "    return all_encoder_layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvks82rKE8gT",
        "colab_type": "text"
      },
      "source": [
        "A thing that basically spits out the hidden state of the first token\n",
        "for \"pooling purposes\"\n",
        "very curious"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ijH4U9PE8vB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertPooler(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertPooler, self).__init__()\n",
        "    self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "    self.activation = nn.Tanh()\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "    first_token = hidden_states[:, 0]\n",
        "    pooled_output = self.dense(first_token)\n",
        "    pooled_output = self.activation(pooled_output)\n",
        "    return pooled_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY9K2OM0NxPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PreTrainedBertModel(nn.Module):\n",
        "    \"\"\" An abstract class to handle weights initialization and\n",
        "        a simple interface for dowloading and loading pretrained models.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, *inputs, **kwargs):\n",
        "        super(PreTrainedBertModel, self).__init__()\n",
        "        if not isinstance(config, BertConfig):\n",
        "            raise ValueError(\n",
        "                \"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"\n",
        "                \"To create a model from a Google pretrained model use \"\n",
        "                \"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\".format(\n",
        "                    self.__class__.__name__, self.__class__.__name__\n",
        "                ))\n",
        "        self.config = config\n",
        "\n",
        "    def init_bert_weights(self, module):\n",
        "        \"\"\" Initialize the weights.\n",
        "        \"\"\"\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
        "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, BertLayerNorm):\n",
        "            module.bias.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, pretrained_model_name, state_dict=None, cache_dir=None, *inputs, **kwargs):\n",
        "        \"\"\"\n",
        "        Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.\n",
        "        Download and cache the pre-trained model file if needed.\n",
        "        Params:\n",
        "            pretrained_model_name: either:\n",
        "                - a str with the name of a pre-trained model to load selected in the list of:\n",
        "                    . `bert-base-uncased`\n",
        "                    . `bert-large-uncased`\n",
        "                    . `bert-base-cased`\n",
        "                    . `bert-base-multilingual`\n",
        "                    . `bert-base-chinese`\n",
        "                - a path or url to a pretrained model archive containing:\n",
        "                    . `bert_config.json` a configuration file for the model\n",
        "                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n",
        "            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n",
        "            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models\n",
        "            *inputs, **kwargs: additional input for the specific Bert class\n",
        "                (ex: num_labels for BertForSequenceClassification)\n",
        "        \"\"\"\n",
        "        if pretrained_model_name in PRETRAINED_MODEL_ARCHIVE_MAP:\n",
        "            archive_file = PRETRAINED_MODEL_ARCHIVE_MAP[pretrained_model_name]\n",
        "        else:\n",
        "            archive_file = pretrained_model_name\n",
        "        # redirect to the cache, if necessary\n",
        "        try:\n",
        "            resolved_archive_file = cached_path(archive_file, cache_dir=cache_dir)\n",
        "        except FileNotFoundError:\n",
        "            logger.error(\n",
        "                \"Model name '{}' was not found in model name list ({}). \"\n",
        "                \"We assumed '{}' was a path or url but couldn't find any file \"\n",
        "                \"associated to this path or url.\".format(\n",
        "                    pretrained_model_name,\n",
        "                    ', '.join(PRETRAINED_MODEL_ARCHIVE_MAP.keys()),\n",
        "                    archive_file))\n",
        "            return None\n",
        "        if resolved_archive_file == archive_file:\n",
        "            logger.info(\"loading archive file {}\".format(archive_file))\n",
        "        else:\n",
        "            logger.info(\"loading archive file {} from cache at {}\".format(\n",
        "                archive_file, resolved_archive_file))\n",
        "        tempdir = None\n",
        "        if os.path.isdir(resolved_archive_file):\n",
        "            serialization_dir = resolved_archive_file\n",
        "        else:\n",
        "            # Extract archive to temp dir\n",
        "            tempdir = tempfile.mkdtemp()\n",
        "            logger.info(\"extracting archive file {} to temp dir {}\".format(\n",
        "                resolved_archive_file, tempdir))\n",
        "            with tarfile.open(resolved_archive_file, 'r:gz') as archive:\n",
        "                archive.extractall(tempdir)\n",
        "            serialization_dir = tempdir\n",
        "        # Load config\n",
        "        config_file = os.path.join(serialization_dir, CONFIG_NAME)\n",
        "        config = BertConfig.from_json_file(config_file)\n",
        "        logger.info(\"Model config {}\".format(config))\n",
        "        # Instantiate model.\n",
        "        model = cls(config, *inputs, **kwargs)\n",
        "        if state_dict is None:\n",
        "            weights_path = os.path.join(serialization_dir, WEIGHTS_NAME)\n",
        "            state_dict = torch.load(weights_path)\n",
        "\n",
        "        old_keys = []\n",
        "        new_keys = []\n",
        "        for key in state_dict.keys():\n",
        "            new_key = None\n",
        "            if 'gamma' in key:\n",
        "                new_key = key.replace('gamma', 'weight')\n",
        "            if 'beta' in key:\n",
        "                new_key = key.replace('beta', 'bias')\n",
        "            if new_key:\n",
        "                old_keys.append(key)\n",
        "                new_keys.append(new_key)\n",
        "        for old_key, new_key in zip(old_keys, new_keys):\n",
        "            state_dict[new_key] = state_dict.pop(old_key)\n",
        "\n",
        "        missing_keys = []\n",
        "        unexpected_keys = []\n",
        "        error_msgs = []\n",
        "        # copy state_dict so _load_from_state_dict can modify it\n",
        "        metadata = getattr(state_dict, '_metadata', None)\n",
        "        state_dict = state_dict.copy()\n",
        "        if metadata is not None:\n",
        "            state_dict._metadata = metadata\n",
        "\n",
        "        def load(module, prefix=''):\n",
        "            local_metadata = {} if metadata is None else metadata.get(prefix[:-1], {})\n",
        "            module._load_from_state_dict(\n",
        "                state_dict, prefix, local_metadata, True, missing_keys, unexpected_keys, error_msgs)\n",
        "            for name, child in module._modules.items():\n",
        "                if child is not None:\n",
        "                    load(child, prefix + name + '.')\n",
        "        load(model, prefix='' if hasattr(model, 'bert') else 'bert.')\n",
        "        if len(missing_keys) > 0:\n",
        "            logger.info(\"Weights of {} not initialized from pretrained model: {}\".format(\n",
        "                model.__class__.__name__, missing_keys))\n",
        "        if len(unexpected_keys) > 0:\n",
        "            logger.info(\"Weights from pretrained model not used in {}: {}\".format(\n",
        "                model.__class__.__name__, unexpected_keys))\n",
        "        if tempdir:\n",
        "            # Clean up temp dir\n",
        "            shutil.rmtree(tempdir)\n",
        "        return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-sFi_SpYbHh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1jMlzBaTEi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertPredictionHeadTransform(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super(BertPredictionHeadTransform, self).__init__()\n",
        "    self.dense = nn.Linear(config.hidden_size, config_hidden_size)\n",
        "    self.transform_activation = ACT2FN[config.hidden_act]\n",
        "    self.LayerNorm = BertLayerNorm(config.hidden_size, epsilon=1e-12)\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "    hidden_states = self.dense(hidden_states)\n",
        "    hidden_states = self.transform_activation(hidden_states)\n",
        "    hidden states = self.LayerNorm(hidden_states)\n",
        "    return hidden_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Miq3FqJcST56",
        "colab_type": "text"
      },
      "source": [
        "A \"Head\" that takes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSMIpGO2SUT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertLMPredictionHead(nn.Module):\n",
        "  def __init__(self, config, bert_model_embedding_weights):\n",
        "    super(BertLMPredictionHead, self).__init__()\n",
        "    self.transform = BertPredictionHeadTransform(config)\n",
        "\n",
        "    self.decoder = nn.Linear(bert_model_embedding_weights.size(1),\n",
        "                             bert_model_embedding_weights.size(0),\n",
        "                             bias=False)\n",
        "    self.decoder.weight = bert_model_embedding_weights\n",
        "    self.bias = nn.Parameter(torch.zeros(bert_model_embedding_weights.size(0)))\n",
        "\n",
        "  def forward(self, hidden_states):\n",
        "    hidden_states = self.transform(hidden_states)\n",
        "    hidden_states = self.decoder(hidden_states)\n",
        "    return hidden_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEN0_iO0R7KP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqsnbbiqR67e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertPreTrainingHeads(nn.Module):\n",
        "  def __init__(self, config, bert_model_embedding_weights):\n",
        "    super(BertPreTrainingHeads, self).__init__()\n",
        "    self.predictions = BertLMPredictionHead(config, bert_model_embedding_weights)\n",
        "    self.seq_relationship = nn.Linear(config.hidden_size, 2)\n",
        "\n",
        "  def forward(self, sequence_output, pooled_output):\n",
        "    prediction_scores = self.predictions(sequence_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMG-9wofOnr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertForSequenceClassification(PreTrainedBertModel):\n",
        "  def __init__(self, config, num_labels=2):\n",
        "    super(BertForSequenceClassification, self).__init__(config)\n",
        "    self.num_labels = num_labels\n",
        "    self.bert = BertModel(config)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-skRc_EBRhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluation_summary(description, predictions, true_labels):\n",
        "  print(\"Evaluation for: \" + description)\n",
        "  precision = precision_score(predictions, true_labels, average='macro')\n",
        "  recall = recall_score(predictions, true_labels, average='macro')\n",
        "  accuracy = accuracy_score(predictions, true_labels)\n",
        "  f1 = fbeta_score(predictions, true_labels, 1, average='macro') #1 means f_1 measure\n",
        "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f F1=%0.3f\" % (description,accuracy,precision,recall,f1))\n",
        "  print(classification_report(predictions, true_labels, digits=3))\n",
        "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions))\n",
        "  return precision,recall,accuracy,f1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-UHhzD-H_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from inspect import signature\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "def l2_matrix_norm(m):\n",
        "  return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)\n",
        "\n",
        "\n",
        "def load_data(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i] = Variable(data[i]).cuda()\n",
        "  return data\n",
        "\n",
        "def free_data(data):\n",
        "  for point in data:\n",
        "    del(point)\n",
        "def check_data(loader, model):\n",
        "  sample_data = loader.dataset[0]\n",
        "  print(torch.max(loader.dataset[:][-1]))\n",
        "  model_params = len(signature(model).parameters)\n",
        "  return len(sample_data) - 1 != model_params \n",
        "\n",
        "def train(model=None, \n",
        "          train_loader=None, \n",
        "          loss_function=None, \n",
        "          optimiser=None, \n",
        "          hp=None, \n",
        "          using_gradient_clipping=False):\n",
        "  \n",
        "  model.reset_for_testing(train_loader.batch_size)\n",
        "  model.train()\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  is_binary = hp.num_classes == 1\n",
        "  \n",
        "  if train_loader.name == \"entailment_data\" and hp.num_classes != 3:\n",
        "      raise ValueError(\"Three classes are needed for entailment to safely happen\")\n",
        "  elif train_loader.name == \"fact_data\" and hp.num_classes !=1:\n",
        "      raise ValueError(\"Two classes are needed for fact checking to safely happen\")\n",
        "\n",
        "  for epoch in range(hp.epochs):\n",
        "    print(\"Running EPOCH:\",epoch+1)\n",
        "    total_loss = 0\n",
        "    batch_count = 0\n",
        "    correct = 0\n",
        "    penal = 0\n",
        "    for batch_index, train_data in enumerate(train_loader):\n",
        "      #setting everything up\n",
        "      model.hidden_state = model.init_hidden()\n",
        "      train_data = load_data(train_data)\n",
        "      \n",
        "      #get y values - do forward pass and process\n",
        "      predicted_y, attention = model(*train_data[:-1])\n",
        "      actual_y = train_data[-1]\n",
        "      squeezed_y = predicted_y.double().squeeze(1)\n",
        "\n",
        "      #handling regularisation\n",
        "      if hp.C > 0:\n",
        "        attentionT = attention.transpose(1,2)\n",
        "        identity = torch.eye(attention.size(1))\n",
        "        identity = Variable(identity.unsqueeze(0).expand(train_loader.batch_size,\n",
        "                                                         attention.size(1),\n",
        "                                                         attention.size(1))).cuda()\n",
        "        penal = l2_matrix_norm(attention@attentionT - identity).cuda()\n",
        "\n",
        "      #get loss, accuracy\n",
        "      if is_binary:\n",
        "        loss = loss_function(squeezed_y, actual_y.double())\n",
        "        loss += hp.C * penal/train_loader.batch_size\n",
        "        correct += torch.eq(torch.round(squeezed_y), actual_y).data.sum()\n",
        "      else:\n",
        "        loss = loss_function(squeezed_y,actual_y.long()) + hp.C * (penal/train_loader.batch_size)\n",
        "        correct += torch.eq(torch.argmax(squeezed_y, 1), actual_y).data.sum()\n",
        "      total_loss += loss.data\n",
        "\n",
        "      #cleaning up regularisation\n",
        "      if hp.C > 0:\n",
        "        del(penal)\n",
        "        del(identity)\n",
        "        del(attentionT)\n",
        "      #woah we gotta do this to do backprop!!!\n",
        "      optimiser.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      if hp.is_debug and batch_index % 10 == 0:\n",
        "        print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "            epoch, batch_index * len(train_data[0]), len(train_loader.dataset),\n",
        "            100. * batch_index / len(train_loader), loss.item()\n",
        "        ))\n",
        "\n",
        "      if using_gradient_clipping:\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.5)\n",
        "      batch_count += 1\n",
        "      optimiser.step()\n",
        "      free_data(train_data)\n",
        "\n",
        "    print(\"Average loss is:\",total_loss/batch_count)\n",
        "    correct_but_numpy = correct.data.cpu().numpy().astype(int)\n",
        "    accuracy = correct_but_numpy / float(batch_count * train_loader.batch_size)\n",
        "    print(\"Accuracy of the model\", accuracy)\n",
        "    losses.append(total_loss/batch_count)\n",
        "    accuracies.append(accuracy)\n",
        "  return losses, accuracies\n",
        "\n",
        "def evaluate(model, test_premise, test_hypothesis, test_y):\n",
        "\n",
        "  model.hp.batch_size = test_hypothesis.shape[0] #why\n",
        "  model.initial_hidden_state = model.init_hidden()\n",
        "\n",
        "  premise_variable = Variable(torch.from_numpy(test_premise).type(torch.LongTensor)).cuda()\n",
        "  hypothesis_variable = Variable(torch.from_numpy(test_hypothesis).type(torch.LongTensor)).cuda()\n",
        "  y_actual_variable = Variable(torch.from_numpy(test_y).type(torch.DoubleTensor)).cuda()\n",
        "  y_predicted = model(premise_variable, hypothesis_variable)\n",
        "  y_predicted_rounded = torch.round(y_predicted.type(torch.DoubleTensor).squeeze(1))\n",
        "\n",
        "  test_data_count = premise_variable.size(0)\n",
        "\n",
        "\n",
        "\n",
        "  total_accuracy = torch.eq(torch.argmax(y_predicted,1), y_actual_variable).data.sum()\n",
        "  average_accuracy = total_accuracy.data.cpu().numpy().astype(int)/float(test_data_count)\n",
        "  return average_accuracy, torch.argmax(y_predicted,1)\n",
        "\n",
        "\n",
        "def batch_wise_evaluate(model, test_loader, hp):\n",
        "  batch_count = 0\n",
        "  total_accuracy = 0\n",
        "  all_results = []\n",
        "  model.eval()\n",
        "  is_binary = hp.num_classes == 1\n",
        "  with torch.no_grad():\n",
        "    for batch_index, test_data in enumerate(test_loader):\n",
        "      #reset everything\n",
        "      model.reset_for_testing(test_data[0].shape[0])\n",
        "      test_data = load_data(test_data)\n",
        "    \n",
        "      #get ys from model and data\n",
        "      y_predicted, _ = model(*test_data[:-1])\n",
        "      y_actual = test_data[-1]\n",
        "      y_squeezed = y_predicted.double().squeeze(1)\n",
        "\n",
        "      #get accuracy\n",
        "      if is_binary:\n",
        "        total_accuracy += torch.eq(torch.round(y_squeezed), y_actual).data.sum()\n",
        "        all_results.append(torch.round(y_squeezed))\n",
        "\n",
        "      else: \n",
        "        total_accuracy += torch.eq(torch.argmax(y_squeezed,1), y_actual).data.sum()\n",
        "        all_results.append(torch.argmax(y_squeezed, 1))\n",
        "\n",
        "      batch_count += 1\n",
        "    \n",
        "  average_accuracy = total_accuracy.data.cpu().numpy()/float(batch_count * test_loader.batch_size)\n",
        "  return average_accuracy, torch.cat(all_results, 0)\n",
        "\n",
        "def plot_stuff(epochs, losses, accuracies=None, title=\"sup nerds\"):\n",
        "\n",
        "  fig = plt.figure()\n",
        "  if accuracies:\n",
        "    plt.plot(range(1, epochs+1), accuracies, scalex=True, scaley=True, label=\"Accuracy\")\n",
        "    plt.annotate(str(accuracies[-1]), xy=(epochs,accuracies[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "\n",
        "  plt.plot(range(1, epochs+1), losses,scalex=True, scaley=True, label=\"Loss\")\n",
        "  plt.annotate(str(losses[-1]), xy=(epochs,losses[-1]), xytext=(3, 3),textcoords=\"offset points\")\n",
        "  plt.legend()\n",
        "  plt.xlabel(\"Epochs\", fontsize=16)\n",
        "  plt.ylabel(\"Amount\", fontsize=16)\n",
        "  plt.title(title)\n",
        "  \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ai-rCghJy-2",
        "colab_type": "text"
      },
      "source": [
        "OK WE MADE THE HELPERS LETS RUN THIS SHIT :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU2rJspTahqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Hyperparameters:\n",
        "  lstm_hidden_size = 150\n",
        "  dense_dimension = 300\n",
        "  attention_hops = 30\n",
        "  batch_size = BATCH_SIZE\n",
        "  max_length = MAX_LENGTH\n",
        "  gravity = 450\n",
        "  num_classes = 1\n",
        "  epochs = 6\n",
        "  C = 0.3\n",
        "  is_debug = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBH1XvNkpdl",
        "colab_type": "code",
        "outputId": "a82cb8d6-bbd3-4829-98ed-40075011201e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "glove_embeddings = load_glove_embeddings(\"glove.6B.300d.txt\",x_tokeniser.word_to_id,300)\n",
        "print(glove_embeddings.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34370\n",
            "torch.Size([34370, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2R9PS64QS5",
        "colab_type": "code",
        "outputId": "83292a73-96fd-431f-f1ea-b42f80300df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" \n",
        "\n",
        "textual_entailment_model = None\n",
        "if(textual_entailment_model):\n",
        "  del(textual_entailment_model)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "textual_entailment_model = TextualEntailmentModel(Hyperparameters, glove_embeddings).cuda()\n",
        "#textual_entailment_model.to(device)\n",
        "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
        "bce_loss = torch.nn.BCELoss()\n",
        "rms_optimiser = torch.optim.Adagrad(textual_entailment_model.parameters(), \n",
        "                                    lr=0.01)\n",
        "\n",
        "loss, accuracy = train(model=textual_entailment_model,\n",
        "                       train_loader=train_snopes_loader,\n",
        "                       loss_function=bce_loss,\n",
        "                       optimiser = rms_optimiser,\n",
        "                       hp = Hyperparameters,\n",
        "                       using_gradient_clipping=True)\n",
        "\n",
        "print(torch.cuda.memory_allocated)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running EPOCH: 1\n",
            "Train Epoch: 0 [0/6484 (0%)]\tLoss: 2.313532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [2560/6484 (40%)]\tLoss: 4.665306\n",
            "Train Epoch: 0 [5120/6484 (80%)]\tLoss: 7.011110\n",
            "Average loss is: tensor(7.2695, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.77390625\n",
            "Running EPOCH: 2\n",
            "Train Epoch: 1 [0/6484 (0%)]\tLoss: 10.897703\n",
            "Train Epoch: 1 [2560/6484 (40%)]\tLoss: 4.612847\n",
            "Train Epoch: 1 [5120/6484 (80%)]\tLoss: 6.984265\n",
            "Average loss is: tensor(7.8433, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.77390625\n",
            "Running EPOCH: 3\n",
            "Train Epoch: 2 [0/6484 (0%)]\tLoss: 10.869830\n",
            "Train Epoch: 2 [2560/6484 (40%)]\tLoss: 4.609650\n",
            "Train Epoch: 2 [5120/6484 (80%)]\tLoss: 6.984197\n",
            "Average loss is: tensor(7.8348, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.77390625\n",
            "Running EPOCH: 4\n",
            "Train Epoch: 3 [0/6484 (0%)]\tLoss: 10.869853\n",
            "Train Epoch: 3 [2560/6484 (40%)]\tLoss: 4.609627\n",
            "Train Epoch: 3 [5120/6484 (80%)]\tLoss: 6.984158\n",
            "Average loss is: tensor(7.8347, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.77390625\n",
            "Running EPOCH: 5\n",
            "Train Epoch: 4 [0/6484 (0%)]\tLoss: 10.869792\n",
            "Train Epoch: 4 [2560/6484 (40%)]\tLoss: 4.609620\n",
            "Train Epoch: 4 [5120/6484 (80%)]\tLoss: 6.984152\n",
            "Average loss is: tensor(7.8347, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.77390625\n",
            "Running EPOCH: 6\n",
            "Train Epoch: 5 [0/6484 (0%)]\tLoss: 10.869777\n",
            "Train Epoch: 5 [2560/6484 (40%)]\tLoss: 4.609616\n",
            "Train Epoch: 5 [5120/6484 (80%)]\tLoss: 6.984149\n",
            "Average loss is: tensor(7.8347, device='cuda:0', dtype=torch.float64)\n",
            "Accuracy of the model 0.77390625\n",
            "<function memory_allocated at 0x7fceb86d49d8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvG0N3VwyiwV",
        "colab_type": "code",
        "outputId": "c72e574c-7886-4ca2-b8c4-b2f145fa6469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot_stuff(Hyperparameters.epochs, loss, accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAEbCAYAAABEAYkUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM8sJJ35mZmZmOeHEz8zMzCwn/j++DAe72pIrxQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcOuT8wWW7X",
        "colab_type": "code",
        "outputId": "917dfd09-a027-4247-d3b5-c2929cdfb4e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "accuracy, predicted_ys = batch_wise_evaluate(textual_entailment_model, \n",
        "         test_snopes_loader,\n",
        "         Hyperparameters)\n",
        "print(predicted_ys.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1516])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNM29gWaAhWz",
        "colab_type": "code",
        "outputId": "8042117c-f0bd-4388-ecc0-593ea54ba177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "print(accuracy)\n",
        "evaluation_summary(\"textual entailment model\", predicted_ys.cpu(), y_snopes_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7109375\n",
            "Evaluation for: textual entailment model\n",
            "Classifier 'textual entailment model' has Acc=0.720 P=0.500 R=0.360 F1=0.419\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      1.000     0.720     0.837      1516\n",
            "         1.0      0.000     0.000     0.000         0\n",
            "\n",
            "    accuracy                          0.720      1516\n",
            "   macro avg      0.500     0.360     0.419      1516\n",
            "weighted avg      1.000     0.720     0.837      1516\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[1092    0]\n",
            " [ 424    0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.36015831134564646, 0.7203166226912929, 0.4187116564417178)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9tLOcRYOc9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}